
import os
os.environ['PYTORCH_KERNEL_CACHE_PATH'] = '/mnt/mffuse/.cache/torch/kernels'
os.environ['TORCH_DISABLE_ADDR2LINE'] = '1'
os.environ['TORCH_TRACE'] = '/mnt/mffuse/outputs/sfsdp-dsv3-16b--tp1-bs2-inductor-128-ivankobzarev-hkpmbjc3/torch_trace/'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
os.environ['TORCHELASTIC_LOG_LINE_PREFIX_TEMPLATE'] = '[${role_name}${rank}|${local_rank}]:'
os.environ['TORCHELASTIC_MAX_RESTARTS'] = '0'
os.environ['TORCHX_INTERNAL_SESSION_ID'] = '03a200cc-023c-47d4-8372-8d223aedc5c2'
os.environ['TORCHX_RUN_PYTHONPATH'] = ''
os.environ['TORCHELASTIC_ERROR_FILE'] = '/tmp/torchelastic_i226b1gg/sfsdp-dsv3-16b--tp1-bs2-inductor-128-ivankobzarev-hkpmbjc3_ukylfuu9/attempt_0/0/error.json'
os.environ['TORCH_ADDR2LINE_BINARY'] = '/packages/folly.symbolizer/folly-addr2line'
os.environ['TORCHX_JOB_ID'] = 'mast_conda://torchx/sfsdp-dsv3-16b--tp1-bs2-inductor-128-ivankobzarev-hkpmbjc3'
os.environ['TORCH_NCCL_ASYNC_ERROR_HANDLING'] = '3'
os.environ['TORCHELASTIC_SIGNALS_TO_HANDLE'] = 'SIGTERM,SIGINT,SIGHUP,SIGQUIT'
os.environ['TORCHELASTIC_RUN_ID'] = 'sfsdp-dsv3-16b--tp1-bs2-inductor-128-ivankobzarev-hkpmbjc3'
os.environ['TORCH_SHOW_CPP_STACKTRACES'] = '1'
os.environ['TORCHELASTIC_RESTART_COUNT'] = '0'
os.environ['TORCHELASTIC_USE_AGENT_STORE'] = 'False'
os.environ['PYTORCH_DDP_USE_SIDE_STREAM'] = '0'
os.environ['TORCHINDUCTOR_CACHE_DIR'] = '/tmp/torchinductor_root'
os.environ['TORCH_FR_BUFFER_SIZE'] = '20000'
os.environ['TORCH_NCCL_DUMP_ON_TIMEOUT'] = '1'
os.environ['TORCH_FR_DUMP_TEMP_FILE'] = '/mnt/mffuse_nccl_trace/nccl_trace/sfsdp-dsv3-16b--tp1-bs2-inductor-128-ivankobzarev-hkpmbjc3/v_0/attempt_0/nccl_trace_rank_'
os.environ['TRITON_CACHE_DIR'] = '/tmp/torchinductor_root/triton/0'

import torch
from torch import tensor, device
import torch.fx as fx
from torch._dynamo.testing import rand_strided
from math import inf
import torch._inductor.inductor_prims
import torch.distributed as dist
from torch.testing._internal.distributed.fake_pg import FakeStore
import triton
import triton.language as tl

import torch._dynamo.config
import torch._inductor.config
import torch._functorch.config
import torch.fx.experimental._config
torch._dynamo.config.capture_scalar_outputs = True
torch._inductor.config.allow_buffer_reuse = False
torch._inductor.config.reorder_for_compute_comm_overlap = False
torch._inductor.config.reorder_for_peak_memory = False
torch._inductor.config.max_autotune = False
torch._inductor.config.coordinate_descent_tuning = False
torch._inductor.config.deterministic = False
torch._inductor.config.aten_distributed_optimizations.collective_bucketing = True
torch._inductor.config.aten_distributed_optimizations.insert_overlap_deps = True
torch._inductor.config.wrap_inductor_compiled_regions = False
torch._inductor.config.triton.cudagraphs = False
torch._inductor.config.triton.store_cubin = False
torch._inductor.config.test_configs.runtime_triton_dtype_assert = False
torch._functorch.config.functionalize_rng_ops = False
torch._functorch.config.fake_tensor_allow_unsafe_data_ptr_access = True
torch._functorch.config.unlift_effect_tokens = True
torch._functorch.config.selective_decompose = False



isolate_fails_code_str = None





if "__compile_source__" in globals():
    import inspect as __after_aot_inspect
    import linecache as __after_aot_linecache
    __after_aot_filename = __after_aot_inspect.currentframe().f_code.co_filename
    __after_aot_linecache.cache[__after_aot_filename] = (
        len(__compile_source__),
        None,
        __compile_source__.splitlines(True),
        __after_aot_filename,
    )
# torch version: 2.11.0a0+git5ac4d4b
# torch cuda version: 12.4
# torch git version: 5ac4d4bf3f85e15fdd6676f46b090568ea91e47e


# CUDA Info: 
# nvcc not found
# GPU Hardware Info: 
# NVIDIA H100 80GB HBM3 : 8 

torch._higher_order_ops.triton_kernel_wrap.kernel_side_table.reset_table()

@triton.jit
def _fill_indices_kernel_0(
    tokens_per_expert_group_ptr,
    start_index_values_ptr,
    write_offsets_ptr,
    output_ptr,
    experts_per_rank: tl.constexpr,
    num_ranks: tl.constexpr,
    BLOCK_SIZE: tl.constexpr,  # Number of threads per block
):
    pid = tl.program_id(axis=0)
    num_programs = tl.num_programs(axis=0)

    # map programs (blocks) to the experts and loop (grid stride) if needed
    for expert_id in range(pid, experts_per_rank, num_programs):
        # read this experts write offset
        write_offset = tl.load(write_offsets_ptr + expert_id)

        for r in range(num_ranks):
            # index into tokens_per_expert_group array
            i = r * experts_per_rank + expert_id

            # load start index and number of tokens for this expert-rank pair
            start_index = tl.load(start_index_values_ptr + i)
            length = tl.load(tokens_per_expert_group_ptr + i)

            # each thread in block processes tokens in parallel
            offsets = tl.arange(0, BLOCK_SIZE)

            # tokens are processed in chunks of BLOCK_SIZE
            for chunk_start in range(0, length, BLOCK_SIZE):
                chunk_offsets = chunk_start + offsets

                # mask valid indices
                mask = chunk_offsets < length

                values = start_index + chunk_offsets

                # destination
                dest_indices = write_offset + chunk_offsets

                # store
                tl.store(output_ptr + dest_indices, values, mask=mask)

            # update write offset for next rank
            write_offset += length

torch._higher_order_ops.triton_kernel_wrap.kernel_side_table.add_kernel(_fill_indices_kernel_0)
torch._higher_order_ops.triton_kernel_wrap.kernel_side_table.constant_args={0: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 1: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 2: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 3: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 4: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 5: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 6: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 7: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 8: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 9: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 10: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 11: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 12: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 13: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 14: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 15: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 16: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 17: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 18: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 19: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 20: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 21: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 22: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 23: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 24: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 25: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}}

from torch.nn import *
# Stub for submodules referenced in backward graph
class GraphModule(torch.nn.Module):
    def __init__(self):
        super().__init__()
    def forward(self, *args, **kwargs):
        pass
class Repro(torch.nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.fw_graph0 = GraphModule()
        self.joint_graph0 = GraphModule()
        self.mask_graph0 = GraphModule()
        self.fw_graph1 = GraphModule()
        self.joint_graph1 = GraphModule()
        self.mask_graph1 = GraphModule()
        self.fw_graph2 = GraphModule()
        self.joint_graph2 = GraphModule()
        self.mask_graph2 = GraphModule()
        self.fw_graph3 = GraphModule()
        self.joint_graph3 = GraphModule()
        self.mask_graph3 = GraphModule()
        self.fw_graph4 = GraphModule()
        self.joint_graph4 = GraphModule()
        self.mask_graph4 = GraphModule()
        self.fw_graph5 = GraphModule()
        self.joint_graph5 = GraphModule()
        self.mask_graph5 = GraphModule()
        self.fw_graph6 = GraphModule()
        self.joint_graph6 = GraphModule()
        self.mask_graph6 = GraphModule()
        self.fw_graph7 = GraphModule()
        self.joint_graph7 = GraphModule()
        self.mask_graph7 = GraphModule()
        self.fw_graph8 = GraphModule()
        self.joint_graph8 = GraphModule()
        self.mask_graph8 = GraphModule()
        self.fw_graph9 = GraphModule()
        self.joint_graph9 = GraphModule()
        self.mask_graph9 = GraphModule()
        self.fw_graph10 = GraphModule()
        self.joint_graph10 = GraphModule()
        self.mask_graph10 = GraphModule()
        self.fw_graph11 = GraphModule()
        self.joint_graph11 = GraphModule()
        self.mask_graph11 = GraphModule()
        self.fw_graph12 = GraphModule()
        self.joint_graph12 = GraphModule()
        self.mask_graph12 = GraphModule()
        self.fw_graph13 = GraphModule()
        self.joint_graph13 = GraphModule()
        self.mask_graph13 = GraphModule()
        self.fw_graph14 = GraphModule()
        self.joint_graph14 = GraphModule()
        self.mask_graph14 = GraphModule()
        self.fw_graph15 = GraphModule()
        self.joint_graph15 = GraphModule()
        self.mask_graph15 = GraphModule()
        self.fw_graph16 = GraphModule()
        self.joint_graph16 = GraphModule()
        self.mask_graph16 = GraphModule()
        self.fw_graph17 = GraphModule()
        self.joint_graph17 = GraphModule()
        self.mask_graph17 = GraphModule()
        self.fw_graph18 = GraphModule()
        self.joint_graph18 = GraphModule()
        self.mask_graph18 = GraphModule()
        self.fw_graph19 = GraphModule()
        self.joint_graph19 = GraphModule()
        self.mask_graph19 = GraphModule()
        self.fw_graph20 = GraphModule()
        self.joint_graph20 = GraphModule()
        self.mask_graph20 = GraphModule()
        self.fw_graph21 = GraphModule()
        self.joint_graph21 = GraphModule()
        self.mask_graph21 = GraphModule()
        self.fw_graph22 = GraphModule()
        self.joint_graph22 = GraphModule()
        self.mask_graph22 = GraphModule()
        self.fw_graph23 = GraphModule()
        self.joint_graph23 = GraphModule()
        self.mask_graph23 = GraphModule()
        self.fw_graph24 = GraphModule()
        self.joint_graph24 = GraphModule()
        self.mask_graph24 = GraphModule()
        self.fw_graph25 = GraphModule()
        self.joint_graph25 = GraphModule()
        self.mask_graph25 = GraphModule()
        self.fw_graph26 = GraphModule()
        self.joint_graph26 = GraphModule()
        self.mask_graph26 = GraphModule()



    def forward(self, _local_scalar_dense, _local_scalar_dense_1, _local_scalar_dense_2, _local_scalar_dense_3, _local_scalar_dense_4, _local_scalar_dense_5, _local_scalar_dense_6, _local_scalar_dense_7, _local_scalar_dense_8, _local_scalar_dense_9, _local_scalar_dense_10, _local_scalar_dense_11, _local_scalar_dense_12, _local_scalar_dense_13, _local_scalar_dense_14, _local_scalar_dense_15, _local_scalar_dense_16, _local_scalar_dense_17, _local_scalar_dense_18, _local_scalar_dense_19, _local_scalar_dense_20, _local_scalar_dense_21, _local_scalar_dense_22, _local_scalar_dense_23, _local_scalar_dense_24, _local_scalar_dense_25, _local_scalar_dense_26, _local_scalar_dense_27, _local_scalar_dense_28, _local_scalar_dense_29, _local_scalar_dense_30, _local_scalar_dense_31, _local_scalar_dense_32, _local_scalar_dense_33, _local_scalar_dense_34, _local_scalar_dense_35, _local_scalar_dense_36, _local_scalar_dense_37, _local_scalar_dense_38, _local_scalar_dense_39, _local_scalar_dense_40, _local_scalar_dense_41, _local_scalar_dense_42, _local_scalar_dense_43, _local_scalar_dense_44, _local_scalar_dense_45, _local_scalar_dense_46, _local_scalar_dense_47, _local_scalar_dense_48, _local_scalar_dense_49, _local_scalar_dense_50, _local_scalar_dense_51, _local_scalar_dense_52, _local_scalar_dense_53, _local_scalar_dense_54, _local_scalar_dense_55, _local_scalar_dense_56, _local_scalar_dense_57, _local_scalar_dense_58, _local_scalar_dense_59, _local_scalar_dense_60, _local_scalar_dense_61, _local_scalar_dense_62, _local_scalar_dense_63, _local_scalar_dense_64, _local_scalar_dense_65, _local_scalar_dense_66, _local_scalar_dense_67, _local_scalar_dense_68, _local_scalar_dense_69, _local_scalar_dense_70, _local_scalar_dense_71, _local_scalar_dense_72, _local_scalar_dense_73, _local_scalar_dense_74, _local_scalar_dense_75, _local_scalar_dense_76, _local_scalar_dense_77, _local_scalar_dense_78, _local_scalar_dense_79, _local_scalar_dense_80, _local_scalar_dense_81, _local_scalar_dense_82, _local_scalar_dense_83, _local_scalar_dense_84, _local_scalar_dense_85, _local_scalar_dense_86, _local_scalar_dense_87, _local_scalar_dense_88, _local_scalar_dense_89, _local_scalar_dense_90, _local_scalar_dense_91, _local_scalar_dense_92, _local_scalar_dense_93, _local_scalar_dense_94, _local_scalar_dense_95, _local_scalar_dense_96, _local_scalar_dense_97, _local_scalar_dense_98, _local_scalar_dense_99, _local_scalar_dense_100, _local_scalar_dense_101, _local_scalar_dense_102, _local_scalar_dense_103, _local_scalar_dense_104, _local_scalar_dense_105, _local_scalar_dense_106, _local_scalar_dense_107, _local_scalar_dense_108, _local_scalar_dense_109, _local_scalar_dense_110, _local_scalar_dense_111, _local_scalar_dense_112, _local_scalar_dense_113, _local_scalar_dense_114, _local_scalar_dense_115, _local_scalar_dense_116, _local_scalar_dense_117, _local_scalar_dense_118, _local_scalar_dense_119, _local_scalar_dense_120, _local_scalar_dense_121, _local_scalar_dense_122, _local_scalar_dense_123, _local_scalar_dense_124, _local_scalar_dense_125, _local_scalar_dense_126, _local_scalar_dense_127, _local_scalar_dense_128, _local_scalar_dense_129, _local_scalar_dense_130, _local_scalar_dense_131, _local_scalar_dense_132, _local_scalar_dense_133, _local_scalar_dense_134, _local_scalar_dense_135, _local_scalar_dense_136, _local_scalar_dense_137, _local_scalar_dense_138, _local_scalar_dense_139, _local_scalar_dense_140, _local_scalar_dense_141, _local_scalar_dense_142, _local_scalar_dense_143, _local_scalar_dense_144, _local_scalar_dense_145, _local_scalar_dense_146, _local_scalar_dense_147, _local_scalar_dense_148, _local_scalar_dense_149, _local_scalar_dense_150, _local_scalar_dense_151, _local_scalar_dense_152, _local_scalar_dense_153, _local_scalar_dense_154, _local_scalar_dense_155, _local_scalar_dense_156, _local_scalar_dense_157, _local_scalar_dense_158, _local_scalar_dense_159, _local_scalar_dense_160, _local_scalar_dense_161, _local_scalar_dense_162, _local_scalar_dense_163, _local_scalar_dense_164, _local_scalar_dense_165, _local_scalar_dense_166, _local_scalar_dense_167, _local_scalar_dense_168, _local_scalar_dense_169, _local_scalar_dense_170, _local_scalar_dense_171, _local_scalar_dense_172, _local_scalar_dense_173, _local_scalar_dense_174, _local_scalar_dense_175, _local_scalar_dense_176, _local_scalar_dense_177, _local_scalar_dense_178, _local_scalar_dense_179, _local_scalar_dense_180, _local_scalar_dense_181, _local_scalar_dense_182, _local_scalar_dense_183, _local_scalar_dense_184, _local_scalar_dense_185, _local_scalar_dense_186, _local_scalar_dense_187, _local_scalar_dense_188, _local_scalar_dense_189, _local_scalar_dense_190, _local_scalar_dense_191, _local_scalar_dense_192, _local_scalar_dense_193, _local_scalar_dense_194, _local_scalar_dense_195, _local_scalar_dense_196, _local_scalar_dense_197, _local_scalar_dense_198, _local_scalar_dense_199, _local_scalar_dense_200, _local_scalar_dense_201, _local_scalar_dense_202, _local_scalar_dense_203, _local_scalar_dense_204, _local_scalar_dense_205, _local_scalar_dense_206, _local_scalar_dense_207, _local_scalar_dense_208, _local_scalar_dense_209, _local_scalar_dense_210, _local_scalar_dense_211, _local_scalar_dense_212, _local_scalar_dense_213, _local_scalar_dense_214, _local_scalar_dense_215, _local_scalar_dense_216, _local_scalar_dense_217, _local_scalar_dense_218, _local_scalar_dense_219, _local_scalar_dense_220, _local_scalar_dense_221, _local_scalar_dense_222, _local_scalar_dense_223, _local_scalar_dense_224, _local_scalar_dense_225, _local_scalar_dense_226, _local_scalar_dense_227, _local_scalar_dense_228, _local_scalar_dense_229, _local_scalar_dense_230, _local_scalar_dense_231, _local_scalar_dense_232, _local_scalar_dense_233, _local_scalar_dense_234, _local_scalar_dense_235, _local_scalar_dense_236, _local_scalar_dense_237, _local_scalar_dense_238, _local_scalar_dense_239, _local_scalar_dense_240, _local_scalar_dense_241, _local_scalar_dense_242, _local_scalar_dense_243, _local_scalar_dense_244, _local_scalar_dense_245, _local_scalar_dense_246, _local_scalar_dense_247, _local_scalar_dense_248, _local_scalar_dense_249, _local_scalar_dense_250, _local_scalar_dense_251, _local_scalar_dense_252, _local_scalar_dense_253, _local_scalar_dense_254, _local_scalar_dense_255, _local_scalar_dense_256, _local_scalar_dense_257, _local_scalar_dense_258, _local_scalar_dense_259, _local_scalar_dense_260, _local_scalar_dense_261, _local_scalar_dense_262, _local_scalar_dense_263, _local_scalar_dense_264, _local_scalar_dense_265, _local_scalar_dense_266, _local_scalar_dense_267, _local_scalar_dense_268, _local_scalar_dense_269, _local_scalar_dense_270, _local_scalar_dense_271, _local_scalar_dense_272, _local_scalar_dense_273, _local_scalar_dense_274, _local_scalar_dense_275, _local_scalar_dense_276, _local_scalar_dense_277, _local_scalar_dense_278, _local_scalar_dense_279, _local_scalar_dense_280, _local_scalar_dense_281, _local_scalar_dense_282, _local_scalar_dense_283, _local_scalar_dense_284, _local_scalar_dense_285, _local_scalar_dense_286, _local_scalar_dense_287, _local_scalar_dense_288, _local_scalar_dense_289, _local_scalar_dense_290, _local_scalar_dense_291, _local_scalar_dense_292, _local_scalar_dense_293, _local_scalar_dense_294, _local_scalar_dense_295, _local_scalar_dense_296, _local_scalar_dense_297, _local_scalar_dense_298, _local_scalar_dense_299, _local_scalar_dense_300, _local_scalar_dense_301, _local_scalar_dense_302, _local_scalar_dense_303, _local_scalar_dense_304, _local_scalar_dense_305, _local_scalar_dense_306, _local_scalar_dense_307, _local_scalar_dense_308, _local_scalar_dense_309, _local_scalar_dense_310, _local_scalar_dense_311, _local_scalar_dense_312, _local_scalar_dense_313, _local_scalar_dense_314, _local_scalar_dense_315, _local_scalar_dense_316, _local_scalar_dense_317, _local_scalar_dense_318, _local_scalar_dense_319, _local_scalar_dense_320, _local_scalar_dense_321, _local_scalar_dense_322, _local_scalar_dense_323, _local_scalar_dense_324, _local_scalar_dense_325, _local_scalar_dense_326, _local_scalar_dense_327, _local_scalar_dense_328, _local_scalar_dense_329, _local_scalar_dense_330, _local_scalar_dense_331, _local_scalar_dense_332, _local_scalar_dense_333, _local_scalar_dense_334, _local_scalar_dense_335, _local_scalar_dense_336, _local_scalar_dense_337, _local_scalar_dense_338, _local_scalar_dense_339, _local_scalar_dense_340, _local_scalar_dense_341, _local_scalar_dense_342, _local_scalar_dense_343, _local_scalar_dense_344, _local_scalar_dense_345, _local_scalar_dense_346, _local_scalar_dense_347, _local_scalar_dense_348, _local_scalar_dense_349, _local_scalar_dense_350, _local_scalar_dense_351, _local_scalar_dense_352, _local_scalar_dense_353, _local_scalar_dense_354, _local_scalar_dense_355, _local_scalar_dense_356, _local_scalar_dense_357, _local_scalar_dense_358, _local_scalar_dense_359, _local_scalar_dense_360, _local_scalar_dense_361, _local_scalar_dense_362, _local_scalar_dense_363, _local_scalar_dense_364, _local_scalar_dense_365, _local_scalar_dense_366, _local_scalar_dense_367, _local_scalar_dense_368, _local_scalar_dense_369, _local_scalar_dense_370, _local_scalar_dense_371, _local_scalar_dense_372, _local_scalar_dense_373, _local_scalar_dense_374, _local_scalar_dense_375, _local_scalar_dense_376, _local_scalar_dense_377, _local_scalar_dense_378, _local_scalar_dense_379, _local_scalar_dense_380, _local_scalar_dense_381, _local_scalar_dense_382, _local_scalar_dense_383, _local_scalar_dense_384, _local_scalar_dense_385, _local_scalar_dense_386, _local_scalar_dense_387, _local_scalar_dense_388, _local_scalar_dense_389, _local_scalar_dense_390, _local_scalar_dense_391, _local_scalar_dense_392, _local_scalar_dense_393, _local_scalar_dense_394, _local_scalar_dense_395, _local_scalar_dense_396, _local_scalar_dense_397, _local_scalar_dense_398, _local_scalar_dense_399, _local_scalar_dense_400, _local_scalar_dense_401, _local_scalar_dense_402, _local_scalar_dense_403, _local_scalar_dense_404, _local_scalar_dense_405, _local_scalar_dense_406, _local_scalar_dense_407, _local_scalar_dense_408, _local_scalar_dense_409, _local_scalar_dense_410, _local_scalar_dense_411, _local_scalar_dense_412, _local_scalar_dense_413, _local_scalar_dense_414, _local_scalar_dense_415, sym_size_int_1, sym_size_int_5, sym_size_int_9, sym_size_int_13, sym_size_int_17, sym_size_int_21, sym_size_int_25, sym_size_int_29, sym_size_int_33, sym_size_int_37, sym_size_int_41, sym_size_int_45, sym_size_int_49, sym_size_int_53, sym_size_int_57, sym_size_int_61, sym_size_int_65, sym_size_int_69, sym_size_int_73, sym_size_int_77, sym_size_int_81, sym_size_int_85, sym_size_int_89, sym_size_int_93, sym_size_int_97, sym_size_int_101, add_1781, add_1796, add_1811, add_1826, add_1841, add_1856, add_1871, add_1886, add_1901, add_1916, add_1931, add_1946, add_1961, add_1976, add_1991, add_2006, add_2021, add_2036, add_2051, add_2066, add_2081, add_2096, add_2111, add_2126, add_2141, add_2156, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_31, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_47, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_63, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_79, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_95, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_111, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_127, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_143, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_159, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_175, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_191, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_207, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_223, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_239, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_255, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_271, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_287, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_303, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_319, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_335, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_351, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_367, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_383, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_399, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_415, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_431, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440, embedding, rsqrt, view_3, getitem_2, rsqrt_1, view_17, permute_3, permute_4, permute_5, getitem_6, getitem_7, mm_3, rsqrt_2, view_26, mm_4, mm_5, view_32, add_5, rsqrt_3, view_36, getitem_11, rsqrt_4, view_50, permute_14, permute_15, permute_16, getitem_15, getitem_16, add_8, rsqrt_5, view_58, mm_11, amax, sum_1, getitem_19, getitem_21, div_2, getitem_22, index_1, cumsum_2, _grouped_mm, _grouped_mm_1, mul_35, mm_12, mm_13, mul_55, add_73, rsqrt_6, view_103, getitem_121, rsqrt_7, view_117, permute_29, permute_30, permute_31, getitem_125, getitem_126, add_76, rsqrt_8, view_125, mm_19, amax_1, sum_5, getitem_129, getitem_131, div_7, getitem_132, index_3, cumsum_5, _grouped_mm_3, _grouped_mm_4, mul_84, mm_20, mm_21, mul_104, add_141, rsqrt_9, view_170, getitem_231, rsqrt_10, view_184, permute_44, permute_45, permute_46, getitem_235, getitem_236, add_144, rsqrt_11, view_192, mm_27, amax_2, sum_9, getitem_239, getitem_241, div_12, getitem_242, index_5, cumsum_8, _grouped_mm_6, _grouped_mm_7, mul_133, mm_28, mm_29, mul_153, add_209, rsqrt_12, view_237, getitem_341, rsqrt_13, view_251, permute_59, permute_60, permute_61, getitem_345, getitem_346, add_212, rsqrt_14, view_259, mm_35, amax_3, sum_13, getitem_349, getitem_351, div_17, getitem_352, index_7, cumsum_11, _grouped_mm_9, _grouped_mm_10, mul_182, mm_36, mm_37, mul_202, add_277, rsqrt_15, view_304, getitem_451, rsqrt_16, view_318, permute_74, permute_75, permute_76, getitem_455, getitem_456, add_280, rsqrt_17, view_326, mm_43, amax_4, sum_17, getitem_459, getitem_461, div_22, getitem_462, index_9, cumsum_14, _grouped_mm_12, _grouped_mm_13, mul_231, mm_44, mm_45, mul_251, add_345, rsqrt_18, view_371, getitem_561, rsqrt_19, view_385, permute_89, permute_90, permute_91, getitem_565, getitem_566, add_348, rsqrt_20, view_393, mm_51, amax_5, sum_21, getitem_569, getitem_571, div_27, getitem_572, index_11, cumsum_17, _grouped_mm_15, _grouped_mm_16, mul_280, mm_52, mm_53, mul_300, add_413, rsqrt_21, view_438, getitem_671, rsqrt_22, view_452, permute_104, permute_105, permute_106, getitem_675, getitem_676, add_416, rsqrt_23, view_460, mm_59, amax_6, sum_25, getitem_679, getitem_681, div_32, getitem_682, index_13, cumsum_20, _grouped_mm_18, _grouped_mm_19, mul_329, mm_60, mm_61, mul_349, add_481, rsqrt_24, view_505, getitem_781, rsqrt_25, view_519, permute_119, permute_120, permute_121, getitem_785, getitem_786, add_484, rsqrt_26, view_527, mm_67, amax_7, sum_29, getitem_789, getitem_791, div_37, getitem_792, index_15, cumsum_23, _grouped_mm_21, _grouped_mm_22, mul_378, mm_68, mm_69, mul_398, add_549, rsqrt_27, view_572, getitem_891, rsqrt_28, view_586, permute_134, permute_135, permute_136, getitem_895, getitem_896, add_552, rsqrt_29, view_594, mm_75, amax_8, sum_33, getitem_899, getitem_901, div_42, getitem_902, index_17, cumsum_26, _grouped_mm_24, _grouped_mm_25, mul_427, mm_76, mm_77, mul_447, add_617, rsqrt_30, view_639, getitem_1001, rsqrt_31, view_653, permute_149, permute_150, permute_151, getitem_1005, getitem_1006, add_620, rsqrt_32, view_661, mm_83, amax_9, sum_37, getitem_1009, getitem_1011, div_47, getitem_1012, index_19, cumsum_29, _grouped_mm_27, _grouped_mm_28, mul_476, mm_84, mm_85, mul_496, add_685, rsqrt_33, view_706, getitem_1111, rsqrt_34, view_720, permute_164, permute_165, permute_166, getitem_1115, getitem_1116, add_688, rsqrt_35, view_728, mm_91, amax_10, sum_41, getitem_1119, getitem_1121, div_52, getitem_1122, index_21, cumsum_32, _grouped_mm_30, _grouped_mm_31, mul_525, mm_92, mm_93, mul_545, add_753, rsqrt_36, view_773, getitem_1221, rsqrt_37, view_787, permute_179, permute_180, permute_181, getitem_1225, getitem_1226, add_756, rsqrt_38, view_795, mm_99, amax_11, sum_45, getitem_1229, getitem_1231, div_57, getitem_1232, index_23, cumsum_35, _grouped_mm_33, _grouped_mm_34, mul_574, mm_100, mm_101, mul_594, add_821, rsqrt_39, view_840, getitem_1331, rsqrt_40, view_854, permute_194, permute_195, permute_196, getitem_1335, getitem_1336, add_824, rsqrt_41, view_862, mm_107, amax_12, sum_49, getitem_1339, getitem_1341, div_62, getitem_1342, index_25, cumsum_38, _grouped_mm_36, _grouped_mm_37, mul_623, mm_108, mm_109, mul_643, add_889, rsqrt_42, view_907, getitem_1441, rsqrt_43, view_921, permute_209, permute_210, permute_211, getitem_1445, getitem_1446, add_892, rsqrt_44, view_929, mm_115, amax_13, sum_53, getitem_1449, getitem_1451, div_67, getitem_1452, index_27, cumsum_41, _grouped_mm_39, _grouped_mm_40, mul_672, mm_116, mm_117, mul_692, add_957, rsqrt_45, view_974, getitem_1551, rsqrt_46, view_988, permute_224, permute_225, permute_226, getitem_1555, getitem_1556, add_960, rsqrt_47, view_996, mm_123, amax_14, sum_57, getitem_1559, getitem_1561, div_72, getitem_1562, index_29, cumsum_44, _grouped_mm_42, _grouped_mm_43, mul_721, mm_124, mm_125, mul_741, add_1025, rsqrt_48, view_1041, getitem_1661, rsqrt_49, view_1055, permute_239, permute_240, permute_241, getitem_1665, getitem_1666, add_1028, rsqrt_50, view_1063, mm_131, amax_15, sum_61, getitem_1669, getitem_1671, div_77, getitem_1672, index_31, cumsum_47, _grouped_mm_45, _grouped_mm_46, mul_770, mm_132, mm_133, mul_790, add_1093, rsqrt_51, view_1108, getitem_1771, rsqrt_52, view_1122, permute_254, permute_255, permute_256, getitem_1775, getitem_1776, add_1096, rsqrt_53, view_1130, mm_139, amax_16, sum_65, getitem_1779, getitem_1781, div_82, getitem_1782, index_33, cumsum_50, _grouped_mm_48, _grouped_mm_49, mul_819, mm_140, mm_141, mul_839, add_1161, rsqrt_54, view_1175, getitem_1881, rsqrt_55, view_1189, permute_269, permute_270, permute_271, getitem_1885, getitem_1886, add_1164, rsqrt_56, view_1197, mm_147, amax_17, sum_69, getitem_1889, getitem_1891, div_87, getitem_1892, index_35, cumsum_53, _grouped_mm_51, _grouped_mm_52, mul_868, mm_148, mm_149, mul_888, add_1229, rsqrt_57, view_1242, getitem_1991, rsqrt_58, view_1256, permute_284, permute_285, permute_286, getitem_1995, getitem_1996, add_1232, rsqrt_59, view_1264, mm_155, amax_18, sum_73, getitem_1999, getitem_2001, div_92, getitem_2002, index_37, cumsum_56, _grouped_mm_54, _grouped_mm_55, mul_917, mm_156, mm_157, mul_937, add_1297, rsqrt_60, view_1309, getitem_2101, rsqrt_61, view_1323, permute_299, permute_300, permute_301, getitem_2105, getitem_2106, add_1300, rsqrt_62, view_1331, mm_163, amax_19, sum_77, getitem_2109, getitem_2111, div_97, getitem_2112, index_39, cumsum_59, _grouped_mm_57, _grouped_mm_58, mul_966, mm_164, mm_165, mul_986, add_1365, rsqrt_63, view_1376, getitem_2211, rsqrt_64, view_1390, permute_314, permute_315, permute_316, getitem_2215, getitem_2216, add_1368, rsqrt_65, view_1398, mm_171, amax_20, sum_81, getitem_2219, getitem_2221, div_102, getitem_2222, index_41, cumsum_62, _grouped_mm_60, _grouped_mm_61, mul_1015, mm_172, mm_173, mul_1035, add_1433, rsqrt_66, view_1443, getitem_2321, rsqrt_67, view_1457, permute_329, permute_330, permute_331, getitem_2325, getitem_2326, add_1436, rsqrt_68, view_1465, mm_179, amax_21, sum_85, getitem_2329, getitem_2331, div_107, getitem_2332, index_43, cumsum_65, _grouped_mm_63, _grouped_mm_64, mul_1064, mm_180, mm_181, mul_1084, add_1501, rsqrt_69, view_1510, getitem_2431, rsqrt_70, view_1524, permute_344, permute_345, permute_346, getitem_2435, getitem_2436, add_1504, rsqrt_71, view_1532, mm_187, amax_22, sum_89, getitem_2439, getitem_2441, div_112, getitem_2442, index_45, cumsum_68, _grouped_mm_66, _grouped_mm_67, mul_1113, mm_188, mm_189, mul_1133, add_1569, rsqrt_72, view_1577, getitem_2541, rsqrt_73, view_1591, permute_359, permute_360, permute_361, getitem_2545, getitem_2546, add_1572, rsqrt_74, view_1599, mm_195, amax_23, sum_93, getitem_2549, getitem_2551, div_117, getitem_2552, index_47, cumsum_71, _grouped_mm_69, _grouped_mm_70, mul_1162, mm_196, mm_197, mul_1182, add_1637, rsqrt_75, view_1644, getitem_2651, rsqrt_76, view_1658, permute_374, permute_375, permute_376, getitem_2655, getitem_2656, add_1640, rsqrt_77, view_1666, mm_203, amax_24, sum_97, getitem_2659, getitem_2661, div_122, getitem_2662, index_49, cumsum_74, _grouped_mm_72, _grouped_mm_73, mul_1211, mm_204, mm_205, mul_1231, add_1705, rsqrt_78, view_1711, getitem_2761, rsqrt_79, view_1725, permute_389, permute_390, permute_391, getitem_2765, getitem_2766, add_1708, rsqrt_80, view_1733, mm_211, amax_25, sum_101, getitem_2769, getitem_2771, div_127, getitem_2772, index_51, cumsum_77, _grouped_mm_75, _grouped_mm_76, mul_1260, mm_212, mm_213, mul_1280, add_1773, rsqrt_81, view_1778, permute_406, permute_407, permute_422, permute_426, permute_430, full_default_54, permute_456, permute_457, permute_472, permute_476, permute_480, permute_506, permute_507, permute_522, permute_526, permute_530, permute_556, permute_557, permute_572, permute_576, permute_580, permute_606, permute_607, permute_622, permute_626, permute_630, permute_656, permute_657, permute_672, permute_676, permute_680, permute_706, permute_707, permute_722, permute_726, permute_730, permute_756, permute_757, permute_772, permute_776, permute_780, permute_806, permute_807, permute_822, permute_826, permute_830, permute_856, permute_857, permute_872, permute_876, permute_880, permute_906, permute_907, permute_922, permute_926, permute_930, permute_956, permute_957, permute_972, permute_976, permute_980, permute_1006, permute_1007, permute_1022, permute_1026, permute_1030, permute_1056, permute_1057, permute_1072, permute_1076, permute_1080, permute_1106, permute_1107, permute_1122, permute_1126, permute_1130, permute_1156, permute_1157, permute_1172, permute_1176, permute_1180, permute_1206, permute_1207, permute_1222, permute_1226, permute_1230, permute_1256, permute_1257, permute_1272, permute_1276, permute_1280, permute_1306, permute_1307, permute_1322, permute_1326, permute_1330, permute_1356, permute_1357, permute_1372, permute_1376, permute_1380, permute_1406, permute_1407, permute_1422, permute_1426, permute_1430, permute_1456, permute_1457, permute_1472, permute_1476, permute_1480, permute_1506, permute_1507, permute_1522, permute_1526, permute_1530, permute_1556, permute_1557, permute_1572, permute_1576, permute_1580, permute_1606, permute_1607, permute_1622, permute_1626, permute_1630, permute_1656, permute_1657, permute_1672, permute_1676, permute_1680, tangents_1):
        view_1780 = torch.ops.aten.view.default(tangents_1, [8192, 102400]);  tangents_1 = None
        permute_402 = torch.ops.aten.permute.default(view_1780, [1, 0])
        mm_216 = torch.ops.aten.mm.default(permute_402, view_1778);  permute_402 = view_1778 = None
        convert_element_type_1444 = torch.ops.prims.convert_element_type.default(primals_440, torch.bfloat16);  primals_440 = None
        all_gather_into_tensor_454 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1444, 128, '0');  convert_element_type_1444 = None
        wait_tensor_558 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_454);  all_gather_into_tensor_454 = None
        permute_401 = torch.ops.aten.permute.default(wait_tensor_558, [1, 0]);  wait_tensor_558 = None
        permute_404 = torch.ops.aten.permute.default(permute_401, [1, 0]);  permute_401 = None
        mm_217 = torch.ops.aten.mm.default(view_1780, permute_404);  view_1780 = permute_404 = None
        view_1781 = torch.ops.aten.view.default(mm_217, [2, 4096, 2048]);  mm_217 = None
        convert_element_type_1451 = torch.ops.prims.convert_element_type.default(mm_216, torch.float32);  mm_216 = None
        reduce_scatter_tensor = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1451, 'avg', 128, '0');  convert_element_type_1451 = None
        wait_tensor_559 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor);  reduce_scatter_tensor = None
        convert_element_type_1452 = torch.ops.prims.convert_element_type.default(view_1781, torch.float32);  view_1781 = None
        convert_element_type_1441 = torch.ops.prims.convert_element_type.default(primals_439, torch.bfloat16);  primals_439 = None
        all_gather_into_tensor_453 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1441, 128, '0');  convert_element_type_1441 = None
        wait_tensor_557 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_453);  all_gather_into_tensor_453 = None
        convert_element_type_1454 = torch.ops.prims.convert_element_type.default(wait_tensor_557, torch.float32);  wait_tensor_557 = None
        mul_1285 = torch.ops.aten.mul.Tensor(convert_element_type_1452, convert_element_type_1454);  convert_element_type_1454 = None
        convert_element_type_1442 = torch.ops.prims.convert_element_type.default(add_1773, torch.float32);  add_1773 = None
        mul_1283 = torch.ops.aten.mul.Tensor(convert_element_type_1442, rsqrt_81);  convert_element_type_1442 = None
        mul_1287 = torch.ops.aten.mul.Tensor(mul_1283, mul_1285)
        sum_105 = torch.ops.aten.sum.dim_IntList(mul_1287, [2], True);  mul_1287 = None
        div_131 = torch.ops.aten.div.Tensor(mul_1283, 2048)
        mul_1288 = torch.ops.aten.mul.Tensor(div_131, sum_105);  div_131 = sum_105 = None
        sub_624 = torch.ops.aten.sub.Tensor(mul_1285, mul_1288);  mul_1285 = mul_1288 = None
        mul_1289 = torch.ops.aten.mul.Tensor(sub_624, rsqrt_81);  sub_624 = rsqrt_81 = None
        mul_1290 = torch.ops.aten.mul.Tensor(convert_element_type_1452, mul_1283);  convert_element_type_1452 = mul_1283 = None
        sum_106 = torch.ops.aten.sum.dim_IntList(mul_1290, [0, 1]);  mul_1290 = None
        convert_element_type_1455 = torch.ops.prims.convert_element_type.default(mul_1289, torch.bfloat16);  mul_1289 = None
        convert_element_type_default_82 = torch.ops.prims.convert_element_type.default(sum_106, torch.float32);  sum_106 = None
        reduce_scatter_tensor_1 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_82, 'avg', 128, '0');  convert_element_type_default_82 = None
        wait_tensor_560 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_1);  reduce_scatter_tensor_1 = None
        view_1782 = torch.ops.aten.view.default(convert_element_type_1455, [8192, 2048])
        unsqueeze_53 = torch.ops.aten.unsqueeze.default(view_1782, 1)
        convert_element_type_1458 = torch.ops.prims.convert_element_type.default(unsqueeze_53, torch.float32);  unsqueeze_53 = None
        bmm_26 = torch.ops.aten.bmm.default(permute_406, convert_element_type_1458);  permute_406 = None
        bmm_27 = torch.ops.aten.bmm.default(convert_element_type_1458, permute_407);  convert_element_type_1458 = permute_407 = None
        convert_element_type_1459 = torch.ops.prims.convert_element_type.default(bmm_26, torch.bfloat16);  bmm_26 = None
        view_1783 = torch.ops.aten.view.default(bmm_27, [8192, 6]);  bmm_27 = None
        view_1784 = torch.ops.aten.view.default(convert_element_type_1459, [49152, 2048]);  convert_element_type_1459 = None
        index_52 = torch.ops.aten.index.Tensor(view_1784, [getitem_2771]);  view_1784 = getitem_2771 = None
        permute_408 = torch.ops.aten.permute.default(view_1782, [1, 0])
        mm_218 = torch.ops.aten.mm.default(permute_408, mul_1280);  permute_408 = mul_1280 = None
        convert_element_type_1436 = torch.ops.prims.convert_element_type.default(primals_438, torch.bfloat16);  primals_438 = None
        all_gather_into_tensor_452 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1436, 128, '0');  convert_element_type_1436 = None
        wait_tensor_556 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_452);  all_gather_into_tensor_452 = None
        permute_400 = torch.ops.aten.permute.default(wait_tensor_556, [1, 0]);  wait_tensor_556 = None
        permute_410 = torch.ops.aten.permute.default(permute_400, [1, 0]);  permute_400 = None
        mm_219 = torch.ops.aten.mm.default(view_1782, permute_410);  view_1782 = permute_410 = None
        convert_element_type_1464 = torch.ops.prims.convert_element_type.default(mm_218, torch.float32);  mm_218 = None
        reduce_scatter_tensor_2 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1464, 'avg', 128, '0');  convert_element_type_1464 = None
        wait_tensor_561 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_2);  reduce_scatter_tensor_2 = None
        convert_element_type_1431 = torch.ops.prims.convert_element_type.default(mm_212, torch.float32);  mm_212 = None
        neg_52 = torch.ops.aten.neg.default(convert_element_type_1431)
        exp_78 = torch.ops.aten.exp.default(neg_52);  neg_52 = None
        add_1768 = torch.ops.aten.add.Tensor(exp_78, 1);  exp_78 = None
        div_130 = torch.ops.aten.div.Tensor(convert_element_type_1431, add_1768)
        convert_element_type_1432 = torch.ops.prims.convert_element_type.default(div_130, torch.bfloat16);  div_130 = None
        mul_1291 = torch.ops.aten.mul.Tensor(mm_219, convert_element_type_1432);  convert_element_type_1432 = None
        mul_1292 = torch.ops.aten.mul.Tensor(mm_219, mm_213);  mm_219 = mm_213 = None
        permute_412 = torch.ops.aten.permute.default(mul_1291, [1, 0])
        mm_220 = torch.ops.aten.mm.default(permute_412, view_1733);  permute_412 = None
        convert_element_type_1433 = torch.ops.prims.convert_element_type.default(primals_437, torch.bfloat16);  primals_437 = None
        all_gather_into_tensor_451 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1433, 128, '0');  convert_element_type_1433 = None
        wait_tensor_555 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_451);  all_gather_into_tensor_451 = None
        permute_399 = torch.ops.aten.permute.default(wait_tensor_555, [1, 0]);  wait_tensor_555 = None
        permute_414 = torch.ops.aten.permute.default(permute_399, [1, 0]);  permute_399 = None
        mm_221 = torch.ops.aten.mm.default(mul_1291, permute_414);  mul_1291 = permute_414 = None
        convert_element_type_1469 = torch.ops.prims.convert_element_type.default(mm_220, torch.float32);  mm_220 = None
        reduce_scatter_tensor_3 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1469, 'avg', 128, '0');  convert_element_type_1469 = None
        wait_tensor_562 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_3);  reduce_scatter_tensor_3 = None
        convert_element_type_1470 = torch.ops.prims.convert_element_type.default(mul_1292, torch.float32);  mul_1292 = None
        reciprocal = torch.ops.aten.reciprocal.default(add_1768);  add_1768 = None
        mul_1293 = torch.ops.aten.mul.Tensor(reciprocal, 1);  reciprocal = None
        mul_1294 = torch.ops.aten.mul.Tensor(convert_element_type_1470, mul_1293);  convert_element_type_1470 = None
        sub_625 = torch.ops.aten.sub.Tensor(1, mul_1293);  mul_1293 = None
        mul_1295 = torch.ops.aten.mul.Tensor(convert_element_type_1431, sub_625);  convert_element_type_1431 = sub_625 = None
        add_1776 = torch.ops.aten.add.Tensor(mul_1295, 1);  mul_1295 = None
        mul_1296 = torch.ops.aten.mul.Tensor(mul_1294, add_1776);  mul_1294 = add_1776 = None
        convert_element_type_1472 = torch.ops.prims.convert_element_type.default(mul_1296, torch.bfloat16);  mul_1296 = None
        permute_416 = torch.ops.aten.permute.default(convert_element_type_1472, [1, 0])
        mm_222 = torch.ops.aten.mm.default(permute_416, view_1733);  permute_416 = None
        convert_element_type_1428 = torch.ops.prims.convert_element_type.default(primals_436, torch.bfloat16);  primals_436 = None
        all_gather_into_tensor_450 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1428, 128, '0');  convert_element_type_1428 = None
        wait_tensor_554 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_450);  all_gather_into_tensor_450 = None
        permute_398 = torch.ops.aten.permute.default(wait_tensor_554, [1, 0]);  wait_tensor_554 = None
        permute_418 = torch.ops.aten.permute.default(permute_398, [1, 0]);  permute_398 = None
        mm_223 = torch.ops.aten.mm.default(convert_element_type_1472, permute_418);  convert_element_type_1472 = permute_418 = None
        add_1777 = torch.ops.aten.add.Tensor(mm_221, mm_223);  mm_221 = mm_223 = None
        convert_element_type_1477 = torch.ops.prims.convert_element_type.default(mm_222, torch.float32);  mm_222 = None
        reduce_scatter_tensor_4 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1477, 'avg', 128, '0');  convert_element_type_1477 = None
        wait_tensor_563 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_4);  reduce_scatter_tensor_4 = None
        all_to_all_single_78 = torch.ops._c10d_functional.all_to_all_single.default(index_52, [_local_scalar_dense_408, _local_scalar_dense_409, _local_scalar_dense_410, _local_scalar_dense_411, _local_scalar_dense_412, _local_scalar_dense_413, _local_scalar_dense_414, _local_scalar_dense_415], [_local_scalar_dense_400, _local_scalar_dense_401, _local_scalar_dense_402, _local_scalar_dense_403, _local_scalar_dense_404, _local_scalar_dense_405, _local_scalar_dense_406, _local_scalar_dense_407], '1033');  index_52 = None
        wait_tensor_564 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_78);  all_to_all_single_78 = None
        full_348 = torch.ops.aten.full.default([sym_size_int_101, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_101 = None
        slice_scatter = torch.ops.aten.slice_scatter.default(full_348, wait_tensor_564, 0, 0, -1);  wait_tensor_564 = None
        index_53 = torch.ops.aten.index.Tensor(slice_scatter, [getitem_2772]);  slice_scatter = None
        permute_420 = torch.ops.aten.permute.default(index_53, [1, 0])
        _grouped_mm_78 = torch.ops.aten._grouped_mm.default(permute_420, mul_1260, cumsum_77);  permute_420 = mul_1260 = None
        _grouped_mm_79 = torch.ops.aten._grouped_mm.default(index_53, permute_422, cumsum_77);  index_53 = permute_422 = None
        convert_element_type_1426 = torch.ops.prims.convert_element_type.default(_grouped_mm_75, torch.float32);  _grouped_mm_75 = None
        neg_51 = torch.ops.aten.neg.default(convert_element_type_1426)
        exp_77 = torch.ops.aten.exp.default(neg_51);  neg_51 = None
        add_1732 = torch.ops.aten.add.Tensor(exp_77, 1);  exp_77 = None
        div_129 = torch.ops.aten.div.Tensor(convert_element_type_1426, add_1732)
        convert_element_type_1427 = torch.ops.prims.convert_element_type.default(div_129, torch.bfloat16);  div_129 = None
        mul_1297 = torch.ops.aten.mul.Tensor(_grouped_mm_79, convert_element_type_1427);  convert_element_type_1427 = None
        mul_1298 = torch.ops.aten.mul.Tensor(_grouped_mm_79, _grouped_mm_76);  _grouped_mm_79 = _grouped_mm_76 = None
        permute_424 = torch.ops.aten.permute.default(mul_1297, [1, 0])
        _grouped_mm_80 = torch.ops.aten._grouped_mm.default(permute_424, index_51, cumsum_77);  permute_424 = None
        _grouped_mm_81 = torch.ops.aten._grouped_mm.default(mul_1297, permute_426, cumsum_77);  mul_1297 = permute_426 = None
        convert_element_type_1478 = torch.ops.prims.convert_element_type.default(mul_1298, torch.float32);  mul_1298 = None
        reciprocal_1 = torch.ops.aten.reciprocal.default(add_1732);  add_1732 = None
        mul_1299 = torch.ops.aten.mul.Tensor(reciprocal_1, 1);  reciprocal_1 = None
        mul_1300 = torch.ops.aten.mul.Tensor(convert_element_type_1478, mul_1299);  convert_element_type_1478 = None
        sub_626 = torch.ops.aten.sub.Tensor(1, mul_1299);  mul_1299 = None
        mul_1301 = torch.ops.aten.mul.Tensor(convert_element_type_1426, sub_626);  convert_element_type_1426 = sub_626 = None
        add_1779 = torch.ops.aten.add.Tensor(mul_1301, 1);  mul_1301 = None
        mul_1302 = torch.ops.aten.mul.Tensor(mul_1300, add_1779);  mul_1300 = add_1779 = None
        convert_element_type_1480 = torch.ops.prims.convert_element_type.default(mul_1302, torch.bfloat16);  mul_1302 = None
        permute_428 = torch.ops.aten.permute.default(convert_element_type_1480, [1, 0])
        _grouped_mm_82 = torch.ops.aten._grouped_mm.default(permute_428, index_51, cumsum_77);  permute_428 = index_51 = None
        _grouped_mm_83 = torch.ops.aten._grouped_mm.default(convert_element_type_1480, permute_430, cumsum_77);  convert_element_type_1480 = permute_430 = cumsum_77 = None
        add_1780 = torch.ops.aten.add.Tensor(_grouped_mm_81, _grouped_mm_83);  _grouped_mm_81 = _grouped_mm_83 = None
        convert_element_type_1481 = torch.ops.prims.convert_element_type.default(_grouped_mm_80, torch.float32);  _grouped_mm_80 = None
        div_132 = torch.ops.aten.div.Tensor(convert_element_type_1481, 128);  convert_element_type_1481 = None
        split_157 = torch.ops.aten.split.Tensor(div_132, 88, 1);  div_132 = None
        getitem_2885 = split_157[0]
        getitem_2902 = split_157[1]
        getitem_2919 = split_157[2]
        getitem_2936 = split_157[3]
        getitem_2953 = split_157[4]
        getitem_2970 = split_157[5]
        getitem_2987 = split_157[6]
        getitem_3004 = split_157[7]
        getitem_3021 = split_157[8]
        getitem_3038 = split_157[9]
        getitem_3055 = split_157[10]
        getitem_3072 = split_157[11]
        getitem_3089 = split_157[12]
        getitem_3106 = split_157[13]
        getitem_3123 = split_157[14]
        getitem_3140 = split_157[15];  split_157 = None
        cat_236 = torch.ops.aten.cat.default([getitem_2885, getitem_2902, getitem_2919, getitem_2936, getitem_2953, getitem_2970, getitem_2987, getitem_3004, getitem_3021, getitem_3038, getitem_3055, getitem_3072, getitem_3089, getitem_3106, getitem_3123, getitem_3140]);  getitem_2885 = getitem_2902 = getitem_2919 = getitem_2936 = getitem_2953 = getitem_2970 = getitem_2987 = getitem_3004 = getitem_3021 = getitem_3038 = getitem_3055 = getitem_3072 = getitem_3089 = getitem_3106 = getitem_3123 = getitem_3140 = None
        reduce_scatter_tensor_5 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_236, 'sum', 16, '1025');  cat_236 = None
        wait_tensor_565 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_5);  reduce_scatter_tensor_5 = None
        convert_element_type_1482 = torch.ops.prims.convert_element_type.default(_grouped_mm_78, torch.float32);  _grouped_mm_78 = None
        div_133 = torch.ops.aten.div.Tensor(convert_element_type_1482, 128);  convert_element_type_1482 = None
        split_174 = torch.ops.aten.split.Tensor(div_133, 128, 1);  div_133 = None
        getitem_3157 = split_174[0]
        getitem_3174 = split_174[1]
        getitem_3191 = split_174[2]
        getitem_3208 = split_174[3]
        getitem_3225 = split_174[4]
        getitem_3242 = split_174[5]
        getitem_3259 = split_174[6]
        getitem_3276 = split_174[7]
        getitem_3293 = split_174[8]
        getitem_3310 = split_174[9]
        getitem_3327 = split_174[10]
        getitem_3344 = split_174[11]
        getitem_3361 = split_174[12]
        getitem_3378 = split_174[13]
        getitem_3395 = split_174[14]
        getitem_3412 = split_174[15];  split_174 = None
        cat_237 = torch.ops.aten.cat.default([getitem_3157, getitem_3174, getitem_3191, getitem_3208, getitem_3225, getitem_3242, getitem_3259, getitem_3276, getitem_3293, getitem_3310, getitem_3327, getitem_3344, getitem_3361, getitem_3378, getitem_3395, getitem_3412]);  getitem_3157 = getitem_3174 = getitem_3191 = getitem_3208 = getitem_3225 = getitem_3242 = getitem_3259 = getitem_3276 = getitem_3293 = getitem_3310 = getitem_3327 = getitem_3344 = getitem_3361 = getitem_3378 = getitem_3395 = getitem_3412 = None
        reduce_scatter_tensor_6 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_237, 'sum', 16, '1025');  cat_237 = None
        wait_tensor_566 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_6);  reduce_scatter_tensor_6 = None
        convert_element_type_1483 = torch.ops.prims.convert_element_type.default(_grouped_mm_82, torch.float32);  _grouped_mm_82 = None
        div_134 = torch.ops.aten.div.Tensor(convert_element_type_1483, 128);  convert_element_type_1483 = None
        split_191 = torch.ops.aten.split.Tensor(div_134, 88, 1);  div_134 = None
        getitem_3429 = split_191[0]
        getitem_3446 = split_191[1]
        getitem_3463 = split_191[2]
        getitem_3480 = split_191[3]
        getitem_3497 = split_191[4]
        getitem_3514 = split_191[5]
        getitem_3531 = split_191[6]
        getitem_3548 = split_191[7]
        getitem_3565 = split_191[8]
        getitem_3582 = split_191[9]
        getitem_3599 = split_191[10]
        getitem_3616 = split_191[11]
        getitem_3633 = split_191[12]
        getitem_3650 = split_191[13]
        getitem_3667 = split_191[14]
        getitem_3684 = split_191[15];  split_191 = None
        cat_238 = torch.ops.aten.cat.default([getitem_3429, getitem_3446, getitem_3463, getitem_3480, getitem_3497, getitem_3514, getitem_3531, getitem_3548, getitem_3565, getitem_3582, getitem_3599, getitem_3616, getitem_3633, getitem_3650, getitem_3667, getitem_3684]);  getitem_3429 = getitem_3446 = getitem_3463 = getitem_3480 = getitem_3497 = getitem_3514 = getitem_3531 = getitem_3548 = getitem_3565 = getitem_3582 = getitem_3599 = getitem_3616 = getitem_3633 = getitem_3650 = getitem_3667 = getitem_3684 = None
        reduce_scatter_tensor_7 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_238, 'sum', 16, '1025');  cat_238 = None
        wait_tensor_567 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_7);  reduce_scatter_tensor_7 = None
        index_put_52 = torch.ops.aten.index_put.default(full_348, [getitem_2772], add_1780, True);  full_348 = getitem_2772 = add_1780 = None
        slice_162 = torch.ops.aten.slice.Tensor(index_put_52, 0, 0, add_1781);  index_put_52 = add_1781 = None
        all_to_all_single_79 = torch.ops._c10d_functional.all_to_all_single.default(slice_162, [_local_scalar_dense_400, _local_scalar_dense_401, _local_scalar_dense_402, _local_scalar_dense_403, _local_scalar_dense_404, _local_scalar_dense_405, _local_scalar_dense_406, _local_scalar_dense_407], [_local_scalar_dense_408, _local_scalar_dense_409, _local_scalar_dense_410, _local_scalar_dense_411, _local_scalar_dense_412, _local_scalar_dense_413, _local_scalar_dense_414, _local_scalar_dense_415], '1033');  slice_162 = _local_scalar_dense_400 = _local_scalar_dense_401 = _local_scalar_dense_402 = _local_scalar_dense_403 = _local_scalar_dense_404 = _local_scalar_dense_405 = _local_scalar_dense_406 = _local_scalar_dense_407 = _local_scalar_dense_408 = _local_scalar_dense_409 = _local_scalar_dense_410 = _local_scalar_dense_411 = _local_scalar_dense_412 = _local_scalar_dense_413 = _local_scalar_dense_414 = _local_scalar_dense_415 = None
        wait_tensor_568 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_79);  all_to_all_single_79 = None
        full_default_52 = torch.ops.aten.full.default([8192, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_53 = torch.ops.aten.index_put.default(full_default_52, [div_127], wait_tensor_568, True);  div_127 = wait_tensor_568 = None
        add_1785 = torch.ops.aten.add.Tensor(add_1777, index_put_53);  add_1777 = index_put_53 = None
        mul_1303 = torch.ops.aten.mul.Tensor(view_1783, 1.0);  view_1783 = None
        full_default_53 = torch.ops.aten.full.default([8192, 64], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        scatter_add = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_2769, mul_1303);  getitem_2769 = mul_1303 = None
        convert_element_type_1415 = torch.ops.prims.convert_element_type.default(mm_211, torch.float32);  mm_211 = None
        sub_600 = torch.ops.aten.sub.Tensor(convert_element_type_1415, amax_25);  convert_element_type_1415 = amax_25 = None
        exp_76 = torch.ops.aten.exp.default(sub_600);  sub_600 = None
        div_126 = torch.ops.aten.div.Tensor(exp_76, sum_101);  exp_76 = sum_101 = None
        mul_1304 = torch.ops.aten.mul.Tensor(scatter_add, div_126);  scatter_add = None
        sum_107 = torch.ops.aten.sum.dim_IntList(mul_1304, [1], True)
        neg_55 = torch.ops.aten.neg.default(div_126);  div_126 = None
        fma = torch.ops.prims.fma.default(neg_55, sum_107, mul_1304);  neg_55 = sum_107 = mul_1304 = None
        convert_element_type_1484 = torch.ops.prims.convert_element_type.default(fma, torch.bfloat16);  fma = None
        permute_432 = torch.ops.aten.permute.default(convert_element_type_1484, [1, 0])
        mm_224 = torch.ops.aten.mm.default(permute_432, view_1733);  permute_432 = view_1733 = None
        convert_element_type_1412 = torch.ops.prims.convert_element_type.default(primals_431, torch.bfloat16);  primals_431 = None
        all_gather_into_tensor_443 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1412, 128, '0');  convert_element_type_1412 = None
        wait_tensor_543 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_443);  all_gather_into_tensor_443 = None
        slice_159 = torch.ops.aten.slice.Tensor(wait_tensor_543, 0, 0, 64);  wait_tensor_543 = None
        permute_394 = torch.ops.aten.permute.default(slice_159, [1, 0]);  slice_159 = None
        permute_434 = torch.ops.aten.permute.default(permute_394, [1, 0]);  permute_394 = None
        mm_225 = torch.ops.aten.mm.default(convert_element_type_1484, permute_434);  convert_element_type_1484 = permute_434 = None
        add_1786 = torch.ops.aten.add.Tensor(add_1785, mm_225);  add_1785 = mm_225 = None
        convert_element_type_1489 = torch.ops.prims.convert_element_type.default(mm_224, torch.float32);  mm_224 = None
        split_207 = torch.ops.aten.split.Tensor(convert_element_type_1489, 1);  convert_element_type_1489 = None
        getitem_3685 = split_207[0]
        getitem_3686 = split_207[1]
        getitem_3687 = split_207[2]
        getitem_3688 = split_207[3]
        getitem_3689 = split_207[4]
        getitem_3690 = split_207[5]
        getitem_3691 = split_207[6]
        getitem_3692 = split_207[7]
        getitem_3693 = split_207[8]
        getitem_3694 = split_207[9]
        getitem_3695 = split_207[10]
        getitem_3696 = split_207[11]
        getitem_3697 = split_207[12]
        getitem_3698 = split_207[13]
        getitem_3699 = split_207[14]
        getitem_3700 = split_207[15]
        getitem_3701 = split_207[16]
        getitem_3702 = split_207[17]
        getitem_3703 = split_207[18]
        getitem_3704 = split_207[19]
        getitem_3705 = split_207[20]
        getitem_3706 = split_207[21]
        getitem_3707 = split_207[22]
        getitem_3708 = split_207[23]
        getitem_3709 = split_207[24]
        getitem_3710 = split_207[25]
        getitem_3711 = split_207[26]
        getitem_3712 = split_207[27]
        getitem_3713 = split_207[28]
        getitem_3714 = split_207[29]
        getitem_3715 = split_207[30]
        getitem_3716 = split_207[31]
        getitem_3717 = split_207[32]
        getitem_3718 = split_207[33]
        getitem_3719 = split_207[34]
        getitem_3720 = split_207[35]
        getitem_3721 = split_207[36]
        getitem_3722 = split_207[37]
        getitem_3723 = split_207[38]
        getitem_3724 = split_207[39]
        getitem_3725 = split_207[40]
        getitem_3726 = split_207[41]
        getitem_3727 = split_207[42]
        getitem_3728 = split_207[43]
        getitem_3729 = split_207[44]
        getitem_3730 = split_207[45]
        getitem_3731 = split_207[46]
        getitem_3732 = split_207[47]
        getitem_3733 = split_207[48]
        getitem_3734 = split_207[49]
        getitem_3735 = split_207[50]
        getitem_3736 = split_207[51]
        getitem_3737 = split_207[52]
        getitem_3738 = split_207[53]
        getitem_3739 = split_207[54]
        getitem_3740 = split_207[55]
        getitem_3741 = split_207[56]
        getitem_3742 = split_207[57]
        getitem_3743 = split_207[58]
        getitem_3744 = split_207[59]
        getitem_3745 = split_207[60]
        getitem_3746 = split_207[61]
        getitem_3747 = split_207[62]
        getitem_3748 = split_207[63];  split_207 = None
        constant_pad_nd = torch.ops.aten.constant_pad_nd.default(full_default_54, [0, 0, 0, 1], 0.0)
        cat_239 = torch.ops.aten.cat.default([getitem_3685, getitem_3686, getitem_3687, getitem_3688, getitem_3689, getitem_3690, getitem_3691, getitem_3692, getitem_3693, getitem_3694, getitem_3695, getitem_3696, getitem_3697, getitem_3698, getitem_3699, getitem_3700, getitem_3701, getitem_3702, getitem_3703, getitem_3704, getitem_3705, getitem_3706, getitem_3707, getitem_3708, getitem_3709, getitem_3710, getitem_3711, getitem_3712, getitem_3713, getitem_3714, getitem_3715, getitem_3716, getitem_3717, getitem_3718, getitem_3719, getitem_3720, getitem_3721, getitem_3722, getitem_3723, getitem_3724, getitem_3725, getitem_3726, getitem_3727, getitem_3728, getitem_3729, getitem_3730, getitem_3731, getitem_3732, getitem_3733, getitem_3734, getitem_3735, getitem_3736, getitem_3737, getitem_3738, getitem_3739, getitem_3740, getitem_3741, getitem_3742, getitem_3743, getitem_3744, getitem_3745, getitem_3746, getitem_3747, getitem_3748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_3685 = getitem_3686 = getitem_3687 = getitem_3688 = getitem_3689 = getitem_3690 = getitem_3691 = getitem_3692 = getitem_3693 = getitem_3694 = getitem_3695 = getitem_3696 = getitem_3697 = getitem_3698 = getitem_3699 = getitem_3700 = getitem_3701 = getitem_3702 = getitem_3703 = getitem_3704 = getitem_3705 = getitem_3706 = getitem_3707 = getitem_3708 = getitem_3709 = getitem_3710 = getitem_3711 = getitem_3712 = getitem_3713 = getitem_3714 = getitem_3715 = getitem_3716 = getitem_3717 = getitem_3718 = getitem_3719 = getitem_3720 = getitem_3721 = getitem_3722 = getitem_3723 = getitem_3724 = getitem_3725 = getitem_3726 = getitem_3727 = getitem_3728 = getitem_3729 = getitem_3730 = getitem_3731 = getitem_3732 = getitem_3733 = getitem_3734 = getitem_3735 = getitem_3736 = getitem_3737 = getitem_3738 = getitem_3739 = getitem_3740 = getitem_3741 = getitem_3742 = getitem_3743 = getitem_3744 = getitem_3745 = getitem_3746 = getitem_3747 = getitem_3748 = None
        reduce_scatter_tensor_8 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_239, 'avg', 128, '0');  cat_239 = None
        wait_tensor_569 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_8);  reduce_scatter_tensor_8 = None
        view_1785 = torch.ops.aten.view.default(add_1786, [2, 4096, 2048]);  add_1786 = None
        convert_element_type_1490 = torch.ops.prims.convert_element_type.default(view_1785, torch.float32);  view_1785 = None
        convert_element_type_1409 = torch.ops.prims.convert_element_type.default(primals_429, torch.bfloat16);  primals_429 = None
        all_gather_into_tensor_442 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1409, 128, '0');  convert_element_type_1409 = None
        wait_tensor_542 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_442);  all_gather_into_tensor_442 = None
        convert_element_type_1492 = torch.ops.prims.convert_element_type.default(wait_tensor_542, torch.float32);  wait_tensor_542 = None
        mul_1305 = torch.ops.aten.mul.Tensor(convert_element_type_1490, convert_element_type_1492);  convert_element_type_1492 = None
        convert_element_type_1410 = torch.ops.prims.convert_element_type.default(add_1708, torch.float32);  add_1708 = None
        mul_1240 = torch.ops.aten.mul.Tensor(convert_element_type_1410, rsqrt_80);  convert_element_type_1410 = None
        mul_1307 = torch.ops.aten.mul.Tensor(mul_1240, mul_1305)
        sum_108 = torch.ops.aten.sum.dim_IntList(mul_1307, [2], True);  mul_1307 = None
        div_135 = torch.ops.aten.div.Tensor(mul_1240, 2048)
        mul_1308 = torch.ops.aten.mul.Tensor(div_135, sum_108);  div_135 = sum_108 = None
        sub_628 = torch.ops.aten.sub.Tensor(mul_1305, mul_1308);  mul_1305 = mul_1308 = None
        mul_1309 = torch.ops.aten.mul.Tensor(sub_628, rsqrt_80);  sub_628 = rsqrt_80 = None
        mul_1310 = torch.ops.aten.mul.Tensor(convert_element_type_1490, mul_1240);  convert_element_type_1490 = mul_1240 = None
        sum_109 = torch.ops.aten.sum.dim_IntList(mul_1310, [0, 1]);  mul_1310 = None
        convert_element_type_1493 = torch.ops.prims.convert_element_type.default(mul_1309, torch.bfloat16);  mul_1309 = None
        add_1787 = torch.ops.aten.add.Tensor(convert_element_type_1455, convert_element_type_1493);  convert_element_type_1455 = convert_element_type_1493 = None
        convert_element_type_default_81 = torch.ops.prims.convert_element_type.default(sum_109, torch.float32);  sum_109 = None
        reduce_scatter_tensor_9 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_81, 'avg', 128, '0');  convert_element_type_default_81 = None
        wait_tensor_570 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_9);  reduce_scatter_tensor_9 = None
        view_1786 = torch.ops.aten.view.default(add_1787, [8192, 2048])
        permute_436 = torch.ops.aten.permute.default(view_1786, [1, 0])
        permute_392 = torch.ops.aten.permute.default(getitem_2765, [0, 2, 1, 3])
        view_1728 = torch.ops.aten.view.default(permute_392, [2, 4096, -1]);  permute_392 = None
        view_1730 = torch.ops.aten.view.default(view_1728, [8192, 2048]);  view_1728 = None
        mm_226 = torch.ops.aten.mm.default(permute_436, view_1730);  permute_436 = view_1730 = None
        convert_element_type_1406 = torch.ops.prims.convert_element_type.default(primals_428, torch.bfloat16);  primals_428 = None
        all_gather_into_tensor_441 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1406, 128, '0');  convert_element_type_1406 = None
        wait_tensor_541 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_441);  all_gather_into_tensor_441 = None
        permute_393 = torch.ops.aten.permute.default(wait_tensor_541, [1, 0]);  wait_tensor_541 = None
        permute_438 = torch.ops.aten.permute.default(permute_393, [1, 0]);  permute_393 = None
        mm_227 = torch.ops.aten.mm.default(view_1786, permute_438);  view_1786 = permute_438 = None
        view_1787 = torch.ops.aten.view.default(mm_227, [2, 4096, 2048]);  mm_227 = None
        convert_element_type_1500 = torch.ops.prims.convert_element_type.default(mm_226, torch.float32);  mm_226 = None
        reduce_scatter_tensor_10 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1500, 'avg', 128, '0');  convert_element_type_1500 = None
        wait_tensor_571 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_10);  reduce_scatter_tensor_10 = None
        view_1788 = torch.ops.aten.view.default(view_1787, [2, 4096, 16, 128]);  view_1787 = None
        permute_440 = torch.ops.aten.permute.default(view_1788, [0, 2, 1, 3]);  view_1788 = None
        fw_graph0 = self.fw_graph0
        joint_graph0 = self.joint_graph0
        mask_graph0 = self.mask_graph0
        flex_attention_backward = torch.ops.higher_order.flex_attention_backward(permute_389, permute_390, permute_391, getitem_2765, getitem_2766, permute_440, None, fw_graph0, joint_graph0, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph0), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_389 = permute_390 = permute_391 = getitem_2765 = getitem_2766 = permute_440 = fw_graph0 = joint_graph0 = mask_graph0 = None
        getitem_3749 = flex_attention_backward[0]
        getitem_3750 = flex_attention_backward[1]
        getitem_3751 = flex_attention_backward[2];  flex_attention_backward = None
        permute_441 = torch.ops.aten.permute.default(getitem_3751, [0, 2, 1, 3]);  getitem_3751 = None
        permute_442 = torch.ops.aten.permute.default(getitem_3750, [0, 2, 1, 3]);  getitem_3750 = None
        permute_443 = torch.ops.aten.permute.default(getitem_3749, [0, 2, 1, 3]);  getitem_3749 = None
        slice_164 = torch.ops.aten.slice.Tensor(permute_442, 3, 0, 128)
        slice_165 = torch.ops.aten.slice.Tensor(permute_442, 3, 128, 192);  permute_442 = None
        sum_110 = torch.ops.aten.sum.dim_IntList(slice_165, [2], True);  slice_165 = None
        cat_240 = torch.ops.aten.cat.default([slice_164, permute_441], 3);  slice_164 = permute_441 = None
        view_1789 = torch.ops.aten.view.default(cat_240, [2, 4096, 4096]);  cat_240 = None
        view_1790 = torch.ops.aten.view.default(view_1789, [8192, 4096]);  view_1789 = None
        permute_444 = torch.ops.aten.permute.default(view_1790, [1, 0])
        mm_228 = torch.ops.aten.mm.default(permute_444, view_1725);  permute_444 = view_1725 = None
        convert_element_type_1403 = torch.ops.prims.convert_element_type.default(primals_427, torch.bfloat16);  primals_427 = None
        all_gather_into_tensor_440 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1403, 128, '0');  convert_element_type_1403 = None
        wait_tensor_540 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_440);  all_gather_into_tensor_440 = None
        permute_388 = torch.ops.aten.permute.default(wait_tensor_540, [1, 0]);  wait_tensor_540 = None
        permute_446 = torch.ops.aten.permute.default(permute_388, [1, 0]);  permute_388 = None
        mm_229 = torch.ops.aten.mm.default(view_1790, permute_446);  view_1790 = permute_446 = None
        view_1791 = torch.ops.aten.view.default(mm_229, [2, 4096, 512]);  mm_229 = None
        convert_element_type_1505 = torch.ops.prims.convert_element_type.default(mm_228, torch.float32);  mm_228 = None
        reduce_scatter_tensor_11 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1505, 'avg', 128, '0');  convert_element_type_1505 = None
        wait_tensor_572 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_11);  reduce_scatter_tensor_11 = None
        convert_element_type_1506 = torch.ops.prims.convert_element_type.default(view_1791, torch.float32);  view_1791 = None
        convert_element_type_1400 = torch.ops.prims.convert_element_type.default(primals_426, torch.bfloat16);  primals_426 = None
        all_gather_into_tensor_439 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1400, 128, '0');  convert_element_type_1400 = None
        wait_tensor_539 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_439);  all_gather_into_tensor_439 = None
        convert_element_type_1508 = torch.ops.prims.convert_element_type.default(wait_tensor_539, torch.float32);  wait_tensor_539 = None
        mul_1311 = torch.ops.aten.mul.Tensor(convert_element_type_1506, convert_element_type_1508);  convert_element_type_1508 = None
        convert_element_type_1401 = torch.ops.prims.convert_element_type.default(getitem_2761, torch.float32);  getitem_2761 = None
        mul_1238 = torch.ops.aten.mul.Tensor(convert_element_type_1401, rsqrt_79);  convert_element_type_1401 = None
        mul_1313 = torch.ops.aten.mul.Tensor(mul_1238, mul_1311)
        sum_111 = torch.ops.aten.sum.dim_IntList(mul_1313, [2], True);  mul_1313 = None
        div_136 = torch.ops.aten.div.Tensor(mul_1238, 512)
        mul_1314 = torch.ops.aten.mul.Tensor(div_136, sum_111);  div_136 = sum_111 = None
        sub_629 = torch.ops.aten.sub.Tensor(mul_1311, mul_1314);  mul_1311 = mul_1314 = None
        mul_1315 = torch.ops.aten.mul.Tensor(sub_629, rsqrt_79);  sub_629 = rsqrt_79 = None
        mul_1316 = torch.ops.aten.mul.Tensor(convert_element_type_1506, mul_1238);  convert_element_type_1506 = mul_1238 = None
        sum_112 = torch.ops.aten.sum.dim_IntList(mul_1316, [0, 1]);  mul_1316 = None
        convert_element_type_1509 = torch.ops.prims.convert_element_type.default(mul_1315, torch.bfloat16);  mul_1315 = None
        convert_element_type_default_80 = torch.ops.prims.convert_element_type.default(sum_112, torch.float32);  sum_112 = None
        reduce_scatter_tensor_12 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_80, 'avg', 128, '0');  convert_element_type_default_80 = None
        wait_tensor_573 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_12);  reduce_scatter_tensor_12 = None
        convert_element_type_1512 = torch.ops.prims.convert_element_type.default(sum_110, torch.float32);  sum_110 = None
        view_1792 = torch.ops.aten.view.default(convert_element_type_1512, [2, 4096, 1, 32, 2]);  convert_element_type_1512 = None
        view_as_complex_54 = torch.ops.aten.view_as_complex.default(view_1792);  view_1792 = None
        view_7 = torch.ops.aten.view.default(primals_3, [1, 4096, 1, 32]);  primals_3 = None
        _conj = torch.ops.aten._conj.default(view_7);  view_7 = None
        clone_9 = torch.ops.aten.clone.default(_conj);  _conj = None
        mul_1317 = torch.ops.aten.mul.Tensor(view_as_complex_54, clone_9);  view_as_complex_54 = None
        view_as_real_54 = torch.ops.aten.view_as_real.default(mul_1317);  mul_1317 = None
        view_1793 = torch.ops.aten.view.default(view_as_real_54, [2, 4096, 1, 64]);  view_as_real_54 = None
        convert_element_type_1513 = torch.ops.prims.convert_element_type.default(view_1793, torch.bfloat16);  view_1793 = None
        squeeze_26 = torch.ops.aten.squeeze.dim(convert_element_type_1513, 2);  convert_element_type_1513 = None
        cat_241 = torch.ops.aten.cat.default([convert_element_type_1509, squeeze_26], 2);  convert_element_type_1509 = squeeze_26 = None
        view_1794 = torch.ops.aten.view.default(cat_241, [8192, 576]);  cat_241 = None
        permute_448 = torch.ops.aten.permute.default(view_1794, [1, 0])
        mm_230 = torch.ops.aten.mm.default(permute_448, view_1711);  permute_448 = None
        convert_element_type_1395 = torch.ops.prims.convert_element_type.default(primals_425, torch.bfloat16);  primals_425 = None
        all_gather_into_tensor_438 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1395, 128, '0');  convert_element_type_1395 = None
        wait_tensor_538 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_438);  all_gather_into_tensor_438 = None
        slice_157 = torch.ops.aten.slice.Tensor(wait_tensor_538, 0, 0, 576);  wait_tensor_538 = None
        permute_387 = torch.ops.aten.permute.default(slice_157, [1, 0]);  slice_157 = None
        permute_450 = torch.ops.aten.permute.default(permute_387, [1, 0]);  permute_387 = None
        mm_231 = torch.ops.aten.mm.default(view_1794, permute_450);  view_1794 = permute_450 = None
        view_1795 = torch.ops.aten.view.default(mm_231, [2, 4096, 2048]);  mm_231 = None
        convert_element_type_1518 = torch.ops.prims.convert_element_type.default(mm_230, torch.float32);  mm_230 = None
        split_208 = torch.ops.aten.split.Tensor(convert_element_type_1518, 5);  convert_element_type_1518 = None
        getitem_3753 = split_208[0]
        getitem_3754 = split_208[1]
        getitem_3755 = split_208[2]
        getitem_3756 = split_208[3]
        getitem_3757 = split_208[4]
        getitem_3758 = split_208[5]
        getitem_3759 = split_208[6]
        getitem_3760 = split_208[7]
        getitem_3761 = split_208[8]
        getitem_3762 = split_208[9]
        getitem_3763 = split_208[10]
        getitem_3764 = split_208[11]
        getitem_3765 = split_208[12]
        getitem_3766 = split_208[13]
        getitem_3767 = split_208[14]
        getitem_3768 = split_208[15]
        getitem_3769 = split_208[16]
        getitem_3770 = split_208[17]
        getitem_3771 = split_208[18]
        getitem_3772 = split_208[19]
        getitem_3773 = split_208[20]
        getitem_3774 = split_208[21]
        getitem_3775 = split_208[22]
        getitem_3776 = split_208[23]
        getitem_3777 = split_208[24]
        getitem_3778 = split_208[25]
        getitem_3779 = split_208[26]
        getitem_3780 = split_208[27]
        getitem_3781 = split_208[28]
        getitem_3782 = split_208[29]
        getitem_3783 = split_208[30]
        getitem_3784 = split_208[31]
        getitem_3785 = split_208[32]
        getitem_3786 = split_208[33]
        getitem_3787 = split_208[34]
        getitem_3788 = split_208[35]
        getitem_3789 = split_208[36]
        getitem_3790 = split_208[37]
        getitem_3791 = split_208[38]
        getitem_3792 = split_208[39]
        getitem_3793 = split_208[40]
        getitem_3794 = split_208[41]
        getitem_3795 = split_208[42]
        getitem_3796 = split_208[43]
        getitem_3797 = split_208[44]
        getitem_3798 = split_208[45]
        getitem_3799 = split_208[46]
        getitem_3800 = split_208[47]
        getitem_3801 = split_208[48]
        getitem_3802 = split_208[49]
        getitem_3803 = split_208[50]
        getitem_3804 = split_208[51]
        getitem_3805 = split_208[52]
        getitem_3806 = split_208[53]
        getitem_3807 = split_208[54]
        getitem_3808 = split_208[55]
        getitem_3809 = split_208[56]
        getitem_3810 = split_208[57]
        getitem_3811 = split_208[58]
        getitem_3812 = split_208[59]
        getitem_3813 = split_208[60]
        getitem_3814 = split_208[61]
        getitem_3815 = split_208[62]
        getitem_3816 = split_208[63]
        getitem_3817 = split_208[64]
        getitem_3818 = split_208[65]
        getitem_3819 = split_208[66]
        getitem_3820 = split_208[67]
        getitem_3821 = split_208[68]
        getitem_3822 = split_208[69]
        getitem_3823 = split_208[70]
        getitem_3824 = split_208[71]
        getitem_3825 = split_208[72]
        getitem_3826 = split_208[73]
        getitem_3827 = split_208[74]
        getitem_3828 = split_208[75]
        getitem_3829 = split_208[76]
        getitem_3830 = split_208[77]
        getitem_3831 = split_208[78]
        getitem_3832 = split_208[79]
        getitem_3833 = split_208[80]
        getitem_3834 = split_208[81]
        getitem_3835 = split_208[82]
        getitem_3836 = split_208[83]
        getitem_3837 = split_208[84]
        getitem_3838 = split_208[85]
        getitem_3839 = split_208[86]
        getitem_3840 = split_208[87]
        getitem_3841 = split_208[88]
        getitem_3842 = split_208[89]
        getitem_3843 = split_208[90]
        getitem_3844 = split_208[91]
        getitem_3845 = split_208[92]
        getitem_3846 = split_208[93]
        getitem_3847 = split_208[94]
        getitem_3848 = split_208[95]
        getitem_3849 = split_208[96]
        getitem_3850 = split_208[97]
        getitem_3851 = split_208[98]
        getitem_3852 = split_208[99]
        getitem_3853 = split_208[100]
        getitem_3854 = split_208[101]
        getitem_3855 = split_208[102]
        getitem_3856 = split_208[103]
        getitem_3857 = split_208[104]
        getitem_3858 = split_208[105]
        getitem_3859 = split_208[106]
        getitem_3860 = split_208[107]
        getitem_3861 = split_208[108]
        getitem_3862 = split_208[109]
        getitem_3863 = split_208[110]
        getitem_3864 = split_208[111]
        getitem_3865 = split_208[112]
        getitem_3866 = split_208[113]
        getitem_3867 = split_208[114]
        getitem_3868 = split_208[115];  split_208 = None
        constant_pad_nd_64 = torch.ops.aten.constant_pad_nd.default(getitem_3868, [0, 0, 0, 4], 0.0);  getitem_3868 = None
        constant_pad_nd_65 = torch.ops.aten.constant_pad_nd.default(full_default_54, [0, 0, 0, 5], 0.0);  full_default_54 = None
        cat_242 = torch.ops.aten.cat.default([getitem_3753, getitem_3754, getitem_3755, getitem_3756, getitem_3757, getitem_3758, getitem_3759, getitem_3760, getitem_3761, getitem_3762, getitem_3763, getitem_3764, getitem_3765, getitem_3766, getitem_3767, getitem_3768, getitem_3769, getitem_3770, getitem_3771, getitem_3772, getitem_3773, getitem_3774, getitem_3775, getitem_3776, getitem_3777, getitem_3778, getitem_3779, getitem_3780, getitem_3781, getitem_3782, getitem_3783, getitem_3784, getitem_3785, getitem_3786, getitem_3787, getitem_3788, getitem_3789, getitem_3790, getitem_3791, getitem_3792, getitem_3793, getitem_3794, getitem_3795, getitem_3796, getitem_3797, getitem_3798, getitem_3799, getitem_3800, getitem_3801, getitem_3802, getitem_3803, getitem_3804, getitem_3805, getitem_3806, getitem_3807, getitem_3808, getitem_3809, getitem_3810, getitem_3811, getitem_3812, getitem_3813, getitem_3814, getitem_3815, getitem_3816, getitem_3817, getitem_3818, getitem_3819, getitem_3820, getitem_3821, getitem_3822, getitem_3823, getitem_3824, getitem_3825, getitem_3826, getitem_3827, getitem_3828, getitem_3829, getitem_3830, getitem_3831, getitem_3832, getitem_3833, getitem_3834, getitem_3835, getitem_3836, getitem_3837, getitem_3838, getitem_3839, getitem_3840, getitem_3841, getitem_3842, getitem_3843, getitem_3844, getitem_3845, getitem_3846, getitem_3847, getitem_3848, getitem_3849, getitem_3850, getitem_3851, getitem_3852, getitem_3853, getitem_3854, getitem_3855, getitem_3856, getitem_3857, getitem_3858, getitem_3859, getitem_3860, getitem_3861, getitem_3862, getitem_3863, getitem_3864, getitem_3865, getitem_3866, getitem_3867, constant_pad_nd_64, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_3753 = getitem_3754 = getitem_3755 = getitem_3756 = getitem_3757 = getitem_3758 = getitem_3759 = getitem_3760 = getitem_3761 = getitem_3762 = getitem_3763 = getitem_3764 = getitem_3765 = getitem_3766 = getitem_3767 = getitem_3768 = getitem_3769 = getitem_3770 = getitem_3771 = getitem_3772 = getitem_3773 = getitem_3774 = getitem_3775 = getitem_3776 = getitem_3777 = getitem_3778 = getitem_3779 = getitem_3780 = getitem_3781 = getitem_3782 = getitem_3783 = getitem_3784 = getitem_3785 = getitem_3786 = getitem_3787 = getitem_3788 = getitem_3789 = getitem_3790 = getitem_3791 = getitem_3792 = getitem_3793 = getitem_3794 = getitem_3795 = getitem_3796 = getitem_3797 = getitem_3798 = getitem_3799 = getitem_3800 = getitem_3801 = getitem_3802 = getitem_3803 = getitem_3804 = getitem_3805 = getitem_3806 = getitem_3807 = getitem_3808 = getitem_3809 = getitem_3810 = getitem_3811 = getitem_3812 = getitem_3813 = getitem_3814 = getitem_3815 = getitem_3816 = getitem_3817 = getitem_3818 = getitem_3819 = getitem_3820 = getitem_3821 = getitem_3822 = getitem_3823 = getitem_3824 = getitem_3825 = getitem_3826 = getitem_3827 = getitem_3828 = getitem_3829 = getitem_3830 = getitem_3831 = getitem_3832 = getitem_3833 = getitem_3834 = getitem_3835 = getitem_3836 = getitem_3837 = getitem_3838 = getitem_3839 = getitem_3840 = getitem_3841 = getitem_3842 = getitem_3843 = getitem_3844 = getitem_3845 = getitem_3846 = getitem_3847 = getitem_3848 = getitem_3849 = getitem_3850 = getitem_3851 = getitem_3852 = getitem_3853 = getitem_3854 = getitem_3855 = getitem_3856 = getitem_3857 = getitem_3858 = getitem_3859 = getitem_3860 = getitem_3861 = getitem_3862 = getitem_3863 = getitem_3864 = getitem_3865 = getitem_3866 = getitem_3867 = constant_pad_nd_64 = None
        reduce_scatter_tensor_13 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_242, 'avg', 128, '0');  cat_242 = None
        wait_tensor_574 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_13);  reduce_scatter_tensor_13 = None
        slice_166 = torch.ops.aten.slice.Tensor(permute_443, 3, 0, 128)
        slice_167 = torch.ops.aten.slice.Tensor(permute_443, 3, 128, 192);  permute_443 = None
        convert_element_type_1519 = torch.ops.prims.convert_element_type.default(slice_167, torch.float32);  slice_167 = None
        view_1796 = torch.ops.aten.view.default(convert_element_type_1519, [2, 4096, 16, 32, 2]);  convert_element_type_1519 = None
        view_as_complex_55 = torch.ops.aten.view_as_complex.default(view_1796);  view_1796 = None
        mul_1318 = torch.ops.aten.mul.Tensor(view_as_complex_55, clone_9);  view_as_complex_55 = None
        view_as_real_55 = torch.ops.aten.view_as_real.default(mul_1318);  mul_1318 = None
        view_1797 = torch.ops.aten.view.default(view_as_real_55, [2, 4096, 16, 64]);  view_as_real_55 = None
        convert_element_type_1520 = torch.ops.prims.convert_element_type.default(view_1797, torch.bfloat16);  view_1797 = None
        cat_243 = torch.ops.aten.cat.default([slice_166, convert_element_type_1520], 3);  slice_166 = convert_element_type_1520 = None
        view_1798 = torch.ops.aten.view.default(cat_243, [2, 4096, 3072]);  cat_243 = None
        view_1799 = torch.ops.aten.view.default(view_1798, [8192, 3072]);  view_1798 = None
        permute_452 = torch.ops.aten.permute.default(view_1799, [1, 0])
        mm_232 = torch.ops.aten.mm.default(permute_452, view_1711);  permute_452 = view_1711 = None
        convert_element_type_1390 = torch.ops.prims.convert_element_type.default(primals_424, torch.bfloat16);  primals_424 = None
        all_gather_into_tensor_437 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1390, 128, '0');  convert_element_type_1390 = None
        wait_tensor_537 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_437);  all_gather_into_tensor_437 = None
        permute_386 = torch.ops.aten.permute.default(wait_tensor_537, [1, 0]);  wait_tensor_537 = None
        permute_454 = torch.ops.aten.permute.default(permute_386, [1, 0]);  permute_386 = None
        mm_233 = torch.ops.aten.mm.default(view_1799, permute_454);  view_1799 = permute_454 = None
        view_1800 = torch.ops.aten.view.default(mm_233, [2, 4096, 2048]);  mm_233 = None
        add_1788 = torch.ops.aten.add.Tensor(view_1795, view_1800);  view_1795 = view_1800 = None
        convert_element_type_1525 = torch.ops.prims.convert_element_type.default(mm_232, torch.float32);  mm_232 = None
        reduce_scatter_tensor_14 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1525, 'avg', 128, '0');  convert_element_type_1525 = None
        wait_tensor_575 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_14);  reduce_scatter_tensor_14 = None
        convert_element_type_1526 = torch.ops.prims.convert_element_type.default(add_1788, torch.float32);  add_1788 = None
        convert_element_type_1387 = torch.ops.prims.convert_element_type.default(primals_423, torch.bfloat16);  primals_423 = None
        all_gather_into_tensor_436 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1387, 128, '0');  convert_element_type_1387 = None
        wait_tensor_536 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_436);  all_gather_into_tensor_436 = None
        convert_element_type_1528 = torch.ops.prims.convert_element_type.default(wait_tensor_536, torch.float32);  wait_tensor_536 = None
        mul_1319 = torch.ops.aten.mul.Tensor(convert_element_type_1526, convert_element_type_1528);  convert_element_type_1528 = None
        convert_element_type_1388 = torch.ops.prims.convert_element_type.default(add_1705, torch.float32);  add_1705 = None
        mul_1234 = torch.ops.aten.mul.Tensor(convert_element_type_1388, rsqrt_78);  convert_element_type_1388 = None
        mul_1321 = torch.ops.aten.mul.Tensor(mul_1234, mul_1319)
        sum_113 = torch.ops.aten.sum.dim_IntList(mul_1321, [2], True);  mul_1321 = None
        div_137 = torch.ops.aten.div.Tensor(mul_1234, 2048)
        mul_1322 = torch.ops.aten.mul.Tensor(div_137, sum_113);  div_137 = sum_113 = None
        sub_630 = torch.ops.aten.sub.Tensor(mul_1319, mul_1322);  mul_1319 = mul_1322 = None
        mul_1323 = torch.ops.aten.mul.Tensor(sub_630, rsqrt_78);  sub_630 = rsqrt_78 = None
        mul_1324 = torch.ops.aten.mul.Tensor(convert_element_type_1526, mul_1234);  convert_element_type_1526 = mul_1234 = None
        sum_114 = torch.ops.aten.sum.dim_IntList(mul_1324, [0, 1]);  mul_1324 = None
        convert_element_type_1529 = torch.ops.prims.convert_element_type.default(mul_1323, torch.bfloat16);  mul_1323 = None
        add_1789 = torch.ops.aten.add.Tensor(add_1787, convert_element_type_1529);  add_1787 = convert_element_type_1529 = None
        convert_element_type_default_79 = torch.ops.prims.convert_element_type.default(sum_114, torch.float32);  sum_114 = None
        reduce_scatter_tensor_15 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_79, 'avg', 128, '0');  convert_element_type_default_79 = None
        wait_tensor_576 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_15);  reduce_scatter_tensor_15 = None
        view_1801 = torch.ops.aten.view.default(add_1789, [8192, 2048])
        unsqueeze_54 = torch.ops.aten.unsqueeze.default(view_1801, 1)
        convert_element_type_1532 = torch.ops.prims.convert_element_type.default(unsqueeze_54, torch.float32);  unsqueeze_54 = None
        bmm_28 = torch.ops.aten.bmm.default(permute_456, convert_element_type_1532);  permute_456 = None
        bmm_29 = torch.ops.aten.bmm.default(convert_element_type_1532, permute_457);  convert_element_type_1532 = permute_457 = None
        convert_element_type_1533 = torch.ops.prims.convert_element_type.default(bmm_28, torch.bfloat16);  bmm_28 = None
        view_1802 = torch.ops.aten.view.default(bmm_29, [8192, 6]);  bmm_29 = None
        view_1803 = torch.ops.aten.view.default(convert_element_type_1533, [49152, 2048]);  convert_element_type_1533 = None
        index_54 = torch.ops.aten.index.Tensor(view_1803, [getitem_2661]);  view_1803 = getitem_2661 = None
        permute_458 = torch.ops.aten.permute.default(view_1801, [1, 0])
        mm_234 = torch.ops.aten.mm.default(permute_458, mul_1231);  permute_458 = mul_1231 = None
        convert_element_type_1382 = torch.ops.prims.convert_element_type.default(primals_422, torch.bfloat16);  primals_422 = None
        all_gather_into_tensor_435 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1382, 128, '0');  convert_element_type_1382 = None
        wait_tensor_535 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_435);  all_gather_into_tensor_435 = None
        permute_385 = torch.ops.aten.permute.default(wait_tensor_535, [1, 0]);  wait_tensor_535 = None
        permute_460 = torch.ops.aten.permute.default(permute_385, [1, 0]);  permute_385 = None
        mm_235 = torch.ops.aten.mm.default(view_1801, permute_460);  view_1801 = permute_460 = None
        convert_element_type_1538 = torch.ops.prims.convert_element_type.default(mm_234, torch.float32);  mm_234 = None
        reduce_scatter_tensor_16 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1538, 'avg', 128, '0');  convert_element_type_1538 = None
        wait_tensor_577 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_16);  reduce_scatter_tensor_16 = None
        convert_element_type_1377 = torch.ops.prims.convert_element_type.default(mm_204, torch.float32);  mm_204 = None
        neg_50 = torch.ops.aten.neg.default(convert_element_type_1377)
        exp_75 = torch.ops.aten.exp.default(neg_50);  neg_50 = None
        add_1700 = torch.ops.aten.add.Tensor(exp_75, 1);  exp_75 = None
        div_125 = torch.ops.aten.div.Tensor(convert_element_type_1377, add_1700)
        convert_element_type_1378 = torch.ops.prims.convert_element_type.default(div_125, torch.bfloat16);  div_125 = None
        mul_1325 = torch.ops.aten.mul.Tensor(mm_235, convert_element_type_1378);  convert_element_type_1378 = None
        mul_1326 = torch.ops.aten.mul.Tensor(mm_235, mm_205);  mm_235 = mm_205 = None
        permute_462 = torch.ops.aten.permute.default(mul_1325, [1, 0])
        mm_236 = torch.ops.aten.mm.default(permute_462, view_1666);  permute_462 = None
        convert_element_type_1379 = torch.ops.prims.convert_element_type.default(primals_421, torch.bfloat16);  primals_421 = None
        all_gather_into_tensor_434 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1379, 128, '0');  convert_element_type_1379 = None
        wait_tensor_534 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_434);  all_gather_into_tensor_434 = None
        permute_384 = torch.ops.aten.permute.default(wait_tensor_534, [1, 0]);  wait_tensor_534 = None
        permute_464 = torch.ops.aten.permute.default(permute_384, [1, 0]);  permute_384 = None
        mm_237 = torch.ops.aten.mm.default(mul_1325, permute_464);  mul_1325 = permute_464 = None
        convert_element_type_1543 = torch.ops.prims.convert_element_type.default(mm_236, torch.float32);  mm_236 = None
        reduce_scatter_tensor_17 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1543, 'avg', 128, '0');  convert_element_type_1543 = None
        wait_tensor_578 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_17);  reduce_scatter_tensor_17 = None
        convert_element_type_1544 = torch.ops.prims.convert_element_type.default(mul_1326, torch.float32);  mul_1326 = None
        reciprocal_2 = torch.ops.aten.reciprocal.default(add_1700);  add_1700 = None
        mul_1327 = torch.ops.aten.mul.Tensor(reciprocal_2, 1);  reciprocal_2 = None
        mul_1328 = torch.ops.aten.mul.Tensor(convert_element_type_1544, mul_1327);  convert_element_type_1544 = None
        sub_631 = torch.ops.aten.sub.Tensor(1, mul_1327);  mul_1327 = None
        mul_1329 = torch.ops.aten.mul.Tensor(convert_element_type_1377, sub_631);  convert_element_type_1377 = sub_631 = None
        add_1791 = torch.ops.aten.add.Tensor(mul_1329, 1);  mul_1329 = None
        mul_1330 = torch.ops.aten.mul.Tensor(mul_1328, add_1791);  mul_1328 = add_1791 = None
        convert_element_type_1546 = torch.ops.prims.convert_element_type.default(mul_1330, torch.bfloat16);  mul_1330 = None
        permute_466 = torch.ops.aten.permute.default(convert_element_type_1546, [1, 0])
        mm_238 = torch.ops.aten.mm.default(permute_466, view_1666);  permute_466 = None
        convert_element_type_1374 = torch.ops.prims.convert_element_type.default(primals_420, torch.bfloat16);  primals_420 = None
        all_gather_into_tensor_433 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1374, 128, '0');  convert_element_type_1374 = None
        wait_tensor_533 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_433);  all_gather_into_tensor_433 = None
        permute_383 = torch.ops.aten.permute.default(wait_tensor_533, [1, 0]);  wait_tensor_533 = None
        permute_468 = torch.ops.aten.permute.default(permute_383, [1, 0]);  permute_383 = None
        mm_239 = torch.ops.aten.mm.default(convert_element_type_1546, permute_468);  convert_element_type_1546 = permute_468 = None
        add_1792 = torch.ops.aten.add.Tensor(mm_237, mm_239);  mm_237 = mm_239 = None
        convert_element_type_1551 = torch.ops.prims.convert_element_type.default(mm_238, torch.float32);  mm_238 = None
        reduce_scatter_tensor_18 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1551, 'avg', 128, '0');  convert_element_type_1551 = None
        wait_tensor_579 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_18);  reduce_scatter_tensor_18 = None
        all_to_all_single_80 = torch.ops._c10d_functional.all_to_all_single.default(index_54, [_local_scalar_dense_392, _local_scalar_dense_393, _local_scalar_dense_394, _local_scalar_dense_395, _local_scalar_dense_396, _local_scalar_dense_397, _local_scalar_dense_398, _local_scalar_dense_399], [_local_scalar_dense_384, _local_scalar_dense_385, _local_scalar_dense_386, _local_scalar_dense_387, _local_scalar_dense_388, _local_scalar_dense_389, _local_scalar_dense_390, _local_scalar_dense_391], '1033');  index_54 = None
        wait_tensor_580 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_80);  all_to_all_single_80 = None
        full_354 = torch.ops.aten.full.default([sym_size_int_97, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_97 = None
        slice_scatter_1 = torch.ops.aten.slice_scatter.default(full_354, wait_tensor_580, 0, 0, -1);  wait_tensor_580 = None
        index_55 = torch.ops.aten.index.Tensor(slice_scatter_1, [getitem_2662]);  slice_scatter_1 = None
        permute_470 = torch.ops.aten.permute.default(index_55, [1, 0])
        _grouped_mm_84 = torch.ops.aten._grouped_mm.default(permute_470, mul_1211, cumsum_74);  permute_470 = mul_1211 = None
        _grouped_mm_85 = torch.ops.aten._grouped_mm.default(index_55, permute_472, cumsum_74);  index_55 = permute_472 = None
        convert_element_type_1372 = torch.ops.prims.convert_element_type.default(_grouped_mm_72, torch.float32);  _grouped_mm_72 = None
        neg_49 = torch.ops.aten.neg.default(convert_element_type_1372)
        exp_74 = torch.ops.aten.exp.default(neg_49);  neg_49 = None
        add_1664 = torch.ops.aten.add.Tensor(exp_74, 1);  exp_74 = None
        div_124 = torch.ops.aten.div.Tensor(convert_element_type_1372, add_1664)
        convert_element_type_1373 = torch.ops.prims.convert_element_type.default(div_124, torch.bfloat16);  div_124 = None
        mul_1331 = torch.ops.aten.mul.Tensor(_grouped_mm_85, convert_element_type_1373);  convert_element_type_1373 = None
        mul_1332 = torch.ops.aten.mul.Tensor(_grouped_mm_85, _grouped_mm_73);  _grouped_mm_85 = _grouped_mm_73 = None
        permute_474 = torch.ops.aten.permute.default(mul_1331, [1, 0])
        _grouped_mm_86 = torch.ops.aten._grouped_mm.default(permute_474, index_49, cumsum_74);  permute_474 = None
        _grouped_mm_87 = torch.ops.aten._grouped_mm.default(mul_1331, permute_476, cumsum_74);  mul_1331 = permute_476 = None
        convert_element_type_1552 = torch.ops.prims.convert_element_type.default(mul_1332, torch.float32);  mul_1332 = None
        reciprocal_3 = torch.ops.aten.reciprocal.default(add_1664);  add_1664 = None
        mul_1333 = torch.ops.aten.mul.Tensor(reciprocal_3, 1);  reciprocal_3 = None
        mul_1334 = torch.ops.aten.mul.Tensor(convert_element_type_1552, mul_1333);  convert_element_type_1552 = None
        sub_632 = torch.ops.aten.sub.Tensor(1, mul_1333);  mul_1333 = None
        mul_1335 = torch.ops.aten.mul.Tensor(convert_element_type_1372, sub_632);  convert_element_type_1372 = sub_632 = None
        add_1794 = torch.ops.aten.add.Tensor(mul_1335, 1);  mul_1335 = None
        mul_1336 = torch.ops.aten.mul.Tensor(mul_1334, add_1794);  mul_1334 = add_1794 = None
        convert_element_type_1554 = torch.ops.prims.convert_element_type.default(mul_1336, torch.bfloat16);  mul_1336 = None
        permute_478 = torch.ops.aten.permute.default(convert_element_type_1554, [1, 0])
        _grouped_mm_88 = torch.ops.aten._grouped_mm.default(permute_478, index_49, cumsum_74);  permute_478 = index_49 = None
        _grouped_mm_89 = torch.ops.aten._grouped_mm.default(convert_element_type_1554, permute_480, cumsum_74);  convert_element_type_1554 = permute_480 = cumsum_74 = None
        add_1795 = torch.ops.aten.add.Tensor(_grouped_mm_87, _grouped_mm_89);  _grouped_mm_87 = _grouped_mm_89 = None
        convert_element_type_1555 = torch.ops.prims.convert_element_type.default(_grouped_mm_86, torch.float32);  _grouped_mm_86 = None
        div_138 = torch.ops.aten.div.Tensor(convert_element_type_1555, 128);  convert_element_type_1555 = None
        split_210 = torch.ops.aten.split.Tensor(div_138, 88, 1);  div_138 = None
        getitem_3885 = split_210[0]
        getitem_3902 = split_210[1]
        getitem_3919 = split_210[2]
        getitem_3936 = split_210[3]
        getitem_3953 = split_210[4]
        getitem_3970 = split_210[5]
        getitem_3987 = split_210[6]
        getitem_4004 = split_210[7]
        getitem_4021 = split_210[8]
        getitem_4038 = split_210[9]
        getitem_4055 = split_210[10]
        getitem_4072 = split_210[11]
        getitem_4089 = split_210[12]
        getitem_4106 = split_210[13]
        getitem_4123 = split_210[14]
        getitem_4140 = split_210[15];  split_210 = None
        cat_244 = torch.ops.aten.cat.default([getitem_3885, getitem_3902, getitem_3919, getitem_3936, getitem_3953, getitem_3970, getitem_3987, getitem_4004, getitem_4021, getitem_4038, getitem_4055, getitem_4072, getitem_4089, getitem_4106, getitem_4123, getitem_4140]);  getitem_3885 = getitem_3902 = getitem_3919 = getitem_3936 = getitem_3953 = getitem_3970 = getitem_3987 = getitem_4004 = getitem_4021 = getitem_4038 = getitem_4055 = getitem_4072 = getitem_4089 = getitem_4106 = getitem_4123 = getitem_4140 = None
        reduce_scatter_tensor_19 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_244, 'sum', 16, '1025');  cat_244 = None
        wait_tensor_581 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_19);  reduce_scatter_tensor_19 = None
        convert_element_type_1556 = torch.ops.prims.convert_element_type.default(_grouped_mm_84, torch.float32);  _grouped_mm_84 = None
        div_139 = torch.ops.aten.div.Tensor(convert_element_type_1556, 128);  convert_element_type_1556 = None
        split_227 = torch.ops.aten.split.Tensor(div_139, 128, 1);  div_139 = None
        getitem_4157 = split_227[0]
        getitem_4174 = split_227[1]
        getitem_4191 = split_227[2]
        getitem_4208 = split_227[3]
        getitem_4225 = split_227[4]
        getitem_4242 = split_227[5]
        getitem_4259 = split_227[6]
        getitem_4276 = split_227[7]
        getitem_4293 = split_227[8]
        getitem_4310 = split_227[9]
        getitem_4327 = split_227[10]
        getitem_4344 = split_227[11]
        getitem_4361 = split_227[12]
        getitem_4378 = split_227[13]
        getitem_4395 = split_227[14]
        getitem_4412 = split_227[15];  split_227 = None
        cat_245 = torch.ops.aten.cat.default([getitem_4157, getitem_4174, getitem_4191, getitem_4208, getitem_4225, getitem_4242, getitem_4259, getitem_4276, getitem_4293, getitem_4310, getitem_4327, getitem_4344, getitem_4361, getitem_4378, getitem_4395, getitem_4412]);  getitem_4157 = getitem_4174 = getitem_4191 = getitem_4208 = getitem_4225 = getitem_4242 = getitem_4259 = getitem_4276 = getitem_4293 = getitem_4310 = getitem_4327 = getitem_4344 = getitem_4361 = getitem_4378 = getitem_4395 = getitem_4412 = None
        reduce_scatter_tensor_20 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_245, 'sum', 16, '1025');  cat_245 = None
        wait_tensor_582 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_20);  reduce_scatter_tensor_20 = None
        convert_element_type_1557 = torch.ops.prims.convert_element_type.default(_grouped_mm_88, torch.float32);  _grouped_mm_88 = None
        div_140 = torch.ops.aten.div.Tensor(convert_element_type_1557, 128);  convert_element_type_1557 = None
        split_244 = torch.ops.aten.split.Tensor(div_140, 88, 1);  div_140 = None
        getitem_4429 = split_244[0]
        getitem_4446 = split_244[1]
        getitem_4463 = split_244[2]
        getitem_4480 = split_244[3]
        getitem_4497 = split_244[4]
        getitem_4514 = split_244[5]
        getitem_4531 = split_244[6]
        getitem_4548 = split_244[7]
        getitem_4565 = split_244[8]
        getitem_4582 = split_244[9]
        getitem_4599 = split_244[10]
        getitem_4616 = split_244[11]
        getitem_4633 = split_244[12]
        getitem_4650 = split_244[13]
        getitem_4667 = split_244[14]
        getitem_4684 = split_244[15];  split_244 = None
        cat_246 = torch.ops.aten.cat.default([getitem_4429, getitem_4446, getitem_4463, getitem_4480, getitem_4497, getitem_4514, getitem_4531, getitem_4548, getitem_4565, getitem_4582, getitem_4599, getitem_4616, getitem_4633, getitem_4650, getitem_4667, getitem_4684]);  getitem_4429 = getitem_4446 = getitem_4463 = getitem_4480 = getitem_4497 = getitem_4514 = getitem_4531 = getitem_4548 = getitem_4565 = getitem_4582 = getitem_4599 = getitem_4616 = getitem_4633 = getitem_4650 = getitem_4667 = getitem_4684 = None
        reduce_scatter_tensor_21 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_246, 'sum', 16, '1025');  cat_246 = None
        wait_tensor_583 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_21);  reduce_scatter_tensor_21 = None
        index_put_54 = torch.ops.aten.index_put.default(full_354, [getitem_2662], add_1795, True);  full_354 = getitem_2662 = add_1795 = None
        slice_168 = torch.ops.aten.slice.Tensor(index_put_54, 0, 0, add_1796);  index_put_54 = add_1796 = None
        all_to_all_single_81 = torch.ops._c10d_functional.all_to_all_single.default(slice_168, [_local_scalar_dense_384, _local_scalar_dense_385, _local_scalar_dense_386, _local_scalar_dense_387, _local_scalar_dense_388, _local_scalar_dense_389, _local_scalar_dense_390, _local_scalar_dense_391], [_local_scalar_dense_392, _local_scalar_dense_393, _local_scalar_dense_394, _local_scalar_dense_395, _local_scalar_dense_396, _local_scalar_dense_397, _local_scalar_dense_398, _local_scalar_dense_399], '1033');  slice_168 = _local_scalar_dense_384 = _local_scalar_dense_385 = _local_scalar_dense_386 = _local_scalar_dense_387 = _local_scalar_dense_388 = _local_scalar_dense_389 = _local_scalar_dense_390 = _local_scalar_dense_391 = _local_scalar_dense_392 = _local_scalar_dense_393 = _local_scalar_dense_394 = _local_scalar_dense_395 = _local_scalar_dense_396 = _local_scalar_dense_397 = _local_scalar_dense_398 = _local_scalar_dense_399 = None
        wait_tensor_584 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_81);  all_to_all_single_81 = None
        index_put_55 = torch.ops.aten.index_put.default(full_default_52, [div_122], wait_tensor_584, True);  div_122 = wait_tensor_584 = None
        add_1800 = torch.ops.aten.add.Tensor(add_1792, index_put_55);  add_1792 = index_put_55 = None
        mul_1337 = torch.ops.aten.mul.Tensor(view_1802, 1.0);  view_1802 = None
        scatter_add_1 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_2659, mul_1337);  getitem_2659 = mul_1337 = None
        convert_element_type_1361 = torch.ops.prims.convert_element_type.default(mm_203, torch.float32);  mm_203 = None
        sub_576 = torch.ops.aten.sub.Tensor(convert_element_type_1361, amax_24);  convert_element_type_1361 = amax_24 = None
        exp_73 = torch.ops.aten.exp.default(sub_576);  sub_576 = None
        div_121 = torch.ops.aten.div.Tensor(exp_73, sum_97);  exp_73 = sum_97 = None
        mul_1338 = torch.ops.aten.mul.Tensor(scatter_add_1, div_121);  scatter_add_1 = None
        sum_115 = torch.ops.aten.sum.dim_IntList(mul_1338, [1], True)
        neg_58 = torch.ops.aten.neg.default(div_121);  div_121 = None
        fma_1 = torch.ops.prims.fma.default(neg_58, sum_115, mul_1338);  neg_58 = sum_115 = mul_1338 = None
        convert_element_type_1558 = torch.ops.prims.convert_element_type.default(fma_1, torch.bfloat16);  fma_1 = None
        permute_482 = torch.ops.aten.permute.default(convert_element_type_1558, [1, 0])
        mm_240 = torch.ops.aten.mm.default(permute_482, view_1666);  permute_482 = view_1666 = None
        convert_element_type_1358 = torch.ops.prims.convert_element_type.default(primals_415, torch.bfloat16);  primals_415 = None
        all_gather_into_tensor_426 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1358, 128, '0');  convert_element_type_1358 = None
        wait_tensor_522 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_426);  all_gather_into_tensor_426 = None
        slice_153 = torch.ops.aten.slice.Tensor(wait_tensor_522, 0, 0, 64);  wait_tensor_522 = None
        permute_379 = torch.ops.aten.permute.default(slice_153, [1, 0]);  slice_153 = None
        permute_484 = torch.ops.aten.permute.default(permute_379, [1, 0]);  permute_379 = None
        mm_241 = torch.ops.aten.mm.default(convert_element_type_1558, permute_484);  convert_element_type_1558 = permute_484 = None
        add_1801 = torch.ops.aten.add.Tensor(add_1800, mm_241);  add_1800 = mm_241 = None
        convert_element_type_1563 = torch.ops.prims.convert_element_type.default(mm_240, torch.float32);  mm_240 = None
        split_260 = torch.ops.aten.split.Tensor(convert_element_type_1563, 1);  convert_element_type_1563 = None
        getitem_4685 = split_260[0]
        getitem_4686 = split_260[1]
        getitem_4687 = split_260[2]
        getitem_4688 = split_260[3]
        getitem_4689 = split_260[4]
        getitem_4690 = split_260[5]
        getitem_4691 = split_260[6]
        getitem_4692 = split_260[7]
        getitem_4693 = split_260[8]
        getitem_4694 = split_260[9]
        getitem_4695 = split_260[10]
        getitem_4696 = split_260[11]
        getitem_4697 = split_260[12]
        getitem_4698 = split_260[13]
        getitem_4699 = split_260[14]
        getitem_4700 = split_260[15]
        getitem_4701 = split_260[16]
        getitem_4702 = split_260[17]
        getitem_4703 = split_260[18]
        getitem_4704 = split_260[19]
        getitem_4705 = split_260[20]
        getitem_4706 = split_260[21]
        getitem_4707 = split_260[22]
        getitem_4708 = split_260[23]
        getitem_4709 = split_260[24]
        getitem_4710 = split_260[25]
        getitem_4711 = split_260[26]
        getitem_4712 = split_260[27]
        getitem_4713 = split_260[28]
        getitem_4714 = split_260[29]
        getitem_4715 = split_260[30]
        getitem_4716 = split_260[31]
        getitem_4717 = split_260[32]
        getitem_4718 = split_260[33]
        getitem_4719 = split_260[34]
        getitem_4720 = split_260[35]
        getitem_4721 = split_260[36]
        getitem_4722 = split_260[37]
        getitem_4723 = split_260[38]
        getitem_4724 = split_260[39]
        getitem_4725 = split_260[40]
        getitem_4726 = split_260[41]
        getitem_4727 = split_260[42]
        getitem_4728 = split_260[43]
        getitem_4729 = split_260[44]
        getitem_4730 = split_260[45]
        getitem_4731 = split_260[46]
        getitem_4732 = split_260[47]
        getitem_4733 = split_260[48]
        getitem_4734 = split_260[49]
        getitem_4735 = split_260[50]
        getitem_4736 = split_260[51]
        getitem_4737 = split_260[52]
        getitem_4738 = split_260[53]
        getitem_4739 = split_260[54]
        getitem_4740 = split_260[55]
        getitem_4741 = split_260[56]
        getitem_4742 = split_260[57]
        getitem_4743 = split_260[58]
        getitem_4744 = split_260[59]
        getitem_4745 = split_260[60]
        getitem_4746 = split_260[61]
        getitem_4747 = split_260[62]
        getitem_4748 = split_260[63];  split_260 = None
        cat_247 = torch.ops.aten.cat.default([getitem_4685, getitem_4686, getitem_4687, getitem_4688, getitem_4689, getitem_4690, getitem_4691, getitem_4692, getitem_4693, getitem_4694, getitem_4695, getitem_4696, getitem_4697, getitem_4698, getitem_4699, getitem_4700, getitem_4701, getitem_4702, getitem_4703, getitem_4704, getitem_4705, getitem_4706, getitem_4707, getitem_4708, getitem_4709, getitem_4710, getitem_4711, getitem_4712, getitem_4713, getitem_4714, getitem_4715, getitem_4716, getitem_4717, getitem_4718, getitem_4719, getitem_4720, getitem_4721, getitem_4722, getitem_4723, getitem_4724, getitem_4725, getitem_4726, getitem_4727, getitem_4728, getitem_4729, getitem_4730, getitem_4731, getitem_4732, getitem_4733, getitem_4734, getitem_4735, getitem_4736, getitem_4737, getitem_4738, getitem_4739, getitem_4740, getitem_4741, getitem_4742, getitem_4743, getitem_4744, getitem_4745, getitem_4746, getitem_4747, getitem_4748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_4685 = getitem_4686 = getitem_4687 = getitem_4688 = getitem_4689 = getitem_4690 = getitem_4691 = getitem_4692 = getitem_4693 = getitem_4694 = getitem_4695 = getitem_4696 = getitem_4697 = getitem_4698 = getitem_4699 = getitem_4700 = getitem_4701 = getitem_4702 = getitem_4703 = getitem_4704 = getitem_4705 = getitem_4706 = getitem_4707 = getitem_4708 = getitem_4709 = getitem_4710 = getitem_4711 = getitem_4712 = getitem_4713 = getitem_4714 = getitem_4715 = getitem_4716 = getitem_4717 = getitem_4718 = getitem_4719 = getitem_4720 = getitem_4721 = getitem_4722 = getitem_4723 = getitem_4724 = getitem_4725 = getitem_4726 = getitem_4727 = getitem_4728 = getitem_4729 = getitem_4730 = getitem_4731 = getitem_4732 = getitem_4733 = getitem_4734 = getitem_4735 = getitem_4736 = getitem_4737 = getitem_4738 = getitem_4739 = getitem_4740 = getitem_4741 = getitem_4742 = getitem_4743 = getitem_4744 = getitem_4745 = getitem_4746 = getitem_4747 = getitem_4748 = None
        reduce_scatter_tensor_22 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_247, 'avg', 128, '0');  cat_247 = None
        wait_tensor_585 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_22);  reduce_scatter_tensor_22 = None
        view_1804 = torch.ops.aten.view.default(add_1801, [2, 4096, 2048]);  add_1801 = None
        convert_element_type_1564 = torch.ops.prims.convert_element_type.default(view_1804, torch.float32);  view_1804 = None
        convert_element_type_1355 = torch.ops.prims.convert_element_type.default(primals_413, torch.bfloat16);  primals_413 = None
        all_gather_into_tensor_425 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1355, 128, '0');  convert_element_type_1355 = None
        wait_tensor_521 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_425);  all_gather_into_tensor_425 = None
        convert_element_type_1566 = torch.ops.prims.convert_element_type.default(wait_tensor_521, torch.float32);  wait_tensor_521 = None
        mul_1339 = torch.ops.aten.mul.Tensor(convert_element_type_1564, convert_element_type_1566);  convert_element_type_1566 = None
        convert_element_type_1356 = torch.ops.prims.convert_element_type.default(add_1640, torch.float32);  add_1640 = None
        mul_1191 = torch.ops.aten.mul.Tensor(convert_element_type_1356, rsqrt_77);  convert_element_type_1356 = None
        mul_1341 = torch.ops.aten.mul.Tensor(mul_1191, mul_1339)
        sum_116 = torch.ops.aten.sum.dim_IntList(mul_1341, [2], True);  mul_1341 = None
        div_141 = torch.ops.aten.div.Tensor(mul_1191, 2048)
        mul_1342 = torch.ops.aten.mul.Tensor(div_141, sum_116);  div_141 = sum_116 = None
        sub_634 = torch.ops.aten.sub.Tensor(mul_1339, mul_1342);  mul_1339 = mul_1342 = None
        mul_1343 = torch.ops.aten.mul.Tensor(sub_634, rsqrt_77);  sub_634 = rsqrt_77 = None
        mul_1344 = torch.ops.aten.mul.Tensor(convert_element_type_1564, mul_1191);  convert_element_type_1564 = mul_1191 = None
        sum_117 = torch.ops.aten.sum.dim_IntList(mul_1344, [0, 1]);  mul_1344 = None
        convert_element_type_1567 = torch.ops.prims.convert_element_type.default(mul_1343, torch.bfloat16);  mul_1343 = None
        add_1802 = torch.ops.aten.add.Tensor(add_1789, convert_element_type_1567);  add_1789 = convert_element_type_1567 = None
        convert_element_type_default_78 = torch.ops.prims.convert_element_type.default(sum_117, torch.float32);  sum_117 = None
        reduce_scatter_tensor_23 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_78, 'avg', 128, '0');  convert_element_type_default_78 = None
        wait_tensor_586 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_23);  reduce_scatter_tensor_23 = None
        view_1805 = torch.ops.aten.view.default(add_1802, [8192, 2048])
        permute_486 = torch.ops.aten.permute.default(view_1805, [1, 0])
        permute_377 = torch.ops.aten.permute.default(getitem_2655, [0, 2, 1, 3])
        view_1661 = torch.ops.aten.view.default(permute_377, [2, 4096, -1]);  permute_377 = None
        view_1663 = torch.ops.aten.view.default(view_1661, [8192, 2048]);  view_1661 = None
        mm_242 = torch.ops.aten.mm.default(permute_486, view_1663);  permute_486 = view_1663 = None
        convert_element_type_1352 = torch.ops.prims.convert_element_type.default(primals_412, torch.bfloat16);  primals_412 = None
        all_gather_into_tensor_424 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1352, 128, '0');  convert_element_type_1352 = None
        wait_tensor_520 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_424);  all_gather_into_tensor_424 = None
        permute_378 = torch.ops.aten.permute.default(wait_tensor_520, [1, 0]);  wait_tensor_520 = None
        permute_488 = torch.ops.aten.permute.default(permute_378, [1, 0]);  permute_378 = None
        mm_243 = torch.ops.aten.mm.default(view_1805, permute_488);  view_1805 = permute_488 = None
        view_1806 = torch.ops.aten.view.default(mm_243, [2, 4096, 2048]);  mm_243 = None
        convert_element_type_1574 = torch.ops.prims.convert_element_type.default(mm_242, torch.float32);  mm_242 = None
        reduce_scatter_tensor_24 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1574, 'avg', 128, '0');  convert_element_type_1574 = None
        wait_tensor_587 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_24);  reduce_scatter_tensor_24 = None
        view_1807 = torch.ops.aten.view.default(view_1806, [2, 4096, 16, 128]);  view_1806 = None
        permute_490 = torch.ops.aten.permute.default(view_1807, [0, 2, 1, 3]);  view_1807 = None
        fw_graph1 = self.fw_graph1
        joint_graph1 = self.joint_graph1
        mask_graph1 = self.mask_graph1
        flex_attention_backward_1 = torch.ops.higher_order.flex_attention_backward(permute_374, permute_375, permute_376, getitem_2655, getitem_2656, permute_490, None, fw_graph1, joint_graph1, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph1), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_374 = permute_375 = permute_376 = getitem_2655 = getitem_2656 = permute_490 = fw_graph1 = joint_graph1 = mask_graph1 = None
        getitem_4749 = flex_attention_backward_1[0]
        getitem_4750 = flex_attention_backward_1[1]
        getitem_4751 = flex_attention_backward_1[2];  flex_attention_backward_1 = None
        permute_491 = torch.ops.aten.permute.default(getitem_4751, [0, 2, 1, 3]);  getitem_4751 = None
        permute_492 = torch.ops.aten.permute.default(getitem_4750, [0, 2, 1, 3]);  getitem_4750 = None
        permute_493 = torch.ops.aten.permute.default(getitem_4749, [0, 2, 1, 3]);  getitem_4749 = None
        slice_170 = torch.ops.aten.slice.Tensor(permute_492, 3, 0, 128)
        slice_171 = torch.ops.aten.slice.Tensor(permute_492, 3, 128, 192);  permute_492 = None
        sum_118 = torch.ops.aten.sum.dim_IntList(slice_171, [2], True);  slice_171 = None
        cat_248 = torch.ops.aten.cat.default([slice_170, permute_491], 3);  slice_170 = permute_491 = None
        view_1808 = torch.ops.aten.view.default(cat_248, [2, 4096, 4096]);  cat_248 = None
        view_1809 = torch.ops.aten.view.default(view_1808, [8192, 4096]);  view_1808 = None
        permute_494 = torch.ops.aten.permute.default(view_1809, [1, 0])
        mm_244 = torch.ops.aten.mm.default(permute_494, view_1658);  permute_494 = view_1658 = None
        convert_element_type_1349 = torch.ops.prims.convert_element_type.default(primals_411, torch.bfloat16);  primals_411 = None
        all_gather_into_tensor_423 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1349, 128, '0');  convert_element_type_1349 = None
        wait_tensor_519 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_423);  all_gather_into_tensor_423 = None
        permute_373 = torch.ops.aten.permute.default(wait_tensor_519, [1, 0]);  wait_tensor_519 = None
        permute_496 = torch.ops.aten.permute.default(permute_373, [1, 0]);  permute_373 = None
        mm_245 = torch.ops.aten.mm.default(view_1809, permute_496);  view_1809 = permute_496 = None
        view_1810 = torch.ops.aten.view.default(mm_245, [2, 4096, 512]);  mm_245 = None
        convert_element_type_1579 = torch.ops.prims.convert_element_type.default(mm_244, torch.float32);  mm_244 = None
        reduce_scatter_tensor_25 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1579, 'avg', 128, '0');  convert_element_type_1579 = None
        wait_tensor_588 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_25);  reduce_scatter_tensor_25 = None
        convert_element_type_1580 = torch.ops.prims.convert_element_type.default(view_1810, torch.float32);  view_1810 = None
        convert_element_type_1346 = torch.ops.prims.convert_element_type.default(primals_410, torch.bfloat16);  primals_410 = None
        all_gather_into_tensor_422 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1346, 128, '0');  convert_element_type_1346 = None
        wait_tensor_518 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_422);  all_gather_into_tensor_422 = None
        convert_element_type_1582 = torch.ops.prims.convert_element_type.default(wait_tensor_518, torch.float32);  wait_tensor_518 = None
        mul_1345 = torch.ops.aten.mul.Tensor(convert_element_type_1580, convert_element_type_1582);  convert_element_type_1582 = None
        convert_element_type_1347 = torch.ops.prims.convert_element_type.default(getitem_2651, torch.float32);  getitem_2651 = None
        mul_1189 = torch.ops.aten.mul.Tensor(convert_element_type_1347, rsqrt_76);  convert_element_type_1347 = None
        mul_1347 = torch.ops.aten.mul.Tensor(mul_1189, mul_1345)
        sum_119 = torch.ops.aten.sum.dim_IntList(mul_1347, [2], True);  mul_1347 = None
        div_142 = torch.ops.aten.div.Tensor(mul_1189, 512)
        mul_1348 = torch.ops.aten.mul.Tensor(div_142, sum_119);  div_142 = sum_119 = None
        sub_635 = torch.ops.aten.sub.Tensor(mul_1345, mul_1348);  mul_1345 = mul_1348 = None
        mul_1349 = torch.ops.aten.mul.Tensor(sub_635, rsqrt_76);  sub_635 = rsqrt_76 = None
        mul_1350 = torch.ops.aten.mul.Tensor(convert_element_type_1580, mul_1189);  convert_element_type_1580 = mul_1189 = None
        sum_120 = torch.ops.aten.sum.dim_IntList(mul_1350, [0, 1]);  mul_1350 = None
        convert_element_type_1583 = torch.ops.prims.convert_element_type.default(mul_1349, torch.bfloat16);  mul_1349 = None
        convert_element_type_default_77 = torch.ops.prims.convert_element_type.default(sum_120, torch.float32);  sum_120 = None
        reduce_scatter_tensor_26 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_77, 'avg', 128, '0');  convert_element_type_default_77 = None
        wait_tensor_589 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_26);  reduce_scatter_tensor_26 = None
        convert_element_type_1586 = torch.ops.prims.convert_element_type.default(sum_118, torch.float32);  sum_118 = None
        view_1811 = torch.ops.aten.view.default(convert_element_type_1586, [2, 4096, 1, 32, 2]);  convert_element_type_1586 = None
        view_as_complex_56 = torch.ops.aten.view_as_complex.default(view_1811);  view_1811 = None
        mul_1351 = torch.ops.aten.mul.Tensor(view_as_complex_56, clone_9);  view_as_complex_56 = None
        view_as_real_56 = torch.ops.aten.view_as_real.default(mul_1351);  mul_1351 = None
        view_1812 = torch.ops.aten.view.default(view_as_real_56, [2, 4096, 1, 64]);  view_as_real_56 = None
        convert_element_type_1587 = torch.ops.prims.convert_element_type.default(view_1812, torch.bfloat16);  view_1812 = None
        squeeze_27 = torch.ops.aten.squeeze.dim(convert_element_type_1587, 2);  convert_element_type_1587 = None
        cat_249 = torch.ops.aten.cat.default([convert_element_type_1583, squeeze_27], 2);  convert_element_type_1583 = squeeze_27 = None
        view_1813 = torch.ops.aten.view.default(cat_249, [8192, 576]);  cat_249 = None
        permute_498 = torch.ops.aten.permute.default(view_1813, [1, 0])
        mm_246 = torch.ops.aten.mm.default(permute_498, view_1644);  permute_498 = None
        convert_element_type_1341 = torch.ops.prims.convert_element_type.default(primals_409, torch.bfloat16);  primals_409 = None
        all_gather_into_tensor_421 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1341, 128, '0');  convert_element_type_1341 = None
        wait_tensor_517 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_421);  all_gather_into_tensor_421 = None
        slice_151 = torch.ops.aten.slice.Tensor(wait_tensor_517, 0, 0, 576);  wait_tensor_517 = None
        permute_372 = torch.ops.aten.permute.default(slice_151, [1, 0]);  slice_151 = None
        permute_500 = torch.ops.aten.permute.default(permute_372, [1, 0]);  permute_372 = None
        mm_247 = torch.ops.aten.mm.default(view_1813, permute_500);  view_1813 = permute_500 = None
        view_1814 = torch.ops.aten.view.default(mm_247, [2, 4096, 2048]);  mm_247 = None
        convert_element_type_1592 = torch.ops.prims.convert_element_type.default(mm_246, torch.float32);  mm_246 = None
        split_261 = torch.ops.aten.split.Tensor(convert_element_type_1592, 5);  convert_element_type_1592 = None
        getitem_4753 = split_261[0]
        getitem_4754 = split_261[1]
        getitem_4755 = split_261[2]
        getitem_4756 = split_261[3]
        getitem_4757 = split_261[4]
        getitem_4758 = split_261[5]
        getitem_4759 = split_261[6]
        getitem_4760 = split_261[7]
        getitem_4761 = split_261[8]
        getitem_4762 = split_261[9]
        getitem_4763 = split_261[10]
        getitem_4764 = split_261[11]
        getitem_4765 = split_261[12]
        getitem_4766 = split_261[13]
        getitem_4767 = split_261[14]
        getitem_4768 = split_261[15]
        getitem_4769 = split_261[16]
        getitem_4770 = split_261[17]
        getitem_4771 = split_261[18]
        getitem_4772 = split_261[19]
        getitem_4773 = split_261[20]
        getitem_4774 = split_261[21]
        getitem_4775 = split_261[22]
        getitem_4776 = split_261[23]
        getitem_4777 = split_261[24]
        getitem_4778 = split_261[25]
        getitem_4779 = split_261[26]
        getitem_4780 = split_261[27]
        getitem_4781 = split_261[28]
        getitem_4782 = split_261[29]
        getitem_4783 = split_261[30]
        getitem_4784 = split_261[31]
        getitem_4785 = split_261[32]
        getitem_4786 = split_261[33]
        getitem_4787 = split_261[34]
        getitem_4788 = split_261[35]
        getitem_4789 = split_261[36]
        getitem_4790 = split_261[37]
        getitem_4791 = split_261[38]
        getitem_4792 = split_261[39]
        getitem_4793 = split_261[40]
        getitem_4794 = split_261[41]
        getitem_4795 = split_261[42]
        getitem_4796 = split_261[43]
        getitem_4797 = split_261[44]
        getitem_4798 = split_261[45]
        getitem_4799 = split_261[46]
        getitem_4800 = split_261[47]
        getitem_4801 = split_261[48]
        getitem_4802 = split_261[49]
        getitem_4803 = split_261[50]
        getitem_4804 = split_261[51]
        getitem_4805 = split_261[52]
        getitem_4806 = split_261[53]
        getitem_4807 = split_261[54]
        getitem_4808 = split_261[55]
        getitem_4809 = split_261[56]
        getitem_4810 = split_261[57]
        getitem_4811 = split_261[58]
        getitem_4812 = split_261[59]
        getitem_4813 = split_261[60]
        getitem_4814 = split_261[61]
        getitem_4815 = split_261[62]
        getitem_4816 = split_261[63]
        getitem_4817 = split_261[64]
        getitem_4818 = split_261[65]
        getitem_4819 = split_261[66]
        getitem_4820 = split_261[67]
        getitem_4821 = split_261[68]
        getitem_4822 = split_261[69]
        getitem_4823 = split_261[70]
        getitem_4824 = split_261[71]
        getitem_4825 = split_261[72]
        getitem_4826 = split_261[73]
        getitem_4827 = split_261[74]
        getitem_4828 = split_261[75]
        getitem_4829 = split_261[76]
        getitem_4830 = split_261[77]
        getitem_4831 = split_261[78]
        getitem_4832 = split_261[79]
        getitem_4833 = split_261[80]
        getitem_4834 = split_261[81]
        getitem_4835 = split_261[82]
        getitem_4836 = split_261[83]
        getitem_4837 = split_261[84]
        getitem_4838 = split_261[85]
        getitem_4839 = split_261[86]
        getitem_4840 = split_261[87]
        getitem_4841 = split_261[88]
        getitem_4842 = split_261[89]
        getitem_4843 = split_261[90]
        getitem_4844 = split_261[91]
        getitem_4845 = split_261[92]
        getitem_4846 = split_261[93]
        getitem_4847 = split_261[94]
        getitem_4848 = split_261[95]
        getitem_4849 = split_261[96]
        getitem_4850 = split_261[97]
        getitem_4851 = split_261[98]
        getitem_4852 = split_261[99]
        getitem_4853 = split_261[100]
        getitem_4854 = split_261[101]
        getitem_4855 = split_261[102]
        getitem_4856 = split_261[103]
        getitem_4857 = split_261[104]
        getitem_4858 = split_261[105]
        getitem_4859 = split_261[106]
        getitem_4860 = split_261[107]
        getitem_4861 = split_261[108]
        getitem_4862 = split_261[109]
        getitem_4863 = split_261[110]
        getitem_4864 = split_261[111]
        getitem_4865 = split_261[112]
        getitem_4866 = split_261[113]
        getitem_4867 = split_261[114]
        getitem_4868 = split_261[115];  split_261 = None
        constant_pad_nd_141 = torch.ops.aten.constant_pad_nd.default(getitem_4868, [0, 0, 0, 4], 0.0);  getitem_4868 = None
        cat_250 = torch.ops.aten.cat.default([getitem_4753, getitem_4754, getitem_4755, getitem_4756, getitem_4757, getitem_4758, getitem_4759, getitem_4760, getitem_4761, getitem_4762, getitem_4763, getitem_4764, getitem_4765, getitem_4766, getitem_4767, getitem_4768, getitem_4769, getitem_4770, getitem_4771, getitem_4772, getitem_4773, getitem_4774, getitem_4775, getitem_4776, getitem_4777, getitem_4778, getitem_4779, getitem_4780, getitem_4781, getitem_4782, getitem_4783, getitem_4784, getitem_4785, getitem_4786, getitem_4787, getitem_4788, getitem_4789, getitem_4790, getitem_4791, getitem_4792, getitem_4793, getitem_4794, getitem_4795, getitem_4796, getitem_4797, getitem_4798, getitem_4799, getitem_4800, getitem_4801, getitem_4802, getitem_4803, getitem_4804, getitem_4805, getitem_4806, getitem_4807, getitem_4808, getitem_4809, getitem_4810, getitem_4811, getitem_4812, getitem_4813, getitem_4814, getitem_4815, getitem_4816, getitem_4817, getitem_4818, getitem_4819, getitem_4820, getitem_4821, getitem_4822, getitem_4823, getitem_4824, getitem_4825, getitem_4826, getitem_4827, getitem_4828, getitem_4829, getitem_4830, getitem_4831, getitem_4832, getitem_4833, getitem_4834, getitem_4835, getitem_4836, getitem_4837, getitem_4838, getitem_4839, getitem_4840, getitem_4841, getitem_4842, getitem_4843, getitem_4844, getitem_4845, getitem_4846, getitem_4847, getitem_4848, getitem_4849, getitem_4850, getitem_4851, getitem_4852, getitem_4853, getitem_4854, getitem_4855, getitem_4856, getitem_4857, getitem_4858, getitem_4859, getitem_4860, getitem_4861, getitem_4862, getitem_4863, getitem_4864, getitem_4865, getitem_4866, getitem_4867, constant_pad_nd_141, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_4753 = getitem_4754 = getitem_4755 = getitem_4756 = getitem_4757 = getitem_4758 = getitem_4759 = getitem_4760 = getitem_4761 = getitem_4762 = getitem_4763 = getitem_4764 = getitem_4765 = getitem_4766 = getitem_4767 = getitem_4768 = getitem_4769 = getitem_4770 = getitem_4771 = getitem_4772 = getitem_4773 = getitem_4774 = getitem_4775 = getitem_4776 = getitem_4777 = getitem_4778 = getitem_4779 = getitem_4780 = getitem_4781 = getitem_4782 = getitem_4783 = getitem_4784 = getitem_4785 = getitem_4786 = getitem_4787 = getitem_4788 = getitem_4789 = getitem_4790 = getitem_4791 = getitem_4792 = getitem_4793 = getitem_4794 = getitem_4795 = getitem_4796 = getitem_4797 = getitem_4798 = getitem_4799 = getitem_4800 = getitem_4801 = getitem_4802 = getitem_4803 = getitem_4804 = getitem_4805 = getitem_4806 = getitem_4807 = getitem_4808 = getitem_4809 = getitem_4810 = getitem_4811 = getitem_4812 = getitem_4813 = getitem_4814 = getitem_4815 = getitem_4816 = getitem_4817 = getitem_4818 = getitem_4819 = getitem_4820 = getitem_4821 = getitem_4822 = getitem_4823 = getitem_4824 = getitem_4825 = getitem_4826 = getitem_4827 = getitem_4828 = getitem_4829 = getitem_4830 = getitem_4831 = getitem_4832 = getitem_4833 = getitem_4834 = getitem_4835 = getitem_4836 = getitem_4837 = getitem_4838 = getitem_4839 = getitem_4840 = getitem_4841 = getitem_4842 = getitem_4843 = getitem_4844 = getitem_4845 = getitem_4846 = getitem_4847 = getitem_4848 = getitem_4849 = getitem_4850 = getitem_4851 = getitem_4852 = getitem_4853 = getitem_4854 = getitem_4855 = getitem_4856 = getitem_4857 = getitem_4858 = getitem_4859 = getitem_4860 = getitem_4861 = getitem_4862 = getitem_4863 = getitem_4864 = getitem_4865 = getitem_4866 = getitem_4867 = constant_pad_nd_141 = None
        reduce_scatter_tensor_27 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_250, 'avg', 128, '0');  cat_250 = None
        wait_tensor_590 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_27);  reduce_scatter_tensor_27 = None
        slice_172 = torch.ops.aten.slice.Tensor(permute_493, 3, 0, 128)
        slice_173 = torch.ops.aten.slice.Tensor(permute_493, 3, 128, 192);  permute_493 = None
        convert_element_type_1593 = torch.ops.prims.convert_element_type.default(slice_173, torch.float32);  slice_173 = None
        view_1815 = torch.ops.aten.view.default(convert_element_type_1593, [2, 4096, 16, 32, 2]);  convert_element_type_1593 = None
        view_as_complex_57 = torch.ops.aten.view_as_complex.default(view_1815);  view_1815 = None
        mul_1352 = torch.ops.aten.mul.Tensor(view_as_complex_57, clone_9);  view_as_complex_57 = None
        view_as_real_57 = torch.ops.aten.view_as_real.default(mul_1352);  mul_1352 = None
        view_1816 = torch.ops.aten.view.default(view_as_real_57, [2, 4096, 16, 64]);  view_as_real_57 = None
        convert_element_type_1594 = torch.ops.prims.convert_element_type.default(view_1816, torch.bfloat16);  view_1816 = None
        cat_251 = torch.ops.aten.cat.default([slice_172, convert_element_type_1594], 3);  slice_172 = convert_element_type_1594 = None
        view_1817 = torch.ops.aten.view.default(cat_251, [2, 4096, 3072]);  cat_251 = None
        view_1818 = torch.ops.aten.view.default(view_1817, [8192, 3072]);  view_1817 = None
        permute_502 = torch.ops.aten.permute.default(view_1818, [1, 0])
        mm_248 = torch.ops.aten.mm.default(permute_502, view_1644);  permute_502 = view_1644 = None
        convert_element_type_1336 = torch.ops.prims.convert_element_type.default(primals_408, torch.bfloat16);  primals_408 = None
        all_gather_into_tensor_420 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1336, 128, '0');  convert_element_type_1336 = None
        wait_tensor_516 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_420);  all_gather_into_tensor_420 = None
        permute_371 = torch.ops.aten.permute.default(wait_tensor_516, [1, 0]);  wait_tensor_516 = None
        permute_504 = torch.ops.aten.permute.default(permute_371, [1, 0]);  permute_371 = None
        mm_249 = torch.ops.aten.mm.default(view_1818, permute_504);  view_1818 = permute_504 = None
        view_1819 = torch.ops.aten.view.default(mm_249, [2, 4096, 2048]);  mm_249 = None
        add_1803 = torch.ops.aten.add.Tensor(view_1814, view_1819);  view_1814 = view_1819 = None
        convert_element_type_1599 = torch.ops.prims.convert_element_type.default(mm_248, torch.float32);  mm_248 = None
        reduce_scatter_tensor_28 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1599, 'avg', 128, '0');  convert_element_type_1599 = None
        wait_tensor_591 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_28);  reduce_scatter_tensor_28 = None
        convert_element_type_1600 = torch.ops.prims.convert_element_type.default(add_1803, torch.float32);  add_1803 = None
        convert_element_type_1333 = torch.ops.prims.convert_element_type.default(primals_407, torch.bfloat16);  primals_407 = None
        all_gather_into_tensor_419 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1333, 128, '0');  convert_element_type_1333 = None
        wait_tensor_515 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_419);  all_gather_into_tensor_419 = None
        convert_element_type_1602 = torch.ops.prims.convert_element_type.default(wait_tensor_515, torch.float32);  wait_tensor_515 = None
        mul_1353 = torch.ops.aten.mul.Tensor(convert_element_type_1600, convert_element_type_1602);  convert_element_type_1602 = None
        convert_element_type_1334 = torch.ops.prims.convert_element_type.default(add_1637, torch.float32);  add_1637 = None
        mul_1185 = torch.ops.aten.mul.Tensor(convert_element_type_1334, rsqrt_75);  convert_element_type_1334 = None
        mul_1355 = torch.ops.aten.mul.Tensor(mul_1185, mul_1353)
        sum_121 = torch.ops.aten.sum.dim_IntList(mul_1355, [2], True);  mul_1355 = None
        div_143 = torch.ops.aten.div.Tensor(mul_1185, 2048)
        mul_1356 = torch.ops.aten.mul.Tensor(div_143, sum_121);  div_143 = sum_121 = None
        sub_636 = torch.ops.aten.sub.Tensor(mul_1353, mul_1356);  mul_1353 = mul_1356 = None
        mul_1357 = torch.ops.aten.mul.Tensor(sub_636, rsqrt_75);  sub_636 = rsqrt_75 = None
        mul_1358 = torch.ops.aten.mul.Tensor(convert_element_type_1600, mul_1185);  convert_element_type_1600 = mul_1185 = None
        sum_122 = torch.ops.aten.sum.dim_IntList(mul_1358, [0, 1]);  mul_1358 = None
        convert_element_type_1603 = torch.ops.prims.convert_element_type.default(mul_1357, torch.bfloat16);  mul_1357 = None
        add_1804 = torch.ops.aten.add.Tensor(add_1802, convert_element_type_1603);  add_1802 = convert_element_type_1603 = None
        convert_element_type_default_76 = torch.ops.prims.convert_element_type.default(sum_122, torch.float32);  sum_122 = None
        reduce_scatter_tensor_29 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_76, 'avg', 128, '0');  convert_element_type_default_76 = None
        wait_tensor_592 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_29);  reduce_scatter_tensor_29 = None
        view_1820 = torch.ops.aten.view.default(add_1804, [8192, 2048])
        unsqueeze_55 = torch.ops.aten.unsqueeze.default(view_1820, 1)
        convert_element_type_1606 = torch.ops.prims.convert_element_type.default(unsqueeze_55, torch.float32);  unsqueeze_55 = None
        bmm_30 = torch.ops.aten.bmm.default(permute_506, convert_element_type_1606);  permute_506 = None
        bmm_31 = torch.ops.aten.bmm.default(convert_element_type_1606, permute_507);  convert_element_type_1606 = permute_507 = None
        convert_element_type_1607 = torch.ops.prims.convert_element_type.default(bmm_30, torch.bfloat16);  bmm_30 = None
        view_1821 = torch.ops.aten.view.default(bmm_31, [8192, 6]);  bmm_31 = None
        view_1822 = torch.ops.aten.view.default(convert_element_type_1607, [49152, 2048]);  convert_element_type_1607 = None
        index_56 = torch.ops.aten.index.Tensor(view_1822, [getitem_2551]);  view_1822 = getitem_2551 = None
        permute_508 = torch.ops.aten.permute.default(view_1820, [1, 0])
        mm_250 = torch.ops.aten.mm.default(permute_508, mul_1182);  permute_508 = mul_1182 = None
        convert_element_type_1328 = torch.ops.prims.convert_element_type.default(primals_406, torch.bfloat16);  primals_406 = None
        all_gather_into_tensor_418 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1328, 128, '0');  convert_element_type_1328 = None
        wait_tensor_514 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_418);  all_gather_into_tensor_418 = None
        permute_370 = torch.ops.aten.permute.default(wait_tensor_514, [1, 0]);  wait_tensor_514 = None
        permute_510 = torch.ops.aten.permute.default(permute_370, [1, 0]);  permute_370 = None
        mm_251 = torch.ops.aten.mm.default(view_1820, permute_510);  view_1820 = permute_510 = None
        convert_element_type_1612 = torch.ops.prims.convert_element_type.default(mm_250, torch.float32);  mm_250 = None
        reduce_scatter_tensor_30 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1612, 'avg', 128, '0');  convert_element_type_1612 = None
        wait_tensor_593 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_30);  reduce_scatter_tensor_30 = None
        convert_element_type_1323 = torch.ops.prims.convert_element_type.default(mm_196, torch.float32);  mm_196 = None
        neg_48 = torch.ops.aten.neg.default(convert_element_type_1323)
        exp_72 = torch.ops.aten.exp.default(neg_48);  neg_48 = None
        add_1632 = torch.ops.aten.add.Tensor(exp_72, 1);  exp_72 = None
        div_120 = torch.ops.aten.div.Tensor(convert_element_type_1323, add_1632)
        convert_element_type_1324 = torch.ops.prims.convert_element_type.default(div_120, torch.bfloat16);  div_120 = None
        mul_1359 = torch.ops.aten.mul.Tensor(mm_251, convert_element_type_1324);  convert_element_type_1324 = None
        mul_1360 = torch.ops.aten.mul.Tensor(mm_251, mm_197);  mm_251 = mm_197 = None
        permute_512 = torch.ops.aten.permute.default(mul_1359, [1, 0])
        mm_252 = torch.ops.aten.mm.default(permute_512, view_1599);  permute_512 = None
        convert_element_type_1325 = torch.ops.prims.convert_element_type.default(primals_405, torch.bfloat16);  primals_405 = None
        all_gather_into_tensor_417 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1325, 128, '0');  convert_element_type_1325 = None
        wait_tensor_513 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_417);  all_gather_into_tensor_417 = None
        permute_369 = torch.ops.aten.permute.default(wait_tensor_513, [1, 0]);  wait_tensor_513 = None
        permute_514 = torch.ops.aten.permute.default(permute_369, [1, 0]);  permute_369 = None
        mm_253 = torch.ops.aten.mm.default(mul_1359, permute_514);  mul_1359 = permute_514 = None
        convert_element_type_1617 = torch.ops.prims.convert_element_type.default(mm_252, torch.float32);  mm_252 = None
        reduce_scatter_tensor_31 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1617, 'avg', 128, '0');  convert_element_type_1617 = None
        wait_tensor_594 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_31);  reduce_scatter_tensor_31 = None
        convert_element_type_1618 = torch.ops.prims.convert_element_type.default(mul_1360, torch.float32);  mul_1360 = None
        reciprocal_4 = torch.ops.aten.reciprocal.default(add_1632);  add_1632 = None
        mul_1361 = torch.ops.aten.mul.Tensor(reciprocal_4, 1);  reciprocal_4 = None
        mul_1362 = torch.ops.aten.mul.Tensor(convert_element_type_1618, mul_1361);  convert_element_type_1618 = None
        sub_637 = torch.ops.aten.sub.Tensor(1, mul_1361);  mul_1361 = None
        mul_1363 = torch.ops.aten.mul.Tensor(convert_element_type_1323, sub_637);  convert_element_type_1323 = sub_637 = None
        add_1806 = torch.ops.aten.add.Tensor(mul_1363, 1);  mul_1363 = None
        mul_1364 = torch.ops.aten.mul.Tensor(mul_1362, add_1806);  mul_1362 = add_1806 = None
        convert_element_type_1620 = torch.ops.prims.convert_element_type.default(mul_1364, torch.bfloat16);  mul_1364 = None
        permute_516 = torch.ops.aten.permute.default(convert_element_type_1620, [1, 0])
        mm_254 = torch.ops.aten.mm.default(permute_516, view_1599);  permute_516 = None
        convert_element_type_1320 = torch.ops.prims.convert_element_type.default(primals_404, torch.bfloat16);  primals_404 = None
        all_gather_into_tensor_416 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1320, 128, '0');  convert_element_type_1320 = None
        wait_tensor_512 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_416);  all_gather_into_tensor_416 = None
        permute_368 = torch.ops.aten.permute.default(wait_tensor_512, [1, 0]);  wait_tensor_512 = None
        permute_518 = torch.ops.aten.permute.default(permute_368, [1, 0]);  permute_368 = None
        mm_255 = torch.ops.aten.mm.default(convert_element_type_1620, permute_518);  convert_element_type_1620 = permute_518 = None
        add_1807 = torch.ops.aten.add.Tensor(mm_253, mm_255);  mm_253 = mm_255 = None
        convert_element_type_1625 = torch.ops.prims.convert_element_type.default(mm_254, torch.float32);  mm_254 = None
        reduce_scatter_tensor_32 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1625, 'avg', 128, '0');  convert_element_type_1625 = None
        wait_tensor_595 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_32);  reduce_scatter_tensor_32 = None
        all_to_all_single_82 = torch.ops._c10d_functional.all_to_all_single.default(index_56, [_local_scalar_dense_376, _local_scalar_dense_377, _local_scalar_dense_378, _local_scalar_dense_379, _local_scalar_dense_380, _local_scalar_dense_381, _local_scalar_dense_382, _local_scalar_dense_383], [_local_scalar_dense_368, _local_scalar_dense_369, _local_scalar_dense_370, _local_scalar_dense_371, _local_scalar_dense_372, _local_scalar_dense_373, _local_scalar_dense_374, _local_scalar_dense_375], '1033');  index_56 = None
        wait_tensor_596 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_82);  all_to_all_single_82 = None
        full_360 = torch.ops.aten.full.default([sym_size_int_93, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_93 = None
        slice_scatter_2 = torch.ops.aten.slice_scatter.default(full_360, wait_tensor_596, 0, 0, -1);  wait_tensor_596 = None
        index_57 = torch.ops.aten.index.Tensor(slice_scatter_2, [getitem_2552]);  slice_scatter_2 = None
        permute_520 = torch.ops.aten.permute.default(index_57, [1, 0])
        _grouped_mm_90 = torch.ops.aten._grouped_mm.default(permute_520, mul_1162, cumsum_71);  permute_520 = mul_1162 = None
        _grouped_mm_91 = torch.ops.aten._grouped_mm.default(index_57, permute_522, cumsum_71);  index_57 = permute_522 = None
        convert_element_type_1318 = torch.ops.prims.convert_element_type.default(_grouped_mm_69, torch.float32);  _grouped_mm_69 = None
        neg_47 = torch.ops.aten.neg.default(convert_element_type_1318)
        exp_71 = torch.ops.aten.exp.default(neg_47);  neg_47 = None
        add_1596 = torch.ops.aten.add.Tensor(exp_71, 1);  exp_71 = None
        div_119 = torch.ops.aten.div.Tensor(convert_element_type_1318, add_1596)
        convert_element_type_1319 = torch.ops.prims.convert_element_type.default(div_119, torch.bfloat16);  div_119 = None
        mul_1365 = torch.ops.aten.mul.Tensor(_grouped_mm_91, convert_element_type_1319);  convert_element_type_1319 = None
        mul_1366 = torch.ops.aten.mul.Tensor(_grouped_mm_91, _grouped_mm_70);  _grouped_mm_91 = _grouped_mm_70 = None
        permute_524 = torch.ops.aten.permute.default(mul_1365, [1, 0])
        _grouped_mm_92 = torch.ops.aten._grouped_mm.default(permute_524, index_47, cumsum_71);  permute_524 = None
        _grouped_mm_93 = torch.ops.aten._grouped_mm.default(mul_1365, permute_526, cumsum_71);  mul_1365 = permute_526 = None
        convert_element_type_1626 = torch.ops.prims.convert_element_type.default(mul_1366, torch.float32);  mul_1366 = None
        reciprocal_5 = torch.ops.aten.reciprocal.default(add_1596);  add_1596 = None
        mul_1367 = torch.ops.aten.mul.Tensor(reciprocal_5, 1);  reciprocal_5 = None
        mul_1368 = torch.ops.aten.mul.Tensor(convert_element_type_1626, mul_1367);  convert_element_type_1626 = None
        sub_638 = torch.ops.aten.sub.Tensor(1, mul_1367);  mul_1367 = None
        mul_1369 = torch.ops.aten.mul.Tensor(convert_element_type_1318, sub_638);  convert_element_type_1318 = sub_638 = None
        add_1809 = torch.ops.aten.add.Tensor(mul_1369, 1);  mul_1369 = None
        mul_1370 = torch.ops.aten.mul.Tensor(mul_1368, add_1809);  mul_1368 = add_1809 = None
        convert_element_type_1628 = torch.ops.prims.convert_element_type.default(mul_1370, torch.bfloat16);  mul_1370 = None
        permute_528 = torch.ops.aten.permute.default(convert_element_type_1628, [1, 0])
        _grouped_mm_94 = torch.ops.aten._grouped_mm.default(permute_528, index_47, cumsum_71);  permute_528 = index_47 = None
        _grouped_mm_95 = torch.ops.aten._grouped_mm.default(convert_element_type_1628, permute_530, cumsum_71);  convert_element_type_1628 = permute_530 = cumsum_71 = None
        add_1810 = torch.ops.aten.add.Tensor(_grouped_mm_93, _grouped_mm_95);  _grouped_mm_93 = _grouped_mm_95 = None
        convert_element_type_1629 = torch.ops.prims.convert_element_type.default(_grouped_mm_92, torch.float32);  _grouped_mm_92 = None
        div_144 = torch.ops.aten.div.Tensor(convert_element_type_1629, 128);  convert_element_type_1629 = None
        split_263 = torch.ops.aten.split.Tensor(div_144, 88, 1);  div_144 = None
        getitem_4885 = split_263[0]
        getitem_4902 = split_263[1]
        getitem_4919 = split_263[2]
        getitem_4936 = split_263[3]
        getitem_4953 = split_263[4]
        getitem_4970 = split_263[5]
        getitem_4987 = split_263[6]
        getitem_5004 = split_263[7]
        getitem_5021 = split_263[8]
        getitem_5038 = split_263[9]
        getitem_5055 = split_263[10]
        getitem_5072 = split_263[11]
        getitem_5089 = split_263[12]
        getitem_5106 = split_263[13]
        getitem_5123 = split_263[14]
        getitem_5140 = split_263[15];  split_263 = None
        cat_252 = torch.ops.aten.cat.default([getitem_4885, getitem_4902, getitem_4919, getitem_4936, getitem_4953, getitem_4970, getitem_4987, getitem_5004, getitem_5021, getitem_5038, getitem_5055, getitem_5072, getitem_5089, getitem_5106, getitem_5123, getitem_5140]);  getitem_4885 = getitem_4902 = getitem_4919 = getitem_4936 = getitem_4953 = getitem_4970 = getitem_4987 = getitem_5004 = getitem_5021 = getitem_5038 = getitem_5055 = getitem_5072 = getitem_5089 = getitem_5106 = getitem_5123 = getitem_5140 = None
        reduce_scatter_tensor_33 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_252, 'sum', 16, '1025');  cat_252 = None
        wait_tensor_597 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_33);  reduce_scatter_tensor_33 = None
        convert_element_type_1630 = torch.ops.prims.convert_element_type.default(_grouped_mm_90, torch.float32);  _grouped_mm_90 = None
        div_145 = torch.ops.aten.div.Tensor(convert_element_type_1630, 128);  convert_element_type_1630 = None
        split_280 = torch.ops.aten.split.Tensor(div_145, 128, 1);  div_145 = None
        getitem_5157 = split_280[0]
        getitem_5174 = split_280[1]
        getitem_5191 = split_280[2]
        getitem_5208 = split_280[3]
        getitem_5225 = split_280[4]
        getitem_5242 = split_280[5]
        getitem_5259 = split_280[6]
        getitem_5276 = split_280[7]
        getitem_5293 = split_280[8]
        getitem_5310 = split_280[9]
        getitem_5327 = split_280[10]
        getitem_5344 = split_280[11]
        getitem_5361 = split_280[12]
        getitem_5378 = split_280[13]
        getitem_5395 = split_280[14]
        getitem_5412 = split_280[15];  split_280 = None
        cat_253 = torch.ops.aten.cat.default([getitem_5157, getitem_5174, getitem_5191, getitem_5208, getitem_5225, getitem_5242, getitem_5259, getitem_5276, getitem_5293, getitem_5310, getitem_5327, getitem_5344, getitem_5361, getitem_5378, getitem_5395, getitem_5412]);  getitem_5157 = getitem_5174 = getitem_5191 = getitem_5208 = getitem_5225 = getitem_5242 = getitem_5259 = getitem_5276 = getitem_5293 = getitem_5310 = getitem_5327 = getitem_5344 = getitem_5361 = getitem_5378 = getitem_5395 = getitem_5412 = None
        reduce_scatter_tensor_34 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_253, 'sum', 16, '1025');  cat_253 = None
        wait_tensor_598 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_34);  reduce_scatter_tensor_34 = None
        convert_element_type_1631 = torch.ops.prims.convert_element_type.default(_grouped_mm_94, torch.float32);  _grouped_mm_94 = None
        div_146 = torch.ops.aten.div.Tensor(convert_element_type_1631, 128);  convert_element_type_1631 = None
        split_297 = torch.ops.aten.split.Tensor(div_146, 88, 1);  div_146 = None
        getitem_5429 = split_297[0]
        getitem_5446 = split_297[1]
        getitem_5463 = split_297[2]
        getitem_5480 = split_297[3]
        getitem_5497 = split_297[4]
        getitem_5514 = split_297[5]
        getitem_5531 = split_297[6]
        getitem_5548 = split_297[7]
        getitem_5565 = split_297[8]
        getitem_5582 = split_297[9]
        getitem_5599 = split_297[10]
        getitem_5616 = split_297[11]
        getitem_5633 = split_297[12]
        getitem_5650 = split_297[13]
        getitem_5667 = split_297[14]
        getitem_5684 = split_297[15];  split_297 = None
        cat_254 = torch.ops.aten.cat.default([getitem_5429, getitem_5446, getitem_5463, getitem_5480, getitem_5497, getitem_5514, getitem_5531, getitem_5548, getitem_5565, getitem_5582, getitem_5599, getitem_5616, getitem_5633, getitem_5650, getitem_5667, getitem_5684]);  getitem_5429 = getitem_5446 = getitem_5463 = getitem_5480 = getitem_5497 = getitem_5514 = getitem_5531 = getitem_5548 = getitem_5565 = getitem_5582 = getitem_5599 = getitem_5616 = getitem_5633 = getitem_5650 = getitem_5667 = getitem_5684 = None
        reduce_scatter_tensor_35 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_254, 'sum', 16, '1025');  cat_254 = None
        wait_tensor_599 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_35);  reduce_scatter_tensor_35 = None
        index_put_56 = torch.ops.aten.index_put.default(full_360, [getitem_2552], add_1810, True);  full_360 = getitem_2552 = add_1810 = None
        slice_174 = torch.ops.aten.slice.Tensor(index_put_56, 0, 0, add_1811);  index_put_56 = add_1811 = None
        all_to_all_single_83 = torch.ops._c10d_functional.all_to_all_single.default(slice_174, [_local_scalar_dense_368, _local_scalar_dense_369, _local_scalar_dense_370, _local_scalar_dense_371, _local_scalar_dense_372, _local_scalar_dense_373, _local_scalar_dense_374, _local_scalar_dense_375], [_local_scalar_dense_376, _local_scalar_dense_377, _local_scalar_dense_378, _local_scalar_dense_379, _local_scalar_dense_380, _local_scalar_dense_381, _local_scalar_dense_382, _local_scalar_dense_383], '1033');  slice_174 = _local_scalar_dense_368 = _local_scalar_dense_369 = _local_scalar_dense_370 = _local_scalar_dense_371 = _local_scalar_dense_372 = _local_scalar_dense_373 = _local_scalar_dense_374 = _local_scalar_dense_375 = _local_scalar_dense_376 = _local_scalar_dense_377 = _local_scalar_dense_378 = _local_scalar_dense_379 = _local_scalar_dense_380 = _local_scalar_dense_381 = _local_scalar_dense_382 = _local_scalar_dense_383 = None
        wait_tensor_600 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_83);  all_to_all_single_83 = None
        index_put_57 = torch.ops.aten.index_put.default(full_default_52, [div_117], wait_tensor_600, True);  div_117 = wait_tensor_600 = None
        add_1815 = torch.ops.aten.add.Tensor(add_1807, index_put_57);  add_1807 = index_put_57 = None
        mul_1371 = torch.ops.aten.mul.Tensor(view_1821, 1.0);  view_1821 = None
        scatter_add_2 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_2549, mul_1371);  getitem_2549 = mul_1371 = None
        convert_element_type_1307 = torch.ops.prims.convert_element_type.default(mm_195, torch.float32);  mm_195 = None
        sub_552 = torch.ops.aten.sub.Tensor(convert_element_type_1307, amax_23);  convert_element_type_1307 = amax_23 = None
        exp_70 = torch.ops.aten.exp.default(sub_552);  sub_552 = None
        div_116 = torch.ops.aten.div.Tensor(exp_70, sum_93);  exp_70 = sum_93 = None
        mul_1372 = torch.ops.aten.mul.Tensor(scatter_add_2, div_116);  scatter_add_2 = None
        sum_123 = torch.ops.aten.sum.dim_IntList(mul_1372, [1], True)
        neg_61 = torch.ops.aten.neg.default(div_116);  div_116 = None
        fma_2 = torch.ops.prims.fma.default(neg_61, sum_123, mul_1372);  neg_61 = sum_123 = mul_1372 = None
        convert_element_type_1632 = torch.ops.prims.convert_element_type.default(fma_2, torch.bfloat16);  fma_2 = None
        permute_532 = torch.ops.aten.permute.default(convert_element_type_1632, [1, 0])
        mm_256 = torch.ops.aten.mm.default(permute_532, view_1599);  permute_532 = view_1599 = None
        convert_element_type_1304 = torch.ops.prims.convert_element_type.default(primals_399, torch.bfloat16);  primals_399 = None
        all_gather_into_tensor_409 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1304, 128, '0');  convert_element_type_1304 = None
        wait_tensor_501 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_409);  all_gather_into_tensor_409 = None
        slice_147 = torch.ops.aten.slice.Tensor(wait_tensor_501, 0, 0, 64);  wait_tensor_501 = None
        permute_364 = torch.ops.aten.permute.default(slice_147, [1, 0]);  slice_147 = None
        permute_534 = torch.ops.aten.permute.default(permute_364, [1, 0]);  permute_364 = None
        mm_257 = torch.ops.aten.mm.default(convert_element_type_1632, permute_534);  convert_element_type_1632 = permute_534 = None
        add_1816 = torch.ops.aten.add.Tensor(add_1815, mm_257);  add_1815 = mm_257 = None
        convert_element_type_1637 = torch.ops.prims.convert_element_type.default(mm_256, torch.float32);  mm_256 = None
        split_313 = torch.ops.aten.split.Tensor(convert_element_type_1637, 1);  convert_element_type_1637 = None
        getitem_5685 = split_313[0]
        getitem_5686 = split_313[1]
        getitem_5687 = split_313[2]
        getitem_5688 = split_313[3]
        getitem_5689 = split_313[4]
        getitem_5690 = split_313[5]
        getitem_5691 = split_313[6]
        getitem_5692 = split_313[7]
        getitem_5693 = split_313[8]
        getitem_5694 = split_313[9]
        getitem_5695 = split_313[10]
        getitem_5696 = split_313[11]
        getitem_5697 = split_313[12]
        getitem_5698 = split_313[13]
        getitem_5699 = split_313[14]
        getitem_5700 = split_313[15]
        getitem_5701 = split_313[16]
        getitem_5702 = split_313[17]
        getitem_5703 = split_313[18]
        getitem_5704 = split_313[19]
        getitem_5705 = split_313[20]
        getitem_5706 = split_313[21]
        getitem_5707 = split_313[22]
        getitem_5708 = split_313[23]
        getitem_5709 = split_313[24]
        getitem_5710 = split_313[25]
        getitem_5711 = split_313[26]
        getitem_5712 = split_313[27]
        getitem_5713 = split_313[28]
        getitem_5714 = split_313[29]
        getitem_5715 = split_313[30]
        getitem_5716 = split_313[31]
        getitem_5717 = split_313[32]
        getitem_5718 = split_313[33]
        getitem_5719 = split_313[34]
        getitem_5720 = split_313[35]
        getitem_5721 = split_313[36]
        getitem_5722 = split_313[37]
        getitem_5723 = split_313[38]
        getitem_5724 = split_313[39]
        getitem_5725 = split_313[40]
        getitem_5726 = split_313[41]
        getitem_5727 = split_313[42]
        getitem_5728 = split_313[43]
        getitem_5729 = split_313[44]
        getitem_5730 = split_313[45]
        getitem_5731 = split_313[46]
        getitem_5732 = split_313[47]
        getitem_5733 = split_313[48]
        getitem_5734 = split_313[49]
        getitem_5735 = split_313[50]
        getitem_5736 = split_313[51]
        getitem_5737 = split_313[52]
        getitem_5738 = split_313[53]
        getitem_5739 = split_313[54]
        getitem_5740 = split_313[55]
        getitem_5741 = split_313[56]
        getitem_5742 = split_313[57]
        getitem_5743 = split_313[58]
        getitem_5744 = split_313[59]
        getitem_5745 = split_313[60]
        getitem_5746 = split_313[61]
        getitem_5747 = split_313[62]
        getitem_5748 = split_313[63];  split_313 = None
        cat_255 = torch.ops.aten.cat.default([getitem_5685, getitem_5686, getitem_5687, getitem_5688, getitem_5689, getitem_5690, getitem_5691, getitem_5692, getitem_5693, getitem_5694, getitem_5695, getitem_5696, getitem_5697, getitem_5698, getitem_5699, getitem_5700, getitem_5701, getitem_5702, getitem_5703, getitem_5704, getitem_5705, getitem_5706, getitem_5707, getitem_5708, getitem_5709, getitem_5710, getitem_5711, getitem_5712, getitem_5713, getitem_5714, getitem_5715, getitem_5716, getitem_5717, getitem_5718, getitem_5719, getitem_5720, getitem_5721, getitem_5722, getitem_5723, getitem_5724, getitem_5725, getitem_5726, getitem_5727, getitem_5728, getitem_5729, getitem_5730, getitem_5731, getitem_5732, getitem_5733, getitem_5734, getitem_5735, getitem_5736, getitem_5737, getitem_5738, getitem_5739, getitem_5740, getitem_5741, getitem_5742, getitem_5743, getitem_5744, getitem_5745, getitem_5746, getitem_5747, getitem_5748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_5685 = getitem_5686 = getitem_5687 = getitem_5688 = getitem_5689 = getitem_5690 = getitem_5691 = getitem_5692 = getitem_5693 = getitem_5694 = getitem_5695 = getitem_5696 = getitem_5697 = getitem_5698 = getitem_5699 = getitem_5700 = getitem_5701 = getitem_5702 = getitem_5703 = getitem_5704 = getitem_5705 = getitem_5706 = getitem_5707 = getitem_5708 = getitem_5709 = getitem_5710 = getitem_5711 = getitem_5712 = getitem_5713 = getitem_5714 = getitem_5715 = getitem_5716 = getitem_5717 = getitem_5718 = getitem_5719 = getitem_5720 = getitem_5721 = getitem_5722 = getitem_5723 = getitem_5724 = getitem_5725 = getitem_5726 = getitem_5727 = getitem_5728 = getitem_5729 = getitem_5730 = getitem_5731 = getitem_5732 = getitem_5733 = getitem_5734 = getitem_5735 = getitem_5736 = getitem_5737 = getitem_5738 = getitem_5739 = getitem_5740 = getitem_5741 = getitem_5742 = getitem_5743 = getitem_5744 = getitem_5745 = getitem_5746 = getitem_5747 = getitem_5748 = None
        reduce_scatter_tensor_36 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_255, 'avg', 128, '0');  cat_255 = None
        wait_tensor_601 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_36);  reduce_scatter_tensor_36 = None
        view_1823 = torch.ops.aten.view.default(add_1816, [2, 4096, 2048]);  add_1816 = None
        convert_element_type_1638 = torch.ops.prims.convert_element_type.default(view_1823, torch.float32);  view_1823 = None
        convert_element_type_1301 = torch.ops.prims.convert_element_type.default(primals_397, torch.bfloat16);  primals_397 = None
        all_gather_into_tensor_408 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1301, 128, '0');  convert_element_type_1301 = None
        wait_tensor_500 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_408);  all_gather_into_tensor_408 = None
        convert_element_type_1640 = torch.ops.prims.convert_element_type.default(wait_tensor_500, torch.float32);  wait_tensor_500 = None
        mul_1373 = torch.ops.aten.mul.Tensor(convert_element_type_1638, convert_element_type_1640);  convert_element_type_1640 = None
        convert_element_type_1302 = torch.ops.prims.convert_element_type.default(add_1572, torch.float32);  add_1572 = None
        mul_1142 = torch.ops.aten.mul.Tensor(convert_element_type_1302, rsqrt_74);  convert_element_type_1302 = None
        mul_1375 = torch.ops.aten.mul.Tensor(mul_1142, mul_1373)
        sum_124 = torch.ops.aten.sum.dim_IntList(mul_1375, [2], True);  mul_1375 = None
        div_147 = torch.ops.aten.div.Tensor(mul_1142, 2048)
        mul_1376 = torch.ops.aten.mul.Tensor(div_147, sum_124);  div_147 = sum_124 = None
        sub_640 = torch.ops.aten.sub.Tensor(mul_1373, mul_1376);  mul_1373 = mul_1376 = None
        mul_1377 = torch.ops.aten.mul.Tensor(sub_640, rsqrt_74);  sub_640 = rsqrt_74 = None
        mul_1378 = torch.ops.aten.mul.Tensor(convert_element_type_1638, mul_1142);  convert_element_type_1638 = mul_1142 = None
        sum_125 = torch.ops.aten.sum.dim_IntList(mul_1378, [0, 1]);  mul_1378 = None
        convert_element_type_1641 = torch.ops.prims.convert_element_type.default(mul_1377, torch.bfloat16);  mul_1377 = None
        add_1817 = torch.ops.aten.add.Tensor(add_1804, convert_element_type_1641);  add_1804 = convert_element_type_1641 = None
        convert_element_type_default_75 = torch.ops.prims.convert_element_type.default(sum_125, torch.float32);  sum_125 = None
        reduce_scatter_tensor_37 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_75, 'avg', 128, '0');  convert_element_type_default_75 = None
        wait_tensor_602 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_37);  reduce_scatter_tensor_37 = None
        view_1824 = torch.ops.aten.view.default(add_1817, [8192, 2048])
        permute_536 = torch.ops.aten.permute.default(view_1824, [1, 0])
        permute_362 = torch.ops.aten.permute.default(getitem_2545, [0, 2, 1, 3])
        view_1594 = torch.ops.aten.view.default(permute_362, [2, 4096, -1]);  permute_362 = None
        view_1596 = torch.ops.aten.view.default(view_1594, [8192, 2048]);  view_1594 = None
        mm_258 = torch.ops.aten.mm.default(permute_536, view_1596);  permute_536 = view_1596 = None
        convert_element_type_1298 = torch.ops.prims.convert_element_type.default(primals_396, torch.bfloat16);  primals_396 = None
        all_gather_into_tensor_407 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1298, 128, '0');  convert_element_type_1298 = None
        wait_tensor_499 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_407);  all_gather_into_tensor_407 = None
        permute_363 = torch.ops.aten.permute.default(wait_tensor_499, [1, 0]);  wait_tensor_499 = None
        permute_538 = torch.ops.aten.permute.default(permute_363, [1, 0]);  permute_363 = None
        mm_259 = torch.ops.aten.mm.default(view_1824, permute_538);  view_1824 = permute_538 = None
        view_1825 = torch.ops.aten.view.default(mm_259, [2, 4096, 2048]);  mm_259 = None
        convert_element_type_1648 = torch.ops.prims.convert_element_type.default(mm_258, torch.float32);  mm_258 = None
        reduce_scatter_tensor_38 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1648, 'avg', 128, '0');  convert_element_type_1648 = None
        wait_tensor_603 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_38);  reduce_scatter_tensor_38 = None
        view_1826 = torch.ops.aten.view.default(view_1825, [2, 4096, 16, 128]);  view_1825 = None
        permute_540 = torch.ops.aten.permute.default(view_1826, [0, 2, 1, 3]);  view_1826 = None
        fw_graph2 = self.fw_graph2
        joint_graph2 = self.joint_graph2
        mask_graph2 = self.mask_graph2
        flex_attention_backward_2 = torch.ops.higher_order.flex_attention_backward(permute_359, permute_360, permute_361, getitem_2545, getitem_2546, permute_540, None, fw_graph2, joint_graph2, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph2), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_359 = permute_360 = permute_361 = getitem_2545 = getitem_2546 = permute_540 = fw_graph2 = joint_graph2 = mask_graph2 = None
        getitem_5749 = flex_attention_backward_2[0]
        getitem_5750 = flex_attention_backward_2[1]
        getitem_5751 = flex_attention_backward_2[2];  flex_attention_backward_2 = None
        permute_541 = torch.ops.aten.permute.default(getitem_5751, [0, 2, 1, 3]);  getitem_5751 = None
        permute_542 = torch.ops.aten.permute.default(getitem_5750, [0, 2, 1, 3]);  getitem_5750 = None
        permute_543 = torch.ops.aten.permute.default(getitem_5749, [0, 2, 1, 3]);  getitem_5749 = None
        slice_176 = torch.ops.aten.slice.Tensor(permute_542, 3, 0, 128)
        slice_177 = torch.ops.aten.slice.Tensor(permute_542, 3, 128, 192);  permute_542 = None
        sum_126 = torch.ops.aten.sum.dim_IntList(slice_177, [2], True);  slice_177 = None
        cat_256 = torch.ops.aten.cat.default([slice_176, permute_541], 3);  slice_176 = permute_541 = None
        view_1827 = torch.ops.aten.view.default(cat_256, [2, 4096, 4096]);  cat_256 = None
        view_1828 = torch.ops.aten.view.default(view_1827, [8192, 4096]);  view_1827 = None
        permute_544 = torch.ops.aten.permute.default(view_1828, [1, 0])
        mm_260 = torch.ops.aten.mm.default(permute_544, view_1591);  permute_544 = view_1591 = None
        convert_element_type_1295 = torch.ops.prims.convert_element_type.default(primals_395, torch.bfloat16);  primals_395 = None
        all_gather_into_tensor_406 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1295, 128, '0');  convert_element_type_1295 = None
        wait_tensor_498 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_406);  all_gather_into_tensor_406 = None
        permute_358 = torch.ops.aten.permute.default(wait_tensor_498, [1, 0]);  wait_tensor_498 = None
        permute_546 = torch.ops.aten.permute.default(permute_358, [1, 0]);  permute_358 = None
        mm_261 = torch.ops.aten.mm.default(view_1828, permute_546);  view_1828 = permute_546 = None
        view_1829 = torch.ops.aten.view.default(mm_261, [2, 4096, 512]);  mm_261 = None
        convert_element_type_1653 = torch.ops.prims.convert_element_type.default(mm_260, torch.float32);  mm_260 = None
        reduce_scatter_tensor_39 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1653, 'avg', 128, '0');  convert_element_type_1653 = None
        wait_tensor_604 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_39);  reduce_scatter_tensor_39 = None
        convert_element_type_1654 = torch.ops.prims.convert_element_type.default(view_1829, torch.float32);  view_1829 = None
        convert_element_type_1292 = torch.ops.prims.convert_element_type.default(primals_394, torch.bfloat16);  primals_394 = None
        all_gather_into_tensor_405 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1292, 128, '0');  convert_element_type_1292 = None
        wait_tensor_497 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_405);  all_gather_into_tensor_405 = None
        convert_element_type_1656 = torch.ops.prims.convert_element_type.default(wait_tensor_497, torch.float32);  wait_tensor_497 = None
        mul_1379 = torch.ops.aten.mul.Tensor(convert_element_type_1654, convert_element_type_1656);  convert_element_type_1656 = None
        convert_element_type_1293 = torch.ops.prims.convert_element_type.default(getitem_2541, torch.float32);  getitem_2541 = None
        mul_1140 = torch.ops.aten.mul.Tensor(convert_element_type_1293, rsqrt_73);  convert_element_type_1293 = None
        mul_1381 = torch.ops.aten.mul.Tensor(mul_1140, mul_1379)
        sum_127 = torch.ops.aten.sum.dim_IntList(mul_1381, [2], True);  mul_1381 = None
        div_148 = torch.ops.aten.div.Tensor(mul_1140, 512)
        mul_1382 = torch.ops.aten.mul.Tensor(div_148, sum_127);  div_148 = sum_127 = None
        sub_641 = torch.ops.aten.sub.Tensor(mul_1379, mul_1382);  mul_1379 = mul_1382 = None
        mul_1383 = torch.ops.aten.mul.Tensor(sub_641, rsqrt_73);  sub_641 = rsqrt_73 = None
        mul_1384 = torch.ops.aten.mul.Tensor(convert_element_type_1654, mul_1140);  convert_element_type_1654 = mul_1140 = None
        sum_128 = torch.ops.aten.sum.dim_IntList(mul_1384, [0, 1]);  mul_1384 = None
        convert_element_type_1657 = torch.ops.prims.convert_element_type.default(mul_1383, torch.bfloat16);  mul_1383 = None
        convert_element_type_default_74 = torch.ops.prims.convert_element_type.default(sum_128, torch.float32);  sum_128 = None
        reduce_scatter_tensor_40 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_74, 'avg', 128, '0');  convert_element_type_default_74 = None
        wait_tensor_605 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_40);  reduce_scatter_tensor_40 = None
        convert_element_type_1660 = torch.ops.prims.convert_element_type.default(sum_126, torch.float32);  sum_126 = None
        view_1830 = torch.ops.aten.view.default(convert_element_type_1660, [2, 4096, 1, 32, 2]);  convert_element_type_1660 = None
        view_as_complex_58 = torch.ops.aten.view_as_complex.default(view_1830);  view_1830 = None
        mul_1385 = torch.ops.aten.mul.Tensor(view_as_complex_58, clone_9);  view_as_complex_58 = None
        view_as_real_58 = torch.ops.aten.view_as_real.default(mul_1385);  mul_1385 = None
        view_1831 = torch.ops.aten.view.default(view_as_real_58, [2, 4096, 1, 64]);  view_as_real_58 = None
        convert_element_type_1661 = torch.ops.prims.convert_element_type.default(view_1831, torch.bfloat16);  view_1831 = None
        squeeze_28 = torch.ops.aten.squeeze.dim(convert_element_type_1661, 2);  convert_element_type_1661 = None
        cat_257 = torch.ops.aten.cat.default([convert_element_type_1657, squeeze_28], 2);  convert_element_type_1657 = squeeze_28 = None
        view_1832 = torch.ops.aten.view.default(cat_257, [8192, 576]);  cat_257 = None
        permute_548 = torch.ops.aten.permute.default(view_1832, [1, 0])
        mm_262 = torch.ops.aten.mm.default(permute_548, view_1577);  permute_548 = None
        convert_element_type_1287 = torch.ops.prims.convert_element_type.default(primals_393, torch.bfloat16);  primals_393 = None
        all_gather_into_tensor_404 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1287, 128, '0');  convert_element_type_1287 = None
        wait_tensor_496 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_404);  all_gather_into_tensor_404 = None
        slice_145 = torch.ops.aten.slice.Tensor(wait_tensor_496, 0, 0, 576);  wait_tensor_496 = None
        permute_357 = torch.ops.aten.permute.default(slice_145, [1, 0]);  slice_145 = None
        permute_550 = torch.ops.aten.permute.default(permute_357, [1, 0]);  permute_357 = None
        mm_263 = torch.ops.aten.mm.default(view_1832, permute_550);  view_1832 = permute_550 = None
        view_1833 = torch.ops.aten.view.default(mm_263, [2, 4096, 2048]);  mm_263 = None
        convert_element_type_1666 = torch.ops.prims.convert_element_type.default(mm_262, torch.float32);  mm_262 = None
        split_314 = torch.ops.aten.split.Tensor(convert_element_type_1666, 5);  convert_element_type_1666 = None
        getitem_5753 = split_314[0]
        getitem_5754 = split_314[1]
        getitem_5755 = split_314[2]
        getitem_5756 = split_314[3]
        getitem_5757 = split_314[4]
        getitem_5758 = split_314[5]
        getitem_5759 = split_314[6]
        getitem_5760 = split_314[7]
        getitem_5761 = split_314[8]
        getitem_5762 = split_314[9]
        getitem_5763 = split_314[10]
        getitem_5764 = split_314[11]
        getitem_5765 = split_314[12]
        getitem_5766 = split_314[13]
        getitem_5767 = split_314[14]
        getitem_5768 = split_314[15]
        getitem_5769 = split_314[16]
        getitem_5770 = split_314[17]
        getitem_5771 = split_314[18]
        getitem_5772 = split_314[19]
        getitem_5773 = split_314[20]
        getitem_5774 = split_314[21]
        getitem_5775 = split_314[22]
        getitem_5776 = split_314[23]
        getitem_5777 = split_314[24]
        getitem_5778 = split_314[25]
        getitem_5779 = split_314[26]
        getitem_5780 = split_314[27]
        getitem_5781 = split_314[28]
        getitem_5782 = split_314[29]
        getitem_5783 = split_314[30]
        getitem_5784 = split_314[31]
        getitem_5785 = split_314[32]
        getitem_5786 = split_314[33]
        getitem_5787 = split_314[34]
        getitem_5788 = split_314[35]
        getitem_5789 = split_314[36]
        getitem_5790 = split_314[37]
        getitem_5791 = split_314[38]
        getitem_5792 = split_314[39]
        getitem_5793 = split_314[40]
        getitem_5794 = split_314[41]
        getitem_5795 = split_314[42]
        getitem_5796 = split_314[43]
        getitem_5797 = split_314[44]
        getitem_5798 = split_314[45]
        getitem_5799 = split_314[46]
        getitem_5800 = split_314[47]
        getitem_5801 = split_314[48]
        getitem_5802 = split_314[49]
        getitem_5803 = split_314[50]
        getitem_5804 = split_314[51]
        getitem_5805 = split_314[52]
        getitem_5806 = split_314[53]
        getitem_5807 = split_314[54]
        getitem_5808 = split_314[55]
        getitem_5809 = split_314[56]
        getitem_5810 = split_314[57]
        getitem_5811 = split_314[58]
        getitem_5812 = split_314[59]
        getitem_5813 = split_314[60]
        getitem_5814 = split_314[61]
        getitem_5815 = split_314[62]
        getitem_5816 = split_314[63]
        getitem_5817 = split_314[64]
        getitem_5818 = split_314[65]
        getitem_5819 = split_314[66]
        getitem_5820 = split_314[67]
        getitem_5821 = split_314[68]
        getitem_5822 = split_314[69]
        getitem_5823 = split_314[70]
        getitem_5824 = split_314[71]
        getitem_5825 = split_314[72]
        getitem_5826 = split_314[73]
        getitem_5827 = split_314[74]
        getitem_5828 = split_314[75]
        getitem_5829 = split_314[76]
        getitem_5830 = split_314[77]
        getitem_5831 = split_314[78]
        getitem_5832 = split_314[79]
        getitem_5833 = split_314[80]
        getitem_5834 = split_314[81]
        getitem_5835 = split_314[82]
        getitem_5836 = split_314[83]
        getitem_5837 = split_314[84]
        getitem_5838 = split_314[85]
        getitem_5839 = split_314[86]
        getitem_5840 = split_314[87]
        getitem_5841 = split_314[88]
        getitem_5842 = split_314[89]
        getitem_5843 = split_314[90]
        getitem_5844 = split_314[91]
        getitem_5845 = split_314[92]
        getitem_5846 = split_314[93]
        getitem_5847 = split_314[94]
        getitem_5848 = split_314[95]
        getitem_5849 = split_314[96]
        getitem_5850 = split_314[97]
        getitem_5851 = split_314[98]
        getitem_5852 = split_314[99]
        getitem_5853 = split_314[100]
        getitem_5854 = split_314[101]
        getitem_5855 = split_314[102]
        getitem_5856 = split_314[103]
        getitem_5857 = split_314[104]
        getitem_5858 = split_314[105]
        getitem_5859 = split_314[106]
        getitem_5860 = split_314[107]
        getitem_5861 = split_314[108]
        getitem_5862 = split_314[109]
        getitem_5863 = split_314[110]
        getitem_5864 = split_314[111]
        getitem_5865 = split_314[112]
        getitem_5866 = split_314[113]
        getitem_5867 = split_314[114]
        getitem_5868 = split_314[115];  split_314 = None
        constant_pad_nd_218 = torch.ops.aten.constant_pad_nd.default(getitem_5868, [0, 0, 0, 4], 0.0);  getitem_5868 = None
        cat_258 = torch.ops.aten.cat.default([getitem_5753, getitem_5754, getitem_5755, getitem_5756, getitem_5757, getitem_5758, getitem_5759, getitem_5760, getitem_5761, getitem_5762, getitem_5763, getitem_5764, getitem_5765, getitem_5766, getitem_5767, getitem_5768, getitem_5769, getitem_5770, getitem_5771, getitem_5772, getitem_5773, getitem_5774, getitem_5775, getitem_5776, getitem_5777, getitem_5778, getitem_5779, getitem_5780, getitem_5781, getitem_5782, getitem_5783, getitem_5784, getitem_5785, getitem_5786, getitem_5787, getitem_5788, getitem_5789, getitem_5790, getitem_5791, getitem_5792, getitem_5793, getitem_5794, getitem_5795, getitem_5796, getitem_5797, getitem_5798, getitem_5799, getitem_5800, getitem_5801, getitem_5802, getitem_5803, getitem_5804, getitem_5805, getitem_5806, getitem_5807, getitem_5808, getitem_5809, getitem_5810, getitem_5811, getitem_5812, getitem_5813, getitem_5814, getitem_5815, getitem_5816, getitem_5817, getitem_5818, getitem_5819, getitem_5820, getitem_5821, getitem_5822, getitem_5823, getitem_5824, getitem_5825, getitem_5826, getitem_5827, getitem_5828, getitem_5829, getitem_5830, getitem_5831, getitem_5832, getitem_5833, getitem_5834, getitem_5835, getitem_5836, getitem_5837, getitem_5838, getitem_5839, getitem_5840, getitem_5841, getitem_5842, getitem_5843, getitem_5844, getitem_5845, getitem_5846, getitem_5847, getitem_5848, getitem_5849, getitem_5850, getitem_5851, getitem_5852, getitem_5853, getitem_5854, getitem_5855, getitem_5856, getitem_5857, getitem_5858, getitem_5859, getitem_5860, getitem_5861, getitem_5862, getitem_5863, getitem_5864, getitem_5865, getitem_5866, getitem_5867, constant_pad_nd_218, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_5753 = getitem_5754 = getitem_5755 = getitem_5756 = getitem_5757 = getitem_5758 = getitem_5759 = getitem_5760 = getitem_5761 = getitem_5762 = getitem_5763 = getitem_5764 = getitem_5765 = getitem_5766 = getitem_5767 = getitem_5768 = getitem_5769 = getitem_5770 = getitem_5771 = getitem_5772 = getitem_5773 = getitem_5774 = getitem_5775 = getitem_5776 = getitem_5777 = getitem_5778 = getitem_5779 = getitem_5780 = getitem_5781 = getitem_5782 = getitem_5783 = getitem_5784 = getitem_5785 = getitem_5786 = getitem_5787 = getitem_5788 = getitem_5789 = getitem_5790 = getitem_5791 = getitem_5792 = getitem_5793 = getitem_5794 = getitem_5795 = getitem_5796 = getitem_5797 = getitem_5798 = getitem_5799 = getitem_5800 = getitem_5801 = getitem_5802 = getitem_5803 = getitem_5804 = getitem_5805 = getitem_5806 = getitem_5807 = getitem_5808 = getitem_5809 = getitem_5810 = getitem_5811 = getitem_5812 = getitem_5813 = getitem_5814 = getitem_5815 = getitem_5816 = getitem_5817 = getitem_5818 = getitem_5819 = getitem_5820 = getitem_5821 = getitem_5822 = getitem_5823 = getitem_5824 = getitem_5825 = getitem_5826 = getitem_5827 = getitem_5828 = getitem_5829 = getitem_5830 = getitem_5831 = getitem_5832 = getitem_5833 = getitem_5834 = getitem_5835 = getitem_5836 = getitem_5837 = getitem_5838 = getitem_5839 = getitem_5840 = getitem_5841 = getitem_5842 = getitem_5843 = getitem_5844 = getitem_5845 = getitem_5846 = getitem_5847 = getitem_5848 = getitem_5849 = getitem_5850 = getitem_5851 = getitem_5852 = getitem_5853 = getitem_5854 = getitem_5855 = getitem_5856 = getitem_5857 = getitem_5858 = getitem_5859 = getitem_5860 = getitem_5861 = getitem_5862 = getitem_5863 = getitem_5864 = getitem_5865 = getitem_5866 = getitem_5867 = constant_pad_nd_218 = None
        reduce_scatter_tensor_41 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_258, 'avg', 128, '0');  cat_258 = None
        wait_tensor_606 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_41);  reduce_scatter_tensor_41 = None
        slice_178 = torch.ops.aten.slice.Tensor(permute_543, 3, 0, 128)
        slice_179 = torch.ops.aten.slice.Tensor(permute_543, 3, 128, 192);  permute_543 = None
        convert_element_type_1667 = torch.ops.prims.convert_element_type.default(slice_179, torch.float32);  slice_179 = None
        view_1834 = torch.ops.aten.view.default(convert_element_type_1667, [2, 4096, 16, 32, 2]);  convert_element_type_1667 = None
        view_as_complex_59 = torch.ops.aten.view_as_complex.default(view_1834);  view_1834 = None
        mul_1386 = torch.ops.aten.mul.Tensor(view_as_complex_59, clone_9);  view_as_complex_59 = None
        view_as_real_59 = torch.ops.aten.view_as_real.default(mul_1386);  mul_1386 = None
        view_1835 = torch.ops.aten.view.default(view_as_real_59, [2, 4096, 16, 64]);  view_as_real_59 = None
        convert_element_type_1668 = torch.ops.prims.convert_element_type.default(view_1835, torch.bfloat16);  view_1835 = None
        cat_259 = torch.ops.aten.cat.default([slice_178, convert_element_type_1668], 3);  slice_178 = convert_element_type_1668 = None
        view_1836 = torch.ops.aten.view.default(cat_259, [2, 4096, 3072]);  cat_259 = None
        view_1837 = torch.ops.aten.view.default(view_1836, [8192, 3072]);  view_1836 = None
        permute_552 = torch.ops.aten.permute.default(view_1837, [1, 0])
        mm_264 = torch.ops.aten.mm.default(permute_552, view_1577);  permute_552 = view_1577 = None
        convert_element_type_1282 = torch.ops.prims.convert_element_type.default(primals_392, torch.bfloat16);  primals_392 = None
        all_gather_into_tensor_403 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1282, 128, '0');  convert_element_type_1282 = None
        wait_tensor_495 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_403);  all_gather_into_tensor_403 = None
        permute_356 = torch.ops.aten.permute.default(wait_tensor_495, [1, 0]);  wait_tensor_495 = None
        permute_554 = torch.ops.aten.permute.default(permute_356, [1, 0]);  permute_356 = None
        mm_265 = torch.ops.aten.mm.default(view_1837, permute_554);  view_1837 = permute_554 = None
        view_1838 = torch.ops.aten.view.default(mm_265, [2, 4096, 2048]);  mm_265 = None
        add_1818 = torch.ops.aten.add.Tensor(view_1833, view_1838);  view_1833 = view_1838 = None
        convert_element_type_1673 = torch.ops.prims.convert_element_type.default(mm_264, torch.float32);  mm_264 = None
        reduce_scatter_tensor_42 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1673, 'avg', 128, '0');  convert_element_type_1673 = None
        wait_tensor_607 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_42);  reduce_scatter_tensor_42 = None
        convert_element_type_1674 = torch.ops.prims.convert_element_type.default(add_1818, torch.float32);  add_1818 = None
        convert_element_type_1279 = torch.ops.prims.convert_element_type.default(primals_391, torch.bfloat16);  primals_391 = None
        all_gather_into_tensor_402 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1279, 128, '0');  convert_element_type_1279 = None
        wait_tensor_494 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_402);  all_gather_into_tensor_402 = None
        convert_element_type_1676 = torch.ops.prims.convert_element_type.default(wait_tensor_494, torch.float32);  wait_tensor_494 = None
        mul_1387 = torch.ops.aten.mul.Tensor(convert_element_type_1674, convert_element_type_1676);  convert_element_type_1676 = None
        convert_element_type_1280 = torch.ops.prims.convert_element_type.default(add_1569, torch.float32);  add_1569 = None
        mul_1136 = torch.ops.aten.mul.Tensor(convert_element_type_1280, rsqrt_72);  convert_element_type_1280 = None
        mul_1389 = torch.ops.aten.mul.Tensor(mul_1136, mul_1387)
        sum_129 = torch.ops.aten.sum.dim_IntList(mul_1389, [2], True);  mul_1389 = None
        div_149 = torch.ops.aten.div.Tensor(mul_1136, 2048)
        mul_1390 = torch.ops.aten.mul.Tensor(div_149, sum_129);  div_149 = sum_129 = None
        sub_642 = torch.ops.aten.sub.Tensor(mul_1387, mul_1390);  mul_1387 = mul_1390 = None
        mul_1391 = torch.ops.aten.mul.Tensor(sub_642, rsqrt_72);  sub_642 = rsqrt_72 = None
        mul_1392 = torch.ops.aten.mul.Tensor(convert_element_type_1674, mul_1136);  convert_element_type_1674 = mul_1136 = None
        sum_130 = torch.ops.aten.sum.dim_IntList(mul_1392, [0, 1]);  mul_1392 = None
        convert_element_type_1677 = torch.ops.prims.convert_element_type.default(mul_1391, torch.bfloat16);  mul_1391 = None
        add_1819 = torch.ops.aten.add.Tensor(add_1817, convert_element_type_1677);  add_1817 = convert_element_type_1677 = None
        convert_element_type_default_73 = torch.ops.prims.convert_element_type.default(sum_130, torch.float32);  sum_130 = None
        reduce_scatter_tensor_43 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_73, 'avg', 128, '0');  convert_element_type_default_73 = None
        wait_tensor_608 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_43);  reduce_scatter_tensor_43 = None
        view_1839 = torch.ops.aten.view.default(add_1819, [8192, 2048])
        unsqueeze_56 = torch.ops.aten.unsqueeze.default(view_1839, 1)
        convert_element_type_1680 = torch.ops.prims.convert_element_type.default(unsqueeze_56, torch.float32);  unsqueeze_56 = None
        bmm_32 = torch.ops.aten.bmm.default(permute_556, convert_element_type_1680);  permute_556 = None
        bmm_33 = torch.ops.aten.bmm.default(convert_element_type_1680, permute_557);  convert_element_type_1680 = permute_557 = None
        convert_element_type_1681 = torch.ops.prims.convert_element_type.default(bmm_32, torch.bfloat16);  bmm_32 = None
        view_1840 = torch.ops.aten.view.default(bmm_33, [8192, 6]);  bmm_33 = None
        view_1841 = torch.ops.aten.view.default(convert_element_type_1681, [49152, 2048]);  convert_element_type_1681 = None
        index_58 = torch.ops.aten.index.Tensor(view_1841, [getitem_2441]);  view_1841 = getitem_2441 = None
        permute_558 = torch.ops.aten.permute.default(view_1839, [1, 0])
        mm_266 = torch.ops.aten.mm.default(permute_558, mul_1133);  permute_558 = mul_1133 = None
        convert_element_type_1274 = torch.ops.prims.convert_element_type.default(primals_390, torch.bfloat16);  primals_390 = None
        all_gather_into_tensor_401 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1274, 128, '0');  convert_element_type_1274 = None
        wait_tensor_493 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_401);  all_gather_into_tensor_401 = None
        permute_355 = torch.ops.aten.permute.default(wait_tensor_493, [1, 0]);  wait_tensor_493 = None
        permute_560 = torch.ops.aten.permute.default(permute_355, [1, 0]);  permute_355 = None
        mm_267 = torch.ops.aten.mm.default(view_1839, permute_560);  view_1839 = permute_560 = None
        convert_element_type_1686 = torch.ops.prims.convert_element_type.default(mm_266, torch.float32);  mm_266 = None
        reduce_scatter_tensor_44 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1686, 'avg', 128, '0');  convert_element_type_1686 = None
        wait_tensor_609 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_44);  reduce_scatter_tensor_44 = None
        convert_element_type_1269 = torch.ops.prims.convert_element_type.default(mm_188, torch.float32);  mm_188 = None
        neg_46 = torch.ops.aten.neg.default(convert_element_type_1269)
        exp_69 = torch.ops.aten.exp.default(neg_46);  neg_46 = None
        add_1564 = torch.ops.aten.add.Tensor(exp_69, 1);  exp_69 = None
        div_115 = torch.ops.aten.div.Tensor(convert_element_type_1269, add_1564)
        convert_element_type_1270 = torch.ops.prims.convert_element_type.default(div_115, torch.bfloat16);  div_115 = None
        mul_1393 = torch.ops.aten.mul.Tensor(mm_267, convert_element_type_1270);  convert_element_type_1270 = None
        mul_1394 = torch.ops.aten.mul.Tensor(mm_267, mm_189);  mm_267 = mm_189 = None
        permute_562 = torch.ops.aten.permute.default(mul_1393, [1, 0])
        mm_268 = torch.ops.aten.mm.default(permute_562, view_1532);  permute_562 = None
        convert_element_type_1271 = torch.ops.prims.convert_element_type.default(primals_389, torch.bfloat16);  primals_389 = None
        all_gather_into_tensor_400 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1271, 128, '0');  convert_element_type_1271 = None
        wait_tensor_492 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_400);  all_gather_into_tensor_400 = None
        permute_354 = torch.ops.aten.permute.default(wait_tensor_492, [1, 0]);  wait_tensor_492 = None
        permute_564 = torch.ops.aten.permute.default(permute_354, [1, 0]);  permute_354 = None
        mm_269 = torch.ops.aten.mm.default(mul_1393, permute_564);  mul_1393 = permute_564 = None
        convert_element_type_1691 = torch.ops.prims.convert_element_type.default(mm_268, torch.float32);  mm_268 = None
        reduce_scatter_tensor_45 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1691, 'avg', 128, '0');  convert_element_type_1691 = None
        wait_tensor_610 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_45);  reduce_scatter_tensor_45 = None
        convert_element_type_1692 = torch.ops.prims.convert_element_type.default(mul_1394, torch.float32);  mul_1394 = None
        reciprocal_6 = torch.ops.aten.reciprocal.default(add_1564);  add_1564 = None
        mul_1395 = torch.ops.aten.mul.Tensor(reciprocal_6, 1);  reciprocal_6 = None
        mul_1396 = torch.ops.aten.mul.Tensor(convert_element_type_1692, mul_1395);  convert_element_type_1692 = None
        sub_643 = torch.ops.aten.sub.Tensor(1, mul_1395);  mul_1395 = None
        mul_1397 = torch.ops.aten.mul.Tensor(convert_element_type_1269, sub_643);  convert_element_type_1269 = sub_643 = None
        add_1821 = torch.ops.aten.add.Tensor(mul_1397, 1);  mul_1397 = None
        mul_1398 = torch.ops.aten.mul.Tensor(mul_1396, add_1821);  mul_1396 = add_1821 = None
        convert_element_type_1694 = torch.ops.prims.convert_element_type.default(mul_1398, torch.bfloat16);  mul_1398 = None
        permute_566 = torch.ops.aten.permute.default(convert_element_type_1694, [1, 0])
        mm_270 = torch.ops.aten.mm.default(permute_566, view_1532);  permute_566 = None
        convert_element_type_1266 = torch.ops.prims.convert_element_type.default(primals_388, torch.bfloat16);  primals_388 = None
        all_gather_into_tensor_399 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1266, 128, '0');  convert_element_type_1266 = None
        wait_tensor_491 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_399);  all_gather_into_tensor_399 = None
        permute_353 = torch.ops.aten.permute.default(wait_tensor_491, [1, 0]);  wait_tensor_491 = None
        permute_568 = torch.ops.aten.permute.default(permute_353, [1, 0]);  permute_353 = None
        mm_271 = torch.ops.aten.mm.default(convert_element_type_1694, permute_568);  convert_element_type_1694 = permute_568 = None
        add_1822 = torch.ops.aten.add.Tensor(mm_269, mm_271);  mm_269 = mm_271 = None
        convert_element_type_1699 = torch.ops.prims.convert_element_type.default(mm_270, torch.float32);  mm_270 = None
        reduce_scatter_tensor_46 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1699, 'avg', 128, '0');  convert_element_type_1699 = None
        wait_tensor_611 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_46);  reduce_scatter_tensor_46 = None
        all_to_all_single_84 = torch.ops._c10d_functional.all_to_all_single.default(index_58, [_local_scalar_dense_360, _local_scalar_dense_361, _local_scalar_dense_362, _local_scalar_dense_363, _local_scalar_dense_364, _local_scalar_dense_365, _local_scalar_dense_366, _local_scalar_dense_367], [_local_scalar_dense_352, _local_scalar_dense_353, _local_scalar_dense_354, _local_scalar_dense_355, _local_scalar_dense_356, _local_scalar_dense_357, _local_scalar_dense_358, _local_scalar_dense_359], '1033');  index_58 = None
        wait_tensor_612 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_84);  all_to_all_single_84 = None
        full_366 = torch.ops.aten.full.default([sym_size_int_89, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_89 = None
        slice_scatter_3 = torch.ops.aten.slice_scatter.default(full_366, wait_tensor_612, 0, 0, -1);  wait_tensor_612 = None
        index_59 = torch.ops.aten.index.Tensor(slice_scatter_3, [getitem_2442]);  slice_scatter_3 = None
        permute_570 = torch.ops.aten.permute.default(index_59, [1, 0])
        _grouped_mm_96 = torch.ops.aten._grouped_mm.default(permute_570, mul_1113, cumsum_68);  permute_570 = mul_1113 = None
        _grouped_mm_97 = torch.ops.aten._grouped_mm.default(index_59, permute_572, cumsum_68);  index_59 = permute_572 = None
        convert_element_type_1264 = torch.ops.prims.convert_element_type.default(_grouped_mm_66, torch.float32);  _grouped_mm_66 = None
        neg_45 = torch.ops.aten.neg.default(convert_element_type_1264)
        exp_68 = torch.ops.aten.exp.default(neg_45);  neg_45 = None
        add_1528 = torch.ops.aten.add.Tensor(exp_68, 1);  exp_68 = None
        div_114 = torch.ops.aten.div.Tensor(convert_element_type_1264, add_1528)
        convert_element_type_1265 = torch.ops.prims.convert_element_type.default(div_114, torch.bfloat16);  div_114 = None
        mul_1399 = torch.ops.aten.mul.Tensor(_grouped_mm_97, convert_element_type_1265);  convert_element_type_1265 = None
        mul_1400 = torch.ops.aten.mul.Tensor(_grouped_mm_97, _grouped_mm_67);  _grouped_mm_97 = _grouped_mm_67 = None
        permute_574 = torch.ops.aten.permute.default(mul_1399, [1, 0])
        _grouped_mm_98 = torch.ops.aten._grouped_mm.default(permute_574, index_45, cumsum_68);  permute_574 = None
        _grouped_mm_99 = torch.ops.aten._grouped_mm.default(mul_1399, permute_576, cumsum_68);  mul_1399 = permute_576 = None
        convert_element_type_1700 = torch.ops.prims.convert_element_type.default(mul_1400, torch.float32);  mul_1400 = None
        reciprocal_7 = torch.ops.aten.reciprocal.default(add_1528);  add_1528 = None
        mul_1401 = torch.ops.aten.mul.Tensor(reciprocal_7, 1);  reciprocal_7 = None
        mul_1402 = torch.ops.aten.mul.Tensor(convert_element_type_1700, mul_1401);  convert_element_type_1700 = None
        sub_644 = torch.ops.aten.sub.Tensor(1, mul_1401);  mul_1401 = None
        mul_1403 = torch.ops.aten.mul.Tensor(convert_element_type_1264, sub_644);  convert_element_type_1264 = sub_644 = None
        add_1824 = torch.ops.aten.add.Tensor(mul_1403, 1);  mul_1403 = None
        mul_1404 = torch.ops.aten.mul.Tensor(mul_1402, add_1824);  mul_1402 = add_1824 = None
        convert_element_type_1702 = torch.ops.prims.convert_element_type.default(mul_1404, torch.bfloat16);  mul_1404 = None
        permute_578 = torch.ops.aten.permute.default(convert_element_type_1702, [1, 0])
        _grouped_mm_100 = torch.ops.aten._grouped_mm.default(permute_578, index_45, cumsum_68);  permute_578 = index_45 = None
        _grouped_mm_101 = torch.ops.aten._grouped_mm.default(convert_element_type_1702, permute_580, cumsum_68);  convert_element_type_1702 = permute_580 = cumsum_68 = None
        add_1825 = torch.ops.aten.add.Tensor(_grouped_mm_99, _grouped_mm_101);  _grouped_mm_99 = _grouped_mm_101 = None
        convert_element_type_1703 = torch.ops.prims.convert_element_type.default(_grouped_mm_98, torch.float32);  _grouped_mm_98 = None
        div_150 = torch.ops.aten.div.Tensor(convert_element_type_1703, 128);  convert_element_type_1703 = None
        split_316 = torch.ops.aten.split.Tensor(div_150, 88, 1);  div_150 = None
        getitem_5885 = split_316[0]
        getitem_5902 = split_316[1]
        getitem_5919 = split_316[2]
        getitem_5936 = split_316[3]
        getitem_5953 = split_316[4]
        getitem_5970 = split_316[5]
        getitem_5987 = split_316[6]
        getitem_6004 = split_316[7]
        getitem_6021 = split_316[8]
        getitem_6038 = split_316[9]
        getitem_6055 = split_316[10]
        getitem_6072 = split_316[11]
        getitem_6089 = split_316[12]
        getitem_6106 = split_316[13]
        getitem_6123 = split_316[14]
        getitem_6140 = split_316[15];  split_316 = None
        cat_260 = torch.ops.aten.cat.default([getitem_5885, getitem_5902, getitem_5919, getitem_5936, getitem_5953, getitem_5970, getitem_5987, getitem_6004, getitem_6021, getitem_6038, getitem_6055, getitem_6072, getitem_6089, getitem_6106, getitem_6123, getitem_6140]);  getitem_5885 = getitem_5902 = getitem_5919 = getitem_5936 = getitem_5953 = getitem_5970 = getitem_5987 = getitem_6004 = getitem_6021 = getitem_6038 = getitem_6055 = getitem_6072 = getitem_6089 = getitem_6106 = getitem_6123 = getitem_6140 = None
        reduce_scatter_tensor_47 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_260, 'sum', 16, '1025');  cat_260 = None
        wait_tensor_613 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_47);  reduce_scatter_tensor_47 = None
        convert_element_type_1704 = torch.ops.prims.convert_element_type.default(_grouped_mm_96, torch.float32);  _grouped_mm_96 = None
        div_151 = torch.ops.aten.div.Tensor(convert_element_type_1704, 128);  convert_element_type_1704 = None
        split_333 = torch.ops.aten.split.Tensor(div_151, 128, 1);  div_151 = None
        getitem_6157 = split_333[0]
        getitem_6174 = split_333[1]
        getitem_6191 = split_333[2]
        getitem_6208 = split_333[3]
        getitem_6225 = split_333[4]
        getitem_6242 = split_333[5]
        getitem_6259 = split_333[6]
        getitem_6276 = split_333[7]
        getitem_6293 = split_333[8]
        getitem_6310 = split_333[9]
        getitem_6327 = split_333[10]
        getitem_6344 = split_333[11]
        getitem_6361 = split_333[12]
        getitem_6378 = split_333[13]
        getitem_6395 = split_333[14]
        getitem_6412 = split_333[15];  split_333 = None
        cat_261 = torch.ops.aten.cat.default([getitem_6157, getitem_6174, getitem_6191, getitem_6208, getitem_6225, getitem_6242, getitem_6259, getitem_6276, getitem_6293, getitem_6310, getitem_6327, getitem_6344, getitem_6361, getitem_6378, getitem_6395, getitem_6412]);  getitem_6157 = getitem_6174 = getitem_6191 = getitem_6208 = getitem_6225 = getitem_6242 = getitem_6259 = getitem_6276 = getitem_6293 = getitem_6310 = getitem_6327 = getitem_6344 = getitem_6361 = getitem_6378 = getitem_6395 = getitem_6412 = None
        reduce_scatter_tensor_48 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_261, 'sum', 16, '1025');  cat_261 = None
        wait_tensor_614 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_48);  reduce_scatter_tensor_48 = None
        convert_element_type_1705 = torch.ops.prims.convert_element_type.default(_grouped_mm_100, torch.float32);  _grouped_mm_100 = None
        div_152 = torch.ops.aten.div.Tensor(convert_element_type_1705, 128);  convert_element_type_1705 = None
        split_350 = torch.ops.aten.split.Tensor(div_152, 88, 1);  div_152 = None
        getitem_6429 = split_350[0]
        getitem_6446 = split_350[1]
        getitem_6463 = split_350[2]
        getitem_6480 = split_350[3]
        getitem_6497 = split_350[4]
        getitem_6514 = split_350[5]
        getitem_6531 = split_350[6]
        getitem_6548 = split_350[7]
        getitem_6565 = split_350[8]
        getitem_6582 = split_350[9]
        getitem_6599 = split_350[10]
        getitem_6616 = split_350[11]
        getitem_6633 = split_350[12]
        getitem_6650 = split_350[13]
        getitem_6667 = split_350[14]
        getitem_6684 = split_350[15];  split_350 = None
        cat_262 = torch.ops.aten.cat.default([getitem_6429, getitem_6446, getitem_6463, getitem_6480, getitem_6497, getitem_6514, getitem_6531, getitem_6548, getitem_6565, getitem_6582, getitem_6599, getitem_6616, getitem_6633, getitem_6650, getitem_6667, getitem_6684]);  getitem_6429 = getitem_6446 = getitem_6463 = getitem_6480 = getitem_6497 = getitem_6514 = getitem_6531 = getitem_6548 = getitem_6565 = getitem_6582 = getitem_6599 = getitem_6616 = getitem_6633 = getitem_6650 = getitem_6667 = getitem_6684 = None
        reduce_scatter_tensor_49 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_262, 'sum', 16, '1025');  cat_262 = None
        wait_tensor_615 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_49);  reduce_scatter_tensor_49 = None
        index_put_58 = torch.ops.aten.index_put.default(full_366, [getitem_2442], add_1825, True);  full_366 = getitem_2442 = add_1825 = None
        slice_180 = torch.ops.aten.slice.Tensor(index_put_58, 0, 0, add_1826);  index_put_58 = add_1826 = None
        all_to_all_single_85 = torch.ops._c10d_functional.all_to_all_single.default(slice_180, [_local_scalar_dense_352, _local_scalar_dense_353, _local_scalar_dense_354, _local_scalar_dense_355, _local_scalar_dense_356, _local_scalar_dense_357, _local_scalar_dense_358, _local_scalar_dense_359], [_local_scalar_dense_360, _local_scalar_dense_361, _local_scalar_dense_362, _local_scalar_dense_363, _local_scalar_dense_364, _local_scalar_dense_365, _local_scalar_dense_366, _local_scalar_dense_367], '1033');  slice_180 = _local_scalar_dense_352 = _local_scalar_dense_353 = _local_scalar_dense_354 = _local_scalar_dense_355 = _local_scalar_dense_356 = _local_scalar_dense_357 = _local_scalar_dense_358 = _local_scalar_dense_359 = _local_scalar_dense_360 = _local_scalar_dense_361 = _local_scalar_dense_362 = _local_scalar_dense_363 = _local_scalar_dense_364 = _local_scalar_dense_365 = _local_scalar_dense_366 = _local_scalar_dense_367 = None
        wait_tensor_616 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_85);  all_to_all_single_85 = None
        index_put_59 = torch.ops.aten.index_put.default(full_default_52, [div_112], wait_tensor_616, True);  div_112 = wait_tensor_616 = None
        add_1830 = torch.ops.aten.add.Tensor(add_1822, index_put_59);  add_1822 = index_put_59 = None
        mul_1405 = torch.ops.aten.mul.Tensor(view_1840, 1.0);  view_1840 = None
        scatter_add_3 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_2439, mul_1405);  getitem_2439 = mul_1405 = None
        convert_element_type_1253 = torch.ops.prims.convert_element_type.default(mm_187, torch.float32);  mm_187 = None
        sub_528 = torch.ops.aten.sub.Tensor(convert_element_type_1253, amax_22);  convert_element_type_1253 = amax_22 = None
        exp_67 = torch.ops.aten.exp.default(sub_528);  sub_528 = None
        div_111 = torch.ops.aten.div.Tensor(exp_67, sum_89);  exp_67 = sum_89 = None
        mul_1406 = torch.ops.aten.mul.Tensor(scatter_add_3, div_111);  scatter_add_3 = None
        sum_131 = torch.ops.aten.sum.dim_IntList(mul_1406, [1], True)
        neg_64 = torch.ops.aten.neg.default(div_111);  div_111 = None
        fma_3 = torch.ops.prims.fma.default(neg_64, sum_131, mul_1406);  neg_64 = sum_131 = mul_1406 = None
        convert_element_type_1706 = torch.ops.prims.convert_element_type.default(fma_3, torch.bfloat16);  fma_3 = None
        permute_582 = torch.ops.aten.permute.default(convert_element_type_1706, [1, 0])
        mm_272 = torch.ops.aten.mm.default(permute_582, view_1532);  permute_582 = view_1532 = None
        convert_element_type_1250 = torch.ops.prims.convert_element_type.default(primals_383, torch.bfloat16);  primals_383 = None
        all_gather_into_tensor_392 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1250, 128, '0');  convert_element_type_1250 = None
        wait_tensor_480 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_392);  all_gather_into_tensor_392 = None
        slice_141 = torch.ops.aten.slice.Tensor(wait_tensor_480, 0, 0, 64);  wait_tensor_480 = None
        permute_349 = torch.ops.aten.permute.default(slice_141, [1, 0]);  slice_141 = None
        permute_584 = torch.ops.aten.permute.default(permute_349, [1, 0]);  permute_349 = None
        mm_273 = torch.ops.aten.mm.default(convert_element_type_1706, permute_584);  convert_element_type_1706 = permute_584 = None
        add_1831 = torch.ops.aten.add.Tensor(add_1830, mm_273);  add_1830 = mm_273 = None
        convert_element_type_1711 = torch.ops.prims.convert_element_type.default(mm_272, torch.float32);  mm_272 = None
        split_366 = torch.ops.aten.split.Tensor(convert_element_type_1711, 1);  convert_element_type_1711 = None
        getitem_6685 = split_366[0]
        getitem_6686 = split_366[1]
        getitem_6687 = split_366[2]
        getitem_6688 = split_366[3]
        getitem_6689 = split_366[4]
        getitem_6690 = split_366[5]
        getitem_6691 = split_366[6]
        getitem_6692 = split_366[7]
        getitem_6693 = split_366[8]
        getitem_6694 = split_366[9]
        getitem_6695 = split_366[10]
        getitem_6696 = split_366[11]
        getitem_6697 = split_366[12]
        getitem_6698 = split_366[13]
        getitem_6699 = split_366[14]
        getitem_6700 = split_366[15]
        getitem_6701 = split_366[16]
        getitem_6702 = split_366[17]
        getitem_6703 = split_366[18]
        getitem_6704 = split_366[19]
        getitem_6705 = split_366[20]
        getitem_6706 = split_366[21]
        getitem_6707 = split_366[22]
        getitem_6708 = split_366[23]
        getitem_6709 = split_366[24]
        getitem_6710 = split_366[25]
        getitem_6711 = split_366[26]
        getitem_6712 = split_366[27]
        getitem_6713 = split_366[28]
        getitem_6714 = split_366[29]
        getitem_6715 = split_366[30]
        getitem_6716 = split_366[31]
        getitem_6717 = split_366[32]
        getitem_6718 = split_366[33]
        getitem_6719 = split_366[34]
        getitem_6720 = split_366[35]
        getitem_6721 = split_366[36]
        getitem_6722 = split_366[37]
        getitem_6723 = split_366[38]
        getitem_6724 = split_366[39]
        getitem_6725 = split_366[40]
        getitem_6726 = split_366[41]
        getitem_6727 = split_366[42]
        getitem_6728 = split_366[43]
        getitem_6729 = split_366[44]
        getitem_6730 = split_366[45]
        getitem_6731 = split_366[46]
        getitem_6732 = split_366[47]
        getitem_6733 = split_366[48]
        getitem_6734 = split_366[49]
        getitem_6735 = split_366[50]
        getitem_6736 = split_366[51]
        getitem_6737 = split_366[52]
        getitem_6738 = split_366[53]
        getitem_6739 = split_366[54]
        getitem_6740 = split_366[55]
        getitem_6741 = split_366[56]
        getitem_6742 = split_366[57]
        getitem_6743 = split_366[58]
        getitem_6744 = split_366[59]
        getitem_6745 = split_366[60]
        getitem_6746 = split_366[61]
        getitem_6747 = split_366[62]
        getitem_6748 = split_366[63];  split_366 = None
        cat_263 = torch.ops.aten.cat.default([getitem_6685, getitem_6686, getitem_6687, getitem_6688, getitem_6689, getitem_6690, getitem_6691, getitem_6692, getitem_6693, getitem_6694, getitem_6695, getitem_6696, getitem_6697, getitem_6698, getitem_6699, getitem_6700, getitem_6701, getitem_6702, getitem_6703, getitem_6704, getitem_6705, getitem_6706, getitem_6707, getitem_6708, getitem_6709, getitem_6710, getitem_6711, getitem_6712, getitem_6713, getitem_6714, getitem_6715, getitem_6716, getitem_6717, getitem_6718, getitem_6719, getitem_6720, getitem_6721, getitem_6722, getitem_6723, getitem_6724, getitem_6725, getitem_6726, getitem_6727, getitem_6728, getitem_6729, getitem_6730, getitem_6731, getitem_6732, getitem_6733, getitem_6734, getitem_6735, getitem_6736, getitem_6737, getitem_6738, getitem_6739, getitem_6740, getitem_6741, getitem_6742, getitem_6743, getitem_6744, getitem_6745, getitem_6746, getitem_6747, getitem_6748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_6685 = getitem_6686 = getitem_6687 = getitem_6688 = getitem_6689 = getitem_6690 = getitem_6691 = getitem_6692 = getitem_6693 = getitem_6694 = getitem_6695 = getitem_6696 = getitem_6697 = getitem_6698 = getitem_6699 = getitem_6700 = getitem_6701 = getitem_6702 = getitem_6703 = getitem_6704 = getitem_6705 = getitem_6706 = getitem_6707 = getitem_6708 = getitem_6709 = getitem_6710 = getitem_6711 = getitem_6712 = getitem_6713 = getitem_6714 = getitem_6715 = getitem_6716 = getitem_6717 = getitem_6718 = getitem_6719 = getitem_6720 = getitem_6721 = getitem_6722 = getitem_6723 = getitem_6724 = getitem_6725 = getitem_6726 = getitem_6727 = getitem_6728 = getitem_6729 = getitem_6730 = getitem_6731 = getitem_6732 = getitem_6733 = getitem_6734 = getitem_6735 = getitem_6736 = getitem_6737 = getitem_6738 = getitem_6739 = getitem_6740 = getitem_6741 = getitem_6742 = getitem_6743 = getitem_6744 = getitem_6745 = getitem_6746 = getitem_6747 = getitem_6748 = None
        reduce_scatter_tensor_50 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_263, 'avg', 128, '0');  cat_263 = None
        wait_tensor_617 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_50);  reduce_scatter_tensor_50 = None
        view_1842 = torch.ops.aten.view.default(add_1831, [2, 4096, 2048]);  add_1831 = None
        convert_element_type_1712 = torch.ops.prims.convert_element_type.default(view_1842, torch.float32);  view_1842 = None
        convert_element_type_1247 = torch.ops.prims.convert_element_type.default(primals_381, torch.bfloat16);  primals_381 = None
        all_gather_into_tensor_391 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1247, 128, '0');  convert_element_type_1247 = None
        wait_tensor_479 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_391);  all_gather_into_tensor_391 = None
        convert_element_type_1714 = torch.ops.prims.convert_element_type.default(wait_tensor_479, torch.float32);  wait_tensor_479 = None
        mul_1407 = torch.ops.aten.mul.Tensor(convert_element_type_1712, convert_element_type_1714);  convert_element_type_1714 = None
        convert_element_type_1248 = torch.ops.prims.convert_element_type.default(add_1504, torch.float32);  add_1504 = None
        mul_1093 = torch.ops.aten.mul.Tensor(convert_element_type_1248, rsqrt_71);  convert_element_type_1248 = None
        mul_1409 = torch.ops.aten.mul.Tensor(mul_1093, mul_1407)
        sum_132 = torch.ops.aten.sum.dim_IntList(mul_1409, [2], True);  mul_1409 = None
        div_153 = torch.ops.aten.div.Tensor(mul_1093, 2048)
        mul_1410 = torch.ops.aten.mul.Tensor(div_153, sum_132);  div_153 = sum_132 = None
        sub_646 = torch.ops.aten.sub.Tensor(mul_1407, mul_1410);  mul_1407 = mul_1410 = None
        mul_1411 = torch.ops.aten.mul.Tensor(sub_646, rsqrt_71);  sub_646 = rsqrt_71 = None
        mul_1412 = torch.ops.aten.mul.Tensor(convert_element_type_1712, mul_1093);  convert_element_type_1712 = mul_1093 = None
        sum_133 = torch.ops.aten.sum.dim_IntList(mul_1412, [0, 1]);  mul_1412 = None
        convert_element_type_1715 = torch.ops.prims.convert_element_type.default(mul_1411, torch.bfloat16);  mul_1411 = None
        add_1832 = torch.ops.aten.add.Tensor(add_1819, convert_element_type_1715);  add_1819 = convert_element_type_1715 = None
        convert_element_type_default_72 = torch.ops.prims.convert_element_type.default(sum_133, torch.float32);  sum_133 = None
        reduce_scatter_tensor_51 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_72, 'avg', 128, '0');  convert_element_type_default_72 = None
        wait_tensor_618 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_51);  reduce_scatter_tensor_51 = None
        view_1843 = torch.ops.aten.view.default(add_1832, [8192, 2048])
        permute_586 = torch.ops.aten.permute.default(view_1843, [1, 0])
        permute_347 = torch.ops.aten.permute.default(getitem_2435, [0, 2, 1, 3])
        view_1527 = torch.ops.aten.view.default(permute_347, [2, 4096, -1]);  permute_347 = None
        view_1529 = torch.ops.aten.view.default(view_1527, [8192, 2048]);  view_1527 = None
        mm_274 = torch.ops.aten.mm.default(permute_586, view_1529);  permute_586 = view_1529 = None
        convert_element_type_1244 = torch.ops.prims.convert_element_type.default(primals_380, torch.bfloat16);  primals_380 = None
        all_gather_into_tensor_390 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1244, 128, '0');  convert_element_type_1244 = None
        wait_tensor_478 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_390);  all_gather_into_tensor_390 = None
        permute_348 = torch.ops.aten.permute.default(wait_tensor_478, [1, 0]);  wait_tensor_478 = None
        permute_588 = torch.ops.aten.permute.default(permute_348, [1, 0]);  permute_348 = None
        mm_275 = torch.ops.aten.mm.default(view_1843, permute_588);  view_1843 = permute_588 = None
        view_1844 = torch.ops.aten.view.default(mm_275, [2, 4096, 2048]);  mm_275 = None
        convert_element_type_1722 = torch.ops.prims.convert_element_type.default(mm_274, torch.float32);  mm_274 = None
        reduce_scatter_tensor_52 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1722, 'avg', 128, '0');  convert_element_type_1722 = None
        wait_tensor_619 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_52);  reduce_scatter_tensor_52 = None
        view_1845 = torch.ops.aten.view.default(view_1844, [2, 4096, 16, 128]);  view_1844 = None
        permute_590 = torch.ops.aten.permute.default(view_1845, [0, 2, 1, 3]);  view_1845 = None
        fw_graph3 = self.fw_graph3
        joint_graph3 = self.joint_graph3
        mask_graph3 = self.mask_graph3
        flex_attention_backward_3 = torch.ops.higher_order.flex_attention_backward(permute_344, permute_345, permute_346, getitem_2435, getitem_2436, permute_590, None, fw_graph3, joint_graph3, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph3), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_344 = permute_345 = permute_346 = getitem_2435 = getitem_2436 = permute_590 = fw_graph3 = joint_graph3 = mask_graph3 = None
        getitem_6749 = flex_attention_backward_3[0]
        getitem_6750 = flex_attention_backward_3[1]
        getitem_6751 = flex_attention_backward_3[2];  flex_attention_backward_3 = None
        permute_591 = torch.ops.aten.permute.default(getitem_6751, [0, 2, 1, 3]);  getitem_6751 = None
        permute_592 = torch.ops.aten.permute.default(getitem_6750, [0, 2, 1, 3]);  getitem_6750 = None
        permute_593 = torch.ops.aten.permute.default(getitem_6749, [0, 2, 1, 3]);  getitem_6749 = None
        slice_182 = torch.ops.aten.slice.Tensor(permute_592, 3, 0, 128)
        slice_183 = torch.ops.aten.slice.Tensor(permute_592, 3, 128, 192);  permute_592 = None
        sum_134 = torch.ops.aten.sum.dim_IntList(slice_183, [2], True);  slice_183 = None
        cat_264 = torch.ops.aten.cat.default([slice_182, permute_591], 3);  slice_182 = permute_591 = None
        view_1846 = torch.ops.aten.view.default(cat_264, [2, 4096, 4096]);  cat_264 = None
        view_1847 = torch.ops.aten.view.default(view_1846, [8192, 4096]);  view_1846 = None
        permute_594 = torch.ops.aten.permute.default(view_1847, [1, 0])
        mm_276 = torch.ops.aten.mm.default(permute_594, view_1524);  permute_594 = view_1524 = None
        convert_element_type_1241 = torch.ops.prims.convert_element_type.default(primals_379, torch.bfloat16);  primals_379 = None
        all_gather_into_tensor_389 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1241, 128, '0');  convert_element_type_1241 = None
        wait_tensor_477 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_389);  all_gather_into_tensor_389 = None
        permute_343 = torch.ops.aten.permute.default(wait_tensor_477, [1, 0]);  wait_tensor_477 = None
        permute_596 = torch.ops.aten.permute.default(permute_343, [1, 0]);  permute_343 = None
        mm_277 = torch.ops.aten.mm.default(view_1847, permute_596);  view_1847 = permute_596 = None
        view_1848 = torch.ops.aten.view.default(mm_277, [2, 4096, 512]);  mm_277 = None
        convert_element_type_1727 = torch.ops.prims.convert_element_type.default(mm_276, torch.float32);  mm_276 = None
        reduce_scatter_tensor_53 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1727, 'avg', 128, '0');  convert_element_type_1727 = None
        wait_tensor_620 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_53);  reduce_scatter_tensor_53 = None
        convert_element_type_1728 = torch.ops.prims.convert_element_type.default(view_1848, torch.float32);  view_1848 = None
        convert_element_type_1238 = torch.ops.prims.convert_element_type.default(primals_378, torch.bfloat16);  primals_378 = None
        all_gather_into_tensor_388 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1238, 128, '0');  convert_element_type_1238 = None
        wait_tensor_476 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_388);  all_gather_into_tensor_388 = None
        convert_element_type_1730 = torch.ops.prims.convert_element_type.default(wait_tensor_476, torch.float32);  wait_tensor_476 = None
        mul_1413 = torch.ops.aten.mul.Tensor(convert_element_type_1728, convert_element_type_1730);  convert_element_type_1730 = None
        convert_element_type_1239 = torch.ops.prims.convert_element_type.default(getitem_2431, torch.float32);  getitem_2431 = None
        mul_1091 = torch.ops.aten.mul.Tensor(convert_element_type_1239, rsqrt_70);  convert_element_type_1239 = None
        mul_1415 = torch.ops.aten.mul.Tensor(mul_1091, mul_1413)
        sum_135 = torch.ops.aten.sum.dim_IntList(mul_1415, [2], True);  mul_1415 = None
        div_154 = torch.ops.aten.div.Tensor(mul_1091, 512)
        mul_1416 = torch.ops.aten.mul.Tensor(div_154, sum_135);  div_154 = sum_135 = None
        sub_647 = torch.ops.aten.sub.Tensor(mul_1413, mul_1416);  mul_1413 = mul_1416 = None
        mul_1417 = torch.ops.aten.mul.Tensor(sub_647, rsqrt_70);  sub_647 = rsqrt_70 = None
        mul_1418 = torch.ops.aten.mul.Tensor(convert_element_type_1728, mul_1091);  convert_element_type_1728 = mul_1091 = None
        sum_136 = torch.ops.aten.sum.dim_IntList(mul_1418, [0, 1]);  mul_1418 = None
        convert_element_type_1731 = torch.ops.prims.convert_element_type.default(mul_1417, torch.bfloat16);  mul_1417 = None
        convert_element_type_default_71 = torch.ops.prims.convert_element_type.default(sum_136, torch.float32);  sum_136 = None
        reduce_scatter_tensor_54 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_71, 'avg', 128, '0');  convert_element_type_default_71 = None
        wait_tensor_621 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_54);  reduce_scatter_tensor_54 = None
        convert_element_type_1734 = torch.ops.prims.convert_element_type.default(sum_134, torch.float32);  sum_134 = None
        view_1849 = torch.ops.aten.view.default(convert_element_type_1734, [2, 4096, 1, 32, 2]);  convert_element_type_1734 = None
        view_as_complex_60 = torch.ops.aten.view_as_complex.default(view_1849);  view_1849 = None
        mul_1419 = torch.ops.aten.mul.Tensor(view_as_complex_60, clone_9);  view_as_complex_60 = None
        view_as_real_60 = torch.ops.aten.view_as_real.default(mul_1419);  mul_1419 = None
        view_1850 = torch.ops.aten.view.default(view_as_real_60, [2, 4096, 1, 64]);  view_as_real_60 = None
        convert_element_type_1735 = torch.ops.prims.convert_element_type.default(view_1850, torch.bfloat16);  view_1850 = None
        squeeze_29 = torch.ops.aten.squeeze.dim(convert_element_type_1735, 2);  convert_element_type_1735 = None
        cat_265 = torch.ops.aten.cat.default([convert_element_type_1731, squeeze_29], 2);  convert_element_type_1731 = squeeze_29 = None
        view_1851 = torch.ops.aten.view.default(cat_265, [8192, 576]);  cat_265 = None
        permute_598 = torch.ops.aten.permute.default(view_1851, [1, 0])
        mm_278 = torch.ops.aten.mm.default(permute_598, view_1510);  permute_598 = None
        convert_element_type_1233 = torch.ops.prims.convert_element_type.default(primals_377, torch.bfloat16);  primals_377 = None
        all_gather_into_tensor_387 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1233, 128, '0');  convert_element_type_1233 = None
        wait_tensor_475 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_387);  all_gather_into_tensor_387 = None
        slice_139 = torch.ops.aten.slice.Tensor(wait_tensor_475, 0, 0, 576);  wait_tensor_475 = None
        permute_342 = torch.ops.aten.permute.default(slice_139, [1, 0]);  slice_139 = None
        permute_600 = torch.ops.aten.permute.default(permute_342, [1, 0]);  permute_342 = None
        mm_279 = torch.ops.aten.mm.default(view_1851, permute_600);  view_1851 = permute_600 = None
        view_1852 = torch.ops.aten.view.default(mm_279, [2, 4096, 2048]);  mm_279 = None
        convert_element_type_1740 = torch.ops.prims.convert_element_type.default(mm_278, torch.float32);  mm_278 = None
        split_367 = torch.ops.aten.split.Tensor(convert_element_type_1740, 5);  convert_element_type_1740 = None
        getitem_6753 = split_367[0]
        getitem_6754 = split_367[1]
        getitem_6755 = split_367[2]
        getitem_6756 = split_367[3]
        getitem_6757 = split_367[4]
        getitem_6758 = split_367[5]
        getitem_6759 = split_367[6]
        getitem_6760 = split_367[7]
        getitem_6761 = split_367[8]
        getitem_6762 = split_367[9]
        getitem_6763 = split_367[10]
        getitem_6764 = split_367[11]
        getitem_6765 = split_367[12]
        getitem_6766 = split_367[13]
        getitem_6767 = split_367[14]
        getitem_6768 = split_367[15]
        getitem_6769 = split_367[16]
        getitem_6770 = split_367[17]
        getitem_6771 = split_367[18]
        getitem_6772 = split_367[19]
        getitem_6773 = split_367[20]
        getitem_6774 = split_367[21]
        getitem_6775 = split_367[22]
        getitem_6776 = split_367[23]
        getitem_6777 = split_367[24]
        getitem_6778 = split_367[25]
        getitem_6779 = split_367[26]
        getitem_6780 = split_367[27]
        getitem_6781 = split_367[28]
        getitem_6782 = split_367[29]
        getitem_6783 = split_367[30]
        getitem_6784 = split_367[31]
        getitem_6785 = split_367[32]
        getitem_6786 = split_367[33]
        getitem_6787 = split_367[34]
        getitem_6788 = split_367[35]
        getitem_6789 = split_367[36]
        getitem_6790 = split_367[37]
        getitem_6791 = split_367[38]
        getitem_6792 = split_367[39]
        getitem_6793 = split_367[40]
        getitem_6794 = split_367[41]
        getitem_6795 = split_367[42]
        getitem_6796 = split_367[43]
        getitem_6797 = split_367[44]
        getitem_6798 = split_367[45]
        getitem_6799 = split_367[46]
        getitem_6800 = split_367[47]
        getitem_6801 = split_367[48]
        getitem_6802 = split_367[49]
        getitem_6803 = split_367[50]
        getitem_6804 = split_367[51]
        getitem_6805 = split_367[52]
        getitem_6806 = split_367[53]
        getitem_6807 = split_367[54]
        getitem_6808 = split_367[55]
        getitem_6809 = split_367[56]
        getitem_6810 = split_367[57]
        getitem_6811 = split_367[58]
        getitem_6812 = split_367[59]
        getitem_6813 = split_367[60]
        getitem_6814 = split_367[61]
        getitem_6815 = split_367[62]
        getitem_6816 = split_367[63]
        getitem_6817 = split_367[64]
        getitem_6818 = split_367[65]
        getitem_6819 = split_367[66]
        getitem_6820 = split_367[67]
        getitem_6821 = split_367[68]
        getitem_6822 = split_367[69]
        getitem_6823 = split_367[70]
        getitem_6824 = split_367[71]
        getitem_6825 = split_367[72]
        getitem_6826 = split_367[73]
        getitem_6827 = split_367[74]
        getitem_6828 = split_367[75]
        getitem_6829 = split_367[76]
        getitem_6830 = split_367[77]
        getitem_6831 = split_367[78]
        getitem_6832 = split_367[79]
        getitem_6833 = split_367[80]
        getitem_6834 = split_367[81]
        getitem_6835 = split_367[82]
        getitem_6836 = split_367[83]
        getitem_6837 = split_367[84]
        getitem_6838 = split_367[85]
        getitem_6839 = split_367[86]
        getitem_6840 = split_367[87]
        getitem_6841 = split_367[88]
        getitem_6842 = split_367[89]
        getitem_6843 = split_367[90]
        getitem_6844 = split_367[91]
        getitem_6845 = split_367[92]
        getitem_6846 = split_367[93]
        getitem_6847 = split_367[94]
        getitem_6848 = split_367[95]
        getitem_6849 = split_367[96]
        getitem_6850 = split_367[97]
        getitem_6851 = split_367[98]
        getitem_6852 = split_367[99]
        getitem_6853 = split_367[100]
        getitem_6854 = split_367[101]
        getitem_6855 = split_367[102]
        getitem_6856 = split_367[103]
        getitem_6857 = split_367[104]
        getitem_6858 = split_367[105]
        getitem_6859 = split_367[106]
        getitem_6860 = split_367[107]
        getitem_6861 = split_367[108]
        getitem_6862 = split_367[109]
        getitem_6863 = split_367[110]
        getitem_6864 = split_367[111]
        getitem_6865 = split_367[112]
        getitem_6866 = split_367[113]
        getitem_6867 = split_367[114]
        getitem_6868 = split_367[115];  split_367 = None
        constant_pad_nd_295 = torch.ops.aten.constant_pad_nd.default(getitem_6868, [0, 0, 0, 4], 0.0);  getitem_6868 = None
        cat_266 = torch.ops.aten.cat.default([getitem_6753, getitem_6754, getitem_6755, getitem_6756, getitem_6757, getitem_6758, getitem_6759, getitem_6760, getitem_6761, getitem_6762, getitem_6763, getitem_6764, getitem_6765, getitem_6766, getitem_6767, getitem_6768, getitem_6769, getitem_6770, getitem_6771, getitem_6772, getitem_6773, getitem_6774, getitem_6775, getitem_6776, getitem_6777, getitem_6778, getitem_6779, getitem_6780, getitem_6781, getitem_6782, getitem_6783, getitem_6784, getitem_6785, getitem_6786, getitem_6787, getitem_6788, getitem_6789, getitem_6790, getitem_6791, getitem_6792, getitem_6793, getitem_6794, getitem_6795, getitem_6796, getitem_6797, getitem_6798, getitem_6799, getitem_6800, getitem_6801, getitem_6802, getitem_6803, getitem_6804, getitem_6805, getitem_6806, getitem_6807, getitem_6808, getitem_6809, getitem_6810, getitem_6811, getitem_6812, getitem_6813, getitem_6814, getitem_6815, getitem_6816, getitem_6817, getitem_6818, getitem_6819, getitem_6820, getitem_6821, getitem_6822, getitem_6823, getitem_6824, getitem_6825, getitem_6826, getitem_6827, getitem_6828, getitem_6829, getitem_6830, getitem_6831, getitem_6832, getitem_6833, getitem_6834, getitem_6835, getitem_6836, getitem_6837, getitem_6838, getitem_6839, getitem_6840, getitem_6841, getitem_6842, getitem_6843, getitem_6844, getitem_6845, getitem_6846, getitem_6847, getitem_6848, getitem_6849, getitem_6850, getitem_6851, getitem_6852, getitem_6853, getitem_6854, getitem_6855, getitem_6856, getitem_6857, getitem_6858, getitem_6859, getitem_6860, getitem_6861, getitem_6862, getitem_6863, getitem_6864, getitem_6865, getitem_6866, getitem_6867, constant_pad_nd_295, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_6753 = getitem_6754 = getitem_6755 = getitem_6756 = getitem_6757 = getitem_6758 = getitem_6759 = getitem_6760 = getitem_6761 = getitem_6762 = getitem_6763 = getitem_6764 = getitem_6765 = getitem_6766 = getitem_6767 = getitem_6768 = getitem_6769 = getitem_6770 = getitem_6771 = getitem_6772 = getitem_6773 = getitem_6774 = getitem_6775 = getitem_6776 = getitem_6777 = getitem_6778 = getitem_6779 = getitem_6780 = getitem_6781 = getitem_6782 = getitem_6783 = getitem_6784 = getitem_6785 = getitem_6786 = getitem_6787 = getitem_6788 = getitem_6789 = getitem_6790 = getitem_6791 = getitem_6792 = getitem_6793 = getitem_6794 = getitem_6795 = getitem_6796 = getitem_6797 = getitem_6798 = getitem_6799 = getitem_6800 = getitem_6801 = getitem_6802 = getitem_6803 = getitem_6804 = getitem_6805 = getitem_6806 = getitem_6807 = getitem_6808 = getitem_6809 = getitem_6810 = getitem_6811 = getitem_6812 = getitem_6813 = getitem_6814 = getitem_6815 = getitem_6816 = getitem_6817 = getitem_6818 = getitem_6819 = getitem_6820 = getitem_6821 = getitem_6822 = getitem_6823 = getitem_6824 = getitem_6825 = getitem_6826 = getitem_6827 = getitem_6828 = getitem_6829 = getitem_6830 = getitem_6831 = getitem_6832 = getitem_6833 = getitem_6834 = getitem_6835 = getitem_6836 = getitem_6837 = getitem_6838 = getitem_6839 = getitem_6840 = getitem_6841 = getitem_6842 = getitem_6843 = getitem_6844 = getitem_6845 = getitem_6846 = getitem_6847 = getitem_6848 = getitem_6849 = getitem_6850 = getitem_6851 = getitem_6852 = getitem_6853 = getitem_6854 = getitem_6855 = getitem_6856 = getitem_6857 = getitem_6858 = getitem_6859 = getitem_6860 = getitem_6861 = getitem_6862 = getitem_6863 = getitem_6864 = getitem_6865 = getitem_6866 = getitem_6867 = constant_pad_nd_295 = None
        reduce_scatter_tensor_55 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_266, 'avg', 128, '0');  cat_266 = None
        wait_tensor_622 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_55);  reduce_scatter_tensor_55 = None
        slice_184 = torch.ops.aten.slice.Tensor(permute_593, 3, 0, 128)
        slice_185 = torch.ops.aten.slice.Tensor(permute_593, 3, 128, 192);  permute_593 = None
        convert_element_type_1741 = torch.ops.prims.convert_element_type.default(slice_185, torch.float32);  slice_185 = None
        view_1853 = torch.ops.aten.view.default(convert_element_type_1741, [2, 4096, 16, 32, 2]);  convert_element_type_1741 = None
        view_as_complex_61 = torch.ops.aten.view_as_complex.default(view_1853);  view_1853 = None
        mul_1420 = torch.ops.aten.mul.Tensor(view_as_complex_61, clone_9);  view_as_complex_61 = None
        view_as_real_61 = torch.ops.aten.view_as_real.default(mul_1420);  mul_1420 = None
        view_1854 = torch.ops.aten.view.default(view_as_real_61, [2, 4096, 16, 64]);  view_as_real_61 = None
        convert_element_type_1742 = torch.ops.prims.convert_element_type.default(view_1854, torch.bfloat16);  view_1854 = None
        cat_267 = torch.ops.aten.cat.default([slice_184, convert_element_type_1742], 3);  slice_184 = convert_element_type_1742 = None
        view_1855 = torch.ops.aten.view.default(cat_267, [2, 4096, 3072]);  cat_267 = None
        view_1856 = torch.ops.aten.view.default(view_1855, [8192, 3072]);  view_1855 = None
        permute_602 = torch.ops.aten.permute.default(view_1856, [1, 0])
        mm_280 = torch.ops.aten.mm.default(permute_602, view_1510);  permute_602 = view_1510 = None
        convert_element_type_1228 = torch.ops.prims.convert_element_type.default(primals_376, torch.bfloat16);  primals_376 = None
        all_gather_into_tensor_386 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1228, 128, '0');  convert_element_type_1228 = None
        wait_tensor_474 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_386);  all_gather_into_tensor_386 = None
        permute_341 = torch.ops.aten.permute.default(wait_tensor_474, [1, 0]);  wait_tensor_474 = None
        permute_604 = torch.ops.aten.permute.default(permute_341, [1, 0]);  permute_341 = None
        mm_281 = torch.ops.aten.mm.default(view_1856, permute_604);  view_1856 = permute_604 = None
        view_1857 = torch.ops.aten.view.default(mm_281, [2, 4096, 2048]);  mm_281 = None
        add_1833 = torch.ops.aten.add.Tensor(view_1852, view_1857);  view_1852 = view_1857 = None
        convert_element_type_1747 = torch.ops.prims.convert_element_type.default(mm_280, torch.float32);  mm_280 = None
        reduce_scatter_tensor_56 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1747, 'avg', 128, '0');  convert_element_type_1747 = None
        wait_tensor_623 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_56);  reduce_scatter_tensor_56 = None
        convert_element_type_1748 = torch.ops.prims.convert_element_type.default(add_1833, torch.float32);  add_1833 = None
        convert_element_type_1225 = torch.ops.prims.convert_element_type.default(primals_375, torch.bfloat16);  primals_375 = None
        all_gather_into_tensor_385 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1225, 128, '0');  convert_element_type_1225 = None
        wait_tensor_473 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_385);  all_gather_into_tensor_385 = None
        convert_element_type_1750 = torch.ops.prims.convert_element_type.default(wait_tensor_473, torch.float32);  wait_tensor_473 = None
        mul_1421 = torch.ops.aten.mul.Tensor(convert_element_type_1748, convert_element_type_1750);  convert_element_type_1750 = None
        convert_element_type_1226 = torch.ops.prims.convert_element_type.default(add_1501, torch.float32);  add_1501 = None
        mul_1087 = torch.ops.aten.mul.Tensor(convert_element_type_1226, rsqrt_69);  convert_element_type_1226 = None
        mul_1423 = torch.ops.aten.mul.Tensor(mul_1087, mul_1421)
        sum_137 = torch.ops.aten.sum.dim_IntList(mul_1423, [2], True);  mul_1423 = None
        div_155 = torch.ops.aten.div.Tensor(mul_1087, 2048)
        mul_1424 = torch.ops.aten.mul.Tensor(div_155, sum_137);  div_155 = sum_137 = None
        sub_648 = torch.ops.aten.sub.Tensor(mul_1421, mul_1424);  mul_1421 = mul_1424 = None
        mul_1425 = torch.ops.aten.mul.Tensor(sub_648, rsqrt_69);  sub_648 = rsqrt_69 = None
        mul_1426 = torch.ops.aten.mul.Tensor(convert_element_type_1748, mul_1087);  convert_element_type_1748 = mul_1087 = None
        sum_138 = torch.ops.aten.sum.dim_IntList(mul_1426, [0, 1]);  mul_1426 = None
        convert_element_type_1751 = torch.ops.prims.convert_element_type.default(mul_1425, torch.bfloat16);  mul_1425 = None
        add_1834 = torch.ops.aten.add.Tensor(add_1832, convert_element_type_1751);  add_1832 = convert_element_type_1751 = None
        convert_element_type_default_70 = torch.ops.prims.convert_element_type.default(sum_138, torch.float32);  sum_138 = None
        reduce_scatter_tensor_57 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_70, 'avg', 128, '0');  convert_element_type_default_70 = None
        wait_tensor_624 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_57);  reduce_scatter_tensor_57 = None
        view_1858 = torch.ops.aten.view.default(add_1834, [8192, 2048])
        unsqueeze_57 = torch.ops.aten.unsqueeze.default(view_1858, 1)
        convert_element_type_1754 = torch.ops.prims.convert_element_type.default(unsqueeze_57, torch.float32);  unsqueeze_57 = None
        bmm_34 = torch.ops.aten.bmm.default(permute_606, convert_element_type_1754);  permute_606 = None
        bmm_35 = torch.ops.aten.bmm.default(convert_element_type_1754, permute_607);  convert_element_type_1754 = permute_607 = None
        convert_element_type_1755 = torch.ops.prims.convert_element_type.default(bmm_34, torch.bfloat16);  bmm_34 = None
        view_1859 = torch.ops.aten.view.default(bmm_35, [8192, 6]);  bmm_35 = None
        view_1860 = torch.ops.aten.view.default(convert_element_type_1755, [49152, 2048]);  convert_element_type_1755 = None
        index_60 = torch.ops.aten.index.Tensor(view_1860, [getitem_2331]);  view_1860 = getitem_2331 = None
        permute_608 = torch.ops.aten.permute.default(view_1858, [1, 0])
        mm_282 = torch.ops.aten.mm.default(permute_608, mul_1084);  permute_608 = mul_1084 = None
        convert_element_type_1220 = torch.ops.prims.convert_element_type.default(primals_374, torch.bfloat16);  primals_374 = None
        all_gather_into_tensor_384 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1220, 128, '0');  convert_element_type_1220 = None
        wait_tensor_472 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_384);  all_gather_into_tensor_384 = None
        permute_340 = torch.ops.aten.permute.default(wait_tensor_472, [1, 0]);  wait_tensor_472 = None
        permute_610 = torch.ops.aten.permute.default(permute_340, [1, 0]);  permute_340 = None
        mm_283 = torch.ops.aten.mm.default(view_1858, permute_610);  view_1858 = permute_610 = None
        convert_element_type_1760 = torch.ops.prims.convert_element_type.default(mm_282, torch.float32);  mm_282 = None
        reduce_scatter_tensor_58 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1760, 'avg', 128, '0');  convert_element_type_1760 = None
        wait_tensor_625 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_58);  reduce_scatter_tensor_58 = None
        convert_element_type_1215 = torch.ops.prims.convert_element_type.default(mm_180, torch.float32);  mm_180 = None
        neg_44 = torch.ops.aten.neg.default(convert_element_type_1215)
        exp_66 = torch.ops.aten.exp.default(neg_44);  neg_44 = None
        add_1496 = torch.ops.aten.add.Tensor(exp_66, 1);  exp_66 = None
        div_110 = torch.ops.aten.div.Tensor(convert_element_type_1215, add_1496)
        convert_element_type_1216 = torch.ops.prims.convert_element_type.default(div_110, torch.bfloat16);  div_110 = None
        mul_1427 = torch.ops.aten.mul.Tensor(mm_283, convert_element_type_1216);  convert_element_type_1216 = None
        mul_1428 = torch.ops.aten.mul.Tensor(mm_283, mm_181);  mm_283 = mm_181 = None
        permute_612 = torch.ops.aten.permute.default(mul_1427, [1, 0])
        mm_284 = torch.ops.aten.mm.default(permute_612, view_1465);  permute_612 = None
        convert_element_type_1217 = torch.ops.prims.convert_element_type.default(primals_373, torch.bfloat16);  primals_373 = None
        all_gather_into_tensor_383 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1217, 128, '0');  convert_element_type_1217 = None
        wait_tensor_471 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_383);  all_gather_into_tensor_383 = None
        permute_339 = torch.ops.aten.permute.default(wait_tensor_471, [1, 0]);  wait_tensor_471 = None
        permute_614 = torch.ops.aten.permute.default(permute_339, [1, 0]);  permute_339 = None
        mm_285 = torch.ops.aten.mm.default(mul_1427, permute_614);  mul_1427 = permute_614 = None
        convert_element_type_1765 = torch.ops.prims.convert_element_type.default(mm_284, torch.float32);  mm_284 = None
        reduce_scatter_tensor_59 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1765, 'avg', 128, '0');  convert_element_type_1765 = None
        wait_tensor_626 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_59);  reduce_scatter_tensor_59 = None
        convert_element_type_1766 = torch.ops.prims.convert_element_type.default(mul_1428, torch.float32);  mul_1428 = None
        reciprocal_8 = torch.ops.aten.reciprocal.default(add_1496);  add_1496 = None
        mul_1429 = torch.ops.aten.mul.Tensor(reciprocal_8, 1);  reciprocal_8 = None
        mul_1430 = torch.ops.aten.mul.Tensor(convert_element_type_1766, mul_1429);  convert_element_type_1766 = None
        sub_649 = torch.ops.aten.sub.Tensor(1, mul_1429);  mul_1429 = None
        mul_1431 = torch.ops.aten.mul.Tensor(convert_element_type_1215, sub_649);  convert_element_type_1215 = sub_649 = None
        add_1836 = torch.ops.aten.add.Tensor(mul_1431, 1);  mul_1431 = None
        mul_1432 = torch.ops.aten.mul.Tensor(mul_1430, add_1836);  mul_1430 = add_1836 = None
        convert_element_type_1768 = torch.ops.prims.convert_element_type.default(mul_1432, torch.bfloat16);  mul_1432 = None
        permute_616 = torch.ops.aten.permute.default(convert_element_type_1768, [1, 0])
        mm_286 = torch.ops.aten.mm.default(permute_616, view_1465);  permute_616 = None
        convert_element_type_1212 = torch.ops.prims.convert_element_type.default(primals_372, torch.bfloat16);  primals_372 = None
        all_gather_into_tensor_382 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1212, 128, '0');  convert_element_type_1212 = None
        wait_tensor_470 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_382);  all_gather_into_tensor_382 = None
        permute_338 = torch.ops.aten.permute.default(wait_tensor_470, [1, 0]);  wait_tensor_470 = None
        permute_618 = torch.ops.aten.permute.default(permute_338, [1, 0]);  permute_338 = None
        mm_287 = torch.ops.aten.mm.default(convert_element_type_1768, permute_618);  convert_element_type_1768 = permute_618 = None
        add_1837 = torch.ops.aten.add.Tensor(mm_285, mm_287);  mm_285 = mm_287 = None
        convert_element_type_1773 = torch.ops.prims.convert_element_type.default(mm_286, torch.float32);  mm_286 = None
        reduce_scatter_tensor_60 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1773, 'avg', 128, '0');  convert_element_type_1773 = None
        wait_tensor_627 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_60);  reduce_scatter_tensor_60 = None
        all_to_all_single_86 = torch.ops._c10d_functional.all_to_all_single.default(index_60, [_local_scalar_dense_344, _local_scalar_dense_345, _local_scalar_dense_346, _local_scalar_dense_347, _local_scalar_dense_348, _local_scalar_dense_349, _local_scalar_dense_350, _local_scalar_dense_351], [_local_scalar_dense_336, _local_scalar_dense_337, _local_scalar_dense_338, _local_scalar_dense_339, _local_scalar_dense_340, _local_scalar_dense_341, _local_scalar_dense_342, _local_scalar_dense_343], '1033');  index_60 = None
        wait_tensor_628 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_86);  all_to_all_single_86 = None
        full_372 = torch.ops.aten.full.default([sym_size_int_85, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_85 = None
        slice_scatter_4 = torch.ops.aten.slice_scatter.default(full_372, wait_tensor_628, 0, 0, -1);  wait_tensor_628 = None
        index_61 = torch.ops.aten.index.Tensor(slice_scatter_4, [getitem_2332]);  slice_scatter_4 = None
        permute_620 = torch.ops.aten.permute.default(index_61, [1, 0])
        _grouped_mm_102 = torch.ops.aten._grouped_mm.default(permute_620, mul_1064, cumsum_65);  permute_620 = mul_1064 = None
        _grouped_mm_103 = torch.ops.aten._grouped_mm.default(index_61, permute_622, cumsum_65);  index_61 = permute_622 = None
        convert_element_type_1210 = torch.ops.prims.convert_element_type.default(_grouped_mm_63, torch.float32);  _grouped_mm_63 = None
        neg_43 = torch.ops.aten.neg.default(convert_element_type_1210)
        exp_65 = torch.ops.aten.exp.default(neg_43);  neg_43 = None
        add_1460 = torch.ops.aten.add.Tensor(exp_65, 1);  exp_65 = None
        div_109 = torch.ops.aten.div.Tensor(convert_element_type_1210, add_1460)
        convert_element_type_1211 = torch.ops.prims.convert_element_type.default(div_109, torch.bfloat16);  div_109 = None
        mul_1433 = torch.ops.aten.mul.Tensor(_grouped_mm_103, convert_element_type_1211);  convert_element_type_1211 = None
        mul_1434 = torch.ops.aten.mul.Tensor(_grouped_mm_103, _grouped_mm_64);  _grouped_mm_103 = _grouped_mm_64 = None
        permute_624 = torch.ops.aten.permute.default(mul_1433, [1, 0])
        _grouped_mm_104 = torch.ops.aten._grouped_mm.default(permute_624, index_43, cumsum_65);  permute_624 = None
        _grouped_mm_105 = torch.ops.aten._grouped_mm.default(mul_1433, permute_626, cumsum_65);  mul_1433 = permute_626 = None
        convert_element_type_1774 = torch.ops.prims.convert_element_type.default(mul_1434, torch.float32);  mul_1434 = None
        reciprocal_9 = torch.ops.aten.reciprocal.default(add_1460);  add_1460 = None
        mul_1435 = torch.ops.aten.mul.Tensor(reciprocal_9, 1);  reciprocal_9 = None
        mul_1436 = torch.ops.aten.mul.Tensor(convert_element_type_1774, mul_1435);  convert_element_type_1774 = None
        sub_650 = torch.ops.aten.sub.Tensor(1, mul_1435);  mul_1435 = None
        mul_1437 = torch.ops.aten.mul.Tensor(convert_element_type_1210, sub_650);  convert_element_type_1210 = sub_650 = None
        add_1839 = torch.ops.aten.add.Tensor(mul_1437, 1);  mul_1437 = None
        mul_1438 = torch.ops.aten.mul.Tensor(mul_1436, add_1839);  mul_1436 = add_1839 = None
        convert_element_type_1776 = torch.ops.prims.convert_element_type.default(mul_1438, torch.bfloat16);  mul_1438 = None
        permute_628 = torch.ops.aten.permute.default(convert_element_type_1776, [1, 0])
        _grouped_mm_106 = torch.ops.aten._grouped_mm.default(permute_628, index_43, cumsum_65);  permute_628 = index_43 = None
        _grouped_mm_107 = torch.ops.aten._grouped_mm.default(convert_element_type_1776, permute_630, cumsum_65);  convert_element_type_1776 = permute_630 = cumsum_65 = None
        add_1840 = torch.ops.aten.add.Tensor(_grouped_mm_105, _grouped_mm_107);  _grouped_mm_105 = _grouped_mm_107 = None
        convert_element_type_1777 = torch.ops.prims.convert_element_type.default(_grouped_mm_104, torch.float32);  _grouped_mm_104 = None
        div_156 = torch.ops.aten.div.Tensor(convert_element_type_1777, 128);  convert_element_type_1777 = None
        split_369 = torch.ops.aten.split.Tensor(div_156, 88, 1);  div_156 = None
        getitem_6885 = split_369[0]
        getitem_6902 = split_369[1]
        getitem_6919 = split_369[2]
        getitem_6936 = split_369[3]
        getitem_6953 = split_369[4]
        getitem_6970 = split_369[5]
        getitem_6987 = split_369[6]
        getitem_7004 = split_369[7]
        getitem_7021 = split_369[8]
        getitem_7038 = split_369[9]
        getitem_7055 = split_369[10]
        getitem_7072 = split_369[11]
        getitem_7089 = split_369[12]
        getitem_7106 = split_369[13]
        getitem_7123 = split_369[14]
        getitem_7140 = split_369[15];  split_369 = None
        cat_268 = torch.ops.aten.cat.default([getitem_6885, getitem_6902, getitem_6919, getitem_6936, getitem_6953, getitem_6970, getitem_6987, getitem_7004, getitem_7021, getitem_7038, getitem_7055, getitem_7072, getitem_7089, getitem_7106, getitem_7123, getitem_7140]);  getitem_6885 = getitem_6902 = getitem_6919 = getitem_6936 = getitem_6953 = getitem_6970 = getitem_6987 = getitem_7004 = getitem_7021 = getitem_7038 = getitem_7055 = getitem_7072 = getitem_7089 = getitem_7106 = getitem_7123 = getitem_7140 = None
        reduce_scatter_tensor_61 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_268, 'sum', 16, '1025');  cat_268 = None
        wait_tensor_629 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_61);  reduce_scatter_tensor_61 = None
        convert_element_type_1778 = torch.ops.prims.convert_element_type.default(_grouped_mm_102, torch.float32);  _grouped_mm_102 = None
        div_157 = torch.ops.aten.div.Tensor(convert_element_type_1778, 128);  convert_element_type_1778 = None
        split_386 = torch.ops.aten.split.Tensor(div_157, 128, 1);  div_157 = None
        getitem_7157 = split_386[0]
        getitem_7174 = split_386[1]
        getitem_7191 = split_386[2]
        getitem_7208 = split_386[3]
        getitem_7225 = split_386[4]
        getitem_7242 = split_386[5]
        getitem_7259 = split_386[6]
        getitem_7276 = split_386[7]
        getitem_7293 = split_386[8]
        getitem_7310 = split_386[9]
        getitem_7327 = split_386[10]
        getitem_7344 = split_386[11]
        getitem_7361 = split_386[12]
        getitem_7378 = split_386[13]
        getitem_7395 = split_386[14]
        getitem_7412 = split_386[15];  split_386 = None
        cat_269 = torch.ops.aten.cat.default([getitem_7157, getitem_7174, getitem_7191, getitem_7208, getitem_7225, getitem_7242, getitem_7259, getitem_7276, getitem_7293, getitem_7310, getitem_7327, getitem_7344, getitem_7361, getitem_7378, getitem_7395, getitem_7412]);  getitem_7157 = getitem_7174 = getitem_7191 = getitem_7208 = getitem_7225 = getitem_7242 = getitem_7259 = getitem_7276 = getitem_7293 = getitem_7310 = getitem_7327 = getitem_7344 = getitem_7361 = getitem_7378 = getitem_7395 = getitem_7412 = None
        reduce_scatter_tensor_62 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_269, 'sum', 16, '1025');  cat_269 = None
        wait_tensor_630 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_62);  reduce_scatter_tensor_62 = None
        convert_element_type_1779 = torch.ops.prims.convert_element_type.default(_grouped_mm_106, torch.float32);  _grouped_mm_106 = None
        div_158 = torch.ops.aten.div.Tensor(convert_element_type_1779, 128);  convert_element_type_1779 = None
        split_403 = torch.ops.aten.split.Tensor(div_158, 88, 1);  div_158 = None
        getitem_7429 = split_403[0]
        getitem_7446 = split_403[1]
        getitem_7463 = split_403[2]
        getitem_7480 = split_403[3]
        getitem_7497 = split_403[4]
        getitem_7514 = split_403[5]
        getitem_7531 = split_403[6]
        getitem_7548 = split_403[7]
        getitem_7565 = split_403[8]
        getitem_7582 = split_403[9]
        getitem_7599 = split_403[10]
        getitem_7616 = split_403[11]
        getitem_7633 = split_403[12]
        getitem_7650 = split_403[13]
        getitem_7667 = split_403[14]
        getitem_7684 = split_403[15];  split_403 = None
        cat_270 = torch.ops.aten.cat.default([getitem_7429, getitem_7446, getitem_7463, getitem_7480, getitem_7497, getitem_7514, getitem_7531, getitem_7548, getitem_7565, getitem_7582, getitem_7599, getitem_7616, getitem_7633, getitem_7650, getitem_7667, getitem_7684]);  getitem_7429 = getitem_7446 = getitem_7463 = getitem_7480 = getitem_7497 = getitem_7514 = getitem_7531 = getitem_7548 = getitem_7565 = getitem_7582 = getitem_7599 = getitem_7616 = getitem_7633 = getitem_7650 = getitem_7667 = getitem_7684 = None
        reduce_scatter_tensor_63 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_270, 'sum', 16, '1025');  cat_270 = None
        wait_tensor_631 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_63);  reduce_scatter_tensor_63 = None
        index_put_60 = torch.ops.aten.index_put.default(full_372, [getitem_2332], add_1840, True);  full_372 = getitem_2332 = add_1840 = None
        slice_186 = torch.ops.aten.slice.Tensor(index_put_60, 0, 0, add_1841);  index_put_60 = add_1841 = None
        all_to_all_single_87 = torch.ops._c10d_functional.all_to_all_single.default(slice_186, [_local_scalar_dense_336, _local_scalar_dense_337, _local_scalar_dense_338, _local_scalar_dense_339, _local_scalar_dense_340, _local_scalar_dense_341, _local_scalar_dense_342, _local_scalar_dense_343], [_local_scalar_dense_344, _local_scalar_dense_345, _local_scalar_dense_346, _local_scalar_dense_347, _local_scalar_dense_348, _local_scalar_dense_349, _local_scalar_dense_350, _local_scalar_dense_351], '1033');  slice_186 = _local_scalar_dense_336 = _local_scalar_dense_337 = _local_scalar_dense_338 = _local_scalar_dense_339 = _local_scalar_dense_340 = _local_scalar_dense_341 = _local_scalar_dense_342 = _local_scalar_dense_343 = _local_scalar_dense_344 = _local_scalar_dense_345 = _local_scalar_dense_346 = _local_scalar_dense_347 = _local_scalar_dense_348 = _local_scalar_dense_349 = _local_scalar_dense_350 = _local_scalar_dense_351 = None
        wait_tensor_632 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_87);  all_to_all_single_87 = None
        index_put_61 = torch.ops.aten.index_put.default(full_default_52, [div_107], wait_tensor_632, True);  div_107 = wait_tensor_632 = None
        add_1845 = torch.ops.aten.add.Tensor(add_1837, index_put_61);  add_1837 = index_put_61 = None
        mul_1439 = torch.ops.aten.mul.Tensor(view_1859, 1.0);  view_1859 = None
        scatter_add_4 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_2329, mul_1439);  getitem_2329 = mul_1439 = None
        convert_element_type_1199 = torch.ops.prims.convert_element_type.default(mm_179, torch.float32);  mm_179 = None
        sub_504 = torch.ops.aten.sub.Tensor(convert_element_type_1199, amax_21);  convert_element_type_1199 = amax_21 = None
        exp_64 = torch.ops.aten.exp.default(sub_504);  sub_504 = None
        div_106 = torch.ops.aten.div.Tensor(exp_64, sum_85);  exp_64 = sum_85 = None
        mul_1440 = torch.ops.aten.mul.Tensor(scatter_add_4, div_106);  scatter_add_4 = None
        sum_139 = torch.ops.aten.sum.dim_IntList(mul_1440, [1], True)
        neg_67 = torch.ops.aten.neg.default(div_106);  div_106 = None
        fma_4 = torch.ops.prims.fma.default(neg_67, sum_139, mul_1440);  neg_67 = sum_139 = mul_1440 = None
        convert_element_type_1780 = torch.ops.prims.convert_element_type.default(fma_4, torch.bfloat16);  fma_4 = None
        permute_632 = torch.ops.aten.permute.default(convert_element_type_1780, [1, 0])
        mm_288 = torch.ops.aten.mm.default(permute_632, view_1465);  permute_632 = view_1465 = None
        convert_element_type_1196 = torch.ops.prims.convert_element_type.default(primals_367, torch.bfloat16);  primals_367 = None
        all_gather_into_tensor_375 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1196, 128, '0');  convert_element_type_1196 = None
        wait_tensor_459 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_375);  all_gather_into_tensor_375 = None
        slice_135 = torch.ops.aten.slice.Tensor(wait_tensor_459, 0, 0, 64);  wait_tensor_459 = None
        permute_334 = torch.ops.aten.permute.default(slice_135, [1, 0]);  slice_135 = None
        permute_634 = torch.ops.aten.permute.default(permute_334, [1, 0]);  permute_334 = None
        mm_289 = torch.ops.aten.mm.default(convert_element_type_1780, permute_634);  convert_element_type_1780 = permute_634 = None
        add_1846 = torch.ops.aten.add.Tensor(add_1845, mm_289);  add_1845 = mm_289 = None
        convert_element_type_1785 = torch.ops.prims.convert_element_type.default(mm_288, torch.float32);  mm_288 = None
        split_419 = torch.ops.aten.split.Tensor(convert_element_type_1785, 1);  convert_element_type_1785 = None
        getitem_7685 = split_419[0]
        getitem_7686 = split_419[1]
        getitem_7687 = split_419[2]
        getitem_7688 = split_419[3]
        getitem_7689 = split_419[4]
        getitem_7690 = split_419[5]
        getitem_7691 = split_419[6]
        getitem_7692 = split_419[7]
        getitem_7693 = split_419[8]
        getitem_7694 = split_419[9]
        getitem_7695 = split_419[10]
        getitem_7696 = split_419[11]
        getitem_7697 = split_419[12]
        getitem_7698 = split_419[13]
        getitem_7699 = split_419[14]
        getitem_7700 = split_419[15]
        getitem_7701 = split_419[16]
        getitem_7702 = split_419[17]
        getitem_7703 = split_419[18]
        getitem_7704 = split_419[19]
        getitem_7705 = split_419[20]
        getitem_7706 = split_419[21]
        getitem_7707 = split_419[22]
        getitem_7708 = split_419[23]
        getitem_7709 = split_419[24]
        getitem_7710 = split_419[25]
        getitem_7711 = split_419[26]
        getitem_7712 = split_419[27]
        getitem_7713 = split_419[28]
        getitem_7714 = split_419[29]
        getitem_7715 = split_419[30]
        getitem_7716 = split_419[31]
        getitem_7717 = split_419[32]
        getitem_7718 = split_419[33]
        getitem_7719 = split_419[34]
        getitem_7720 = split_419[35]
        getitem_7721 = split_419[36]
        getitem_7722 = split_419[37]
        getitem_7723 = split_419[38]
        getitem_7724 = split_419[39]
        getitem_7725 = split_419[40]
        getitem_7726 = split_419[41]
        getitem_7727 = split_419[42]
        getitem_7728 = split_419[43]
        getitem_7729 = split_419[44]
        getitem_7730 = split_419[45]
        getitem_7731 = split_419[46]
        getitem_7732 = split_419[47]
        getitem_7733 = split_419[48]
        getitem_7734 = split_419[49]
        getitem_7735 = split_419[50]
        getitem_7736 = split_419[51]
        getitem_7737 = split_419[52]
        getitem_7738 = split_419[53]
        getitem_7739 = split_419[54]
        getitem_7740 = split_419[55]
        getitem_7741 = split_419[56]
        getitem_7742 = split_419[57]
        getitem_7743 = split_419[58]
        getitem_7744 = split_419[59]
        getitem_7745 = split_419[60]
        getitem_7746 = split_419[61]
        getitem_7747 = split_419[62]
        getitem_7748 = split_419[63];  split_419 = None
        cat_271 = torch.ops.aten.cat.default([getitem_7685, getitem_7686, getitem_7687, getitem_7688, getitem_7689, getitem_7690, getitem_7691, getitem_7692, getitem_7693, getitem_7694, getitem_7695, getitem_7696, getitem_7697, getitem_7698, getitem_7699, getitem_7700, getitem_7701, getitem_7702, getitem_7703, getitem_7704, getitem_7705, getitem_7706, getitem_7707, getitem_7708, getitem_7709, getitem_7710, getitem_7711, getitem_7712, getitem_7713, getitem_7714, getitem_7715, getitem_7716, getitem_7717, getitem_7718, getitem_7719, getitem_7720, getitem_7721, getitem_7722, getitem_7723, getitem_7724, getitem_7725, getitem_7726, getitem_7727, getitem_7728, getitem_7729, getitem_7730, getitem_7731, getitem_7732, getitem_7733, getitem_7734, getitem_7735, getitem_7736, getitem_7737, getitem_7738, getitem_7739, getitem_7740, getitem_7741, getitem_7742, getitem_7743, getitem_7744, getitem_7745, getitem_7746, getitem_7747, getitem_7748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_7685 = getitem_7686 = getitem_7687 = getitem_7688 = getitem_7689 = getitem_7690 = getitem_7691 = getitem_7692 = getitem_7693 = getitem_7694 = getitem_7695 = getitem_7696 = getitem_7697 = getitem_7698 = getitem_7699 = getitem_7700 = getitem_7701 = getitem_7702 = getitem_7703 = getitem_7704 = getitem_7705 = getitem_7706 = getitem_7707 = getitem_7708 = getitem_7709 = getitem_7710 = getitem_7711 = getitem_7712 = getitem_7713 = getitem_7714 = getitem_7715 = getitem_7716 = getitem_7717 = getitem_7718 = getitem_7719 = getitem_7720 = getitem_7721 = getitem_7722 = getitem_7723 = getitem_7724 = getitem_7725 = getitem_7726 = getitem_7727 = getitem_7728 = getitem_7729 = getitem_7730 = getitem_7731 = getitem_7732 = getitem_7733 = getitem_7734 = getitem_7735 = getitem_7736 = getitem_7737 = getitem_7738 = getitem_7739 = getitem_7740 = getitem_7741 = getitem_7742 = getitem_7743 = getitem_7744 = getitem_7745 = getitem_7746 = getitem_7747 = getitem_7748 = None
        reduce_scatter_tensor_64 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_271, 'avg', 128, '0');  cat_271 = None
        wait_tensor_633 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_64);  reduce_scatter_tensor_64 = None
        view_1861 = torch.ops.aten.view.default(add_1846, [2, 4096, 2048]);  add_1846 = None
        convert_element_type_1786 = torch.ops.prims.convert_element_type.default(view_1861, torch.float32);  view_1861 = None
        convert_element_type_1193 = torch.ops.prims.convert_element_type.default(primals_365, torch.bfloat16);  primals_365 = None
        all_gather_into_tensor_374 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1193, 128, '0');  convert_element_type_1193 = None
        wait_tensor_458 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_374);  all_gather_into_tensor_374 = None
        convert_element_type_1788 = torch.ops.prims.convert_element_type.default(wait_tensor_458, torch.float32);  wait_tensor_458 = None
        mul_1441 = torch.ops.aten.mul.Tensor(convert_element_type_1786, convert_element_type_1788);  convert_element_type_1788 = None
        convert_element_type_1194 = torch.ops.prims.convert_element_type.default(add_1436, torch.float32);  add_1436 = None
        mul_1044 = torch.ops.aten.mul.Tensor(convert_element_type_1194, rsqrt_68);  convert_element_type_1194 = None
        mul_1443 = torch.ops.aten.mul.Tensor(mul_1044, mul_1441)
        sum_140 = torch.ops.aten.sum.dim_IntList(mul_1443, [2], True);  mul_1443 = None
        div_159 = torch.ops.aten.div.Tensor(mul_1044, 2048)
        mul_1444 = torch.ops.aten.mul.Tensor(div_159, sum_140);  div_159 = sum_140 = None
        sub_652 = torch.ops.aten.sub.Tensor(mul_1441, mul_1444);  mul_1441 = mul_1444 = None
        mul_1445 = torch.ops.aten.mul.Tensor(sub_652, rsqrt_68);  sub_652 = rsqrt_68 = None
        mul_1446 = torch.ops.aten.mul.Tensor(convert_element_type_1786, mul_1044);  convert_element_type_1786 = mul_1044 = None
        sum_141 = torch.ops.aten.sum.dim_IntList(mul_1446, [0, 1]);  mul_1446 = None
        convert_element_type_1789 = torch.ops.prims.convert_element_type.default(mul_1445, torch.bfloat16);  mul_1445 = None
        add_1847 = torch.ops.aten.add.Tensor(add_1834, convert_element_type_1789);  add_1834 = convert_element_type_1789 = None
        convert_element_type_default_69 = torch.ops.prims.convert_element_type.default(sum_141, torch.float32);  sum_141 = None
        reduce_scatter_tensor_65 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_69, 'avg', 128, '0');  convert_element_type_default_69 = None
        wait_tensor_634 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_65);  reduce_scatter_tensor_65 = None
        view_1862 = torch.ops.aten.view.default(add_1847, [8192, 2048])
        permute_636 = torch.ops.aten.permute.default(view_1862, [1, 0])
        permute_332 = torch.ops.aten.permute.default(getitem_2325, [0, 2, 1, 3])
        view_1460 = torch.ops.aten.view.default(permute_332, [2, 4096, -1]);  permute_332 = None
        view_1462 = torch.ops.aten.view.default(view_1460, [8192, 2048]);  view_1460 = None
        mm_290 = torch.ops.aten.mm.default(permute_636, view_1462);  permute_636 = view_1462 = None
        convert_element_type_1190 = torch.ops.prims.convert_element_type.default(primals_364, torch.bfloat16);  primals_364 = None
        all_gather_into_tensor_373 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1190, 128, '0');  convert_element_type_1190 = None
        wait_tensor_457 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_373);  all_gather_into_tensor_373 = None
        permute_333 = torch.ops.aten.permute.default(wait_tensor_457, [1, 0]);  wait_tensor_457 = None
        permute_638 = torch.ops.aten.permute.default(permute_333, [1, 0]);  permute_333 = None
        mm_291 = torch.ops.aten.mm.default(view_1862, permute_638);  view_1862 = permute_638 = None
        view_1863 = torch.ops.aten.view.default(mm_291, [2, 4096, 2048]);  mm_291 = None
        convert_element_type_1796 = torch.ops.prims.convert_element_type.default(mm_290, torch.float32);  mm_290 = None
        reduce_scatter_tensor_66 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1796, 'avg', 128, '0');  convert_element_type_1796 = None
        wait_tensor_635 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_66);  reduce_scatter_tensor_66 = None
        view_1864 = torch.ops.aten.view.default(view_1863, [2, 4096, 16, 128]);  view_1863 = None
        permute_640 = torch.ops.aten.permute.default(view_1864, [0, 2, 1, 3]);  view_1864 = None
        fw_graph4 = self.fw_graph4
        joint_graph4 = self.joint_graph4
        mask_graph4 = self.mask_graph4
        flex_attention_backward_4 = torch.ops.higher_order.flex_attention_backward(permute_329, permute_330, permute_331, getitem_2325, getitem_2326, permute_640, None, fw_graph4, joint_graph4, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph4), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_329 = permute_330 = permute_331 = getitem_2325 = getitem_2326 = permute_640 = fw_graph4 = joint_graph4 = mask_graph4 = None
        getitem_7749 = flex_attention_backward_4[0]
        getitem_7750 = flex_attention_backward_4[1]
        getitem_7751 = flex_attention_backward_4[2];  flex_attention_backward_4 = None
        permute_641 = torch.ops.aten.permute.default(getitem_7751, [0, 2, 1, 3]);  getitem_7751 = None
        permute_642 = torch.ops.aten.permute.default(getitem_7750, [0, 2, 1, 3]);  getitem_7750 = None
        permute_643 = torch.ops.aten.permute.default(getitem_7749, [0, 2, 1, 3]);  getitem_7749 = None
        slice_188 = torch.ops.aten.slice.Tensor(permute_642, 3, 0, 128)
        slice_189 = torch.ops.aten.slice.Tensor(permute_642, 3, 128, 192);  permute_642 = None
        sum_142 = torch.ops.aten.sum.dim_IntList(slice_189, [2], True);  slice_189 = None
        cat_272 = torch.ops.aten.cat.default([slice_188, permute_641], 3);  slice_188 = permute_641 = None
        view_1865 = torch.ops.aten.view.default(cat_272, [2, 4096, 4096]);  cat_272 = None
        view_1866 = torch.ops.aten.view.default(view_1865, [8192, 4096]);  view_1865 = None
        permute_644 = torch.ops.aten.permute.default(view_1866, [1, 0])
        mm_292 = torch.ops.aten.mm.default(permute_644, view_1457);  permute_644 = view_1457 = None
        convert_element_type_1187 = torch.ops.prims.convert_element_type.default(primals_363, torch.bfloat16);  primals_363 = None
        all_gather_into_tensor_372 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1187, 128, '0');  convert_element_type_1187 = None
        wait_tensor_456 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_372);  all_gather_into_tensor_372 = None
        permute_328 = torch.ops.aten.permute.default(wait_tensor_456, [1, 0]);  wait_tensor_456 = None
        permute_646 = torch.ops.aten.permute.default(permute_328, [1, 0]);  permute_328 = None
        mm_293 = torch.ops.aten.mm.default(view_1866, permute_646);  view_1866 = permute_646 = None
        view_1867 = torch.ops.aten.view.default(mm_293, [2, 4096, 512]);  mm_293 = None
        convert_element_type_1801 = torch.ops.prims.convert_element_type.default(mm_292, torch.float32);  mm_292 = None
        reduce_scatter_tensor_67 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1801, 'avg', 128, '0');  convert_element_type_1801 = None
        wait_tensor_636 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_67);  reduce_scatter_tensor_67 = None
        convert_element_type_1802 = torch.ops.prims.convert_element_type.default(view_1867, torch.float32);  view_1867 = None
        convert_element_type_1184 = torch.ops.prims.convert_element_type.default(primals_362, torch.bfloat16);  primals_362 = None
        all_gather_into_tensor_371 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1184, 128, '0');  convert_element_type_1184 = None
        wait_tensor_455 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_371);  all_gather_into_tensor_371 = None
        convert_element_type_1804 = torch.ops.prims.convert_element_type.default(wait_tensor_455, torch.float32);  wait_tensor_455 = None
        mul_1447 = torch.ops.aten.mul.Tensor(convert_element_type_1802, convert_element_type_1804);  convert_element_type_1804 = None
        convert_element_type_1185 = torch.ops.prims.convert_element_type.default(getitem_2321, torch.float32);  getitem_2321 = None
        mul_1042 = torch.ops.aten.mul.Tensor(convert_element_type_1185, rsqrt_67);  convert_element_type_1185 = None
        mul_1449 = torch.ops.aten.mul.Tensor(mul_1042, mul_1447)
        sum_143 = torch.ops.aten.sum.dim_IntList(mul_1449, [2], True);  mul_1449 = None
        div_160 = torch.ops.aten.div.Tensor(mul_1042, 512)
        mul_1450 = torch.ops.aten.mul.Tensor(div_160, sum_143);  div_160 = sum_143 = None
        sub_653 = torch.ops.aten.sub.Tensor(mul_1447, mul_1450);  mul_1447 = mul_1450 = None
        mul_1451 = torch.ops.aten.mul.Tensor(sub_653, rsqrt_67);  sub_653 = rsqrt_67 = None
        mul_1452 = torch.ops.aten.mul.Tensor(convert_element_type_1802, mul_1042);  convert_element_type_1802 = mul_1042 = None
        sum_144 = torch.ops.aten.sum.dim_IntList(mul_1452, [0, 1]);  mul_1452 = None
        convert_element_type_1805 = torch.ops.prims.convert_element_type.default(mul_1451, torch.bfloat16);  mul_1451 = None
        convert_element_type_default_68 = torch.ops.prims.convert_element_type.default(sum_144, torch.float32);  sum_144 = None
        reduce_scatter_tensor_68 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_68, 'avg', 128, '0');  convert_element_type_default_68 = None
        wait_tensor_637 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_68);  reduce_scatter_tensor_68 = None
        convert_element_type_1808 = torch.ops.prims.convert_element_type.default(sum_142, torch.float32);  sum_142 = None
        view_1868 = torch.ops.aten.view.default(convert_element_type_1808, [2, 4096, 1, 32, 2]);  convert_element_type_1808 = None
        view_as_complex_62 = torch.ops.aten.view_as_complex.default(view_1868);  view_1868 = None
        mul_1453 = torch.ops.aten.mul.Tensor(view_as_complex_62, clone_9);  view_as_complex_62 = None
        view_as_real_62 = torch.ops.aten.view_as_real.default(mul_1453);  mul_1453 = None
        view_1869 = torch.ops.aten.view.default(view_as_real_62, [2, 4096, 1, 64]);  view_as_real_62 = None
        convert_element_type_1809 = torch.ops.prims.convert_element_type.default(view_1869, torch.bfloat16);  view_1869 = None
        squeeze_30 = torch.ops.aten.squeeze.dim(convert_element_type_1809, 2);  convert_element_type_1809 = None
        cat_273 = torch.ops.aten.cat.default([convert_element_type_1805, squeeze_30], 2);  convert_element_type_1805 = squeeze_30 = None
        view_1870 = torch.ops.aten.view.default(cat_273, [8192, 576]);  cat_273 = None
        permute_648 = torch.ops.aten.permute.default(view_1870, [1, 0])
        mm_294 = torch.ops.aten.mm.default(permute_648, view_1443);  permute_648 = None
        convert_element_type_1179 = torch.ops.prims.convert_element_type.default(primals_361, torch.bfloat16);  primals_361 = None
        all_gather_into_tensor_370 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1179, 128, '0');  convert_element_type_1179 = None
        wait_tensor_454 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_370);  all_gather_into_tensor_370 = None
        slice_133 = torch.ops.aten.slice.Tensor(wait_tensor_454, 0, 0, 576);  wait_tensor_454 = None
        permute_327 = torch.ops.aten.permute.default(slice_133, [1, 0]);  slice_133 = None
        permute_650 = torch.ops.aten.permute.default(permute_327, [1, 0]);  permute_327 = None
        mm_295 = torch.ops.aten.mm.default(view_1870, permute_650);  view_1870 = permute_650 = None
        view_1871 = torch.ops.aten.view.default(mm_295, [2, 4096, 2048]);  mm_295 = None
        convert_element_type_1814 = torch.ops.prims.convert_element_type.default(mm_294, torch.float32);  mm_294 = None
        split_420 = torch.ops.aten.split.Tensor(convert_element_type_1814, 5);  convert_element_type_1814 = None
        getitem_7753 = split_420[0]
        getitem_7754 = split_420[1]
        getitem_7755 = split_420[2]
        getitem_7756 = split_420[3]
        getitem_7757 = split_420[4]
        getitem_7758 = split_420[5]
        getitem_7759 = split_420[6]
        getitem_7760 = split_420[7]
        getitem_7761 = split_420[8]
        getitem_7762 = split_420[9]
        getitem_7763 = split_420[10]
        getitem_7764 = split_420[11]
        getitem_7765 = split_420[12]
        getitem_7766 = split_420[13]
        getitem_7767 = split_420[14]
        getitem_7768 = split_420[15]
        getitem_7769 = split_420[16]
        getitem_7770 = split_420[17]
        getitem_7771 = split_420[18]
        getitem_7772 = split_420[19]
        getitem_7773 = split_420[20]
        getitem_7774 = split_420[21]
        getitem_7775 = split_420[22]
        getitem_7776 = split_420[23]
        getitem_7777 = split_420[24]
        getitem_7778 = split_420[25]
        getitem_7779 = split_420[26]
        getitem_7780 = split_420[27]
        getitem_7781 = split_420[28]
        getitem_7782 = split_420[29]
        getitem_7783 = split_420[30]
        getitem_7784 = split_420[31]
        getitem_7785 = split_420[32]
        getitem_7786 = split_420[33]
        getitem_7787 = split_420[34]
        getitem_7788 = split_420[35]
        getitem_7789 = split_420[36]
        getitem_7790 = split_420[37]
        getitem_7791 = split_420[38]
        getitem_7792 = split_420[39]
        getitem_7793 = split_420[40]
        getitem_7794 = split_420[41]
        getitem_7795 = split_420[42]
        getitem_7796 = split_420[43]
        getitem_7797 = split_420[44]
        getitem_7798 = split_420[45]
        getitem_7799 = split_420[46]
        getitem_7800 = split_420[47]
        getitem_7801 = split_420[48]
        getitem_7802 = split_420[49]
        getitem_7803 = split_420[50]
        getitem_7804 = split_420[51]
        getitem_7805 = split_420[52]
        getitem_7806 = split_420[53]
        getitem_7807 = split_420[54]
        getitem_7808 = split_420[55]
        getitem_7809 = split_420[56]
        getitem_7810 = split_420[57]
        getitem_7811 = split_420[58]
        getitem_7812 = split_420[59]
        getitem_7813 = split_420[60]
        getitem_7814 = split_420[61]
        getitem_7815 = split_420[62]
        getitem_7816 = split_420[63]
        getitem_7817 = split_420[64]
        getitem_7818 = split_420[65]
        getitem_7819 = split_420[66]
        getitem_7820 = split_420[67]
        getitem_7821 = split_420[68]
        getitem_7822 = split_420[69]
        getitem_7823 = split_420[70]
        getitem_7824 = split_420[71]
        getitem_7825 = split_420[72]
        getitem_7826 = split_420[73]
        getitem_7827 = split_420[74]
        getitem_7828 = split_420[75]
        getitem_7829 = split_420[76]
        getitem_7830 = split_420[77]
        getitem_7831 = split_420[78]
        getitem_7832 = split_420[79]
        getitem_7833 = split_420[80]
        getitem_7834 = split_420[81]
        getitem_7835 = split_420[82]
        getitem_7836 = split_420[83]
        getitem_7837 = split_420[84]
        getitem_7838 = split_420[85]
        getitem_7839 = split_420[86]
        getitem_7840 = split_420[87]
        getitem_7841 = split_420[88]
        getitem_7842 = split_420[89]
        getitem_7843 = split_420[90]
        getitem_7844 = split_420[91]
        getitem_7845 = split_420[92]
        getitem_7846 = split_420[93]
        getitem_7847 = split_420[94]
        getitem_7848 = split_420[95]
        getitem_7849 = split_420[96]
        getitem_7850 = split_420[97]
        getitem_7851 = split_420[98]
        getitem_7852 = split_420[99]
        getitem_7853 = split_420[100]
        getitem_7854 = split_420[101]
        getitem_7855 = split_420[102]
        getitem_7856 = split_420[103]
        getitem_7857 = split_420[104]
        getitem_7858 = split_420[105]
        getitem_7859 = split_420[106]
        getitem_7860 = split_420[107]
        getitem_7861 = split_420[108]
        getitem_7862 = split_420[109]
        getitem_7863 = split_420[110]
        getitem_7864 = split_420[111]
        getitem_7865 = split_420[112]
        getitem_7866 = split_420[113]
        getitem_7867 = split_420[114]
        getitem_7868 = split_420[115];  split_420 = None
        constant_pad_nd_372 = torch.ops.aten.constant_pad_nd.default(getitem_7868, [0, 0, 0, 4], 0.0);  getitem_7868 = None
        cat_274 = torch.ops.aten.cat.default([getitem_7753, getitem_7754, getitem_7755, getitem_7756, getitem_7757, getitem_7758, getitem_7759, getitem_7760, getitem_7761, getitem_7762, getitem_7763, getitem_7764, getitem_7765, getitem_7766, getitem_7767, getitem_7768, getitem_7769, getitem_7770, getitem_7771, getitem_7772, getitem_7773, getitem_7774, getitem_7775, getitem_7776, getitem_7777, getitem_7778, getitem_7779, getitem_7780, getitem_7781, getitem_7782, getitem_7783, getitem_7784, getitem_7785, getitem_7786, getitem_7787, getitem_7788, getitem_7789, getitem_7790, getitem_7791, getitem_7792, getitem_7793, getitem_7794, getitem_7795, getitem_7796, getitem_7797, getitem_7798, getitem_7799, getitem_7800, getitem_7801, getitem_7802, getitem_7803, getitem_7804, getitem_7805, getitem_7806, getitem_7807, getitem_7808, getitem_7809, getitem_7810, getitem_7811, getitem_7812, getitem_7813, getitem_7814, getitem_7815, getitem_7816, getitem_7817, getitem_7818, getitem_7819, getitem_7820, getitem_7821, getitem_7822, getitem_7823, getitem_7824, getitem_7825, getitem_7826, getitem_7827, getitem_7828, getitem_7829, getitem_7830, getitem_7831, getitem_7832, getitem_7833, getitem_7834, getitem_7835, getitem_7836, getitem_7837, getitem_7838, getitem_7839, getitem_7840, getitem_7841, getitem_7842, getitem_7843, getitem_7844, getitem_7845, getitem_7846, getitem_7847, getitem_7848, getitem_7849, getitem_7850, getitem_7851, getitem_7852, getitem_7853, getitem_7854, getitem_7855, getitem_7856, getitem_7857, getitem_7858, getitem_7859, getitem_7860, getitem_7861, getitem_7862, getitem_7863, getitem_7864, getitem_7865, getitem_7866, getitem_7867, constant_pad_nd_372, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_7753 = getitem_7754 = getitem_7755 = getitem_7756 = getitem_7757 = getitem_7758 = getitem_7759 = getitem_7760 = getitem_7761 = getitem_7762 = getitem_7763 = getitem_7764 = getitem_7765 = getitem_7766 = getitem_7767 = getitem_7768 = getitem_7769 = getitem_7770 = getitem_7771 = getitem_7772 = getitem_7773 = getitem_7774 = getitem_7775 = getitem_7776 = getitem_7777 = getitem_7778 = getitem_7779 = getitem_7780 = getitem_7781 = getitem_7782 = getitem_7783 = getitem_7784 = getitem_7785 = getitem_7786 = getitem_7787 = getitem_7788 = getitem_7789 = getitem_7790 = getitem_7791 = getitem_7792 = getitem_7793 = getitem_7794 = getitem_7795 = getitem_7796 = getitem_7797 = getitem_7798 = getitem_7799 = getitem_7800 = getitem_7801 = getitem_7802 = getitem_7803 = getitem_7804 = getitem_7805 = getitem_7806 = getitem_7807 = getitem_7808 = getitem_7809 = getitem_7810 = getitem_7811 = getitem_7812 = getitem_7813 = getitem_7814 = getitem_7815 = getitem_7816 = getitem_7817 = getitem_7818 = getitem_7819 = getitem_7820 = getitem_7821 = getitem_7822 = getitem_7823 = getitem_7824 = getitem_7825 = getitem_7826 = getitem_7827 = getitem_7828 = getitem_7829 = getitem_7830 = getitem_7831 = getitem_7832 = getitem_7833 = getitem_7834 = getitem_7835 = getitem_7836 = getitem_7837 = getitem_7838 = getitem_7839 = getitem_7840 = getitem_7841 = getitem_7842 = getitem_7843 = getitem_7844 = getitem_7845 = getitem_7846 = getitem_7847 = getitem_7848 = getitem_7849 = getitem_7850 = getitem_7851 = getitem_7852 = getitem_7853 = getitem_7854 = getitem_7855 = getitem_7856 = getitem_7857 = getitem_7858 = getitem_7859 = getitem_7860 = getitem_7861 = getitem_7862 = getitem_7863 = getitem_7864 = getitem_7865 = getitem_7866 = getitem_7867 = constant_pad_nd_372 = None
        reduce_scatter_tensor_69 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_274, 'avg', 128, '0');  cat_274 = None
        wait_tensor_638 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_69);  reduce_scatter_tensor_69 = None
        slice_190 = torch.ops.aten.slice.Tensor(permute_643, 3, 0, 128)
        slice_191 = torch.ops.aten.slice.Tensor(permute_643, 3, 128, 192);  permute_643 = None
        convert_element_type_1815 = torch.ops.prims.convert_element_type.default(slice_191, torch.float32);  slice_191 = None
        view_1872 = torch.ops.aten.view.default(convert_element_type_1815, [2, 4096, 16, 32, 2]);  convert_element_type_1815 = None
        view_as_complex_63 = torch.ops.aten.view_as_complex.default(view_1872);  view_1872 = None
        mul_1454 = torch.ops.aten.mul.Tensor(view_as_complex_63, clone_9);  view_as_complex_63 = None
        view_as_real_63 = torch.ops.aten.view_as_real.default(mul_1454);  mul_1454 = None
        view_1873 = torch.ops.aten.view.default(view_as_real_63, [2, 4096, 16, 64]);  view_as_real_63 = None
        convert_element_type_1816 = torch.ops.prims.convert_element_type.default(view_1873, torch.bfloat16);  view_1873 = None
        cat_275 = torch.ops.aten.cat.default([slice_190, convert_element_type_1816], 3);  slice_190 = convert_element_type_1816 = None
        view_1874 = torch.ops.aten.view.default(cat_275, [2, 4096, 3072]);  cat_275 = None
        view_1875 = torch.ops.aten.view.default(view_1874, [8192, 3072]);  view_1874 = None
        permute_652 = torch.ops.aten.permute.default(view_1875, [1, 0])
        mm_296 = torch.ops.aten.mm.default(permute_652, view_1443);  permute_652 = view_1443 = None
        convert_element_type_1174 = torch.ops.prims.convert_element_type.default(primals_360, torch.bfloat16);  primals_360 = None
        all_gather_into_tensor_369 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1174, 128, '0');  convert_element_type_1174 = None
        wait_tensor_453 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_369);  all_gather_into_tensor_369 = None
        permute_326 = torch.ops.aten.permute.default(wait_tensor_453, [1, 0]);  wait_tensor_453 = None
        permute_654 = torch.ops.aten.permute.default(permute_326, [1, 0]);  permute_326 = None
        mm_297 = torch.ops.aten.mm.default(view_1875, permute_654);  view_1875 = permute_654 = None
        view_1876 = torch.ops.aten.view.default(mm_297, [2, 4096, 2048]);  mm_297 = None
        add_1848 = torch.ops.aten.add.Tensor(view_1871, view_1876);  view_1871 = view_1876 = None
        convert_element_type_1821 = torch.ops.prims.convert_element_type.default(mm_296, torch.float32);  mm_296 = None
        reduce_scatter_tensor_70 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1821, 'avg', 128, '0');  convert_element_type_1821 = None
        wait_tensor_639 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_70);  reduce_scatter_tensor_70 = None
        convert_element_type_1822 = torch.ops.prims.convert_element_type.default(add_1848, torch.float32);  add_1848 = None
        convert_element_type_1171 = torch.ops.prims.convert_element_type.default(primals_359, torch.bfloat16);  primals_359 = None
        all_gather_into_tensor_368 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1171, 128, '0');  convert_element_type_1171 = None
        wait_tensor_452 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_368);  all_gather_into_tensor_368 = None
        convert_element_type_1824 = torch.ops.prims.convert_element_type.default(wait_tensor_452, torch.float32);  wait_tensor_452 = None
        mul_1455 = torch.ops.aten.mul.Tensor(convert_element_type_1822, convert_element_type_1824);  convert_element_type_1824 = None
        convert_element_type_1172 = torch.ops.prims.convert_element_type.default(add_1433, torch.float32);  add_1433 = None
        mul_1038 = torch.ops.aten.mul.Tensor(convert_element_type_1172, rsqrt_66);  convert_element_type_1172 = None
        mul_1457 = torch.ops.aten.mul.Tensor(mul_1038, mul_1455)
        sum_145 = torch.ops.aten.sum.dim_IntList(mul_1457, [2], True);  mul_1457 = None
        div_161 = torch.ops.aten.div.Tensor(mul_1038, 2048)
        mul_1458 = torch.ops.aten.mul.Tensor(div_161, sum_145);  div_161 = sum_145 = None
        sub_654 = torch.ops.aten.sub.Tensor(mul_1455, mul_1458);  mul_1455 = mul_1458 = None
        mul_1459 = torch.ops.aten.mul.Tensor(sub_654, rsqrt_66);  sub_654 = rsqrt_66 = None
        mul_1460 = torch.ops.aten.mul.Tensor(convert_element_type_1822, mul_1038);  convert_element_type_1822 = mul_1038 = None
        sum_146 = torch.ops.aten.sum.dim_IntList(mul_1460, [0, 1]);  mul_1460 = None
        convert_element_type_1825 = torch.ops.prims.convert_element_type.default(mul_1459, torch.bfloat16);  mul_1459 = None
        add_1849 = torch.ops.aten.add.Tensor(add_1847, convert_element_type_1825);  add_1847 = convert_element_type_1825 = None
        convert_element_type_default_67 = torch.ops.prims.convert_element_type.default(sum_146, torch.float32);  sum_146 = None
        reduce_scatter_tensor_71 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_67, 'avg', 128, '0');  convert_element_type_default_67 = None
        wait_tensor_640 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_71);  reduce_scatter_tensor_71 = None
        view_1877 = torch.ops.aten.view.default(add_1849, [8192, 2048])
        unsqueeze_58 = torch.ops.aten.unsqueeze.default(view_1877, 1)
        convert_element_type_1828 = torch.ops.prims.convert_element_type.default(unsqueeze_58, torch.float32);  unsqueeze_58 = None
        bmm_36 = torch.ops.aten.bmm.default(permute_656, convert_element_type_1828);  permute_656 = None
        bmm_37 = torch.ops.aten.bmm.default(convert_element_type_1828, permute_657);  convert_element_type_1828 = permute_657 = None
        convert_element_type_1829 = torch.ops.prims.convert_element_type.default(bmm_36, torch.bfloat16);  bmm_36 = None
        view_1878 = torch.ops.aten.view.default(bmm_37, [8192, 6]);  bmm_37 = None
        view_1879 = torch.ops.aten.view.default(convert_element_type_1829, [49152, 2048]);  convert_element_type_1829 = None
        index_62 = torch.ops.aten.index.Tensor(view_1879, [getitem_2221]);  view_1879 = getitem_2221 = None
        permute_658 = torch.ops.aten.permute.default(view_1877, [1, 0])
        mm_298 = torch.ops.aten.mm.default(permute_658, mul_1035);  permute_658 = mul_1035 = None
        convert_element_type_1166 = torch.ops.prims.convert_element_type.default(primals_358, torch.bfloat16);  primals_358 = None
        all_gather_into_tensor_367 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1166, 128, '0');  convert_element_type_1166 = None
        wait_tensor_451 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_367);  all_gather_into_tensor_367 = None
        permute_325 = torch.ops.aten.permute.default(wait_tensor_451, [1, 0]);  wait_tensor_451 = None
        permute_660 = torch.ops.aten.permute.default(permute_325, [1, 0]);  permute_325 = None
        mm_299 = torch.ops.aten.mm.default(view_1877, permute_660);  view_1877 = permute_660 = None
        convert_element_type_1834 = torch.ops.prims.convert_element_type.default(mm_298, torch.float32);  mm_298 = None
        reduce_scatter_tensor_72 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1834, 'avg', 128, '0');  convert_element_type_1834 = None
        wait_tensor_641 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_72);  reduce_scatter_tensor_72 = None
        convert_element_type_1161 = torch.ops.prims.convert_element_type.default(mm_172, torch.float32);  mm_172 = None
        neg_42 = torch.ops.aten.neg.default(convert_element_type_1161)
        exp_63 = torch.ops.aten.exp.default(neg_42);  neg_42 = None
        add_1428 = torch.ops.aten.add.Tensor(exp_63, 1);  exp_63 = None
        div_105 = torch.ops.aten.div.Tensor(convert_element_type_1161, add_1428)
        convert_element_type_1162 = torch.ops.prims.convert_element_type.default(div_105, torch.bfloat16);  div_105 = None
        mul_1461 = torch.ops.aten.mul.Tensor(mm_299, convert_element_type_1162);  convert_element_type_1162 = None
        mul_1462 = torch.ops.aten.mul.Tensor(mm_299, mm_173);  mm_299 = mm_173 = None
        permute_662 = torch.ops.aten.permute.default(mul_1461, [1, 0])
        mm_300 = torch.ops.aten.mm.default(permute_662, view_1398);  permute_662 = None
        convert_element_type_1163 = torch.ops.prims.convert_element_type.default(primals_357, torch.bfloat16);  primals_357 = None
        all_gather_into_tensor_366 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1163, 128, '0');  convert_element_type_1163 = None
        wait_tensor_450 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_366);  all_gather_into_tensor_366 = None
        permute_324 = torch.ops.aten.permute.default(wait_tensor_450, [1, 0]);  wait_tensor_450 = None
        permute_664 = torch.ops.aten.permute.default(permute_324, [1, 0]);  permute_324 = None
        mm_301 = torch.ops.aten.mm.default(mul_1461, permute_664);  mul_1461 = permute_664 = None
        convert_element_type_1839 = torch.ops.prims.convert_element_type.default(mm_300, torch.float32);  mm_300 = None
        reduce_scatter_tensor_73 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1839, 'avg', 128, '0');  convert_element_type_1839 = None
        wait_tensor_642 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_73);  reduce_scatter_tensor_73 = None
        convert_element_type_1840 = torch.ops.prims.convert_element_type.default(mul_1462, torch.float32);  mul_1462 = None
        reciprocal_10 = torch.ops.aten.reciprocal.default(add_1428);  add_1428 = None
        mul_1463 = torch.ops.aten.mul.Tensor(reciprocal_10, 1);  reciprocal_10 = None
        mul_1464 = torch.ops.aten.mul.Tensor(convert_element_type_1840, mul_1463);  convert_element_type_1840 = None
        sub_655 = torch.ops.aten.sub.Tensor(1, mul_1463);  mul_1463 = None
        mul_1465 = torch.ops.aten.mul.Tensor(convert_element_type_1161, sub_655);  convert_element_type_1161 = sub_655 = None
        add_1851 = torch.ops.aten.add.Tensor(mul_1465, 1);  mul_1465 = None
        mul_1466 = torch.ops.aten.mul.Tensor(mul_1464, add_1851);  mul_1464 = add_1851 = None
        convert_element_type_1842 = torch.ops.prims.convert_element_type.default(mul_1466, torch.bfloat16);  mul_1466 = None
        permute_666 = torch.ops.aten.permute.default(convert_element_type_1842, [1, 0])
        mm_302 = torch.ops.aten.mm.default(permute_666, view_1398);  permute_666 = None
        convert_element_type_1158 = torch.ops.prims.convert_element_type.default(primals_356, torch.bfloat16);  primals_356 = None
        all_gather_into_tensor_365 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1158, 128, '0');  convert_element_type_1158 = None
        wait_tensor_449 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_365);  all_gather_into_tensor_365 = None
        permute_323 = torch.ops.aten.permute.default(wait_tensor_449, [1, 0]);  wait_tensor_449 = None
        permute_668 = torch.ops.aten.permute.default(permute_323, [1, 0]);  permute_323 = None
        mm_303 = torch.ops.aten.mm.default(convert_element_type_1842, permute_668);  convert_element_type_1842 = permute_668 = None
        add_1852 = torch.ops.aten.add.Tensor(mm_301, mm_303);  mm_301 = mm_303 = None
        convert_element_type_1847 = torch.ops.prims.convert_element_type.default(mm_302, torch.float32);  mm_302 = None
        reduce_scatter_tensor_74 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1847, 'avg', 128, '0');  convert_element_type_1847 = None
        wait_tensor_643 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_74);  reduce_scatter_tensor_74 = None
        all_to_all_single_88 = torch.ops._c10d_functional.all_to_all_single.default(index_62, [_local_scalar_dense_328, _local_scalar_dense_329, _local_scalar_dense_330, _local_scalar_dense_331, _local_scalar_dense_332, _local_scalar_dense_333, _local_scalar_dense_334, _local_scalar_dense_335], [_local_scalar_dense_320, _local_scalar_dense_321, _local_scalar_dense_322, _local_scalar_dense_323, _local_scalar_dense_324, _local_scalar_dense_325, _local_scalar_dense_326, _local_scalar_dense_327], '1033');  index_62 = None
        wait_tensor_644 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_88);  all_to_all_single_88 = None
        full_378 = torch.ops.aten.full.default([sym_size_int_81, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_81 = None
        slice_scatter_5 = torch.ops.aten.slice_scatter.default(full_378, wait_tensor_644, 0, 0, -1);  wait_tensor_644 = None
        index_63 = torch.ops.aten.index.Tensor(slice_scatter_5, [getitem_2222]);  slice_scatter_5 = None
        permute_670 = torch.ops.aten.permute.default(index_63, [1, 0])
        _grouped_mm_108 = torch.ops.aten._grouped_mm.default(permute_670, mul_1015, cumsum_62);  permute_670 = mul_1015 = None
        _grouped_mm_109 = torch.ops.aten._grouped_mm.default(index_63, permute_672, cumsum_62);  index_63 = permute_672 = None
        convert_element_type_1156 = torch.ops.prims.convert_element_type.default(_grouped_mm_60, torch.float32);  _grouped_mm_60 = None
        neg_41 = torch.ops.aten.neg.default(convert_element_type_1156)
        exp_62 = torch.ops.aten.exp.default(neg_41);  neg_41 = None
        add_1392 = torch.ops.aten.add.Tensor(exp_62, 1);  exp_62 = None
        div_104 = torch.ops.aten.div.Tensor(convert_element_type_1156, add_1392)
        convert_element_type_1157 = torch.ops.prims.convert_element_type.default(div_104, torch.bfloat16);  div_104 = None
        mul_1467 = torch.ops.aten.mul.Tensor(_grouped_mm_109, convert_element_type_1157);  convert_element_type_1157 = None
        mul_1468 = torch.ops.aten.mul.Tensor(_grouped_mm_109, _grouped_mm_61);  _grouped_mm_109 = _grouped_mm_61 = None
        permute_674 = torch.ops.aten.permute.default(mul_1467, [1, 0])
        _grouped_mm_110 = torch.ops.aten._grouped_mm.default(permute_674, index_41, cumsum_62);  permute_674 = None
        _grouped_mm_111 = torch.ops.aten._grouped_mm.default(mul_1467, permute_676, cumsum_62);  mul_1467 = permute_676 = None
        convert_element_type_1848 = torch.ops.prims.convert_element_type.default(mul_1468, torch.float32);  mul_1468 = None
        reciprocal_11 = torch.ops.aten.reciprocal.default(add_1392);  add_1392 = None
        mul_1469 = torch.ops.aten.mul.Tensor(reciprocal_11, 1);  reciprocal_11 = None
        mul_1470 = torch.ops.aten.mul.Tensor(convert_element_type_1848, mul_1469);  convert_element_type_1848 = None
        sub_656 = torch.ops.aten.sub.Tensor(1, mul_1469);  mul_1469 = None
        mul_1471 = torch.ops.aten.mul.Tensor(convert_element_type_1156, sub_656);  convert_element_type_1156 = sub_656 = None
        add_1854 = torch.ops.aten.add.Tensor(mul_1471, 1);  mul_1471 = None
        mul_1472 = torch.ops.aten.mul.Tensor(mul_1470, add_1854);  mul_1470 = add_1854 = None
        convert_element_type_1850 = torch.ops.prims.convert_element_type.default(mul_1472, torch.bfloat16);  mul_1472 = None
        permute_678 = torch.ops.aten.permute.default(convert_element_type_1850, [1, 0])
        _grouped_mm_112 = torch.ops.aten._grouped_mm.default(permute_678, index_41, cumsum_62);  permute_678 = index_41 = None
        _grouped_mm_113 = torch.ops.aten._grouped_mm.default(convert_element_type_1850, permute_680, cumsum_62);  convert_element_type_1850 = permute_680 = cumsum_62 = None
        add_1855 = torch.ops.aten.add.Tensor(_grouped_mm_111, _grouped_mm_113);  _grouped_mm_111 = _grouped_mm_113 = None
        convert_element_type_1851 = torch.ops.prims.convert_element_type.default(_grouped_mm_110, torch.float32);  _grouped_mm_110 = None
        div_162 = torch.ops.aten.div.Tensor(convert_element_type_1851, 128);  convert_element_type_1851 = None
        split_422 = torch.ops.aten.split.Tensor(div_162, 88, 1);  div_162 = None
        getitem_7885 = split_422[0]
        getitem_7902 = split_422[1]
        getitem_7919 = split_422[2]
        getitem_7936 = split_422[3]
        getitem_7953 = split_422[4]
        getitem_7970 = split_422[5]
        getitem_7987 = split_422[6]
        getitem_8004 = split_422[7]
        getitem_8021 = split_422[8]
        getitem_8038 = split_422[9]
        getitem_8055 = split_422[10]
        getitem_8072 = split_422[11]
        getitem_8089 = split_422[12]
        getitem_8106 = split_422[13]
        getitem_8123 = split_422[14]
        getitem_8140 = split_422[15];  split_422 = None
        cat_276 = torch.ops.aten.cat.default([getitem_7885, getitem_7902, getitem_7919, getitem_7936, getitem_7953, getitem_7970, getitem_7987, getitem_8004, getitem_8021, getitem_8038, getitem_8055, getitem_8072, getitem_8089, getitem_8106, getitem_8123, getitem_8140]);  getitem_7885 = getitem_7902 = getitem_7919 = getitem_7936 = getitem_7953 = getitem_7970 = getitem_7987 = getitem_8004 = getitem_8021 = getitem_8038 = getitem_8055 = getitem_8072 = getitem_8089 = getitem_8106 = getitem_8123 = getitem_8140 = None
        reduce_scatter_tensor_75 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_276, 'sum', 16, '1025');  cat_276 = None
        wait_tensor_645 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_75);  reduce_scatter_tensor_75 = None
        convert_element_type_1852 = torch.ops.prims.convert_element_type.default(_grouped_mm_108, torch.float32);  _grouped_mm_108 = None
        div_163 = torch.ops.aten.div.Tensor(convert_element_type_1852, 128);  convert_element_type_1852 = None
        split_439 = torch.ops.aten.split.Tensor(div_163, 128, 1);  div_163 = None
        getitem_8157 = split_439[0]
        getitem_8174 = split_439[1]
        getitem_8191 = split_439[2]
        getitem_8208 = split_439[3]
        getitem_8225 = split_439[4]
        getitem_8242 = split_439[5]
        getitem_8259 = split_439[6]
        getitem_8276 = split_439[7]
        getitem_8293 = split_439[8]
        getitem_8310 = split_439[9]
        getitem_8327 = split_439[10]
        getitem_8344 = split_439[11]
        getitem_8361 = split_439[12]
        getitem_8378 = split_439[13]
        getitem_8395 = split_439[14]
        getitem_8412 = split_439[15];  split_439 = None
        cat_277 = torch.ops.aten.cat.default([getitem_8157, getitem_8174, getitem_8191, getitem_8208, getitem_8225, getitem_8242, getitem_8259, getitem_8276, getitem_8293, getitem_8310, getitem_8327, getitem_8344, getitem_8361, getitem_8378, getitem_8395, getitem_8412]);  getitem_8157 = getitem_8174 = getitem_8191 = getitem_8208 = getitem_8225 = getitem_8242 = getitem_8259 = getitem_8276 = getitem_8293 = getitem_8310 = getitem_8327 = getitem_8344 = getitem_8361 = getitem_8378 = getitem_8395 = getitem_8412 = None
        reduce_scatter_tensor_76 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_277, 'sum', 16, '1025');  cat_277 = None
        wait_tensor_646 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_76);  reduce_scatter_tensor_76 = None
        convert_element_type_1853 = torch.ops.prims.convert_element_type.default(_grouped_mm_112, torch.float32);  _grouped_mm_112 = None
        div_164 = torch.ops.aten.div.Tensor(convert_element_type_1853, 128);  convert_element_type_1853 = None
        split_456 = torch.ops.aten.split.Tensor(div_164, 88, 1);  div_164 = None
        getitem_8429 = split_456[0]
        getitem_8446 = split_456[1]
        getitem_8463 = split_456[2]
        getitem_8480 = split_456[3]
        getitem_8497 = split_456[4]
        getitem_8514 = split_456[5]
        getitem_8531 = split_456[6]
        getitem_8548 = split_456[7]
        getitem_8565 = split_456[8]
        getitem_8582 = split_456[9]
        getitem_8599 = split_456[10]
        getitem_8616 = split_456[11]
        getitem_8633 = split_456[12]
        getitem_8650 = split_456[13]
        getitem_8667 = split_456[14]
        getitem_8684 = split_456[15];  split_456 = None
        cat_278 = torch.ops.aten.cat.default([getitem_8429, getitem_8446, getitem_8463, getitem_8480, getitem_8497, getitem_8514, getitem_8531, getitem_8548, getitem_8565, getitem_8582, getitem_8599, getitem_8616, getitem_8633, getitem_8650, getitem_8667, getitem_8684]);  getitem_8429 = getitem_8446 = getitem_8463 = getitem_8480 = getitem_8497 = getitem_8514 = getitem_8531 = getitem_8548 = getitem_8565 = getitem_8582 = getitem_8599 = getitem_8616 = getitem_8633 = getitem_8650 = getitem_8667 = getitem_8684 = None
        reduce_scatter_tensor_77 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_278, 'sum', 16, '1025');  cat_278 = None
        wait_tensor_647 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_77);  reduce_scatter_tensor_77 = None
        index_put_62 = torch.ops.aten.index_put.default(full_378, [getitem_2222], add_1855, True);  full_378 = getitem_2222 = add_1855 = None
        slice_192 = torch.ops.aten.slice.Tensor(index_put_62, 0, 0, add_1856);  index_put_62 = add_1856 = None
        all_to_all_single_89 = torch.ops._c10d_functional.all_to_all_single.default(slice_192, [_local_scalar_dense_320, _local_scalar_dense_321, _local_scalar_dense_322, _local_scalar_dense_323, _local_scalar_dense_324, _local_scalar_dense_325, _local_scalar_dense_326, _local_scalar_dense_327], [_local_scalar_dense_328, _local_scalar_dense_329, _local_scalar_dense_330, _local_scalar_dense_331, _local_scalar_dense_332, _local_scalar_dense_333, _local_scalar_dense_334, _local_scalar_dense_335], '1033');  slice_192 = _local_scalar_dense_320 = _local_scalar_dense_321 = _local_scalar_dense_322 = _local_scalar_dense_323 = _local_scalar_dense_324 = _local_scalar_dense_325 = _local_scalar_dense_326 = _local_scalar_dense_327 = _local_scalar_dense_328 = _local_scalar_dense_329 = _local_scalar_dense_330 = _local_scalar_dense_331 = _local_scalar_dense_332 = _local_scalar_dense_333 = _local_scalar_dense_334 = _local_scalar_dense_335 = None
        wait_tensor_648 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_89);  all_to_all_single_89 = None
        index_put_63 = torch.ops.aten.index_put.default(full_default_52, [div_102], wait_tensor_648, True);  div_102 = wait_tensor_648 = None
        add_1860 = torch.ops.aten.add.Tensor(add_1852, index_put_63);  add_1852 = index_put_63 = None
        mul_1473 = torch.ops.aten.mul.Tensor(view_1878, 1.0);  view_1878 = None
        scatter_add_5 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_2219, mul_1473);  getitem_2219 = mul_1473 = None
        convert_element_type_1145 = torch.ops.prims.convert_element_type.default(mm_171, torch.float32);  mm_171 = None
        sub_480 = torch.ops.aten.sub.Tensor(convert_element_type_1145, amax_20);  convert_element_type_1145 = amax_20 = None
        exp_61 = torch.ops.aten.exp.default(sub_480);  sub_480 = None
        div_101 = torch.ops.aten.div.Tensor(exp_61, sum_81);  exp_61 = sum_81 = None
        mul_1474 = torch.ops.aten.mul.Tensor(scatter_add_5, div_101);  scatter_add_5 = None
        sum_147 = torch.ops.aten.sum.dim_IntList(mul_1474, [1], True)
        neg_70 = torch.ops.aten.neg.default(div_101);  div_101 = None
        fma_5 = torch.ops.prims.fma.default(neg_70, sum_147, mul_1474);  neg_70 = sum_147 = mul_1474 = None
        convert_element_type_1854 = torch.ops.prims.convert_element_type.default(fma_5, torch.bfloat16);  fma_5 = None
        permute_682 = torch.ops.aten.permute.default(convert_element_type_1854, [1, 0])
        mm_304 = torch.ops.aten.mm.default(permute_682, view_1398);  permute_682 = view_1398 = None
        convert_element_type_1142 = torch.ops.prims.convert_element_type.default(primals_351, torch.bfloat16);  primals_351 = None
        all_gather_into_tensor_358 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1142, 128, '0');  convert_element_type_1142 = None
        wait_tensor_438 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_358);  all_gather_into_tensor_358 = None
        slice_129 = torch.ops.aten.slice.Tensor(wait_tensor_438, 0, 0, 64);  wait_tensor_438 = None
        permute_319 = torch.ops.aten.permute.default(slice_129, [1, 0]);  slice_129 = None
        permute_684 = torch.ops.aten.permute.default(permute_319, [1, 0]);  permute_319 = None
        mm_305 = torch.ops.aten.mm.default(convert_element_type_1854, permute_684);  convert_element_type_1854 = permute_684 = None
        add_1861 = torch.ops.aten.add.Tensor(add_1860, mm_305);  add_1860 = mm_305 = None
        convert_element_type_1859 = torch.ops.prims.convert_element_type.default(mm_304, torch.float32);  mm_304 = None
        split_472 = torch.ops.aten.split.Tensor(convert_element_type_1859, 1);  convert_element_type_1859 = None
        getitem_8685 = split_472[0]
        getitem_8686 = split_472[1]
        getitem_8687 = split_472[2]
        getitem_8688 = split_472[3]
        getitem_8689 = split_472[4]
        getitem_8690 = split_472[5]
        getitem_8691 = split_472[6]
        getitem_8692 = split_472[7]
        getitem_8693 = split_472[8]
        getitem_8694 = split_472[9]
        getitem_8695 = split_472[10]
        getitem_8696 = split_472[11]
        getitem_8697 = split_472[12]
        getitem_8698 = split_472[13]
        getitem_8699 = split_472[14]
        getitem_8700 = split_472[15]
        getitem_8701 = split_472[16]
        getitem_8702 = split_472[17]
        getitem_8703 = split_472[18]
        getitem_8704 = split_472[19]
        getitem_8705 = split_472[20]
        getitem_8706 = split_472[21]
        getitem_8707 = split_472[22]
        getitem_8708 = split_472[23]
        getitem_8709 = split_472[24]
        getitem_8710 = split_472[25]
        getitem_8711 = split_472[26]
        getitem_8712 = split_472[27]
        getitem_8713 = split_472[28]
        getitem_8714 = split_472[29]
        getitem_8715 = split_472[30]
        getitem_8716 = split_472[31]
        getitem_8717 = split_472[32]
        getitem_8718 = split_472[33]
        getitem_8719 = split_472[34]
        getitem_8720 = split_472[35]
        getitem_8721 = split_472[36]
        getitem_8722 = split_472[37]
        getitem_8723 = split_472[38]
        getitem_8724 = split_472[39]
        getitem_8725 = split_472[40]
        getitem_8726 = split_472[41]
        getitem_8727 = split_472[42]
        getitem_8728 = split_472[43]
        getitem_8729 = split_472[44]
        getitem_8730 = split_472[45]
        getitem_8731 = split_472[46]
        getitem_8732 = split_472[47]
        getitem_8733 = split_472[48]
        getitem_8734 = split_472[49]
        getitem_8735 = split_472[50]
        getitem_8736 = split_472[51]
        getitem_8737 = split_472[52]
        getitem_8738 = split_472[53]
        getitem_8739 = split_472[54]
        getitem_8740 = split_472[55]
        getitem_8741 = split_472[56]
        getitem_8742 = split_472[57]
        getitem_8743 = split_472[58]
        getitem_8744 = split_472[59]
        getitem_8745 = split_472[60]
        getitem_8746 = split_472[61]
        getitem_8747 = split_472[62]
        getitem_8748 = split_472[63];  split_472 = None
        cat_279 = torch.ops.aten.cat.default([getitem_8685, getitem_8686, getitem_8687, getitem_8688, getitem_8689, getitem_8690, getitem_8691, getitem_8692, getitem_8693, getitem_8694, getitem_8695, getitem_8696, getitem_8697, getitem_8698, getitem_8699, getitem_8700, getitem_8701, getitem_8702, getitem_8703, getitem_8704, getitem_8705, getitem_8706, getitem_8707, getitem_8708, getitem_8709, getitem_8710, getitem_8711, getitem_8712, getitem_8713, getitem_8714, getitem_8715, getitem_8716, getitem_8717, getitem_8718, getitem_8719, getitem_8720, getitem_8721, getitem_8722, getitem_8723, getitem_8724, getitem_8725, getitem_8726, getitem_8727, getitem_8728, getitem_8729, getitem_8730, getitem_8731, getitem_8732, getitem_8733, getitem_8734, getitem_8735, getitem_8736, getitem_8737, getitem_8738, getitem_8739, getitem_8740, getitem_8741, getitem_8742, getitem_8743, getitem_8744, getitem_8745, getitem_8746, getitem_8747, getitem_8748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_8685 = getitem_8686 = getitem_8687 = getitem_8688 = getitem_8689 = getitem_8690 = getitem_8691 = getitem_8692 = getitem_8693 = getitem_8694 = getitem_8695 = getitem_8696 = getitem_8697 = getitem_8698 = getitem_8699 = getitem_8700 = getitem_8701 = getitem_8702 = getitem_8703 = getitem_8704 = getitem_8705 = getitem_8706 = getitem_8707 = getitem_8708 = getitem_8709 = getitem_8710 = getitem_8711 = getitem_8712 = getitem_8713 = getitem_8714 = getitem_8715 = getitem_8716 = getitem_8717 = getitem_8718 = getitem_8719 = getitem_8720 = getitem_8721 = getitem_8722 = getitem_8723 = getitem_8724 = getitem_8725 = getitem_8726 = getitem_8727 = getitem_8728 = getitem_8729 = getitem_8730 = getitem_8731 = getitem_8732 = getitem_8733 = getitem_8734 = getitem_8735 = getitem_8736 = getitem_8737 = getitem_8738 = getitem_8739 = getitem_8740 = getitem_8741 = getitem_8742 = getitem_8743 = getitem_8744 = getitem_8745 = getitem_8746 = getitem_8747 = getitem_8748 = None
        reduce_scatter_tensor_78 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_279, 'avg', 128, '0');  cat_279 = None
        wait_tensor_649 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_78);  reduce_scatter_tensor_78 = None
        view_1880 = torch.ops.aten.view.default(add_1861, [2, 4096, 2048]);  add_1861 = None
        convert_element_type_1860 = torch.ops.prims.convert_element_type.default(view_1880, torch.float32);  view_1880 = None
        convert_element_type_1139 = torch.ops.prims.convert_element_type.default(primals_349, torch.bfloat16);  primals_349 = None
        all_gather_into_tensor_357 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1139, 128, '0');  convert_element_type_1139 = None
        wait_tensor_437 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_357);  all_gather_into_tensor_357 = None
        convert_element_type_1862 = torch.ops.prims.convert_element_type.default(wait_tensor_437, torch.float32);  wait_tensor_437 = None
        mul_1475 = torch.ops.aten.mul.Tensor(convert_element_type_1860, convert_element_type_1862);  convert_element_type_1862 = None
        convert_element_type_1140 = torch.ops.prims.convert_element_type.default(add_1368, torch.float32);  add_1368 = None
        mul_995 = torch.ops.aten.mul.Tensor(convert_element_type_1140, rsqrt_65);  convert_element_type_1140 = None
        mul_1477 = torch.ops.aten.mul.Tensor(mul_995, mul_1475)
        sum_148 = torch.ops.aten.sum.dim_IntList(mul_1477, [2], True);  mul_1477 = None
        div_165 = torch.ops.aten.div.Tensor(mul_995, 2048)
        mul_1478 = torch.ops.aten.mul.Tensor(div_165, sum_148);  div_165 = sum_148 = None
        sub_658 = torch.ops.aten.sub.Tensor(mul_1475, mul_1478);  mul_1475 = mul_1478 = None
        mul_1479 = torch.ops.aten.mul.Tensor(sub_658, rsqrt_65);  sub_658 = rsqrt_65 = None
        mul_1480 = torch.ops.aten.mul.Tensor(convert_element_type_1860, mul_995);  convert_element_type_1860 = mul_995 = None
        sum_149 = torch.ops.aten.sum.dim_IntList(mul_1480, [0, 1]);  mul_1480 = None
        convert_element_type_1863 = torch.ops.prims.convert_element_type.default(mul_1479, torch.bfloat16);  mul_1479 = None
        add_1862 = torch.ops.aten.add.Tensor(add_1849, convert_element_type_1863);  add_1849 = convert_element_type_1863 = None
        convert_element_type_default_66 = torch.ops.prims.convert_element_type.default(sum_149, torch.float32);  sum_149 = None
        reduce_scatter_tensor_79 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_66, 'avg', 128, '0');  convert_element_type_default_66 = None
        wait_tensor_650 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_79);  reduce_scatter_tensor_79 = None
        view_1881 = torch.ops.aten.view.default(add_1862, [8192, 2048])
        permute_686 = torch.ops.aten.permute.default(view_1881, [1, 0])
        permute_317 = torch.ops.aten.permute.default(getitem_2215, [0, 2, 1, 3])
        view_1393 = torch.ops.aten.view.default(permute_317, [2, 4096, -1]);  permute_317 = None
        view_1395 = torch.ops.aten.view.default(view_1393, [8192, 2048]);  view_1393 = None
        mm_306 = torch.ops.aten.mm.default(permute_686, view_1395);  permute_686 = view_1395 = None
        convert_element_type_1136 = torch.ops.prims.convert_element_type.default(primals_348, torch.bfloat16);  primals_348 = None
        all_gather_into_tensor_356 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1136, 128, '0');  convert_element_type_1136 = None
        wait_tensor_436 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_356);  all_gather_into_tensor_356 = None
        permute_318 = torch.ops.aten.permute.default(wait_tensor_436, [1, 0]);  wait_tensor_436 = None
        permute_688 = torch.ops.aten.permute.default(permute_318, [1, 0]);  permute_318 = None
        mm_307 = torch.ops.aten.mm.default(view_1881, permute_688);  view_1881 = permute_688 = None
        view_1882 = torch.ops.aten.view.default(mm_307, [2, 4096, 2048]);  mm_307 = None
        convert_element_type_1870 = torch.ops.prims.convert_element_type.default(mm_306, torch.float32);  mm_306 = None
        reduce_scatter_tensor_80 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1870, 'avg', 128, '0');  convert_element_type_1870 = None
        wait_tensor_651 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_80);  reduce_scatter_tensor_80 = None
        view_1883 = torch.ops.aten.view.default(view_1882, [2, 4096, 16, 128]);  view_1882 = None
        permute_690 = torch.ops.aten.permute.default(view_1883, [0, 2, 1, 3]);  view_1883 = None
        fw_graph5 = self.fw_graph5
        joint_graph5 = self.joint_graph5
        mask_graph5 = self.mask_graph5
        flex_attention_backward_5 = torch.ops.higher_order.flex_attention_backward(permute_314, permute_315, permute_316, getitem_2215, getitem_2216, permute_690, None, fw_graph5, joint_graph5, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph5), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_314 = permute_315 = permute_316 = getitem_2215 = getitem_2216 = permute_690 = fw_graph5 = joint_graph5 = mask_graph5 = None
        getitem_8749 = flex_attention_backward_5[0]
        getitem_8750 = flex_attention_backward_5[1]
        getitem_8751 = flex_attention_backward_5[2];  flex_attention_backward_5 = None
        permute_691 = torch.ops.aten.permute.default(getitem_8751, [0, 2, 1, 3]);  getitem_8751 = None
        permute_692 = torch.ops.aten.permute.default(getitem_8750, [0, 2, 1, 3]);  getitem_8750 = None
        permute_693 = torch.ops.aten.permute.default(getitem_8749, [0, 2, 1, 3]);  getitem_8749 = None
        slice_194 = torch.ops.aten.slice.Tensor(permute_692, 3, 0, 128)
        slice_195 = torch.ops.aten.slice.Tensor(permute_692, 3, 128, 192);  permute_692 = None
        sum_150 = torch.ops.aten.sum.dim_IntList(slice_195, [2], True);  slice_195 = None
        cat_280 = torch.ops.aten.cat.default([slice_194, permute_691], 3);  slice_194 = permute_691 = None
        view_1884 = torch.ops.aten.view.default(cat_280, [2, 4096, 4096]);  cat_280 = None
        view_1885 = torch.ops.aten.view.default(view_1884, [8192, 4096]);  view_1884 = None
        permute_694 = torch.ops.aten.permute.default(view_1885, [1, 0])
        mm_308 = torch.ops.aten.mm.default(permute_694, view_1390);  permute_694 = view_1390 = None
        convert_element_type_1133 = torch.ops.prims.convert_element_type.default(primals_347, torch.bfloat16);  primals_347 = None
        all_gather_into_tensor_355 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1133, 128, '0');  convert_element_type_1133 = None
        wait_tensor_435 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_355);  all_gather_into_tensor_355 = None
        permute_313 = torch.ops.aten.permute.default(wait_tensor_435, [1, 0]);  wait_tensor_435 = None
        permute_696 = torch.ops.aten.permute.default(permute_313, [1, 0]);  permute_313 = None
        mm_309 = torch.ops.aten.mm.default(view_1885, permute_696);  view_1885 = permute_696 = None
        view_1886 = torch.ops.aten.view.default(mm_309, [2, 4096, 512]);  mm_309 = None
        convert_element_type_1875 = torch.ops.prims.convert_element_type.default(mm_308, torch.float32);  mm_308 = None
        reduce_scatter_tensor_81 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1875, 'avg', 128, '0');  convert_element_type_1875 = None
        wait_tensor_652 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_81);  reduce_scatter_tensor_81 = None
        convert_element_type_1876 = torch.ops.prims.convert_element_type.default(view_1886, torch.float32);  view_1886 = None
        convert_element_type_1130 = torch.ops.prims.convert_element_type.default(primals_346, torch.bfloat16);  primals_346 = None
        all_gather_into_tensor_354 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1130, 128, '0');  convert_element_type_1130 = None
        wait_tensor_434 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_354);  all_gather_into_tensor_354 = None
        convert_element_type_1878 = torch.ops.prims.convert_element_type.default(wait_tensor_434, torch.float32);  wait_tensor_434 = None
        mul_1481 = torch.ops.aten.mul.Tensor(convert_element_type_1876, convert_element_type_1878);  convert_element_type_1878 = None
        convert_element_type_1131 = torch.ops.prims.convert_element_type.default(getitem_2211, torch.float32);  getitem_2211 = None
        mul_993 = torch.ops.aten.mul.Tensor(convert_element_type_1131, rsqrt_64);  convert_element_type_1131 = None
        mul_1483 = torch.ops.aten.mul.Tensor(mul_993, mul_1481)
        sum_151 = torch.ops.aten.sum.dim_IntList(mul_1483, [2], True);  mul_1483 = None
        div_166 = torch.ops.aten.div.Tensor(mul_993, 512)
        mul_1484 = torch.ops.aten.mul.Tensor(div_166, sum_151);  div_166 = sum_151 = None
        sub_659 = torch.ops.aten.sub.Tensor(mul_1481, mul_1484);  mul_1481 = mul_1484 = None
        mul_1485 = torch.ops.aten.mul.Tensor(sub_659, rsqrt_64);  sub_659 = rsqrt_64 = None
        mul_1486 = torch.ops.aten.mul.Tensor(convert_element_type_1876, mul_993);  convert_element_type_1876 = mul_993 = None
        sum_152 = torch.ops.aten.sum.dim_IntList(mul_1486, [0, 1]);  mul_1486 = None
        convert_element_type_1879 = torch.ops.prims.convert_element_type.default(mul_1485, torch.bfloat16);  mul_1485 = None
        convert_element_type_default_65 = torch.ops.prims.convert_element_type.default(sum_152, torch.float32);  sum_152 = None
        reduce_scatter_tensor_82 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_65, 'avg', 128, '0');  convert_element_type_default_65 = None
        wait_tensor_653 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_82);  reduce_scatter_tensor_82 = None
        convert_element_type_1882 = torch.ops.prims.convert_element_type.default(sum_150, torch.float32);  sum_150 = None
        view_1887 = torch.ops.aten.view.default(convert_element_type_1882, [2, 4096, 1, 32, 2]);  convert_element_type_1882 = None
        view_as_complex_64 = torch.ops.aten.view_as_complex.default(view_1887);  view_1887 = None
        mul_1487 = torch.ops.aten.mul.Tensor(view_as_complex_64, clone_9);  view_as_complex_64 = None
        view_as_real_64 = torch.ops.aten.view_as_real.default(mul_1487);  mul_1487 = None
        view_1888 = torch.ops.aten.view.default(view_as_real_64, [2, 4096, 1, 64]);  view_as_real_64 = None
        convert_element_type_1883 = torch.ops.prims.convert_element_type.default(view_1888, torch.bfloat16);  view_1888 = None
        squeeze_31 = torch.ops.aten.squeeze.dim(convert_element_type_1883, 2);  convert_element_type_1883 = None
        cat_281 = torch.ops.aten.cat.default([convert_element_type_1879, squeeze_31], 2);  convert_element_type_1879 = squeeze_31 = None
        view_1889 = torch.ops.aten.view.default(cat_281, [8192, 576]);  cat_281 = None
        permute_698 = torch.ops.aten.permute.default(view_1889, [1, 0])
        mm_310 = torch.ops.aten.mm.default(permute_698, view_1376);  permute_698 = None
        convert_element_type_1125 = torch.ops.prims.convert_element_type.default(primals_345, torch.bfloat16);  primals_345 = None
        all_gather_into_tensor_353 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1125, 128, '0');  convert_element_type_1125 = None
        wait_tensor_433 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_353);  all_gather_into_tensor_353 = None
        slice_127 = torch.ops.aten.slice.Tensor(wait_tensor_433, 0, 0, 576);  wait_tensor_433 = None
        permute_312 = torch.ops.aten.permute.default(slice_127, [1, 0]);  slice_127 = None
        permute_700 = torch.ops.aten.permute.default(permute_312, [1, 0]);  permute_312 = None
        mm_311 = torch.ops.aten.mm.default(view_1889, permute_700);  view_1889 = permute_700 = None
        view_1890 = torch.ops.aten.view.default(mm_311, [2, 4096, 2048]);  mm_311 = None
        convert_element_type_1888 = torch.ops.prims.convert_element_type.default(mm_310, torch.float32);  mm_310 = None
        split_473 = torch.ops.aten.split.Tensor(convert_element_type_1888, 5);  convert_element_type_1888 = None
        getitem_8753 = split_473[0]
        getitem_8754 = split_473[1]
        getitem_8755 = split_473[2]
        getitem_8756 = split_473[3]
        getitem_8757 = split_473[4]
        getitem_8758 = split_473[5]
        getitem_8759 = split_473[6]
        getitem_8760 = split_473[7]
        getitem_8761 = split_473[8]
        getitem_8762 = split_473[9]
        getitem_8763 = split_473[10]
        getitem_8764 = split_473[11]
        getitem_8765 = split_473[12]
        getitem_8766 = split_473[13]
        getitem_8767 = split_473[14]
        getitem_8768 = split_473[15]
        getitem_8769 = split_473[16]
        getitem_8770 = split_473[17]
        getitem_8771 = split_473[18]
        getitem_8772 = split_473[19]
        getitem_8773 = split_473[20]
        getitem_8774 = split_473[21]
        getitem_8775 = split_473[22]
        getitem_8776 = split_473[23]
        getitem_8777 = split_473[24]
        getitem_8778 = split_473[25]
        getitem_8779 = split_473[26]
        getitem_8780 = split_473[27]
        getitem_8781 = split_473[28]
        getitem_8782 = split_473[29]
        getitem_8783 = split_473[30]
        getitem_8784 = split_473[31]
        getitem_8785 = split_473[32]
        getitem_8786 = split_473[33]
        getitem_8787 = split_473[34]
        getitem_8788 = split_473[35]
        getitem_8789 = split_473[36]
        getitem_8790 = split_473[37]
        getitem_8791 = split_473[38]
        getitem_8792 = split_473[39]
        getitem_8793 = split_473[40]
        getitem_8794 = split_473[41]
        getitem_8795 = split_473[42]
        getitem_8796 = split_473[43]
        getitem_8797 = split_473[44]
        getitem_8798 = split_473[45]
        getitem_8799 = split_473[46]
        getitem_8800 = split_473[47]
        getitem_8801 = split_473[48]
        getitem_8802 = split_473[49]
        getitem_8803 = split_473[50]
        getitem_8804 = split_473[51]
        getitem_8805 = split_473[52]
        getitem_8806 = split_473[53]
        getitem_8807 = split_473[54]
        getitem_8808 = split_473[55]
        getitem_8809 = split_473[56]
        getitem_8810 = split_473[57]
        getitem_8811 = split_473[58]
        getitem_8812 = split_473[59]
        getitem_8813 = split_473[60]
        getitem_8814 = split_473[61]
        getitem_8815 = split_473[62]
        getitem_8816 = split_473[63]
        getitem_8817 = split_473[64]
        getitem_8818 = split_473[65]
        getitem_8819 = split_473[66]
        getitem_8820 = split_473[67]
        getitem_8821 = split_473[68]
        getitem_8822 = split_473[69]
        getitem_8823 = split_473[70]
        getitem_8824 = split_473[71]
        getitem_8825 = split_473[72]
        getitem_8826 = split_473[73]
        getitem_8827 = split_473[74]
        getitem_8828 = split_473[75]
        getitem_8829 = split_473[76]
        getitem_8830 = split_473[77]
        getitem_8831 = split_473[78]
        getitem_8832 = split_473[79]
        getitem_8833 = split_473[80]
        getitem_8834 = split_473[81]
        getitem_8835 = split_473[82]
        getitem_8836 = split_473[83]
        getitem_8837 = split_473[84]
        getitem_8838 = split_473[85]
        getitem_8839 = split_473[86]
        getitem_8840 = split_473[87]
        getitem_8841 = split_473[88]
        getitem_8842 = split_473[89]
        getitem_8843 = split_473[90]
        getitem_8844 = split_473[91]
        getitem_8845 = split_473[92]
        getitem_8846 = split_473[93]
        getitem_8847 = split_473[94]
        getitem_8848 = split_473[95]
        getitem_8849 = split_473[96]
        getitem_8850 = split_473[97]
        getitem_8851 = split_473[98]
        getitem_8852 = split_473[99]
        getitem_8853 = split_473[100]
        getitem_8854 = split_473[101]
        getitem_8855 = split_473[102]
        getitem_8856 = split_473[103]
        getitem_8857 = split_473[104]
        getitem_8858 = split_473[105]
        getitem_8859 = split_473[106]
        getitem_8860 = split_473[107]
        getitem_8861 = split_473[108]
        getitem_8862 = split_473[109]
        getitem_8863 = split_473[110]
        getitem_8864 = split_473[111]
        getitem_8865 = split_473[112]
        getitem_8866 = split_473[113]
        getitem_8867 = split_473[114]
        getitem_8868 = split_473[115];  split_473 = None
        constant_pad_nd_449 = torch.ops.aten.constant_pad_nd.default(getitem_8868, [0, 0, 0, 4], 0.0);  getitem_8868 = None
        cat_282 = torch.ops.aten.cat.default([getitem_8753, getitem_8754, getitem_8755, getitem_8756, getitem_8757, getitem_8758, getitem_8759, getitem_8760, getitem_8761, getitem_8762, getitem_8763, getitem_8764, getitem_8765, getitem_8766, getitem_8767, getitem_8768, getitem_8769, getitem_8770, getitem_8771, getitem_8772, getitem_8773, getitem_8774, getitem_8775, getitem_8776, getitem_8777, getitem_8778, getitem_8779, getitem_8780, getitem_8781, getitem_8782, getitem_8783, getitem_8784, getitem_8785, getitem_8786, getitem_8787, getitem_8788, getitem_8789, getitem_8790, getitem_8791, getitem_8792, getitem_8793, getitem_8794, getitem_8795, getitem_8796, getitem_8797, getitem_8798, getitem_8799, getitem_8800, getitem_8801, getitem_8802, getitem_8803, getitem_8804, getitem_8805, getitem_8806, getitem_8807, getitem_8808, getitem_8809, getitem_8810, getitem_8811, getitem_8812, getitem_8813, getitem_8814, getitem_8815, getitem_8816, getitem_8817, getitem_8818, getitem_8819, getitem_8820, getitem_8821, getitem_8822, getitem_8823, getitem_8824, getitem_8825, getitem_8826, getitem_8827, getitem_8828, getitem_8829, getitem_8830, getitem_8831, getitem_8832, getitem_8833, getitem_8834, getitem_8835, getitem_8836, getitem_8837, getitem_8838, getitem_8839, getitem_8840, getitem_8841, getitem_8842, getitem_8843, getitem_8844, getitem_8845, getitem_8846, getitem_8847, getitem_8848, getitem_8849, getitem_8850, getitem_8851, getitem_8852, getitem_8853, getitem_8854, getitem_8855, getitem_8856, getitem_8857, getitem_8858, getitem_8859, getitem_8860, getitem_8861, getitem_8862, getitem_8863, getitem_8864, getitem_8865, getitem_8866, getitem_8867, constant_pad_nd_449, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_8753 = getitem_8754 = getitem_8755 = getitem_8756 = getitem_8757 = getitem_8758 = getitem_8759 = getitem_8760 = getitem_8761 = getitem_8762 = getitem_8763 = getitem_8764 = getitem_8765 = getitem_8766 = getitem_8767 = getitem_8768 = getitem_8769 = getitem_8770 = getitem_8771 = getitem_8772 = getitem_8773 = getitem_8774 = getitem_8775 = getitem_8776 = getitem_8777 = getitem_8778 = getitem_8779 = getitem_8780 = getitem_8781 = getitem_8782 = getitem_8783 = getitem_8784 = getitem_8785 = getitem_8786 = getitem_8787 = getitem_8788 = getitem_8789 = getitem_8790 = getitem_8791 = getitem_8792 = getitem_8793 = getitem_8794 = getitem_8795 = getitem_8796 = getitem_8797 = getitem_8798 = getitem_8799 = getitem_8800 = getitem_8801 = getitem_8802 = getitem_8803 = getitem_8804 = getitem_8805 = getitem_8806 = getitem_8807 = getitem_8808 = getitem_8809 = getitem_8810 = getitem_8811 = getitem_8812 = getitem_8813 = getitem_8814 = getitem_8815 = getitem_8816 = getitem_8817 = getitem_8818 = getitem_8819 = getitem_8820 = getitem_8821 = getitem_8822 = getitem_8823 = getitem_8824 = getitem_8825 = getitem_8826 = getitem_8827 = getitem_8828 = getitem_8829 = getitem_8830 = getitem_8831 = getitem_8832 = getitem_8833 = getitem_8834 = getitem_8835 = getitem_8836 = getitem_8837 = getitem_8838 = getitem_8839 = getitem_8840 = getitem_8841 = getitem_8842 = getitem_8843 = getitem_8844 = getitem_8845 = getitem_8846 = getitem_8847 = getitem_8848 = getitem_8849 = getitem_8850 = getitem_8851 = getitem_8852 = getitem_8853 = getitem_8854 = getitem_8855 = getitem_8856 = getitem_8857 = getitem_8858 = getitem_8859 = getitem_8860 = getitem_8861 = getitem_8862 = getitem_8863 = getitem_8864 = getitem_8865 = getitem_8866 = getitem_8867 = constant_pad_nd_449 = None
        reduce_scatter_tensor_83 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_282, 'avg', 128, '0');  cat_282 = None
        wait_tensor_654 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_83);  reduce_scatter_tensor_83 = None
        slice_196 = torch.ops.aten.slice.Tensor(permute_693, 3, 0, 128)
        slice_197 = torch.ops.aten.slice.Tensor(permute_693, 3, 128, 192);  permute_693 = None
        convert_element_type_1889 = torch.ops.prims.convert_element_type.default(slice_197, torch.float32);  slice_197 = None
        view_1891 = torch.ops.aten.view.default(convert_element_type_1889, [2, 4096, 16, 32, 2]);  convert_element_type_1889 = None
        view_as_complex_65 = torch.ops.aten.view_as_complex.default(view_1891);  view_1891 = None
        mul_1488 = torch.ops.aten.mul.Tensor(view_as_complex_65, clone_9);  view_as_complex_65 = None
        view_as_real_65 = torch.ops.aten.view_as_real.default(mul_1488);  mul_1488 = None
        view_1892 = torch.ops.aten.view.default(view_as_real_65, [2, 4096, 16, 64]);  view_as_real_65 = None
        convert_element_type_1890 = torch.ops.prims.convert_element_type.default(view_1892, torch.bfloat16);  view_1892 = None
        cat_283 = torch.ops.aten.cat.default([slice_196, convert_element_type_1890], 3);  slice_196 = convert_element_type_1890 = None
        view_1893 = torch.ops.aten.view.default(cat_283, [2, 4096, 3072]);  cat_283 = None
        view_1894 = torch.ops.aten.view.default(view_1893, [8192, 3072]);  view_1893 = None
        permute_702 = torch.ops.aten.permute.default(view_1894, [1, 0])
        mm_312 = torch.ops.aten.mm.default(permute_702, view_1376);  permute_702 = view_1376 = None
        convert_element_type_1120 = torch.ops.prims.convert_element_type.default(primals_344, torch.bfloat16);  primals_344 = None
        all_gather_into_tensor_352 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1120, 128, '0');  convert_element_type_1120 = None
        wait_tensor_432 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_352);  all_gather_into_tensor_352 = None
        permute_311 = torch.ops.aten.permute.default(wait_tensor_432, [1, 0]);  wait_tensor_432 = None
        permute_704 = torch.ops.aten.permute.default(permute_311, [1, 0]);  permute_311 = None
        mm_313 = torch.ops.aten.mm.default(view_1894, permute_704);  view_1894 = permute_704 = None
        view_1895 = torch.ops.aten.view.default(mm_313, [2, 4096, 2048]);  mm_313 = None
        add_1863 = torch.ops.aten.add.Tensor(view_1890, view_1895);  view_1890 = view_1895 = None
        convert_element_type_1895 = torch.ops.prims.convert_element_type.default(mm_312, torch.float32);  mm_312 = None
        reduce_scatter_tensor_84 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1895, 'avg', 128, '0');  convert_element_type_1895 = None
        wait_tensor_655 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_84);  reduce_scatter_tensor_84 = None
        convert_element_type_1896 = torch.ops.prims.convert_element_type.default(add_1863, torch.float32);  add_1863 = None
        convert_element_type_1117 = torch.ops.prims.convert_element_type.default(primals_343, torch.bfloat16);  primals_343 = None
        all_gather_into_tensor_351 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1117, 128, '0');  convert_element_type_1117 = None
        wait_tensor_431 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_351);  all_gather_into_tensor_351 = None
        convert_element_type_1898 = torch.ops.prims.convert_element_type.default(wait_tensor_431, torch.float32);  wait_tensor_431 = None
        mul_1489 = torch.ops.aten.mul.Tensor(convert_element_type_1896, convert_element_type_1898);  convert_element_type_1898 = None
        convert_element_type_1118 = torch.ops.prims.convert_element_type.default(add_1365, torch.float32);  add_1365 = None
        mul_989 = torch.ops.aten.mul.Tensor(convert_element_type_1118, rsqrt_63);  convert_element_type_1118 = None
        mul_1491 = torch.ops.aten.mul.Tensor(mul_989, mul_1489)
        sum_153 = torch.ops.aten.sum.dim_IntList(mul_1491, [2], True);  mul_1491 = None
        div_167 = torch.ops.aten.div.Tensor(mul_989, 2048)
        mul_1492 = torch.ops.aten.mul.Tensor(div_167, sum_153);  div_167 = sum_153 = None
        sub_660 = torch.ops.aten.sub.Tensor(mul_1489, mul_1492);  mul_1489 = mul_1492 = None
        mul_1493 = torch.ops.aten.mul.Tensor(sub_660, rsqrt_63);  sub_660 = rsqrt_63 = None
        mul_1494 = torch.ops.aten.mul.Tensor(convert_element_type_1896, mul_989);  convert_element_type_1896 = mul_989 = None
        sum_154 = torch.ops.aten.sum.dim_IntList(mul_1494, [0, 1]);  mul_1494 = None
        convert_element_type_1899 = torch.ops.prims.convert_element_type.default(mul_1493, torch.bfloat16);  mul_1493 = None
        add_1864 = torch.ops.aten.add.Tensor(add_1862, convert_element_type_1899);  add_1862 = convert_element_type_1899 = None
        convert_element_type_default_64 = torch.ops.prims.convert_element_type.default(sum_154, torch.float32);  sum_154 = None
        reduce_scatter_tensor_85 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_64, 'avg', 128, '0');  convert_element_type_default_64 = None
        wait_tensor_656 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_85);  reduce_scatter_tensor_85 = None
        view_1896 = torch.ops.aten.view.default(add_1864, [8192, 2048])
        unsqueeze_59 = torch.ops.aten.unsqueeze.default(view_1896, 1)
        convert_element_type_1902 = torch.ops.prims.convert_element_type.default(unsqueeze_59, torch.float32);  unsqueeze_59 = None
        bmm_38 = torch.ops.aten.bmm.default(permute_706, convert_element_type_1902);  permute_706 = None
        bmm_39 = torch.ops.aten.bmm.default(convert_element_type_1902, permute_707);  convert_element_type_1902 = permute_707 = None
        convert_element_type_1903 = torch.ops.prims.convert_element_type.default(bmm_38, torch.bfloat16);  bmm_38 = None
        view_1897 = torch.ops.aten.view.default(bmm_39, [8192, 6]);  bmm_39 = None
        view_1898 = torch.ops.aten.view.default(convert_element_type_1903, [49152, 2048]);  convert_element_type_1903 = None
        index_64 = torch.ops.aten.index.Tensor(view_1898, [getitem_2111]);  view_1898 = getitem_2111 = None
        permute_708 = torch.ops.aten.permute.default(view_1896, [1, 0])
        mm_314 = torch.ops.aten.mm.default(permute_708, mul_986);  permute_708 = mul_986 = None
        convert_element_type_1112 = torch.ops.prims.convert_element_type.default(primals_342, torch.bfloat16);  primals_342 = None
        all_gather_into_tensor_350 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1112, 128, '0');  convert_element_type_1112 = None
        wait_tensor_430 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_350);  all_gather_into_tensor_350 = None
        permute_310 = torch.ops.aten.permute.default(wait_tensor_430, [1, 0]);  wait_tensor_430 = None
        permute_710 = torch.ops.aten.permute.default(permute_310, [1, 0]);  permute_310 = None
        mm_315 = torch.ops.aten.mm.default(view_1896, permute_710);  view_1896 = permute_710 = None
        convert_element_type_1908 = torch.ops.prims.convert_element_type.default(mm_314, torch.float32);  mm_314 = None
        reduce_scatter_tensor_86 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1908, 'avg', 128, '0');  convert_element_type_1908 = None
        wait_tensor_657 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_86);  reduce_scatter_tensor_86 = None
        convert_element_type_1107 = torch.ops.prims.convert_element_type.default(mm_164, torch.float32);  mm_164 = None
        neg_40 = torch.ops.aten.neg.default(convert_element_type_1107)
        exp_60 = torch.ops.aten.exp.default(neg_40);  neg_40 = None
        add_1360 = torch.ops.aten.add.Tensor(exp_60, 1);  exp_60 = None
        div_100 = torch.ops.aten.div.Tensor(convert_element_type_1107, add_1360)
        convert_element_type_1108 = torch.ops.prims.convert_element_type.default(div_100, torch.bfloat16);  div_100 = None
        mul_1495 = torch.ops.aten.mul.Tensor(mm_315, convert_element_type_1108);  convert_element_type_1108 = None
        mul_1496 = torch.ops.aten.mul.Tensor(mm_315, mm_165);  mm_315 = mm_165 = None
        permute_712 = torch.ops.aten.permute.default(mul_1495, [1, 0])
        mm_316 = torch.ops.aten.mm.default(permute_712, view_1331);  permute_712 = None
        convert_element_type_1109 = torch.ops.prims.convert_element_type.default(primals_341, torch.bfloat16);  primals_341 = None
        all_gather_into_tensor_349 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1109, 128, '0');  convert_element_type_1109 = None
        wait_tensor_429 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_349);  all_gather_into_tensor_349 = None
        permute_309 = torch.ops.aten.permute.default(wait_tensor_429, [1, 0]);  wait_tensor_429 = None
        permute_714 = torch.ops.aten.permute.default(permute_309, [1, 0]);  permute_309 = None
        mm_317 = torch.ops.aten.mm.default(mul_1495, permute_714);  mul_1495 = permute_714 = None
        convert_element_type_1913 = torch.ops.prims.convert_element_type.default(mm_316, torch.float32);  mm_316 = None
        reduce_scatter_tensor_87 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1913, 'avg', 128, '0');  convert_element_type_1913 = None
        wait_tensor_658 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_87);  reduce_scatter_tensor_87 = None
        convert_element_type_1914 = torch.ops.prims.convert_element_type.default(mul_1496, torch.float32);  mul_1496 = None
        reciprocal_12 = torch.ops.aten.reciprocal.default(add_1360);  add_1360 = None
        mul_1497 = torch.ops.aten.mul.Tensor(reciprocal_12, 1);  reciprocal_12 = None
        mul_1498 = torch.ops.aten.mul.Tensor(convert_element_type_1914, mul_1497);  convert_element_type_1914 = None
        sub_661 = torch.ops.aten.sub.Tensor(1, mul_1497);  mul_1497 = None
        mul_1499 = torch.ops.aten.mul.Tensor(convert_element_type_1107, sub_661);  convert_element_type_1107 = sub_661 = None
        add_1866 = torch.ops.aten.add.Tensor(mul_1499, 1);  mul_1499 = None
        mul_1500 = torch.ops.aten.mul.Tensor(mul_1498, add_1866);  mul_1498 = add_1866 = None
        convert_element_type_1916 = torch.ops.prims.convert_element_type.default(mul_1500, torch.bfloat16);  mul_1500 = None
        permute_716 = torch.ops.aten.permute.default(convert_element_type_1916, [1, 0])
        mm_318 = torch.ops.aten.mm.default(permute_716, view_1331);  permute_716 = None
        convert_element_type_1104 = torch.ops.prims.convert_element_type.default(primals_340, torch.bfloat16);  primals_340 = None
        all_gather_into_tensor_348 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1104, 128, '0');  convert_element_type_1104 = None
        wait_tensor_428 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_348);  all_gather_into_tensor_348 = None
        permute_308 = torch.ops.aten.permute.default(wait_tensor_428, [1, 0]);  wait_tensor_428 = None
        permute_718 = torch.ops.aten.permute.default(permute_308, [1, 0]);  permute_308 = None
        mm_319 = torch.ops.aten.mm.default(convert_element_type_1916, permute_718);  convert_element_type_1916 = permute_718 = None
        add_1867 = torch.ops.aten.add.Tensor(mm_317, mm_319);  mm_317 = mm_319 = None
        convert_element_type_1921 = torch.ops.prims.convert_element_type.default(mm_318, torch.float32);  mm_318 = None
        reduce_scatter_tensor_88 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1921, 'avg', 128, '0');  convert_element_type_1921 = None
        wait_tensor_659 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_88);  reduce_scatter_tensor_88 = None
        all_to_all_single_90 = torch.ops._c10d_functional.all_to_all_single.default(index_64, [_local_scalar_dense_312, _local_scalar_dense_313, _local_scalar_dense_314, _local_scalar_dense_315, _local_scalar_dense_316, _local_scalar_dense_317, _local_scalar_dense_318, _local_scalar_dense_319], [_local_scalar_dense_304, _local_scalar_dense_305, _local_scalar_dense_306, _local_scalar_dense_307, _local_scalar_dense_308, _local_scalar_dense_309, _local_scalar_dense_310, _local_scalar_dense_311], '1033');  index_64 = None
        wait_tensor_660 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_90);  all_to_all_single_90 = None
        full_384 = torch.ops.aten.full.default([sym_size_int_77, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_77 = None
        slice_scatter_6 = torch.ops.aten.slice_scatter.default(full_384, wait_tensor_660, 0, 0, -1);  wait_tensor_660 = None
        index_65 = torch.ops.aten.index.Tensor(slice_scatter_6, [getitem_2112]);  slice_scatter_6 = None
        permute_720 = torch.ops.aten.permute.default(index_65, [1, 0])
        _grouped_mm_114 = torch.ops.aten._grouped_mm.default(permute_720, mul_966, cumsum_59);  permute_720 = mul_966 = None
        _grouped_mm_115 = torch.ops.aten._grouped_mm.default(index_65, permute_722, cumsum_59);  index_65 = permute_722 = None
        convert_element_type_1102 = torch.ops.prims.convert_element_type.default(_grouped_mm_57, torch.float32);  _grouped_mm_57 = None
        neg_39 = torch.ops.aten.neg.default(convert_element_type_1102)
        exp_59 = torch.ops.aten.exp.default(neg_39);  neg_39 = None
        add_1324 = torch.ops.aten.add.Tensor(exp_59, 1);  exp_59 = None
        div_99 = torch.ops.aten.div.Tensor(convert_element_type_1102, add_1324)
        convert_element_type_1103 = torch.ops.prims.convert_element_type.default(div_99, torch.bfloat16);  div_99 = None
        mul_1501 = torch.ops.aten.mul.Tensor(_grouped_mm_115, convert_element_type_1103);  convert_element_type_1103 = None
        mul_1502 = torch.ops.aten.mul.Tensor(_grouped_mm_115, _grouped_mm_58);  _grouped_mm_115 = _grouped_mm_58 = None
        permute_724 = torch.ops.aten.permute.default(mul_1501, [1, 0])
        _grouped_mm_116 = torch.ops.aten._grouped_mm.default(permute_724, index_39, cumsum_59);  permute_724 = None
        _grouped_mm_117 = torch.ops.aten._grouped_mm.default(mul_1501, permute_726, cumsum_59);  mul_1501 = permute_726 = None
        convert_element_type_1922 = torch.ops.prims.convert_element_type.default(mul_1502, torch.float32);  mul_1502 = None
        reciprocal_13 = torch.ops.aten.reciprocal.default(add_1324);  add_1324 = None
        mul_1503 = torch.ops.aten.mul.Tensor(reciprocal_13, 1);  reciprocal_13 = None
        mul_1504 = torch.ops.aten.mul.Tensor(convert_element_type_1922, mul_1503);  convert_element_type_1922 = None
        sub_662 = torch.ops.aten.sub.Tensor(1, mul_1503);  mul_1503 = None
        mul_1505 = torch.ops.aten.mul.Tensor(convert_element_type_1102, sub_662);  convert_element_type_1102 = sub_662 = None
        add_1869 = torch.ops.aten.add.Tensor(mul_1505, 1);  mul_1505 = None
        mul_1506 = torch.ops.aten.mul.Tensor(mul_1504, add_1869);  mul_1504 = add_1869 = None
        convert_element_type_1924 = torch.ops.prims.convert_element_type.default(mul_1506, torch.bfloat16);  mul_1506 = None
        permute_728 = torch.ops.aten.permute.default(convert_element_type_1924, [1, 0])
        _grouped_mm_118 = torch.ops.aten._grouped_mm.default(permute_728, index_39, cumsum_59);  permute_728 = index_39 = None
        _grouped_mm_119 = torch.ops.aten._grouped_mm.default(convert_element_type_1924, permute_730, cumsum_59);  convert_element_type_1924 = permute_730 = cumsum_59 = None
        add_1870 = torch.ops.aten.add.Tensor(_grouped_mm_117, _grouped_mm_119);  _grouped_mm_117 = _grouped_mm_119 = None
        convert_element_type_1925 = torch.ops.prims.convert_element_type.default(_grouped_mm_116, torch.float32);  _grouped_mm_116 = None
        div_168 = torch.ops.aten.div.Tensor(convert_element_type_1925, 128);  convert_element_type_1925 = None
        split_475 = torch.ops.aten.split.Tensor(div_168, 88, 1);  div_168 = None
        getitem_8885 = split_475[0]
        getitem_8902 = split_475[1]
        getitem_8919 = split_475[2]
        getitem_8936 = split_475[3]
        getitem_8953 = split_475[4]
        getitem_8970 = split_475[5]
        getitem_8987 = split_475[6]
        getitem_9004 = split_475[7]
        getitem_9021 = split_475[8]
        getitem_9038 = split_475[9]
        getitem_9055 = split_475[10]
        getitem_9072 = split_475[11]
        getitem_9089 = split_475[12]
        getitem_9106 = split_475[13]
        getitem_9123 = split_475[14]
        getitem_9140 = split_475[15];  split_475 = None
        cat_284 = torch.ops.aten.cat.default([getitem_8885, getitem_8902, getitem_8919, getitem_8936, getitem_8953, getitem_8970, getitem_8987, getitem_9004, getitem_9021, getitem_9038, getitem_9055, getitem_9072, getitem_9089, getitem_9106, getitem_9123, getitem_9140]);  getitem_8885 = getitem_8902 = getitem_8919 = getitem_8936 = getitem_8953 = getitem_8970 = getitem_8987 = getitem_9004 = getitem_9021 = getitem_9038 = getitem_9055 = getitem_9072 = getitem_9089 = getitem_9106 = getitem_9123 = getitem_9140 = None
        reduce_scatter_tensor_89 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_284, 'sum', 16, '1025');  cat_284 = None
        wait_tensor_661 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_89);  reduce_scatter_tensor_89 = None
        convert_element_type_1926 = torch.ops.prims.convert_element_type.default(_grouped_mm_114, torch.float32);  _grouped_mm_114 = None
        div_169 = torch.ops.aten.div.Tensor(convert_element_type_1926, 128);  convert_element_type_1926 = None
        split_492 = torch.ops.aten.split.Tensor(div_169, 128, 1);  div_169 = None
        getitem_9157 = split_492[0]
        getitem_9174 = split_492[1]
        getitem_9191 = split_492[2]
        getitem_9208 = split_492[3]
        getitem_9225 = split_492[4]
        getitem_9242 = split_492[5]
        getitem_9259 = split_492[6]
        getitem_9276 = split_492[7]
        getitem_9293 = split_492[8]
        getitem_9310 = split_492[9]
        getitem_9327 = split_492[10]
        getitem_9344 = split_492[11]
        getitem_9361 = split_492[12]
        getitem_9378 = split_492[13]
        getitem_9395 = split_492[14]
        getitem_9412 = split_492[15];  split_492 = None
        cat_285 = torch.ops.aten.cat.default([getitem_9157, getitem_9174, getitem_9191, getitem_9208, getitem_9225, getitem_9242, getitem_9259, getitem_9276, getitem_9293, getitem_9310, getitem_9327, getitem_9344, getitem_9361, getitem_9378, getitem_9395, getitem_9412]);  getitem_9157 = getitem_9174 = getitem_9191 = getitem_9208 = getitem_9225 = getitem_9242 = getitem_9259 = getitem_9276 = getitem_9293 = getitem_9310 = getitem_9327 = getitem_9344 = getitem_9361 = getitem_9378 = getitem_9395 = getitem_9412 = None
        reduce_scatter_tensor_90 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_285, 'sum', 16, '1025');  cat_285 = None
        wait_tensor_662 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_90);  reduce_scatter_tensor_90 = None
        convert_element_type_1927 = torch.ops.prims.convert_element_type.default(_grouped_mm_118, torch.float32);  _grouped_mm_118 = None
        div_170 = torch.ops.aten.div.Tensor(convert_element_type_1927, 128);  convert_element_type_1927 = None
        split_509 = torch.ops.aten.split.Tensor(div_170, 88, 1);  div_170 = None
        getitem_9429 = split_509[0]
        getitem_9446 = split_509[1]
        getitem_9463 = split_509[2]
        getitem_9480 = split_509[3]
        getitem_9497 = split_509[4]
        getitem_9514 = split_509[5]
        getitem_9531 = split_509[6]
        getitem_9548 = split_509[7]
        getitem_9565 = split_509[8]
        getitem_9582 = split_509[9]
        getitem_9599 = split_509[10]
        getitem_9616 = split_509[11]
        getitem_9633 = split_509[12]
        getitem_9650 = split_509[13]
        getitem_9667 = split_509[14]
        getitem_9684 = split_509[15];  split_509 = None
        cat_286 = torch.ops.aten.cat.default([getitem_9429, getitem_9446, getitem_9463, getitem_9480, getitem_9497, getitem_9514, getitem_9531, getitem_9548, getitem_9565, getitem_9582, getitem_9599, getitem_9616, getitem_9633, getitem_9650, getitem_9667, getitem_9684]);  getitem_9429 = getitem_9446 = getitem_9463 = getitem_9480 = getitem_9497 = getitem_9514 = getitem_9531 = getitem_9548 = getitem_9565 = getitem_9582 = getitem_9599 = getitem_9616 = getitem_9633 = getitem_9650 = getitem_9667 = getitem_9684 = None
        reduce_scatter_tensor_91 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_286, 'sum', 16, '1025');  cat_286 = None
        wait_tensor_663 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_91);  reduce_scatter_tensor_91 = None
        index_put_64 = torch.ops.aten.index_put.default(full_384, [getitem_2112], add_1870, True);  full_384 = getitem_2112 = add_1870 = None
        slice_198 = torch.ops.aten.slice.Tensor(index_put_64, 0, 0, add_1871);  index_put_64 = add_1871 = None
        all_to_all_single_91 = torch.ops._c10d_functional.all_to_all_single.default(slice_198, [_local_scalar_dense_304, _local_scalar_dense_305, _local_scalar_dense_306, _local_scalar_dense_307, _local_scalar_dense_308, _local_scalar_dense_309, _local_scalar_dense_310, _local_scalar_dense_311], [_local_scalar_dense_312, _local_scalar_dense_313, _local_scalar_dense_314, _local_scalar_dense_315, _local_scalar_dense_316, _local_scalar_dense_317, _local_scalar_dense_318, _local_scalar_dense_319], '1033');  slice_198 = _local_scalar_dense_304 = _local_scalar_dense_305 = _local_scalar_dense_306 = _local_scalar_dense_307 = _local_scalar_dense_308 = _local_scalar_dense_309 = _local_scalar_dense_310 = _local_scalar_dense_311 = _local_scalar_dense_312 = _local_scalar_dense_313 = _local_scalar_dense_314 = _local_scalar_dense_315 = _local_scalar_dense_316 = _local_scalar_dense_317 = _local_scalar_dense_318 = _local_scalar_dense_319 = None
        wait_tensor_664 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_91);  all_to_all_single_91 = None
        index_put_65 = torch.ops.aten.index_put.default(full_default_52, [div_97], wait_tensor_664, True);  div_97 = wait_tensor_664 = None
        add_1875 = torch.ops.aten.add.Tensor(add_1867, index_put_65);  add_1867 = index_put_65 = None
        mul_1507 = torch.ops.aten.mul.Tensor(view_1897, 1.0);  view_1897 = None
        scatter_add_6 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_2109, mul_1507);  getitem_2109 = mul_1507 = None
        convert_element_type_1091 = torch.ops.prims.convert_element_type.default(mm_163, torch.float32);  mm_163 = None
        sub_456 = torch.ops.aten.sub.Tensor(convert_element_type_1091, amax_19);  convert_element_type_1091 = amax_19 = None
        exp_58 = torch.ops.aten.exp.default(sub_456);  sub_456 = None
        div_96 = torch.ops.aten.div.Tensor(exp_58, sum_77);  exp_58 = sum_77 = None
        mul_1508 = torch.ops.aten.mul.Tensor(scatter_add_6, div_96);  scatter_add_6 = None
        sum_155 = torch.ops.aten.sum.dim_IntList(mul_1508, [1], True)
        neg_73 = torch.ops.aten.neg.default(div_96);  div_96 = None
        fma_6 = torch.ops.prims.fma.default(neg_73, sum_155, mul_1508);  neg_73 = sum_155 = mul_1508 = None
        convert_element_type_1928 = torch.ops.prims.convert_element_type.default(fma_6, torch.bfloat16);  fma_6 = None
        permute_732 = torch.ops.aten.permute.default(convert_element_type_1928, [1, 0])
        mm_320 = torch.ops.aten.mm.default(permute_732, view_1331);  permute_732 = view_1331 = None
        convert_element_type_1088 = torch.ops.prims.convert_element_type.default(primals_335, torch.bfloat16);  primals_335 = None
        all_gather_into_tensor_341 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1088, 128, '0');  convert_element_type_1088 = None
        wait_tensor_417 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_341);  all_gather_into_tensor_341 = None
        slice_123 = torch.ops.aten.slice.Tensor(wait_tensor_417, 0, 0, 64);  wait_tensor_417 = None
        permute_304 = torch.ops.aten.permute.default(slice_123, [1, 0]);  slice_123 = None
        permute_734 = torch.ops.aten.permute.default(permute_304, [1, 0]);  permute_304 = None
        mm_321 = torch.ops.aten.mm.default(convert_element_type_1928, permute_734);  convert_element_type_1928 = permute_734 = None
        add_1876 = torch.ops.aten.add.Tensor(add_1875, mm_321);  add_1875 = mm_321 = None
        convert_element_type_1933 = torch.ops.prims.convert_element_type.default(mm_320, torch.float32);  mm_320 = None
        split_525 = torch.ops.aten.split.Tensor(convert_element_type_1933, 1);  convert_element_type_1933 = None
        getitem_9685 = split_525[0]
        getitem_9686 = split_525[1]
        getitem_9687 = split_525[2]
        getitem_9688 = split_525[3]
        getitem_9689 = split_525[4]
        getitem_9690 = split_525[5]
        getitem_9691 = split_525[6]
        getitem_9692 = split_525[7]
        getitem_9693 = split_525[8]
        getitem_9694 = split_525[9]
        getitem_9695 = split_525[10]
        getitem_9696 = split_525[11]
        getitem_9697 = split_525[12]
        getitem_9698 = split_525[13]
        getitem_9699 = split_525[14]
        getitem_9700 = split_525[15]
        getitem_9701 = split_525[16]
        getitem_9702 = split_525[17]
        getitem_9703 = split_525[18]
        getitem_9704 = split_525[19]
        getitem_9705 = split_525[20]
        getitem_9706 = split_525[21]
        getitem_9707 = split_525[22]
        getitem_9708 = split_525[23]
        getitem_9709 = split_525[24]
        getitem_9710 = split_525[25]
        getitem_9711 = split_525[26]
        getitem_9712 = split_525[27]
        getitem_9713 = split_525[28]
        getitem_9714 = split_525[29]
        getitem_9715 = split_525[30]
        getitem_9716 = split_525[31]
        getitem_9717 = split_525[32]
        getitem_9718 = split_525[33]
        getitem_9719 = split_525[34]
        getitem_9720 = split_525[35]
        getitem_9721 = split_525[36]
        getitem_9722 = split_525[37]
        getitem_9723 = split_525[38]
        getitem_9724 = split_525[39]
        getitem_9725 = split_525[40]
        getitem_9726 = split_525[41]
        getitem_9727 = split_525[42]
        getitem_9728 = split_525[43]
        getitem_9729 = split_525[44]
        getitem_9730 = split_525[45]
        getitem_9731 = split_525[46]
        getitem_9732 = split_525[47]
        getitem_9733 = split_525[48]
        getitem_9734 = split_525[49]
        getitem_9735 = split_525[50]
        getitem_9736 = split_525[51]
        getitem_9737 = split_525[52]
        getitem_9738 = split_525[53]
        getitem_9739 = split_525[54]
        getitem_9740 = split_525[55]
        getitem_9741 = split_525[56]
        getitem_9742 = split_525[57]
        getitem_9743 = split_525[58]
        getitem_9744 = split_525[59]
        getitem_9745 = split_525[60]
        getitem_9746 = split_525[61]
        getitem_9747 = split_525[62]
        getitem_9748 = split_525[63];  split_525 = None
        cat_287 = torch.ops.aten.cat.default([getitem_9685, getitem_9686, getitem_9687, getitem_9688, getitem_9689, getitem_9690, getitem_9691, getitem_9692, getitem_9693, getitem_9694, getitem_9695, getitem_9696, getitem_9697, getitem_9698, getitem_9699, getitem_9700, getitem_9701, getitem_9702, getitem_9703, getitem_9704, getitem_9705, getitem_9706, getitem_9707, getitem_9708, getitem_9709, getitem_9710, getitem_9711, getitem_9712, getitem_9713, getitem_9714, getitem_9715, getitem_9716, getitem_9717, getitem_9718, getitem_9719, getitem_9720, getitem_9721, getitem_9722, getitem_9723, getitem_9724, getitem_9725, getitem_9726, getitem_9727, getitem_9728, getitem_9729, getitem_9730, getitem_9731, getitem_9732, getitem_9733, getitem_9734, getitem_9735, getitem_9736, getitem_9737, getitem_9738, getitem_9739, getitem_9740, getitem_9741, getitem_9742, getitem_9743, getitem_9744, getitem_9745, getitem_9746, getitem_9747, getitem_9748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_9685 = getitem_9686 = getitem_9687 = getitem_9688 = getitem_9689 = getitem_9690 = getitem_9691 = getitem_9692 = getitem_9693 = getitem_9694 = getitem_9695 = getitem_9696 = getitem_9697 = getitem_9698 = getitem_9699 = getitem_9700 = getitem_9701 = getitem_9702 = getitem_9703 = getitem_9704 = getitem_9705 = getitem_9706 = getitem_9707 = getitem_9708 = getitem_9709 = getitem_9710 = getitem_9711 = getitem_9712 = getitem_9713 = getitem_9714 = getitem_9715 = getitem_9716 = getitem_9717 = getitem_9718 = getitem_9719 = getitem_9720 = getitem_9721 = getitem_9722 = getitem_9723 = getitem_9724 = getitem_9725 = getitem_9726 = getitem_9727 = getitem_9728 = getitem_9729 = getitem_9730 = getitem_9731 = getitem_9732 = getitem_9733 = getitem_9734 = getitem_9735 = getitem_9736 = getitem_9737 = getitem_9738 = getitem_9739 = getitem_9740 = getitem_9741 = getitem_9742 = getitem_9743 = getitem_9744 = getitem_9745 = getitem_9746 = getitem_9747 = getitem_9748 = None
        reduce_scatter_tensor_92 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_287, 'avg', 128, '0');  cat_287 = None
        wait_tensor_665 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_92);  reduce_scatter_tensor_92 = None
        view_1899 = torch.ops.aten.view.default(add_1876, [2, 4096, 2048]);  add_1876 = None
        convert_element_type_1934 = torch.ops.prims.convert_element_type.default(view_1899, torch.float32);  view_1899 = None
        convert_element_type_1085 = torch.ops.prims.convert_element_type.default(primals_333, torch.bfloat16);  primals_333 = None
        all_gather_into_tensor_340 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1085, 128, '0');  convert_element_type_1085 = None
        wait_tensor_416 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_340);  all_gather_into_tensor_340 = None
        convert_element_type_1936 = torch.ops.prims.convert_element_type.default(wait_tensor_416, torch.float32);  wait_tensor_416 = None
        mul_1509 = torch.ops.aten.mul.Tensor(convert_element_type_1934, convert_element_type_1936);  convert_element_type_1936 = None
        convert_element_type_1086 = torch.ops.prims.convert_element_type.default(add_1300, torch.float32);  add_1300 = None
        mul_946 = torch.ops.aten.mul.Tensor(convert_element_type_1086, rsqrt_62);  convert_element_type_1086 = None
        mul_1511 = torch.ops.aten.mul.Tensor(mul_946, mul_1509)
        sum_156 = torch.ops.aten.sum.dim_IntList(mul_1511, [2], True);  mul_1511 = None
        div_171 = torch.ops.aten.div.Tensor(mul_946, 2048)
        mul_1512 = torch.ops.aten.mul.Tensor(div_171, sum_156);  div_171 = sum_156 = None
        sub_664 = torch.ops.aten.sub.Tensor(mul_1509, mul_1512);  mul_1509 = mul_1512 = None
        mul_1513 = torch.ops.aten.mul.Tensor(sub_664, rsqrt_62);  sub_664 = rsqrt_62 = None
        mul_1514 = torch.ops.aten.mul.Tensor(convert_element_type_1934, mul_946);  convert_element_type_1934 = mul_946 = None
        sum_157 = torch.ops.aten.sum.dim_IntList(mul_1514, [0, 1]);  mul_1514 = None
        convert_element_type_1937 = torch.ops.prims.convert_element_type.default(mul_1513, torch.bfloat16);  mul_1513 = None
        add_1877 = torch.ops.aten.add.Tensor(add_1864, convert_element_type_1937);  add_1864 = convert_element_type_1937 = None
        convert_element_type_default_63 = torch.ops.prims.convert_element_type.default(sum_157, torch.float32);  sum_157 = None
        reduce_scatter_tensor_93 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_63, 'avg', 128, '0');  convert_element_type_default_63 = None
        wait_tensor_666 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_93);  reduce_scatter_tensor_93 = None
        view_1900 = torch.ops.aten.view.default(add_1877, [8192, 2048])
        permute_736 = torch.ops.aten.permute.default(view_1900, [1, 0])
        permute_302 = torch.ops.aten.permute.default(getitem_2105, [0, 2, 1, 3])
        view_1326 = torch.ops.aten.view.default(permute_302, [2, 4096, -1]);  permute_302 = None
        view_1328 = torch.ops.aten.view.default(view_1326, [8192, 2048]);  view_1326 = None
        mm_322 = torch.ops.aten.mm.default(permute_736, view_1328);  permute_736 = view_1328 = None
        convert_element_type_1082 = torch.ops.prims.convert_element_type.default(primals_332, torch.bfloat16);  primals_332 = None
        all_gather_into_tensor_339 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1082, 128, '0');  convert_element_type_1082 = None
        wait_tensor_415 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_339);  all_gather_into_tensor_339 = None
        permute_303 = torch.ops.aten.permute.default(wait_tensor_415, [1, 0]);  wait_tensor_415 = None
        permute_738 = torch.ops.aten.permute.default(permute_303, [1, 0]);  permute_303 = None
        mm_323 = torch.ops.aten.mm.default(view_1900, permute_738);  view_1900 = permute_738 = None
        view_1901 = torch.ops.aten.view.default(mm_323, [2, 4096, 2048]);  mm_323 = None
        convert_element_type_1944 = torch.ops.prims.convert_element_type.default(mm_322, torch.float32);  mm_322 = None
        reduce_scatter_tensor_94 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1944, 'avg', 128, '0');  convert_element_type_1944 = None
        wait_tensor_667 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_94);  reduce_scatter_tensor_94 = None
        view_1902 = torch.ops.aten.view.default(view_1901, [2, 4096, 16, 128]);  view_1901 = None
        permute_740 = torch.ops.aten.permute.default(view_1902, [0, 2, 1, 3]);  view_1902 = None
        fw_graph6 = self.fw_graph6
        joint_graph6 = self.joint_graph6
        mask_graph6 = self.mask_graph6
        flex_attention_backward_6 = torch.ops.higher_order.flex_attention_backward(permute_299, permute_300, permute_301, getitem_2105, getitem_2106, permute_740, None, fw_graph6, joint_graph6, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph6), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_299 = permute_300 = permute_301 = getitem_2105 = getitem_2106 = permute_740 = fw_graph6 = joint_graph6 = mask_graph6 = None
        getitem_9749 = flex_attention_backward_6[0]
        getitem_9750 = flex_attention_backward_6[1]
        getitem_9751 = flex_attention_backward_6[2];  flex_attention_backward_6 = None
        permute_741 = torch.ops.aten.permute.default(getitem_9751, [0, 2, 1, 3]);  getitem_9751 = None
        permute_742 = torch.ops.aten.permute.default(getitem_9750, [0, 2, 1, 3]);  getitem_9750 = None
        permute_743 = torch.ops.aten.permute.default(getitem_9749, [0, 2, 1, 3]);  getitem_9749 = None
        slice_200 = torch.ops.aten.slice.Tensor(permute_742, 3, 0, 128)
        slice_201 = torch.ops.aten.slice.Tensor(permute_742, 3, 128, 192);  permute_742 = None
        sum_158 = torch.ops.aten.sum.dim_IntList(slice_201, [2], True);  slice_201 = None
        cat_288 = torch.ops.aten.cat.default([slice_200, permute_741], 3);  slice_200 = permute_741 = None
        view_1903 = torch.ops.aten.view.default(cat_288, [2, 4096, 4096]);  cat_288 = None
        view_1904 = torch.ops.aten.view.default(view_1903, [8192, 4096]);  view_1903 = None
        permute_744 = torch.ops.aten.permute.default(view_1904, [1, 0])
        mm_324 = torch.ops.aten.mm.default(permute_744, view_1323);  permute_744 = view_1323 = None
        convert_element_type_1079 = torch.ops.prims.convert_element_type.default(primals_331, torch.bfloat16);  primals_331 = None
        all_gather_into_tensor_338 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1079, 128, '0');  convert_element_type_1079 = None
        wait_tensor_414 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_338);  all_gather_into_tensor_338 = None
        permute_298 = torch.ops.aten.permute.default(wait_tensor_414, [1, 0]);  wait_tensor_414 = None
        permute_746 = torch.ops.aten.permute.default(permute_298, [1, 0]);  permute_298 = None
        mm_325 = torch.ops.aten.mm.default(view_1904, permute_746);  view_1904 = permute_746 = None
        view_1905 = torch.ops.aten.view.default(mm_325, [2, 4096, 512]);  mm_325 = None
        convert_element_type_1949 = torch.ops.prims.convert_element_type.default(mm_324, torch.float32);  mm_324 = None
        reduce_scatter_tensor_95 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1949, 'avg', 128, '0');  convert_element_type_1949 = None
        wait_tensor_668 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_95);  reduce_scatter_tensor_95 = None
        convert_element_type_1950 = torch.ops.prims.convert_element_type.default(view_1905, torch.float32);  view_1905 = None
        convert_element_type_1076 = torch.ops.prims.convert_element_type.default(primals_330, torch.bfloat16);  primals_330 = None
        all_gather_into_tensor_337 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1076, 128, '0');  convert_element_type_1076 = None
        wait_tensor_413 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_337);  all_gather_into_tensor_337 = None
        convert_element_type_1952 = torch.ops.prims.convert_element_type.default(wait_tensor_413, torch.float32);  wait_tensor_413 = None
        mul_1515 = torch.ops.aten.mul.Tensor(convert_element_type_1950, convert_element_type_1952);  convert_element_type_1952 = None
        convert_element_type_1077 = torch.ops.prims.convert_element_type.default(getitem_2101, torch.float32);  getitem_2101 = None
        mul_944 = torch.ops.aten.mul.Tensor(convert_element_type_1077, rsqrt_61);  convert_element_type_1077 = None
        mul_1517 = torch.ops.aten.mul.Tensor(mul_944, mul_1515)
        sum_159 = torch.ops.aten.sum.dim_IntList(mul_1517, [2], True);  mul_1517 = None
        div_172 = torch.ops.aten.div.Tensor(mul_944, 512)
        mul_1518 = torch.ops.aten.mul.Tensor(div_172, sum_159);  div_172 = sum_159 = None
        sub_665 = torch.ops.aten.sub.Tensor(mul_1515, mul_1518);  mul_1515 = mul_1518 = None
        mul_1519 = torch.ops.aten.mul.Tensor(sub_665, rsqrt_61);  sub_665 = rsqrt_61 = None
        mul_1520 = torch.ops.aten.mul.Tensor(convert_element_type_1950, mul_944);  convert_element_type_1950 = mul_944 = None
        sum_160 = torch.ops.aten.sum.dim_IntList(mul_1520, [0, 1]);  mul_1520 = None
        convert_element_type_1953 = torch.ops.prims.convert_element_type.default(mul_1519, torch.bfloat16);  mul_1519 = None
        convert_element_type_default_62 = torch.ops.prims.convert_element_type.default(sum_160, torch.float32);  sum_160 = None
        reduce_scatter_tensor_96 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_62, 'avg', 128, '0');  convert_element_type_default_62 = None
        wait_tensor_669 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_96);  reduce_scatter_tensor_96 = None
        convert_element_type_1956 = torch.ops.prims.convert_element_type.default(sum_158, torch.float32);  sum_158 = None
        view_1906 = torch.ops.aten.view.default(convert_element_type_1956, [2, 4096, 1, 32, 2]);  convert_element_type_1956 = None
        view_as_complex_66 = torch.ops.aten.view_as_complex.default(view_1906);  view_1906 = None
        mul_1521 = torch.ops.aten.mul.Tensor(view_as_complex_66, clone_9);  view_as_complex_66 = None
        view_as_real_66 = torch.ops.aten.view_as_real.default(mul_1521);  mul_1521 = None
        view_1907 = torch.ops.aten.view.default(view_as_real_66, [2, 4096, 1, 64]);  view_as_real_66 = None
        convert_element_type_1957 = torch.ops.prims.convert_element_type.default(view_1907, torch.bfloat16);  view_1907 = None
        squeeze_32 = torch.ops.aten.squeeze.dim(convert_element_type_1957, 2);  convert_element_type_1957 = None
        cat_289 = torch.ops.aten.cat.default([convert_element_type_1953, squeeze_32], 2);  convert_element_type_1953 = squeeze_32 = None
        view_1908 = torch.ops.aten.view.default(cat_289, [8192, 576]);  cat_289 = None
        permute_748 = torch.ops.aten.permute.default(view_1908, [1, 0])
        mm_326 = torch.ops.aten.mm.default(permute_748, view_1309);  permute_748 = None
        convert_element_type_1071 = torch.ops.prims.convert_element_type.default(primals_329, torch.bfloat16);  primals_329 = None
        all_gather_into_tensor_336 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1071, 128, '0');  convert_element_type_1071 = None
        wait_tensor_412 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_336);  all_gather_into_tensor_336 = None
        slice_121 = torch.ops.aten.slice.Tensor(wait_tensor_412, 0, 0, 576);  wait_tensor_412 = None
        permute_297 = torch.ops.aten.permute.default(slice_121, [1, 0]);  slice_121 = None
        permute_750 = torch.ops.aten.permute.default(permute_297, [1, 0]);  permute_297 = None
        mm_327 = torch.ops.aten.mm.default(view_1908, permute_750);  view_1908 = permute_750 = None
        view_1909 = torch.ops.aten.view.default(mm_327, [2, 4096, 2048]);  mm_327 = None
        convert_element_type_1962 = torch.ops.prims.convert_element_type.default(mm_326, torch.float32);  mm_326 = None
        split_526 = torch.ops.aten.split.Tensor(convert_element_type_1962, 5);  convert_element_type_1962 = None
        getitem_9753 = split_526[0]
        getitem_9754 = split_526[1]
        getitem_9755 = split_526[2]
        getitem_9756 = split_526[3]
        getitem_9757 = split_526[4]
        getitem_9758 = split_526[5]
        getitem_9759 = split_526[6]
        getitem_9760 = split_526[7]
        getitem_9761 = split_526[8]
        getitem_9762 = split_526[9]
        getitem_9763 = split_526[10]
        getitem_9764 = split_526[11]
        getitem_9765 = split_526[12]
        getitem_9766 = split_526[13]
        getitem_9767 = split_526[14]
        getitem_9768 = split_526[15]
        getitem_9769 = split_526[16]
        getitem_9770 = split_526[17]
        getitem_9771 = split_526[18]
        getitem_9772 = split_526[19]
        getitem_9773 = split_526[20]
        getitem_9774 = split_526[21]
        getitem_9775 = split_526[22]
        getitem_9776 = split_526[23]
        getitem_9777 = split_526[24]
        getitem_9778 = split_526[25]
        getitem_9779 = split_526[26]
        getitem_9780 = split_526[27]
        getitem_9781 = split_526[28]
        getitem_9782 = split_526[29]
        getitem_9783 = split_526[30]
        getitem_9784 = split_526[31]
        getitem_9785 = split_526[32]
        getitem_9786 = split_526[33]
        getitem_9787 = split_526[34]
        getitem_9788 = split_526[35]
        getitem_9789 = split_526[36]
        getitem_9790 = split_526[37]
        getitem_9791 = split_526[38]
        getitem_9792 = split_526[39]
        getitem_9793 = split_526[40]
        getitem_9794 = split_526[41]
        getitem_9795 = split_526[42]
        getitem_9796 = split_526[43]
        getitem_9797 = split_526[44]
        getitem_9798 = split_526[45]
        getitem_9799 = split_526[46]
        getitem_9800 = split_526[47]
        getitem_9801 = split_526[48]
        getitem_9802 = split_526[49]
        getitem_9803 = split_526[50]
        getitem_9804 = split_526[51]
        getitem_9805 = split_526[52]
        getitem_9806 = split_526[53]
        getitem_9807 = split_526[54]
        getitem_9808 = split_526[55]
        getitem_9809 = split_526[56]
        getitem_9810 = split_526[57]
        getitem_9811 = split_526[58]
        getitem_9812 = split_526[59]
        getitem_9813 = split_526[60]
        getitem_9814 = split_526[61]
        getitem_9815 = split_526[62]
        getitem_9816 = split_526[63]
        getitem_9817 = split_526[64]
        getitem_9818 = split_526[65]
        getitem_9819 = split_526[66]
        getitem_9820 = split_526[67]
        getitem_9821 = split_526[68]
        getitem_9822 = split_526[69]
        getitem_9823 = split_526[70]
        getitem_9824 = split_526[71]
        getitem_9825 = split_526[72]
        getitem_9826 = split_526[73]
        getitem_9827 = split_526[74]
        getitem_9828 = split_526[75]
        getitem_9829 = split_526[76]
        getitem_9830 = split_526[77]
        getitem_9831 = split_526[78]
        getitem_9832 = split_526[79]
        getitem_9833 = split_526[80]
        getitem_9834 = split_526[81]
        getitem_9835 = split_526[82]
        getitem_9836 = split_526[83]
        getitem_9837 = split_526[84]
        getitem_9838 = split_526[85]
        getitem_9839 = split_526[86]
        getitem_9840 = split_526[87]
        getitem_9841 = split_526[88]
        getitem_9842 = split_526[89]
        getitem_9843 = split_526[90]
        getitem_9844 = split_526[91]
        getitem_9845 = split_526[92]
        getitem_9846 = split_526[93]
        getitem_9847 = split_526[94]
        getitem_9848 = split_526[95]
        getitem_9849 = split_526[96]
        getitem_9850 = split_526[97]
        getitem_9851 = split_526[98]
        getitem_9852 = split_526[99]
        getitem_9853 = split_526[100]
        getitem_9854 = split_526[101]
        getitem_9855 = split_526[102]
        getitem_9856 = split_526[103]
        getitem_9857 = split_526[104]
        getitem_9858 = split_526[105]
        getitem_9859 = split_526[106]
        getitem_9860 = split_526[107]
        getitem_9861 = split_526[108]
        getitem_9862 = split_526[109]
        getitem_9863 = split_526[110]
        getitem_9864 = split_526[111]
        getitem_9865 = split_526[112]
        getitem_9866 = split_526[113]
        getitem_9867 = split_526[114]
        getitem_9868 = split_526[115];  split_526 = None
        constant_pad_nd_526 = torch.ops.aten.constant_pad_nd.default(getitem_9868, [0, 0, 0, 4], 0.0);  getitem_9868 = None
        cat_290 = torch.ops.aten.cat.default([getitem_9753, getitem_9754, getitem_9755, getitem_9756, getitem_9757, getitem_9758, getitem_9759, getitem_9760, getitem_9761, getitem_9762, getitem_9763, getitem_9764, getitem_9765, getitem_9766, getitem_9767, getitem_9768, getitem_9769, getitem_9770, getitem_9771, getitem_9772, getitem_9773, getitem_9774, getitem_9775, getitem_9776, getitem_9777, getitem_9778, getitem_9779, getitem_9780, getitem_9781, getitem_9782, getitem_9783, getitem_9784, getitem_9785, getitem_9786, getitem_9787, getitem_9788, getitem_9789, getitem_9790, getitem_9791, getitem_9792, getitem_9793, getitem_9794, getitem_9795, getitem_9796, getitem_9797, getitem_9798, getitem_9799, getitem_9800, getitem_9801, getitem_9802, getitem_9803, getitem_9804, getitem_9805, getitem_9806, getitem_9807, getitem_9808, getitem_9809, getitem_9810, getitem_9811, getitem_9812, getitem_9813, getitem_9814, getitem_9815, getitem_9816, getitem_9817, getitem_9818, getitem_9819, getitem_9820, getitem_9821, getitem_9822, getitem_9823, getitem_9824, getitem_9825, getitem_9826, getitem_9827, getitem_9828, getitem_9829, getitem_9830, getitem_9831, getitem_9832, getitem_9833, getitem_9834, getitem_9835, getitem_9836, getitem_9837, getitem_9838, getitem_9839, getitem_9840, getitem_9841, getitem_9842, getitem_9843, getitem_9844, getitem_9845, getitem_9846, getitem_9847, getitem_9848, getitem_9849, getitem_9850, getitem_9851, getitem_9852, getitem_9853, getitem_9854, getitem_9855, getitem_9856, getitem_9857, getitem_9858, getitem_9859, getitem_9860, getitem_9861, getitem_9862, getitem_9863, getitem_9864, getitem_9865, getitem_9866, getitem_9867, constant_pad_nd_526, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_9753 = getitem_9754 = getitem_9755 = getitem_9756 = getitem_9757 = getitem_9758 = getitem_9759 = getitem_9760 = getitem_9761 = getitem_9762 = getitem_9763 = getitem_9764 = getitem_9765 = getitem_9766 = getitem_9767 = getitem_9768 = getitem_9769 = getitem_9770 = getitem_9771 = getitem_9772 = getitem_9773 = getitem_9774 = getitem_9775 = getitem_9776 = getitem_9777 = getitem_9778 = getitem_9779 = getitem_9780 = getitem_9781 = getitem_9782 = getitem_9783 = getitem_9784 = getitem_9785 = getitem_9786 = getitem_9787 = getitem_9788 = getitem_9789 = getitem_9790 = getitem_9791 = getitem_9792 = getitem_9793 = getitem_9794 = getitem_9795 = getitem_9796 = getitem_9797 = getitem_9798 = getitem_9799 = getitem_9800 = getitem_9801 = getitem_9802 = getitem_9803 = getitem_9804 = getitem_9805 = getitem_9806 = getitem_9807 = getitem_9808 = getitem_9809 = getitem_9810 = getitem_9811 = getitem_9812 = getitem_9813 = getitem_9814 = getitem_9815 = getitem_9816 = getitem_9817 = getitem_9818 = getitem_9819 = getitem_9820 = getitem_9821 = getitem_9822 = getitem_9823 = getitem_9824 = getitem_9825 = getitem_9826 = getitem_9827 = getitem_9828 = getitem_9829 = getitem_9830 = getitem_9831 = getitem_9832 = getitem_9833 = getitem_9834 = getitem_9835 = getitem_9836 = getitem_9837 = getitem_9838 = getitem_9839 = getitem_9840 = getitem_9841 = getitem_9842 = getitem_9843 = getitem_9844 = getitem_9845 = getitem_9846 = getitem_9847 = getitem_9848 = getitem_9849 = getitem_9850 = getitem_9851 = getitem_9852 = getitem_9853 = getitem_9854 = getitem_9855 = getitem_9856 = getitem_9857 = getitem_9858 = getitem_9859 = getitem_9860 = getitem_9861 = getitem_9862 = getitem_9863 = getitem_9864 = getitem_9865 = getitem_9866 = getitem_9867 = constant_pad_nd_526 = None
        reduce_scatter_tensor_97 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_290, 'avg', 128, '0');  cat_290 = None
        wait_tensor_670 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_97);  reduce_scatter_tensor_97 = None
        slice_202 = torch.ops.aten.slice.Tensor(permute_743, 3, 0, 128)
        slice_203 = torch.ops.aten.slice.Tensor(permute_743, 3, 128, 192);  permute_743 = None
        convert_element_type_1963 = torch.ops.prims.convert_element_type.default(slice_203, torch.float32);  slice_203 = None
        view_1910 = torch.ops.aten.view.default(convert_element_type_1963, [2, 4096, 16, 32, 2]);  convert_element_type_1963 = None
        view_as_complex_67 = torch.ops.aten.view_as_complex.default(view_1910);  view_1910 = None
        mul_1522 = torch.ops.aten.mul.Tensor(view_as_complex_67, clone_9);  view_as_complex_67 = None
        view_as_real_67 = torch.ops.aten.view_as_real.default(mul_1522);  mul_1522 = None
        view_1911 = torch.ops.aten.view.default(view_as_real_67, [2, 4096, 16, 64]);  view_as_real_67 = None
        convert_element_type_1964 = torch.ops.prims.convert_element_type.default(view_1911, torch.bfloat16);  view_1911 = None
        cat_291 = torch.ops.aten.cat.default([slice_202, convert_element_type_1964], 3);  slice_202 = convert_element_type_1964 = None
        view_1912 = torch.ops.aten.view.default(cat_291, [2, 4096, 3072]);  cat_291 = None
        view_1913 = torch.ops.aten.view.default(view_1912, [8192, 3072]);  view_1912 = None
        permute_752 = torch.ops.aten.permute.default(view_1913, [1, 0])
        mm_328 = torch.ops.aten.mm.default(permute_752, view_1309);  permute_752 = view_1309 = None
        convert_element_type_1066 = torch.ops.prims.convert_element_type.default(primals_328, torch.bfloat16);  primals_328 = None
        all_gather_into_tensor_335 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1066, 128, '0');  convert_element_type_1066 = None
        wait_tensor_411 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_335);  all_gather_into_tensor_335 = None
        permute_296 = torch.ops.aten.permute.default(wait_tensor_411, [1, 0]);  wait_tensor_411 = None
        permute_754 = torch.ops.aten.permute.default(permute_296, [1, 0]);  permute_296 = None
        mm_329 = torch.ops.aten.mm.default(view_1913, permute_754);  view_1913 = permute_754 = None
        view_1914 = torch.ops.aten.view.default(mm_329, [2, 4096, 2048]);  mm_329 = None
        add_1878 = torch.ops.aten.add.Tensor(view_1909, view_1914);  view_1909 = view_1914 = None
        convert_element_type_1969 = torch.ops.prims.convert_element_type.default(mm_328, torch.float32);  mm_328 = None
        reduce_scatter_tensor_98 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1969, 'avg', 128, '0');  convert_element_type_1969 = None
        wait_tensor_671 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_98);  reduce_scatter_tensor_98 = None
        convert_element_type_1970 = torch.ops.prims.convert_element_type.default(add_1878, torch.float32);  add_1878 = None
        convert_element_type_1063 = torch.ops.prims.convert_element_type.default(primals_327, torch.bfloat16);  primals_327 = None
        all_gather_into_tensor_334 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1063, 128, '0');  convert_element_type_1063 = None
        wait_tensor_410 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_334);  all_gather_into_tensor_334 = None
        convert_element_type_1972 = torch.ops.prims.convert_element_type.default(wait_tensor_410, torch.float32);  wait_tensor_410 = None
        mul_1523 = torch.ops.aten.mul.Tensor(convert_element_type_1970, convert_element_type_1972);  convert_element_type_1972 = None
        convert_element_type_1064 = torch.ops.prims.convert_element_type.default(add_1297, torch.float32);  add_1297 = None
        mul_940 = torch.ops.aten.mul.Tensor(convert_element_type_1064, rsqrt_60);  convert_element_type_1064 = None
        mul_1525 = torch.ops.aten.mul.Tensor(mul_940, mul_1523)
        sum_161 = torch.ops.aten.sum.dim_IntList(mul_1525, [2], True);  mul_1525 = None
        div_173 = torch.ops.aten.div.Tensor(mul_940, 2048)
        mul_1526 = torch.ops.aten.mul.Tensor(div_173, sum_161);  div_173 = sum_161 = None
        sub_666 = torch.ops.aten.sub.Tensor(mul_1523, mul_1526);  mul_1523 = mul_1526 = None
        mul_1527 = torch.ops.aten.mul.Tensor(sub_666, rsqrt_60);  sub_666 = rsqrt_60 = None
        mul_1528 = torch.ops.aten.mul.Tensor(convert_element_type_1970, mul_940);  convert_element_type_1970 = mul_940 = None
        sum_162 = torch.ops.aten.sum.dim_IntList(mul_1528, [0, 1]);  mul_1528 = None
        convert_element_type_1973 = torch.ops.prims.convert_element_type.default(mul_1527, torch.bfloat16);  mul_1527 = None
        add_1879 = torch.ops.aten.add.Tensor(add_1877, convert_element_type_1973);  add_1877 = convert_element_type_1973 = None
        convert_element_type_default_61 = torch.ops.prims.convert_element_type.default(sum_162, torch.float32);  sum_162 = None
        reduce_scatter_tensor_99 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_61, 'avg', 128, '0');  convert_element_type_default_61 = None
        wait_tensor_672 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_99);  reduce_scatter_tensor_99 = None
        view_1915 = torch.ops.aten.view.default(add_1879, [8192, 2048])
        unsqueeze_60 = torch.ops.aten.unsqueeze.default(view_1915, 1)
        convert_element_type_1976 = torch.ops.prims.convert_element_type.default(unsqueeze_60, torch.float32);  unsqueeze_60 = None
        bmm_40 = torch.ops.aten.bmm.default(permute_756, convert_element_type_1976);  permute_756 = None
        bmm_41 = torch.ops.aten.bmm.default(convert_element_type_1976, permute_757);  convert_element_type_1976 = permute_757 = None
        convert_element_type_1977 = torch.ops.prims.convert_element_type.default(bmm_40, torch.bfloat16);  bmm_40 = None
        view_1916 = torch.ops.aten.view.default(bmm_41, [8192, 6]);  bmm_41 = None
        view_1917 = torch.ops.aten.view.default(convert_element_type_1977, [49152, 2048]);  convert_element_type_1977 = None
        index_66 = torch.ops.aten.index.Tensor(view_1917, [getitem_2001]);  view_1917 = getitem_2001 = None
        permute_758 = torch.ops.aten.permute.default(view_1915, [1, 0])
        mm_330 = torch.ops.aten.mm.default(permute_758, mul_937);  permute_758 = mul_937 = None
        convert_element_type_1058 = torch.ops.prims.convert_element_type.default(primals_326, torch.bfloat16);  primals_326 = None
        all_gather_into_tensor_333 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1058, 128, '0');  convert_element_type_1058 = None
        wait_tensor_409 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_333);  all_gather_into_tensor_333 = None
        permute_295 = torch.ops.aten.permute.default(wait_tensor_409, [1, 0]);  wait_tensor_409 = None
        permute_760 = torch.ops.aten.permute.default(permute_295, [1, 0]);  permute_295 = None
        mm_331 = torch.ops.aten.mm.default(view_1915, permute_760);  view_1915 = permute_760 = None
        convert_element_type_1982 = torch.ops.prims.convert_element_type.default(mm_330, torch.float32);  mm_330 = None
        reduce_scatter_tensor_100 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1982, 'avg', 128, '0');  convert_element_type_1982 = None
        wait_tensor_673 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_100);  reduce_scatter_tensor_100 = None
        convert_element_type_1053 = torch.ops.prims.convert_element_type.default(mm_156, torch.float32);  mm_156 = None
        neg_38 = torch.ops.aten.neg.default(convert_element_type_1053)
        exp_57 = torch.ops.aten.exp.default(neg_38);  neg_38 = None
        add_1292 = torch.ops.aten.add.Tensor(exp_57, 1);  exp_57 = None
        div_95 = torch.ops.aten.div.Tensor(convert_element_type_1053, add_1292)
        convert_element_type_1054 = torch.ops.prims.convert_element_type.default(div_95, torch.bfloat16);  div_95 = None
        mul_1529 = torch.ops.aten.mul.Tensor(mm_331, convert_element_type_1054);  convert_element_type_1054 = None
        mul_1530 = torch.ops.aten.mul.Tensor(mm_331, mm_157);  mm_331 = mm_157 = None
        permute_762 = torch.ops.aten.permute.default(mul_1529, [1, 0])
        mm_332 = torch.ops.aten.mm.default(permute_762, view_1264);  permute_762 = None
        convert_element_type_1055 = torch.ops.prims.convert_element_type.default(primals_325, torch.bfloat16);  primals_325 = None
        all_gather_into_tensor_332 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1055, 128, '0');  convert_element_type_1055 = None
        wait_tensor_408 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_332);  all_gather_into_tensor_332 = None
        permute_294 = torch.ops.aten.permute.default(wait_tensor_408, [1, 0]);  wait_tensor_408 = None
        permute_764 = torch.ops.aten.permute.default(permute_294, [1, 0]);  permute_294 = None
        mm_333 = torch.ops.aten.mm.default(mul_1529, permute_764);  mul_1529 = permute_764 = None
        convert_element_type_1987 = torch.ops.prims.convert_element_type.default(mm_332, torch.float32);  mm_332 = None
        reduce_scatter_tensor_101 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1987, 'avg', 128, '0');  convert_element_type_1987 = None
        wait_tensor_674 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_101);  reduce_scatter_tensor_101 = None
        convert_element_type_1988 = torch.ops.prims.convert_element_type.default(mul_1530, torch.float32);  mul_1530 = None
        reciprocal_14 = torch.ops.aten.reciprocal.default(add_1292);  add_1292 = None
        mul_1531 = torch.ops.aten.mul.Tensor(reciprocal_14, 1);  reciprocal_14 = None
        mul_1532 = torch.ops.aten.mul.Tensor(convert_element_type_1988, mul_1531);  convert_element_type_1988 = None
        sub_667 = torch.ops.aten.sub.Tensor(1, mul_1531);  mul_1531 = None
        mul_1533 = torch.ops.aten.mul.Tensor(convert_element_type_1053, sub_667);  convert_element_type_1053 = sub_667 = None
        add_1881 = torch.ops.aten.add.Tensor(mul_1533, 1);  mul_1533 = None
        mul_1534 = torch.ops.aten.mul.Tensor(mul_1532, add_1881);  mul_1532 = add_1881 = None
        convert_element_type_1990 = torch.ops.prims.convert_element_type.default(mul_1534, torch.bfloat16);  mul_1534 = None
        permute_766 = torch.ops.aten.permute.default(convert_element_type_1990, [1, 0])
        mm_334 = torch.ops.aten.mm.default(permute_766, view_1264);  permute_766 = None
        convert_element_type_1050 = torch.ops.prims.convert_element_type.default(primals_324, torch.bfloat16);  primals_324 = None
        all_gather_into_tensor_331 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1050, 128, '0');  convert_element_type_1050 = None
        wait_tensor_407 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_331);  all_gather_into_tensor_331 = None
        permute_293 = torch.ops.aten.permute.default(wait_tensor_407, [1, 0]);  wait_tensor_407 = None
        permute_768 = torch.ops.aten.permute.default(permute_293, [1, 0]);  permute_293 = None
        mm_335 = torch.ops.aten.mm.default(convert_element_type_1990, permute_768);  convert_element_type_1990 = permute_768 = None
        add_1882 = torch.ops.aten.add.Tensor(mm_333, mm_335);  mm_333 = mm_335 = None
        convert_element_type_1995 = torch.ops.prims.convert_element_type.default(mm_334, torch.float32);  mm_334 = None
        reduce_scatter_tensor_102 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_1995, 'avg', 128, '0');  convert_element_type_1995 = None
        wait_tensor_675 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_102);  reduce_scatter_tensor_102 = None
        all_to_all_single_92 = torch.ops._c10d_functional.all_to_all_single.default(index_66, [_local_scalar_dense_296, _local_scalar_dense_297, _local_scalar_dense_298, _local_scalar_dense_299, _local_scalar_dense_300, _local_scalar_dense_301, _local_scalar_dense_302, _local_scalar_dense_303], [_local_scalar_dense_288, _local_scalar_dense_289, _local_scalar_dense_290, _local_scalar_dense_291, _local_scalar_dense_292, _local_scalar_dense_293, _local_scalar_dense_294, _local_scalar_dense_295], '1033');  index_66 = None
        wait_tensor_676 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_92);  all_to_all_single_92 = None
        full_390 = torch.ops.aten.full.default([sym_size_int_73, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_73 = None
        slice_scatter_7 = torch.ops.aten.slice_scatter.default(full_390, wait_tensor_676, 0, 0, -1);  wait_tensor_676 = None
        index_67 = torch.ops.aten.index.Tensor(slice_scatter_7, [getitem_2002]);  slice_scatter_7 = None
        permute_770 = torch.ops.aten.permute.default(index_67, [1, 0])
        _grouped_mm_120 = torch.ops.aten._grouped_mm.default(permute_770, mul_917, cumsum_56);  permute_770 = mul_917 = None
        _grouped_mm_121 = torch.ops.aten._grouped_mm.default(index_67, permute_772, cumsum_56);  index_67 = permute_772 = None
        convert_element_type_1048 = torch.ops.prims.convert_element_type.default(_grouped_mm_54, torch.float32);  _grouped_mm_54 = None
        neg_37 = torch.ops.aten.neg.default(convert_element_type_1048)
        exp_56 = torch.ops.aten.exp.default(neg_37);  neg_37 = None
        add_1256 = torch.ops.aten.add.Tensor(exp_56, 1);  exp_56 = None
        div_94 = torch.ops.aten.div.Tensor(convert_element_type_1048, add_1256)
        convert_element_type_1049 = torch.ops.prims.convert_element_type.default(div_94, torch.bfloat16);  div_94 = None
        mul_1535 = torch.ops.aten.mul.Tensor(_grouped_mm_121, convert_element_type_1049);  convert_element_type_1049 = None
        mul_1536 = torch.ops.aten.mul.Tensor(_grouped_mm_121, _grouped_mm_55);  _grouped_mm_121 = _grouped_mm_55 = None
        permute_774 = torch.ops.aten.permute.default(mul_1535, [1, 0])
        _grouped_mm_122 = torch.ops.aten._grouped_mm.default(permute_774, index_37, cumsum_56);  permute_774 = None
        _grouped_mm_123 = torch.ops.aten._grouped_mm.default(mul_1535, permute_776, cumsum_56);  mul_1535 = permute_776 = None
        convert_element_type_1996 = torch.ops.prims.convert_element_type.default(mul_1536, torch.float32);  mul_1536 = None
        reciprocal_15 = torch.ops.aten.reciprocal.default(add_1256);  add_1256 = None
        mul_1537 = torch.ops.aten.mul.Tensor(reciprocal_15, 1);  reciprocal_15 = None
        mul_1538 = torch.ops.aten.mul.Tensor(convert_element_type_1996, mul_1537);  convert_element_type_1996 = None
        sub_668 = torch.ops.aten.sub.Tensor(1, mul_1537);  mul_1537 = None
        mul_1539 = torch.ops.aten.mul.Tensor(convert_element_type_1048, sub_668);  convert_element_type_1048 = sub_668 = None
        add_1884 = torch.ops.aten.add.Tensor(mul_1539, 1);  mul_1539 = None
        mul_1540 = torch.ops.aten.mul.Tensor(mul_1538, add_1884);  mul_1538 = add_1884 = None
        convert_element_type_1998 = torch.ops.prims.convert_element_type.default(mul_1540, torch.bfloat16);  mul_1540 = None
        permute_778 = torch.ops.aten.permute.default(convert_element_type_1998, [1, 0])
        _grouped_mm_124 = torch.ops.aten._grouped_mm.default(permute_778, index_37, cumsum_56);  permute_778 = index_37 = None
        _grouped_mm_125 = torch.ops.aten._grouped_mm.default(convert_element_type_1998, permute_780, cumsum_56);  convert_element_type_1998 = permute_780 = cumsum_56 = None
        add_1885 = torch.ops.aten.add.Tensor(_grouped_mm_123, _grouped_mm_125);  _grouped_mm_123 = _grouped_mm_125 = None
        convert_element_type_1999 = torch.ops.prims.convert_element_type.default(_grouped_mm_122, torch.float32);  _grouped_mm_122 = None
        div_174 = torch.ops.aten.div.Tensor(convert_element_type_1999, 128);  convert_element_type_1999 = None
        split_528 = torch.ops.aten.split.Tensor(div_174, 88, 1);  div_174 = None
        getitem_9885 = split_528[0]
        getitem_9902 = split_528[1]
        getitem_9919 = split_528[2]
        getitem_9936 = split_528[3]
        getitem_9953 = split_528[4]
        getitem_9970 = split_528[5]
        getitem_9987 = split_528[6]
        getitem_10004 = split_528[7]
        getitem_10021 = split_528[8]
        getitem_10038 = split_528[9]
        getitem_10055 = split_528[10]
        getitem_10072 = split_528[11]
        getitem_10089 = split_528[12]
        getitem_10106 = split_528[13]
        getitem_10123 = split_528[14]
        getitem_10140 = split_528[15];  split_528 = None
        cat_292 = torch.ops.aten.cat.default([getitem_9885, getitem_9902, getitem_9919, getitem_9936, getitem_9953, getitem_9970, getitem_9987, getitem_10004, getitem_10021, getitem_10038, getitem_10055, getitem_10072, getitem_10089, getitem_10106, getitem_10123, getitem_10140]);  getitem_9885 = getitem_9902 = getitem_9919 = getitem_9936 = getitem_9953 = getitem_9970 = getitem_9987 = getitem_10004 = getitem_10021 = getitem_10038 = getitem_10055 = getitem_10072 = getitem_10089 = getitem_10106 = getitem_10123 = getitem_10140 = None
        reduce_scatter_tensor_103 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_292, 'sum', 16, '1025');  cat_292 = None
        wait_tensor_677 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_103);  reduce_scatter_tensor_103 = None
        convert_element_type_2000 = torch.ops.prims.convert_element_type.default(_grouped_mm_120, torch.float32);  _grouped_mm_120 = None
        div_175 = torch.ops.aten.div.Tensor(convert_element_type_2000, 128);  convert_element_type_2000 = None
        split_545 = torch.ops.aten.split.Tensor(div_175, 128, 1);  div_175 = None
        getitem_10157 = split_545[0]
        getitem_10174 = split_545[1]
        getitem_10191 = split_545[2]
        getitem_10208 = split_545[3]
        getitem_10225 = split_545[4]
        getitem_10242 = split_545[5]
        getitem_10259 = split_545[6]
        getitem_10276 = split_545[7]
        getitem_10293 = split_545[8]
        getitem_10310 = split_545[9]
        getitem_10327 = split_545[10]
        getitem_10344 = split_545[11]
        getitem_10361 = split_545[12]
        getitem_10378 = split_545[13]
        getitem_10395 = split_545[14]
        getitem_10412 = split_545[15];  split_545 = None
        cat_293 = torch.ops.aten.cat.default([getitem_10157, getitem_10174, getitem_10191, getitem_10208, getitem_10225, getitem_10242, getitem_10259, getitem_10276, getitem_10293, getitem_10310, getitem_10327, getitem_10344, getitem_10361, getitem_10378, getitem_10395, getitem_10412]);  getitem_10157 = getitem_10174 = getitem_10191 = getitem_10208 = getitem_10225 = getitem_10242 = getitem_10259 = getitem_10276 = getitem_10293 = getitem_10310 = getitem_10327 = getitem_10344 = getitem_10361 = getitem_10378 = getitem_10395 = getitem_10412 = None
        reduce_scatter_tensor_104 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_293, 'sum', 16, '1025');  cat_293 = None
        wait_tensor_678 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_104);  reduce_scatter_tensor_104 = None
        convert_element_type_2001 = torch.ops.prims.convert_element_type.default(_grouped_mm_124, torch.float32);  _grouped_mm_124 = None
        div_176 = torch.ops.aten.div.Tensor(convert_element_type_2001, 128);  convert_element_type_2001 = None
        split_562 = torch.ops.aten.split.Tensor(div_176, 88, 1);  div_176 = None
        getitem_10429 = split_562[0]
        getitem_10446 = split_562[1]
        getitem_10463 = split_562[2]
        getitem_10480 = split_562[3]
        getitem_10497 = split_562[4]
        getitem_10514 = split_562[5]
        getitem_10531 = split_562[6]
        getitem_10548 = split_562[7]
        getitem_10565 = split_562[8]
        getitem_10582 = split_562[9]
        getitem_10599 = split_562[10]
        getitem_10616 = split_562[11]
        getitem_10633 = split_562[12]
        getitem_10650 = split_562[13]
        getitem_10667 = split_562[14]
        getitem_10684 = split_562[15];  split_562 = None
        cat_294 = torch.ops.aten.cat.default([getitem_10429, getitem_10446, getitem_10463, getitem_10480, getitem_10497, getitem_10514, getitem_10531, getitem_10548, getitem_10565, getitem_10582, getitem_10599, getitem_10616, getitem_10633, getitem_10650, getitem_10667, getitem_10684]);  getitem_10429 = getitem_10446 = getitem_10463 = getitem_10480 = getitem_10497 = getitem_10514 = getitem_10531 = getitem_10548 = getitem_10565 = getitem_10582 = getitem_10599 = getitem_10616 = getitem_10633 = getitem_10650 = getitem_10667 = getitem_10684 = None
        reduce_scatter_tensor_105 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_294, 'sum', 16, '1025');  cat_294 = None
        wait_tensor_679 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_105);  reduce_scatter_tensor_105 = None
        index_put_66 = torch.ops.aten.index_put.default(full_390, [getitem_2002], add_1885, True);  full_390 = getitem_2002 = add_1885 = None
        slice_204 = torch.ops.aten.slice.Tensor(index_put_66, 0, 0, add_1886);  index_put_66 = add_1886 = None
        all_to_all_single_93 = torch.ops._c10d_functional.all_to_all_single.default(slice_204, [_local_scalar_dense_288, _local_scalar_dense_289, _local_scalar_dense_290, _local_scalar_dense_291, _local_scalar_dense_292, _local_scalar_dense_293, _local_scalar_dense_294, _local_scalar_dense_295], [_local_scalar_dense_296, _local_scalar_dense_297, _local_scalar_dense_298, _local_scalar_dense_299, _local_scalar_dense_300, _local_scalar_dense_301, _local_scalar_dense_302, _local_scalar_dense_303], '1033');  slice_204 = _local_scalar_dense_288 = _local_scalar_dense_289 = _local_scalar_dense_290 = _local_scalar_dense_291 = _local_scalar_dense_292 = _local_scalar_dense_293 = _local_scalar_dense_294 = _local_scalar_dense_295 = _local_scalar_dense_296 = _local_scalar_dense_297 = _local_scalar_dense_298 = _local_scalar_dense_299 = _local_scalar_dense_300 = _local_scalar_dense_301 = _local_scalar_dense_302 = _local_scalar_dense_303 = None
        wait_tensor_680 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_93);  all_to_all_single_93 = None
        index_put_67 = torch.ops.aten.index_put.default(full_default_52, [div_92], wait_tensor_680, True);  div_92 = wait_tensor_680 = None
        add_1890 = torch.ops.aten.add.Tensor(add_1882, index_put_67);  add_1882 = index_put_67 = None
        mul_1541 = torch.ops.aten.mul.Tensor(view_1916, 1.0);  view_1916 = None
        scatter_add_7 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_1999, mul_1541);  getitem_1999 = mul_1541 = None
        convert_element_type_1037 = torch.ops.prims.convert_element_type.default(mm_155, torch.float32);  mm_155 = None
        sub_432 = torch.ops.aten.sub.Tensor(convert_element_type_1037, amax_18);  convert_element_type_1037 = amax_18 = None
        exp_55 = torch.ops.aten.exp.default(sub_432);  sub_432 = None
        div_91 = torch.ops.aten.div.Tensor(exp_55, sum_73);  exp_55 = sum_73 = None
        mul_1542 = torch.ops.aten.mul.Tensor(scatter_add_7, div_91);  scatter_add_7 = None
        sum_163 = torch.ops.aten.sum.dim_IntList(mul_1542, [1], True)
        neg_76 = torch.ops.aten.neg.default(div_91);  div_91 = None
        fma_7 = torch.ops.prims.fma.default(neg_76, sum_163, mul_1542);  neg_76 = sum_163 = mul_1542 = None
        convert_element_type_2002 = torch.ops.prims.convert_element_type.default(fma_7, torch.bfloat16);  fma_7 = None
        permute_782 = torch.ops.aten.permute.default(convert_element_type_2002, [1, 0])
        mm_336 = torch.ops.aten.mm.default(permute_782, view_1264);  permute_782 = view_1264 = None
        convert_element_type_1034 = torch.ops.prims.convert_element_type.default(primals_319, torch.bfloat16);  primals_319 = None
        all_gather_into_tensor_324 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1034, 128, '0');  convert_element_type_1034 = None
        wait_tensor_396 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_324);  all_gather_into_tensor_324 = None
        slice_117 = torch.ops.aten.slice.Tensor(wait_tensor_396, 0, 0, 64);  wait_tensor_396 = None
        permute_289 = torch.ops.aten.permute.default(slice_117, [1, 0]);  slice_117 = None
        permute_784 = torch.ops.aten.permute.default(permute_289, [1, 0]);  permute_289 = None
        mm_337 = torch.ops.aten.mm.default(convert_element_type_2002, permute_784);  convert_element_type_2002 = permute_784 = None
        add_1891 = torch.ops.aten.add.Tensor(add_1890, mm_337);  add_1890 = mm_337 = None
        convert_element_type_2007 = torch.ops.prims.convert_element_type.default(mm_336, torch.float32);  mm_336 = None
        split_578 = torch.ops.aten.split.Tensor(convert_element_type_2007, 1);  convert_element_type_2007 = None
        getitem_10685 = split_578[0]
        getitem_10686 = split_578[1]
        getitem_10687 = split_578[2]
        getitem_10688 = split_578[3]
        getitem_10689 = split_578[4]
        getitem_10690 = split_578[5]
        getitem_10691 = split_578[6]
        getitem_10692 = split_578[7]
        getitem_10693 = split_578[8]
        getitem_10694 = split_578[9]
        getitem_10695 = split_578[10]
        getitem_10696 = split_578[11]
        getitem_10697 = split_578[12]
        getitem_10698 = split_578[13]
        getitem_10699 = split_578[14]
        getitem_10700 = split_578[15]
        getitem_10701 = split_578[16]
        getitem_10702 = split_578[17]
        getitem_10703 = split_578[18]
        getitem_10704 = split_578[19]
        getitem_10705 = split_578[20]
        getitem_10706 = split_578[21]
        getitem_10707 = split_578[22]
        getitem_10708 = split_578[23]
        getitem_10709 = split_578[24]
        getitem_10710 = split_578[25]
        getitem_10711 = split_578[26]
        getitem_10712 = split_578[27]
        getitem_10713 = split_578[28]
        getitem_10714 = split_578[29]
        getitem_10715 = split_578[30]
        getitem_10716 = split_578[31]
        getitem_10717 = split_578[32]
        getitem_10718 = split_578[33]
        getitem_10719 = split_578[34]
        getitem_10720 = split_578[35]
        getitem_10721 = split_578[36]
        getitem_10722 = split_578[37]
        getitem_10723 = split_578[38]
        getitem_10724 = split_578[39]
        getitem_10725 = split_578[40]
        getitem_10726 = split_578[41]
        getitem_10727 = split_578[42]
        getitem_10728 = split_578[43]
        getitem_10729 = split_578[44]
        getitem_10730 = split_578[45]
        getitem_10731 = split_578[46]
        getitem_10732 = split_578[47]
        getitem_10733 = split_578[48]
        getitem_10734 = split_578[49]
        getitem_10735 = split_578[50]
        getitem_10736 = split_578[51]
        getitem_10737 = split_578[52]
        getitem_10738 = split_578[53]
        getitem_10739 = split_578[54]
        getitem_10740 = split_578[55]
        getitem_10741 = split_578[56]
        getitem_10742 = split_578[57]
        getitem_10743 = split_578[58]
        getitem_10744 = split_578[59]
        getitem_10745 = split_578[60]
        getitem_10746 = split_578[61]
        getitem_10747 = split_578[62]
        getitem_10748 = split_578[63];  split_578 = None
        cat_295 = torch.ops.aten.cat.default([getitem_10685, getitem_10686, getitem_10687, getitem_10688, getitem_10689, getitem_10690, getitem_10691, getitem_10692, getitem_10693, getitem_10694, getitem_10695, getitem_10696, getitem_10697, getitem_10698, getitem_10699, getitem_10700, getitem_10701, getitem_10702, getitem_10703, getitem_10704, getitem_10705, getitem_10706, getitem_10707, getitem_10708, getitem_10709, getitem_10710, getitem_10711, getitem_10712, getitem_10713, getitem_10714, getitem_10715, getitem_10716, getitem_10717, getitem_10718, getitem_10719, getitem_10720, getitem_10721, getitem_10722, getitem_10723, getitem_10724, getitem_10725, getitem_10726, getitem_10727, getitem_10728, getitem_10729, getitem_10730, getitem_10731, getitem_10732, getitem_10733, getitem_10734, getitem_10735, getitem_10736, getitem_10737, getitem_10738, getitem_10739, getitem_10740, getitem_10741, getitem_10742, getitem_10743, getitem_10744, getitem_10745, getitem_10746, getitem_10747, getitem_10748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_10685 = getitem_10686 = getitem_10687 = getitem_10688 = getitem_10689 = getitem_10690 = getitem_10691 = getitem_10692 = getitem_10693 = getitem_10694 = getitem_10695 = getitem_10696 = getitem_10697 = getitem_10698 = getitem_10699 = getitem_10700 = getitem_10701 = getitem_10702 = getitem_10703 = getitem_10704 = getitem_10705 = getitem_10706 = getitem_10707 = getitem_10708 = getitem_10709 = getitem_10710 = getitem_10711 = getitem_10712 = getitem_10713 = getitem_10714 = getitem_10715 = getitem_10716 = getitem_10717 = getitem_10718 = getitem_10719 = getitem_10720 = getitem_10721 = getitem_10722 = getitem_10723 = getitem_10724 = getitem_10725 = getitem_10726 = getitem_10727 = getitem_10728 = getitem_10729 = getitem_10730 = getitem_10731 = getitem_10732 = getitem_10733 = getitem_10734 = getitem_10735 = getitem_10736 = getitem_10737 = getitem_10738 = getitem_10739 = getitem_10740 = getitem_10741 = getitem_10742 = getitem_10743 = getitem_10744 = getitem_10745 = getitem_10746 = getitem_10747 = getitem_10748 = None
        reduce_scatter_tensor_106 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_295, 'avg', 128, '0');  cat_295 = None
        wait_tensor_681 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_106);  reduce_scatter_tensor_106 = None
        view_1918 = torch.ops.aten.view.default(add_1891, [2, 4096, 2048]);  add_1891 = None
        convert_element_type_2008 = torch.ops.prims.convert_element_type.default(view_1918, torch.float32);  view_1918 = None
        convert_element_type_1031 = torch.ops.prims.convert_element_type.default(primals_317, torch.bfloat16);  primals_317 = None
        all_gather_into_tensor_323 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1031, 128, '0');  convert_element_type_1031 = None
        wait_tensor_395 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_323);  all_gather_into_tensor_323 = None
        convert_element_type_2010 = torch.ops.prims.convert_element_type.default(wait_tensor_395, torch.float32);  wait_tensor_395 = None
        mul_1543 = torch.ops.aten.mul.Tensor(convert_element_type_2008, convert_element_type_2010);  convert_element_type_2010 = None
        convert_element_type_1032 = torch.ops.prims.convert_element_type.default(add_1232, torch.float32);  add_1232 = None
        mul_897 = torch.ops.aten.mul.Tensor(convert_element_type_1032, rsqrt_59);  convert_element_type_1032 = None
        mul_1545 = torch.ops.aten.mul.Tensor(mul_897, mul_1543)
        sum_164 = torch.ops.aten.sum.dim_IntList(mul_1545, [2], True);  mul_1545 = None
        div_177 = torch.ops.aten.div.Tensor(mul_897, 2048)
        mul_1546 = torch.ops.aten.mul.Tensor(div_177, sum_164);  div_177 = sum_164 = None
        sub_670 = torch.ops.aten.sub.Tensor(mul_1543, mul_1546);  mul_1543 = mul_1546 = None
        mul_1547 = torch.ops.aten.mul.Tensor(sub_670, rsqrt_59);  sub_670 = rsqrt_59 = None
        mul_1548 = torch.ops.aten.mul.Tensor(convert_element_type_2008, mul_897);  convert_element_type_2008 = mul_897 = None
        sum_165 = torch.ops.aten.sum.dim_IntList(mul_1548, [0, 1]);  mul_1548 = None
        convert_element_type_2011 = torch.ops.prims.convert_element_type.default(mul_1547, torch.bfloat16);  mul_1547 = None
        add_1892 = torch.ops.aten.add.Tensor(add_1879, convert_element_type_2011);  add_1879 = convert_element_type_2011 = None
        convert_element_type_default_60 = torch.ops.prims.convert_element_type.default(sum_165, torch.float32);  sum_165 = None
        reduce_scatter_tensor_107 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_60, 'avg', 128, '0');  convert_element_type_default_60 = None
        wait_tensor_682 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_107);  reduce_scatter_tensor_107 = None
        view_1919 = torch.ops.aten.view.default(add_1892, [8192, 2048])
        permute_786 = torch.ops.aten.permute.default(view_1919, [1, 0])
        permute_287 = torch.ops.aten.permute.default(getitem_1995, [0, 2, 1, 3])
        view_1259 = torch.ops.aten.view.default(permute_287, [2, 4096, -1]);  permute_287 = None
        view_1261 = torch.ops.aten.view.default(view_1259, [8192, 2048]);  view_1259 = None
        mm_338 = torch.ops.aten.mm.default(permute_786, view_1261);  permute_786 = view_1261 = None
        convert_element_type_1028 = torch.ops.prims.convert_element_type.default(primals_316, torch.bfloat16);  primals_316 = None
        all_gather_into_tensor_322 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1028, 128, '0');  convert_element_type_1028 = None
        wait_tensor_394 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_322);  all_gather_into_tensor_322 = None
        permute_288 = torch.ops.aten.permute.default(wait_tensor_394, [1, 0]);  wait_tensor_394 = None
        permute_788 = torch.ops.aten.permute.default(permute_288, [1, 0]);  permute_288 = None
        mm_339 = torch.ops.aten.mm.default(view_1919, permute_788);  view_1919 = permute_788 = None
        view_1920 = torch.ops.aten.view.default(mm_339, [2, 4096, 2048]);  mm_339 = None
        convert_element_type_2018 = torch.ops.prims.convert_element_type.default(mm_338, torch.float32);  mm_338 = None
        reduce_scatter_tensor_108 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2018, 'avg', 128, '0');  convert_element_type_2018 = None
        wait_tensor_683 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_108);  reduce_scatter_tensor_108 = None
        view_1921 = torch.ops.aten.view.default(view_1920, [2, 4096, 16, 128]);  view_1920 = None
        permute_790 = torch.ops.aten.permute.default(view_1921, [0, 2, 1, 3]);  view_1921 = None
        fw_graph7 = self.fw_graph7
        joint_graph7 = self.joint_graph7
        mask_graph7 = self.mask_graph7
        flex_attention_backward_7 = torch.ops.higher_order.flex_attention_backward(permute_284, permute_285, permute_286, getitem_1995, getitem_1996, permute_790, None, fw_graph7, joint_graph7, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph7), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_284 = permute_285 = permute_286 = getitem_1995 = getitem_1996 = permute_790 = fw_graph7 = joint_graph7 = mask_graph7 = None
        getitem_10749 = flex_attention_backward_7[0]
        getitem_10750 = flex_attention_backward_7[1]
        getitem_10751 = flex_attention_backward_7[2];  flex_attention_backward_7 = None
        permute_791 = torch.ops.aten.permute.default(getitem_10751, [0, 2, 1, 3]);  getitem_10751 = None
        permute_792 = torch.ops.aten.permute.default(getitem_10750, [0, 2, 1, 3]);  getitem_10750 = None
        permute_793 = torch.ops.aten.permute.default(getitem_10749, [0, 2, 1, 3]);  getitem_10749 = None
        slice_206 = torch.ops.aten.slice.Tensor(permute_792, 3, 0, 128)
        slice_207 = torch.ops.aten.slice.Tensor(permute_792, 3, 128, 192);  permute_792 = None
        sum_166 = torch.ops.aten.sum.dim_IntList(slice_207, [2], True);  slice_207 = None
        cat_296 = torch.ops.aten.cat.default([slice_206, permute_791], 3);  slice_206 = permute_791 = None
        view_1922 = torch.ops.aten.view.default(cat_296, [2, 4096, 4096]);  cat_296 = None
        view_1923 = torch.ops.aten.view.default(view_1922, [8192, 4096]);  view_1922 = None
        permute_794 = torch.ops.aten.permute.default(view_1923, [1, 0])
        mm_340 = torch.ops.aten.mm.default(permute_794, view_1256);  permute_794 = view_1256 = None
        convert_element_type_1025 = torch.ops.prims.convert_element_type.default(primals_315, torch.bfloat16);  primals_315 = None
        all_gather_into_tensor_321 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1025, 128, '0');  convert_element_type_1025 = None
        wait_tensor_393 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_321);  all_gather_into_tensor_321 = None
        permute_283 = torch.ops.aten.permute.default(wait_tensor_393, [1, 0]);  wait_tensor_393 = None
        permute_796 = torch.ops.aten.permute.default(permute_283, [1, 0]);  permute_283 = None
        mm_341 = torch.ops.aten.mm.default(view_1923, permute_796);  view_1923 = permute_796 = None
        view_1924 = torch.ops.aten.view.default(mm_341, [2, 4096, 512]);  mm_341 = None
        convert_element_type_2023 = torch.ops.prims.convert_element_type.default(mm_340, torch.float32);  mm_340 = None
        reduce_scatter_tensor_109 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2023, 'avg', 128, '0');  convert_element_type_2023 = None
        wait_tensor_684 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_109);  reduce_scatter_tensor_109 = None
        convert_element_type_2024 = torch.ops.prims.convert_element_type.default(view_1924, torch.float32);  view_1924 = None
        convert_element_type_1022 = torch.ops.prims.convert_element_type.default(primals_314, torch.bfloat16);  primals_314 = None
        all_gather_into_tensor_320 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1022, 128, '0');  convert_element_type_1022 = None
        wait_tensor_392 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_320);  all_gather_into_tensor_320 = None
        convert_element_type_2026 = torch.ops.prims.convert_element_type.default(wait_tensor_392, torch.float32);  wait_tensor_392 = None
        mul_1549 = torch.ops.aten.mul.Tensor(convert_element_type_2024, convert_element_type_2026);  convert_element_type_2026 = None
        convert_element_type_1023 = torch.ops.prims.convert_element_type.default(getitem_1991, torch.float32);  getitem_1991 = None
        mul_895 = torch.ops.aten.mul.Tensor(convert_element_type_1023, rsqrt_58);  convert_element_type_1023 = None
        mul_1551 = torch.ops.aten.mul.Tensor(mul_895, mul_1549)
        sum_167 = torch.ops.aten.sum.dim_IntList(mul_1551, [2], True);  mul_1551 = None
        div_178 = torch.ops.aten.div.Tensor(mul_895, 512)
        mul_1552 = torch.ops.aten.mul.Tensor(div_178, sum_167);  div_178 = sum_167 = None
        sub_671 = torch.ops.aten.sub.Tensor(mul_1549, mul_1552);  mul_1549 = mul_1552 = None
        mul_1553 = torch.ops.aten.mul.Tensor(sub_671, rsqrt_58);  sub_671 = rsqrt_58 = None
        mul_1554 = torch.ops.aten.mul.Tensor(convert_element_type_2024, mul_895);  convert_element_type_2024 = mul_895 = None
        sum_168 = torch.ops.aten.sum.dim_IntList(mul_1554, [0, 1]);  mul_1554 = None
        convert_element_type_2027 = torch.ops.prims.convert_element_type.default(mul_1553, torch.bfloat16);  mul_1553 = None
        convert_element_type_default_59 = torch.ops.prims.convert_element_type.default(sum_168, torch.float32);  sum_168 = None
        reduce_scatter_tensor_110 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_59, 'avg', 128, '0');  convert_element_type_default_59 = None
        wait_tensor_685 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_110);  reduce_scatter_tensor_110 = None
        convert_element_type_2030 = torch.ops.prims.convert_element_type.default(sum_166, torch.float32);  sum_166 = None
        view_1925 = torch.ops.aten.view.default(convert_element_type_2030, [2, 4096, 1, 32, 2]);  convert_element_type_2030 = None
        view_as_complex_68 = torch.ops.aten.view_as_complex.default(view_1925);  view_1925 = None
        mul_1555 = torch.ops.aten.mul.Tensor(view_as_complex_68, clone_9);  view_as_complex_68 = None
        view_as_real_68 = torch.ops.aten.view_as_real.default(mul_1555);  mul_1555 = None
        view_1926 = torch.ops.aten.view.default(view_as_real_68, [2, 4096, 1, 64]);  view_as_real_68 = None
        convert_element_type_2031 = torch.ops.prims.convert_element_type.default(view_1926, torch.bfloat16);  view_1926 = None
        squeeze_33 = torch.ops.aten.squeeze.dim(convert_element_type_2031, 2);  convert_element_type_2031 = None
        cat_297 = torch.ops.aten.cat.default([convert_element_type_2027, squeeze_33], 2);  convert_element_type_2027 = squeeze_33 = None
        view_1927 = torch.ops.aten.view.default(cat_297, [8192, 576]);  cat_297 = None
        permute_798 = torch.ops.aten.permute.default(view_1927, [1, 0])
        mm_342 = torch.ops.aten.mm.default(permute_798, view_1242);  permute_798 = None
        convert_element_type_1017 = torch.ops.prims.convert_element_type.default(primals_313, torch.bfloat16);  primals_313 = None
        all_gather_into_tensor_319 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1017, 128, '0');  convert_element_type_1017 = None
        wait_tensor_391 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_319);  all_gather_into_tensor_319 = None
        slice_115 = torch.ops.aten.slice.Tensor(wait_tensor_391, 0, 0, 576);  wait_tensor_391 = None
        permute_282 = torch.ops.aten.permute.default(slice_115, [1, 0]);  slice_115 = None
        permute_800 = torch.ops.aten.permute.default(permute_282, [1, 0]);  permute_282 = None
        mm_343 = torch.ops.aten.mm.default(view_1927, permute_800);  view_1927 = permute_800 = None
        view_1928 = torch.ops.aten.view.default(mm_343, [2, 4096, 2048]);  mm_343 = None
        convert_element_type_2036 = torch.ops.prims.convert_element_type.default(mm_342, torch.float32);  mm_342 = None
        split_579 = torch.ops.aten.split.Tensor(convert_element_type_2036, 5);  convert_element_type_2036 = None
        getitem_10753 = split_579[0]
        getitem_10754 = split_579[1]
        getitem_10755 = split_579[2]
        getitem_10756 = split_579[3]
        getitem_10757 = split_579[4]
        getitem_10758 = split_579[5]
        getitem_10759 = split_579[6]
        getitem_10760 = split_579[7]
        getitem_10761 = split_579[8]
        getitem_10762 = split_579[9]
        getitem_10763 = split_579[10]
        getitem_10764 = split_579[11]
        getitem_10765 = split_579[12]
        getitem_10766 = split_579[13]
        getitem_10767 = split_579[14]
        getitem_10768 = split_579[15]
        getitem_10769 = split_579[16]
        getitem_10770 = split_579[17]
        getitem_10771 = split_579[18]
        getitem_10772 = split_579[19]
        getitem_10773 = split_579[20]
        getitem_10774 = split_579[21]
        getitem_10775 = split_579[22]
        getitem_10776 = split_579[23]
        getitem_10777 = split_579[24]
        getitem_10778 = split_579[25]
        getitem_10779 = split_579[26]
        getitem_10780 = split_579[27]
        getitem_10781 = split_579[28]
        getitem_10782 = split_579[29]
        getitem_10783 = split_579[30]
        getitem_10784 = split_579[31]
        getitem_10785 = split_579[32]
        getitem_10786 = split_579[33]
        getitem_10787 = split_579[34]
        getitem_10788 = split_579[35]
        getitem_10789 = split_579[36]
        getitem_10790 = split_579[37]
        getitem_10791 = split_579[38]
        getitem_10792 = split_579[39]
        getitem_10793 = split_579[40]
        getitem_10794 = split_579[41]
        getitem_10795 = split_579[42]
        getitem_10796 = split_579[43]
        getitem_10797 = split_579[44]
        getitem_10798 = split_579[45]
        getitem_10799 = split_579[46]
        getitem_10800 = split_579[47]
        getitem_10801 = split_579[48]
        getitem_10802 = split_579[49]
        getitem_10803 = split_579[50]
        getitem_10804 = split_579[51]
        getitem_10805 = split_579[52]
        getitem_10806 = split_579[53]
        getitem_10807 = split_579[54]
        getitem_10808 = split_579[55]
        getitem_10809 = split_579[56]
        getitem_10810 = split_579[57]
        getitem_10811 = split_579[58]
        getitem_10812 = split_579[59]
        getitem_10813 = split_579[60]
        getitem_10814 = split_579[61]
        getitem_10815 = split_579[62]
        getitem_10816 = split_579[63]
        getitem_10817 = split_579[64]
        getitem_10818 = split_579[65]
        getitem_10819 = split_579[66]
        getitem_10820 = split_579[67]
        getitem_10821 = split_579[68]
        getitem_10822 = split_579[69]
        getitem_10823 = split_579[70]
        getitem_10824 = split_579[71]
        getitem_10825 = split_579[72]
        getitem_10826 = split_579[73]
        getitem_10827 = split_579[74]
        getitem_10828 = split_579[75]
        getitem_10829 = split_579[76]
        getitem_10830 = split_579[77]
        getitem_10831 = split_579[78]
        getitem_10832 = split_579[79]
        getitem_10833 = split_579[80]
        getitem_10834 = split_579[81]
        getitem_10835 = split_579[82]
        getitem_10836 = split_579[83]
        getitem_10837 = split_579[84]
        getitem_10838 = split_579[85]
        getitem_10839 = split_579[86]
        getitem_10840 = split_579[87]
        getitem_10841 = split_579[88]
        getitem_10842 = split_579[89]
        getitem_10843 = split_579[90]
        getitem_10844 = split_579[91]
        getitem_10845 = split_579[92]
        getitem_10846 = split_579[93]
        getitem_10847 = split_579[94]
        getitem_10848 = split_579[95]
        getitem_10849 = split_579[96]
        getitem_10850 = split_579[97]
        getitem_10851 = split_579[98]
        getitem_10852 = split_579[99]
        getitem_10853 = split_579[100]
        getitem_10854 = split_579[101]
        getitem_10855 = split_579[102]
        getitem_10856 = split_579[103]
        getitem_10857 = split_579[104]
        getitem_10858 = split_579[105]
        getitem_10859 = split_579[106]
        getitem_10860 = split_579[107]
        getitem_10861 = split_579[108]
        getitem_10862 = split_579[109]
        getitem_10863 = split_579[110]
        getitem_10864 = split_579[111]
        getitem_10865 = split_579[112]
        getitem_10866 = split_579[113]
        getitem_10867 = split_579[114]
        getitem_10868 = split_579[115];  split_579 = None
        constant_pad_nd_603 = torch.ops.aten.constant_pad_nd.default(getitem_10868, [0, 0, 0, 4], 0.0);  getitem_10868 = None
        cat_298 = torch.ops.aten.cat.default([getitem_10753, getitem_10754, getitem_10755, getitem_10756, getitem_10757, getitem_10758, getitem_10759, getitem_10760, getitem_10761, getitem_10762, getitem_10763, getitem_10764, getitem_10765, getitem_10766, getitem_10767, getitem_10768, getitem_10769, getitem_10770, getitem_10771, getitem_10772, getitem_10773, getitem_10774, getitem_10775, getitem_10776, getitem_10777, getitem_10778, getitem_10779, getitem_10780, getitem_10781, getitem_10782, getitem_10783, getitem_10784, getitem_10785, getitem_10786, getitem_10787, getitem_10788, getitem_10789, getitem_10790, getitem_10791, getitem_10792, getitem_10793, getitem_10794, getitem_10795, getitem_10796, getitem_10797, getitem_10798, getitem_10799, getitem_10800, getitem_10801, getitem_10802, getitem_10803, getitem_10804, getitem_10805, getitem_10806, getitem_10807, getitem_10808, getitem_10809, getitem_10810, getitem_10811, getitem_10812, getitem_10813, getitem_10814, getitem_10815, getitem_10816, getitem_10817, getitem_10818, getitem_10819, getitem_10820, getitem_10821, getitem_10822, getitem_10823, getitem_10824, getitem_10825, getitem_10826, getitem_10827, getitem_10828, getitem_10829, getitem_10830, getitem_10831, getitem_10832, getitem_10833, getitem_10834, getitem_10835, getitem_10836, getitem_10837, getitem_10838, getitem_10839, getitem_10840, getitem_10841, getitem_10842, getitem_10843, getitem_10844, getitem_10845, getitem_10846, getitem_10847, getitem_10848, getitem_10849, getitem_10850, getitem_10851, getitem_10852, getitem_10853, getitem_10854, getitem_10855, getitem_10856, getitem_10857, getitem_10858, getitem_10859, getitem_10860, getitem_10861, getitem_10862, getitem_10863, getitem_10864, getitem_10865, getitem_10866, getitem_10867, constant_pad_nd_603, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_10753 = getitem_10754 = getitem_10755 = getitem_10756 = getitem_10757 = getitem_10758 = getitem_10759 = getitem_10760 = getitem_10761 = getitem_10762 = getitem_10763 = getitem_10764 = getitem_10765 = getitem_10766 = getitem_10767 = getitem_10768 = getitem_10769 = getitem_10770 = getitem_10771 = getitem_10772 = getitem_10773 = getitem_10774 = getitem_10775 = getitem_10776 = getitem_10777 = getitem_10778 = getitem_10779 = getitem_10780 = getitem_10781 = getitem_10782 = getitem_10783 = getitem_10784 = getitem_10785 = getitem_10786 = getitem_10787 = getitem_10788 = getitem_10789 = getitem_10790 = getitem_10791 = getitem_10792 = getitem_10793 = getitem_10794 = getitem_10795 = getitem_10796 = getitem_10797 = getitem_10798 = getitem_10799 = getitem_10800 = getitem_10801 = getitem_10802 = getitem_10803 = getitem_10804 = getitem_10805 = getitem_10806 = getitem_10807 = getitem_10808 = getitem_10809 = getitem_10810 = getitem_10811 = getitem_10812 = getitem_10813 = getitem_10814 = getitem_10815 = getitem_10816 = getitem_10817 = getitem_10818 = getitem_10819 = getitem_10820 = getitem_10821 = getitem_10822 = getitem_10823 = getitem_10824 = getitem_10825 = getitem_10826 = getitem_10827 = getitem_10828 = getitem_10829 = getitem_10830 = getitem_10831 = getitem_10832 = getitem_10833 = getitem_10834 = getitem_10835 = getitem_10836 = getitem_10837 = getitem_10838 = getitem_10839 = getitem_10840 = getitem_10841 = getitem_10842 = getitem_10843 = getitem_10844 = getitem_10845 = getitem_10846 = getitem_10847 = getitem_10848 = getitem_10849 = getitem_10850 = getitem_10851 = getitem_10852 = getitem_10853 = getitem_10854 = getitem_10855 = getitem_10856 = getitem_10857 = getitem_10858 = getitem_10859 = getitem_10860 = getitem_10861 = getitem_10862 = getitem_10863 = getitem_10864 = getitem_10865 = getitem_10866 = getitem_10867 = constant_pad_nd_603 = None
        reduce_scatter_tensor_111 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_298, 'avg', 128, '0');  cat_298 = None
        wait_tensor_686 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_111);  reduce_scatter_tensor_111 = None
        slice_208 = torch.ops.aten.slice.Tensor(permute_793, 3, 0, 128)
        slice_209 = torch.ops.aten.slice.Tensor(permute_793, 3, 128, 192);  permute_793 = None
        convert_element_type_2037 = torch.ops.prims.convert_element_type.default(slice_209, torch.float32);  slice_209 = None
        view_1929 = torch.ops.aten.view.default(convert_element_type_2037, [2, 4096, 16, 32, 2]);  convert_element_type_2037 = None
        view_as_complex_69 = torch.ops.aten.view_as_complex.default(view_1929);  view_1929 = None
        mul_1556 = torch.ops.aten.mul.Tensor(view_as_complex_69, clone_9);  view_as_complex_69 = None
        view_as_real_69 = torch.ops.aten.view_as_real.default(mul_1556);  mul_1556 = None
        view_1930 = torch.ops.aten.view.default(view_as_real_69, [2, 4096, 16, 64]);  view_as_real_69 = None
        convert_element_type_2038 = torch.ops.prims.convert_element_type.default(view_1930, torch.bfloat16);  view_1930 = None
        cat_299 = torch.ops.aten.cat.default([slice_208, convert_element_type_2038], 3);  slice_208 = convert_element_type_2038 = None
        view_1931 = torch.ops.aten.view.default(cat_299, [2, 4096, 3072]);  cat_299 = None
        view_1932 = torch.ops.aten.view.default(view_1931, [8192, 3072]);  view_1931 = None
        permute_802 = torch.ops.aten.permute.default(view_1932, [1, 0])
        mm_344 = torch.ops.aten.mm.default(permute_802, view_1242);  permute_802 = view_1242 = None
        convert_element_type_1012 = torch.ops.prims.convert_element_type.default(primals_312, torch.bfloat16);  primals_312 = None
        all_gather_into_tensor_318 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1012, 128, '0');  convert_element_type_1012 = None
        wait_tensor_390 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_318);  all_gather_into_tensor_318 = None
        permute_281 = torch.ops.aten.permute.default(wait_tensor_390, [1, 0]);  wait_tensor_390 = None
        permute_804 = torch.ops.aten.permute.default(permute_281, [1, 0]);  permute_281 = None
        mm_345 = torch.ops.aten.mm.default(view_1932, permute_804);  view_1932 = permute_804 = None
        view_1933 = torch.ops.aten.view.default(mm_345, [2, 4096, 2048]);  mm_345 = None
        add_1893 = torch.ops.aten.add.Tensor(view_1928, view_1933);  view_1928 = view_1933 = None
        convert_element_type_2043 = torch.ops.prims.convert_element_type.default(mm_344, torch.float32);  mm_344 = None
        reduce_scatter_tensor_112 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2043, 'avg', 128, '0');  convert_element_type_2043 = None
        wait_tensor_687 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_112);  reduce_scatter_tensor_112 = None
        convert_element_type_2044 = torch.ops.prims.convert_element_type.default(add_1893, torch.float32);  add_1893 = None
        convert_element_type_1009 = torch.ops.prims.convert_element_type.default(primals_311, torch.bfloat16);  primals_311 = None
        all_gather_into_tensor_317 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1009, 128, '0');  convert_element_type_1009 = None
        wait_tensor_389 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_317);  all_gather_into_tensor_317 = None
        convert_element_type_2046 = torch.ops.prims.convert_element_type.default(wait_tensor_389, torch.float32);  wait_tensor_389 = None
        mul_1557 = torch.ops.aten.mul.Tensor(convert_element_type_2044, convert_element_type_2046);  convert_element_type_2046 = None
        convert_element_type_1010 = torch.ops.prims.convert_element_type.default(add_1229, torch.float32);  add_1229 = None
        mul_891 = torch.ops.aten.mul.Tensor(convert_element_type_1010, rsqrt_57);  convert_element_type_1010 = None
        mul_1559 = torch.ops.aten.mul.Tensor(mul_891, mul_1557)
        sum_169 = torch.ops.aten.sum.dim_IntList(mul_1559, [2], True);  mul_1559 = None
        div_179 = torch.ops.aten.div.Tensor(mul_891, 2048)
        mul_1560 = torch.ops.aten.mul.Tensor(div_179, sum_169);  div_179 = sum_169 = None
        sub_672 = torch.ops.aten.sub.Tensor(mul_1557, mul_1560);  mul_1557 = mul_1560 = None
        mul_1561 = torch.ops.aten.mul.Tensor(sub_672, rsqrt_57);  sub_672 = rsqrt_57 = None
        mul_1562 = torch.ops.aten.mul.Tensor(convert_element_type_2044, mul_891);  convert_element_type_2044 = mul_891 = None
        sum_170 = torch.ops.aten.sum.dim_IntList(mul_1562, [0, 1]);  mul_1562 = None
        convert_element_type_2047 = torch.ops.prims.convert_element_type.default(mul_1561, torch.bfloat16);  mul_1561 = None
        add_1894 = torch.ops.aten.add.Tensor(add_1892, convert_element_type_2047);  add_1892 = convert_element_type_2047 = None
        convert_element_type_default_58 = torch.ops.prims.convert_element_type.default(sum_170, torch.float32);  sum_170 = None
        reduce_scatter_tensor_113 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_58, 'avg', 128, '0');  convert_element_type_default_58 = None
        wait_tensor_688 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_113);  reduce_scatter_tensor_113 = None
        view_1934 = torch.ops.aten.view.default(add_1894, [8192, 2048])
        unsqueeze_61 = torch.ops.aten.unsqueeze.default(view_1934, 1)
        convert_element_type_2050 = torch.ops.prims.convert_element_type.default(unsqueeze_61, torch.float32);  unsqueeze_61 = None
        bmm_42 = torch.ops.aten.bmm.default(permute_806, convert_element_type_2050);  permute_806 = None
        bmm_43 = torch.ops.aten.bmm.default(convert_element_type_2050, permute_807);  convert_element_type_2050 = permute_807 = None
        convert_element_type_2051 = torch.ops.prims.convert_element_type.default(bmm_42, torch.bfloat16);  bmm_42 = None
        view_1935 = torch.ops.aten.view.default(bmm_43, [8192, 6]);  bmm_43 = None
        view_1936 = torch.ops.aten.view.default(convert_element_type_2051, [49152, 2048]);  convert_element_type_2051 = None
        index_68 = torch.ops.aten.index.Tensor(view_1936, [getitem_1891]);  view_1936 = getitem_1891 = None
        permute_808 = torch.ops.aten.permute.default(view_1934, [1, 0])
        mm_346 = torch.ops.aten.mm.default(permute_808, mul_888);  permute_808 = mul_888 = None
        convert_element_type_1004 = torch.ops.prims.convert_element_type.default(primals_310, torch.bfloat16);  primals_310 = None
        all_gather_into_tensor_316 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1004, 128, '0');  convert_element_type_1004 = None
        wait_tensor_388 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_316);  all_gather_into_tensor_316 = None
        permute_280 = torch.ops.aten.permute.default(wait_tensor_388, [1, 0]);  wait_tensor_388 = None
        permute_810 = torch.ops.aten.permute.default(permute_280, [1, 0]);  permute_280 = None
        mm_347 = torch.ops.aten.mm.default(view_1934, permute_810);  view_1934 = permute_810 = None
        convert_element_type_2056 = torch.ops.prims.convert_element_type.default(mm_346, torch.float32);  mm_346 = None
        reduce_scatter_tensor_114 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2056, 'avg', 128, '0');  convert_element_type_2056 = None
        wait_tensor_689 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_114);  reduce_scatter_tensor_114 = None
        convert_element_type_999 = torch.ops.prims.convert_element_type.default(mm_148, torch.float32);  mm_148 = None
        neg_36 = torch.ops.aten.neg.default(convert_element_type_999)
        exp_54 = torch.ops.aten.exp.default(neg_36);  neg_36 = None
        add_1224 = torch.ops.aten.add.Tensor(exp_54, 1);  exp_54 = None
        div_90 = torch.ops.aten.div.Tensor(convert_element_type_999, add_1224)
        convert_element_type_1000 = torch.ops.prims.convert_element_type.default(div_90, torch.bfloat16);  div_90 = None
        mul_1563 = torch.ops.aten.mul.Tensor(mm_347, convert_element_type_1000);  convert_element_type_1000 = None
        mul_1564 = torch.ops.aten.mul.Tensor(mm_347, mm_149);  mm_347 = mm_149 = None
        permute_812 = torch.ops.aten.permute.default(mul_1563, [1, 0])
        mm_348 = torch.ops.aten.mm.default(permute_812, view_1197);  permute_812 = None
        convert_element_type_1001 = torch.ops.prims.convert_element_type.default(primals_309, torch.bfloat16);  primals_309 = None
        all_gather_into_tensor_315 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1001, 128, '0');  convert_element_type_1001 = None
        wait_tensor_387 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_315);  all_gather_into_tensor_315 = None
        permute_279 = torch.ops.aten.permute.default(wait_tensor_387, [1, 0]);  wait_tensor_387 = None
        permute_814 = torch.ops.aten.permute.default(permute_279, [1, 0]);  permute_279 = None
        mm_349 = torch.ops.aten.mm.default(mul_1563, permute_814);  mul_1563 = permute_814 = None
        convert_element_type_2061 = torch.ops.prims.convert_element_type.default(mm_348, torch.float32);  mm_348 = None
        reduce_scatter_tensor_115 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2061, 'avg', 128, '0');  convert_element_type_2061 = None
        wait_tensor_690 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_115);  reduce_scatter_tensor_115 = None
        convert_element_type_2062 = torch.ops.prims.convert_element_type.default(mul_1564, torch.float32);  mul_1564 = None
        reciprocal_16 = torch.ops.aten.reciprocal.default(add_1224);  add_1224 = None
        mul_1565 = torch.ops.aten.mul.Tensor(reciprocal_16, 1);  reciprocal_16 = None
        mul_1566 = torch.ops.aten.mul.Tensor(convert_element_type_2062, mul_1565);  convert_element_type_2062 = None
        sub_673 = torch.ops.aten.sub.Tensor(1, mul_1565);  mul_1565 = None
        mul_1567 = torch.ops.aten.mul.Tensor(convert_element_type_999, sub_673);  convert_element_type_999 = sub_673 = None
        add_1896 = torch.ops.aten.add.Tensor(mul_1567, 1);  mul_1567 = None
        mul_1568 = torch.ops.aten.mul.Tensor(mul_1566, add_1896);  mul_1566 = add_1896 = None
        convert_element_type_2064 = torch.ops.prims.convert_element_type.default(mul_1568, torch.bfloat16);  mul_1568 = None
        permute_816 = torch.ops.aten.permute.default(convert_element_type_2064, [1, 0])
        mm_350 = torch.ops.aten.mm.default(permute_816, view_1197);  permute_816 = None
        convert_element_type_996 = torch.ops.prims.convert_element_type.default(primals_308, torch.bfloat16);  primals_308 = None
        all_gather_into_tensor_314 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_996, 128, '0');  convert_element_type_996 = None
        wait_tensor_386 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_314);  all_gather_into_tensor_314 = None
        permute_278 = torch.ops.aten.permute.default(wait_tensor_386, [1, 0]);  wait_tensor_386 = None
        permute_818 = torch.ops.aten.permute.default(permute_278, [1, 0]);  permute_278 = None
        mm_351 = torch.ops.aten.mm.default(convert_element_type_2064, permute_818);  convert_element_type_2064 = permute_818 = None
        add_1897 = torch.ops.aten.add.Tensor(mm_349, mm_351);  mm_349 = mm_351 = None
        convert_element_type_2069 = torch.ops.prims.convert_element_type.default(mm_350, torch.float32);  mm_350 = None
        reduce_scatter_tensor_116 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2069, 'avg', 128, '0');  convert_element_type_2069 = None
        wait_tensor_691 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_116);  reduce_scatter_tensor_116 = None
        all_to_all_single_94 = torch.ops._c10d_functional.all_to_all_single.default(index_68, [_local_scalar_dense_280, _local_scalar_dense_281, _local_scalar_dense_282, _local_scalar_dense_283, _local_scalar_dense_284, _local_scalar_dense_285, _local_scalar_dense_286, _local_scalar_dense_287], [_local_scalar_dense_272, _local_scalar_dense_273, _local_scalar_dense_274, _local_scalar_dense_275, _local_scalar_dense_276, _local_scalar_dense_277, _local_scalar_dense_278, _local_scalar_dense_279], '1033');  index_68 = None
        wait_tensor_692 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_94);  all_to_all_single_94 = None
        full_396 = torch.ops.aten.full.default([sym_size_int_69, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_69 = None
        slice_scatter_8 = torch.ops.aten.slice_scatter.default(full_396, wait_tensor_692, 0, 0, -1);  wait_tensor_692 = None
        index_69 = torch.ops.aten.index.Tensor(slice_scatter_8, [getitem_1892]);  slice_scatter_8 = None
        permute_820 = torch.ops.aten.permute.default(index_69, [1, 0])
        _grouped_mm_126 = torch.ops.aten._grouped_mm.default(permute_820, mul_868, cumsum_53);  permute_820 = mul_868 = None
        _grouped_mm_127 = torch.ops.aten._grouped_mm.default(index_69, permute_822, cumsum_53);  index_69 = permute_822 = None
        convert_element_type_994 = torch.ops.prims.convert_element_type.default(_grouped_mm_51, torch.float32);  _grouped_mm_51 = None
        neg_35 = torch.ops.aten.neg.default(convert_element_type_994)
        exp_53 = torch.ops.aten.exp.default(neg_35);  neg_35 = None
        add_1188 = torch.ops.aten.add.Tensor(exp_53, 1);  exp_53 = None
        div_89 = torch.ops.aten.div.Tensor(convert_element_type_994, add_1188)
        convert_element_type_995 = torch.ops.prims.convert_element_type.default(div_89, torch.bfloat16);  div_89 = None
        mul_1569 = torch.ops.aten.mul.Tensor(_grouped_mm_127, convert_element_type_995);  convert_element_type_995 = None
        mul_1570 = torch.ops.aten.mul.Tensor(_grouped_mm_127, _grouped_mm_52);  _grouped_mm_127 = _grouped_mm_52 = None
        permute_824 = torch.ops.aten.permute.default(mul_1569, [1, 0])
        _grouped_mm_128 = torch.ops.aten._grouped_mm.default(permute_824, index_35, cumsum_53);  permute_824 = None
        _grouped_mm_129 = torch.ops.aten._grouped_mm.default(mul_1569, permute_826, cumsum_53);  mul_1569 = permute_826 = None
        convert_element_type_2070 = torch.ops.prims.convert_element_type.default(mul_1570, torch.float32);  mul_1570 = None
        reciprocal_17 = torch.ops.aten.reciprocal.default(add_1188);  add_1188 = None
        mul_1571 = torch.ops.aten.mul.Tensor(reciprocal_17, 1);  reciprocal_17 = None
        mul_1572 = torch.ops.aten.mul.Tensor(convert_element_type_2070, mul_1571);  convert_element_type_2070 = None
        sub_674 = torch.ops.aten.sub.Tensor(1, mul_1571);  mul_1571 = None
        mul_1573 = torch.ops.aten.mul.Tensor(convert_element_type_994, sub_674);  convert_element_type_994 = sub_674 = None
        add_1899 = torch.ops.aten.add.Tensor(mul_1573, 1);  mul_1573 = None
        mul_1574 = torch.ops.aten.mul.Tensor(mul_1572, add_1899);  mul_1572 = add_1899 = None
        convert_element_type_2072 = torch.ops.prims.convert_element_type.default(mul_1574, torch.bfloat16);  mul_1574 = None
        permute_828 = torch.ops.aten.permute.default(convert_element_type_2072, [1, 0])
        _grouped_mm_130 = torch.ops.aten._grouped_mm.default(permute_828, index_35, cumsum_53);  permute_828 = index_35 = None
        _grouped_mm_131 = torch.ops.aten._grouped_mm.default(convert_element_type_2072, permute_830, cumsum_53);  convert_element_type_2072 = permute_830 = cumsum_53 = None
        add_1900 = torch.ops.aten.add.Tensor(_grouped_mm_129, _grouped_mm_131);  _grouped_mm_129 = _grouped_mm_131 = None
        convert_element_type_2073 = torch.ops.prims.convert_element_type.default(_grouped_mm_128, torch.float32);  _grouped_mm_128 = None
        div_180 = torch.ops.aten.div.Tensor(convert_element_type_2073, 128);  convert_element_type_2073 = None
        split_581 = torch.ops.aten.split.Tensor(div_180, 88, 1);  div_180 = None
        getitem_10885 = split_581[0]
        getitem_10902 = split_581[1]
        getitem_10919 = split_581[2]
        getitem_10936 = split_581[3]
        getitem_10953 = split_581[4]
        getitem_10970 = split_581[5]
        getitem_10987 = split_581[6]
        getitem_11004 = split_581[7]
        getitem_11021 = split_581[8]
        getitem_11038 = split_581[9]
        getitem_11055 = split_581[10]
        getitem_11072 = split_581[11]
        getitem_11089 = split_581[12]
        getitem_11106 = split_581[13]
        getitem_11123 = split_581[14]
        getitem_11140 = split_581[15];  split_581 = None
        cat_300 = torch.ops.aten.cat.default([getitem_10885, getitem_10902, getitem_10919, getitem_10936, getitem_10953, getitem_10970, getitem_10987, getitem_11004, getitem_11021, getitem_11038, getitem_11055, getitem_11072, getitem_11089, getitem_11106, getitem_11123, getitem_11140]);  getitem_10885 = getitem_10902 = getitem_10919 = getitem_10936 = getitem_10953 = getitem_10970 = getitem_10987 = getitem_11004 = getitem_11021 = getitem_11038 = getitem_11055 = getitem_11072 = getitem_11089 = getitem_11106 = getitem_11123 = getitem_11140 = None
        reduce_scatter_tensor_117 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_300, 'sum', 16, '1025');  cat_300 = None
        wait_tensor_693 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_117);  reduce_scatter_tensor_117 = None
        convert_element_type_2074 = torch.ops.prims.convert_element_type.default(_grouped_mm_126, torch.float32);  _grouped_mm_126 = None
        div_181 = torch.ops.aten.div.Tensor(convert_element_type_2074, 128);  convert_element_type_2074 = None
        split_598 = torch.ops.aten.split.Tensor(div_181, 128, 1);  div_181 = None
        getitem_11157 = split_598[0]
        getitem_11174 = split_598[1]
        getitem_11191 = split_598[2]
        getitem_11208 = split_598[3]
        getitem_11225 = split_598[4]
        getitem_11242 = split_598[5]
        getitem_11259 = split_598[6]
        getitem_11276 = split_598[7]
        getitem_11293 = split_598[8]
        getitem_11310 = split_598[9]
        getitem_11327 = split_598[10]
        getitem_11344 = split_598[11]
        getitem_11361 = split_598[12]
        getitem_11378 = split_598[13]
        getitem_11395 = split_598[14]
        getitem_11412 = split_598[15];  split_598 = None
        cat_301 = torch.ops.aten.cat.default([getitem_11157, getitem_11174, getitem_11191, getitem_11208, getitem_11225, getitem_11242, getitem_11259, getitem_11276, getitem_11293, getitem_11310, getitem_11327, getitem_11344, getitem_11361, getitem_11378, getitem_11395, getitem_11412]);  getitem_11157 = getitem_11174 = getitem_11191 = getitem_11208 = getitem_11225 = getitem_11242 = getitem_11259 = getitem_11276 = getitem_11293 = getitem_11310 = getitem_11327 = getitem_11344 = getitem_11361 = getitem_11378 = getitem_11395 = getitem_11412 = None
        reduce_scatter_tensor_118 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_301, 'sum', 16, '1025');  cat_301 = None
        wait_tensor_694 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_118);  reduce_scatter_tensor_118 = None
        convert_element_type_2075 = torch.ops.prims.convert_element_type.default(_grouped_mm_130, torch.float32);  _grouped_mm_130 = None
        div_182 = torch.ops.aten.div.Tensor(convert_element_type_2075, 128);  convert_element_type_2075 = None
        split_615 = torch.ops.aten.split.Tensor(div_182, 88, 1);  div_182 = None
        getitem_11429 = split_615[0]
        getitem_11446 = split_615[1]
        getitem_11463 = split_615[2]
        getitem_11480 = split_615[3]
        getitem_11497 = split_615[4]
        getitem_11514 = split_615[5]
        getitem_11531 = split_615[6]
        getitem_11548 = split_615[7]
        getitem_11565 = split_615[8]
        getitem_11582 = split_615[9]
        getitem_11599 = split_615[10]
        getitem_11616 = split_615[11]
        getitem_11633 = split_615[12]
        getitem_11650 = split_615[13]
        getitem_11667 = split_615[14]
        getitem_11684 = split_615[15];  split_615 = None
        cat_302 = torch.ops.aten.cat.default([getitem_11429, getitem_11446, getitem_11463, getitem_11480, getitem_11497, getitem_11514, getitem_11531, getitem_11548, getitem_11565, getitem_11582, getitem_11599, getitem_11616, getitem_11633, getitem_11650, getitem_11667, getitem_11684]);  getitem_11429 = getitem_11446 = getitem_11463 = getitem_11480 = getitem_11497 = getitem_11514 = getitem_11531 = getitem_11548 = getitem_11565 = getitem_11582 = getitem_11599 = getitem_11616 = getitem_11633 = getitem_11650 = getitem_11667 = getitem_11684 = None
        reduce_scatter_tensor_119 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_302, 'sum', 16, '1025');  cat_302 = None
        wait_tensor_695 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_119);  reduce_scatter_tensor_119 = None
        index_put_68 = torch.ops.aten.index_put.default(full_396, [getitem_1892], add_1900, True);  full_396 = getitem_1892 = add_1900 = None
        slice_210 = torch.ops.aten.slice.Tensor(index_put_68, 0, 0, add_1901);  index_put_68 = add_1901 = None
        all_to_all_single_95 = torch.ops._c10d_functional.all_to_all_single.default(slice_210, [_local_scalar_dense_272, _local_scalar_dense_273, _local_scalar_dense_274, _local_scalar_dense_275, _local_scalar_dense_276, _local_scalar_dense_277, _local_scalar_dense_278, _local_scalar_dense_279], [_local_scalar_dense_280, _local_scalar_dense_281, _local_scalar_dense_282, _local_scalar_dense_283, _local_scalar_dense_284, _local_scalar_dense_285, _local_scalar_dense_286, _local_scalar_dense_287], '1033');  slice_210 = _local_scalar_dense_272 = _local_scalar_dense_273 = _local_scalar_dense_274 = _local_scalar_dense_275 = _local_scalar_dense_276 = _local_scalar_dense_277 = _local_scalar_dense_278 = _local_scalar_dense_279 = _local_scalar_dense_280 = _local_scalar_dense_281 = _local_scalar_dense_282 = _local_scalar_dense_283 = _local_scalar_dense_284 = _local_scalar_dense_285 = _local_scalar_dense_286 = _local_scalar_dense_287 = None
        wait_tensor_696 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_95);  all_to_all_single_95 = None
        index_put_69 = torch.ops.aten.index_put.default(full_default_52, [div_87], wait_tensor_696, True);  div_87 = wait_tensor_696 = None
        add_1905 = torch.ops.aten.add.Tensor(add_1897, index_put_69);  add_1897 = index_put_69 = None
        mul_1575 = torch.ops.aten.mul.Tensor(view_1935, 1.0);  view_1935 = None
        scatter_add_8 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_1889, mul_1575);  getitem_1889 = mul_1575 = None
        convert_element_type_983 = torch.ops.prims.convert_element_type.default(mm_147, torch.float32);  mm_147 = None
        sub_408 = torch.ops.aten.sub.Tensor(convert_element_type_983, amax_17);  convert_element_type_983 = amax_17 = None
        exp_52 = torch.ops.aten.exp.default(sub_408);  sub_408 = None
        div_86 = torch.ops.aten.div.Tensor(exp_52, sum_69);  exp_52 = sum_69 = None
        mul_1576 = torch.ops.aten.mul.Tensor(scatter_add_8, div_86);  scatter_add_8 = None
        sum_171 = torch.ops.aten.sum.dim_IntList(mul_1576, [1], True)
        neg_79 = torch.ops.aten.neg.default(div_86);  div_86 = None
        fma_8 = torch.ops.prims.fma.default(neg_79, sum_171, mul_1576);  neg_79 = sum_171 = mul_1576 = None
        convert_element_type_2076 = torch.ops.prims.convert_element_type.default(fma_8, torch.bfloat16);  fma_8 = None
        permute_832 = torch.ops.aten.permute.default(convert_element_type_2076, [1, 0])
        mm_352 = torch.ops.aten.mm.default(permute_832, view_1197);  permute_832 = view_1197 = None
        convert_element_type_980 = torch.ops.prims.convert_element_type.default(primals_303, torch.bfloat16);  primals_303 = None
        all_gather_into_tensor_307 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_980, 128, '0');  convert_element_type_980 = None
        wait_tensor_375 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_307);  all_gather_into_tensor_307 = None
        slice_111 = torch.ops.aten.slice.Tensor(wait_tensor_375, 0, 0, 64);  wait_tensor_375 = None
        permute_274 = torch.ops.aten.permute.default(slice_111, [1, 0]);  slice_111 = None
        permute_834 = torch.ops.aten.permute.default(permute_274, [1, 0]);  permute_274 = None
        mm_353 = torch.ops.aten.mm.default(convert_element_type_2076, permute_834);  convert_element_type_2076 = permute_834 = None
        add_1906 = torch.ops.aten.add.Tensor(add_1905, mm_353);  add_1905 = mm_353 = None
        convert_element_type_2081 = torch.ops.prims.convert_element_type.default(mm_352, torch.float32);  mm_352 = None
        split_631 = torch.ops.aten.split.Tensor(convert_element_type_2081, 1);  convert_element_type_2081 = None
        getitem_11685 = split_631[0]
        getitem_11686 = split_631[1]
        getitem_11687 = split_631[2]
        getitem_11688 = split_631[3]
        getitem_11689 = split_631[4]
        getitem_11690 = split_631[5]
        getitem_11691 = split_631[6]
        getitem_11692 = split_631[7]
        getitem_11693 = split_631[8]
        getitem_11694 = split_631[9]
        getitem_11695 = split_631[10]
        getitem_11696 = split_631[11]
        getitem_11697 = split_631[12]
        getitem_11698 = split_631[13]
        getitem_11699 = split_631[14]
        getitem_11700 = split_631[15]
        getitem_11701 = split_631[16]
        getitem_11702 = split_631[17]
        getitem_11703 = split_631[18]
        getitem_11704 = split_631[19]
        getitem_11705 = split_631[20]
        getitem_11706 = split_631[21]
        getitem_11707 = split_631[22]
        getitem_11708 = split_631[23]
        getitem_11709 = split_631[24]
        getitem_11710 = split_631[25]
        getitem_11711 = split_631[26]
        getitem_11712 = split_631[27]
        getitem_11713 = split_631[28]
        getitem_11714 = split_631[29]
        getitem_11715 = split_631[30]
        getitem_11716 = split_631[31]
        getitem_11717 = split_631[32]
        getitem_11718 = split_631[33]
        getitem_11719 = split_631[34]
        getitem_11720 = split_631[35]
        getitem_11721 = split_631[36]
        getitem_11722 = split_631[37]
        getitem_11723 = split_631[38]
        getitem_11724 = split_631[39]
        getitem_11725 = split_631[40]
        getitem_11726 = split_631[41]
        getitem_11727 = split_631[42]
        getitem_11728 = split_631[43]
        getitem_11729 = split_631[44]
        getitem_11730 = split_631[45]
        getitem_11731 = split_631[46]
        getitem_11732 = split_631[47]
        getitem_11733 = split_631[48]
        getitem_11734 = split_631[49]
        getitem_11735 = split_631[50]
        getitem_11736 = split_631[51]
        getitem_11737 = split_631[52]
        getitem_11738 = split_631[53]
        getitem_11739 = split_631[54]
        getitem_11740 = split_631[55]
        getitem_11741 = split_631[56]
        getitem_11742 = split_631[57]
        getitem_11743 = split_631[58]
        getitem_11744 = split_631[59]
        getitem_11745 = split_631[60]
        getitem_11746 = split_631[61]
        getitem_11747 = split_631[62]
        getitem_11748 = split_631[63];  split_631 = None
        cat_303 = torch.ops.aten.cat.default([getitem_11685, getitem_11686, getitem_11687, getitem_11688, getitem_11689, getitem_11690, getitem_11691, getitem_11692, getitem_11693, getitem_11694, getitem_11695, getitem_11696, getitem_11697, getitem_11698, getitem_11699, getitem_11700, getitem_11701, getitem_11702, getitem_11703, getitem_11704, getitem_11705, getitem_11706, getitem_11707, getitem_11708, getitem_11709, getitem_11710, getitem_11711, getitem_11712, getitem_11713, getitem_11714, getitem_11715, getitem_11716, getitem_11717, getitem_11718, getitem_11719, getitem_11720, getitem_11721, getitem_11722, getitem_11723, getitem_11724, getitem_11725, getitem_11726, getitem_11727, getitem_11728, getitem_11729, getitem_11730, getitem_11731, getitem_11732, getitem_11733, getitem_11734, getitem_11735, getitem_11736, getitem_11737, getitem_11738, getitem_11739, getitem_11740, getitem_11741, getitem_11742, getitem_11743, getitem_11744, getitem_11745, getitem_11746, getitem_11747, getitem_11748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_11685 = getitem_11686 = getitem_11687 = getitem_11688 = getitem_11689 = getitem_11690 = getitem_11691 = getitem_11692 = getitem_11693 = getitem_11694 = getitem_11695 = getitem_11696 = getitem_11697 = getitem_11698 = getitem_11699 = getitem_11700 = getitem_11701 = getitem_11702 = getitem_11703 = getitem_11704 = getitem_11705 = getitem_11706 = getitem_11707 = getitem_11708 = getitem_11709 = getitem_11710 = getitem_11711 = getitem_11712 = getitem_11713 = getitem_11714 = getitem_11715 = getitem_11716 = getitem_11717 = getitem_11718 = getitem_11719 = getitem_11720 = getitem_11721 = getitem_11722 = getitem_11723 = getitem_11724 = getitem_11725 = getitem_11726 = getitem_11727 = getitem_11728 = getitem_11729 = getitem_11730 = getitem_11731 = getitem_11732 = getitem_11733 = getitem_11734 = getitem_11735 = getitem_11736 = getitem_11737 = getitem_11738 = getitem_11739 = getitem_11740 = getitem_11741 = getitem_11742 = getitem_11743 = getitem_11744 = getitem_11745 = getitem_11746 = getitem_11747 = getitem_11748 = None
        reduce_scatter_tensor_120 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_303, 'avg', 128, '0');  cat_303 = None
        wait_tensor_697 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_120);  reduce_scatter_tensor_120 = None
        view_1937 = torch.ops.aten.view.default(add_1906, [2, 4096, 2048]);  add_1906 = None
        convert_element_type_2082 = torch.ops.prims.convert_element_type.default(view_1937, torch.float32);  view_1937 = None
        convert_element_type_977 = torch.ops.prims.convert_element_type.default(primals_301, torch.bfloat16);  primals_301 = None
        all_gather_into_tensor_306 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_977, 128, '0');  convert_element_type_977 = None
        wait_tensor_374 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_306);  all_gather_into_tensor_306 = None
        convert_element_type_2084 = torch.ops.prims.convert_element_type.default(wait_tensor_374, torch.float32);  wait_tensor_374 = None
        mul_1577 = torch.ops.aten.mul.Tensor(convert_element_type_2082, convert_element_type_2084);  convert_element_type_2084 = None
        convert_element_type_978 = torch.ops.prims.convert_element_type.default(add_1164, torch.float32);  add_1164 = None
        mul_848 = torch.ops.aten.mul.Tensor(convert_element_type_978, rsqrt_56);  convert_element_type_978 = None
        mul_1579 = torch.ops.aten.mul.Tensor(mul_848, mul_1577)
        sum_172 = torch.ops.aten.sum.dim_IntList(mul_1579, [2], True);  mul_1579 = None
        div_183 = torch.ops.aten.div.Tensor(mul_848, 2048)
        mul_1580 = torch.ops.aten.mul.Tensor(div_183, sum_172);  div_183 = sum_172 = None
        sub_676 = torch.ops.aten.sub.Tensor(mul_1577, mul_1580);  mul_1577 = mul_1580 = None
        mul_1581 = torch.ops.aten.mul.Tensor(sub_676, rsqrt_56);  sub_676 = rsqrt_56 = None
        mul_1582 = torch.ops.aten.mul.Tensor(convert_element_type_2082, mul_848);  convert_element_type_2082 = mul_848 = None
        sum_173 = torch.ops.aten.sum.dim_IntList(mul_1582, [0, 1]);  mul_1582 = None
        convert_element_type_2085 = torch.ops.prims.convert_element_type.default(mul_1581, torch.bfloat16);  mul_1581 = None
        add_1907 = torch.ops.aten.add.Tensor(add_1894, convert_element_type_2085);  add_1894 = convert_element_type_2085 = None
        convert_element_type_default_57 = torch.ops.prims.convert_element_type.default(sum_173, torch.float32);  sum_173 = None
        reduce_scatter_tensor_121 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_57, 'avg', 128, '0');  convert_element_type_default_57 = None
        wait_tensor_698 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_121);  reduce_scatter_tensor_121 = None
        view_1938 = torch.ops.aten.view.default(add_1907, [8192, 2048])
        permute_836 = torch.ops.aten.permute.default(view_1938, [1, 0])
        permute_272 = torch.ops.aten.permute.default(getitem_1885, [0, 2, 1, 3])
        view_1192 = torch.ops.aten.view.default(permute_272, [2, 4096, -1]);  permute_272 = None
        view_1194 = torch.ops.aten.view.default(view_1192, [8192, 2048]);  view_1192 = None
        mm_354 = torch.ops.aten.mm.default(permute_836, view_1194);  permute_836 = view_1194 = None
        convert_element_type_974 = torch.ops.prims.convert_element_type.default(primals_300, torch.bfloat16);  primals_300 = None
        all_gather_into_tensor_305 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_974, 128, '0');  convert_element_type_974 = None
        wait_tensor_373 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_305);  all_gather_into_tensor_305 = None
        permute_273 = torch.ops.aten.permute.default(wait_tensor_373, [1, 0]);  wait_tensor_373 = None
        permute_838 = torch.ops.aten.permute.default(permute_273, [1, 0]);  permute_273 = None
        mm_355 = torch.ops.aten.mm.default(view_1938, permute_838);  view_1938 = permute_838 = None
        view_1939 = torch.ops.aten.view.default(mm_355, [2, 4096, 2048]);  mm_355 = None
        convert_element_type_2092 = torch.ops.prims.convert_element_type.default(mm_354, torch.float32);  mm_354 = None
        reduce_scatter_tensor_122 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2092, 'avg', 128, '0');  convert_element_type_2092 = None
        wait_tensor_699 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_122);  reduce_scatter_tensor_122 = None
        view_1940 = torch.ops.aten.view.default(view_1939, [2, 4096, 16, 128]);  view_1939 = None
        permute_840 = torch.ops.aten.permute.default(view_1940, [0, 2, 1, 3]);  view_1940 = None
        fw_graph8 = self.fw_graph8
        joint_graph8 = self.joint_graph8
        mask_graph8 = self.mask_graph8
        flex_attention_backward_8 = torch.ops.higher_order.flex_attention_backward(permute_269, permute_270, permute_271, getitem_1885, getitem_1886, permute_840, None, fw_graph8, joint_graph8, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph8), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_269 = permute_270 = permute_271 = getitem_1885 = getitem_1886 = permute_840 = fw_graph8 = joint_graph8 = mask_graph8 = None
        getitem_11749 = flex_attention_backward_8[0]
        getitem_11750 = flex_attention_backward_8[1]
        getitem_11751 = flex_attention_backward_8[2];  flex_attention_backward_8 = None
        permute_841 = torch.ops.aten.permute.default(getitem_11751, [0, 2, 1, 3]);  getitem_11751 = None
        permute_842 = torch.ops.aten.permute.default(getitem_11750, [0, 2, 1, 3]);  getitem_11750 = None
        permute_843 = torch.ops.aten.permute.default(getitem_11749, [0, 2, 1, 3]);  getitem_11749 = None
        slice_212 = torch.ops.aten.slice.Tensor(permute_842, 3, 0, 128)
        slice_213 = torch.ops.aten.slice.Tensor(permute_842, 3, 128, 192);  permute_842 = None
        sum_174 = torch.ops.aten.sum.dim_IntList(slice_213, [2], True);  slice_213 = None
        cat_304 = torch.ops.aten.cat.default([slice_212, permute_841], 3);  slice_212 = permute_841 = None
        view_1941 = torch.ops.aten.view.default(cat_304, [2, 4096, 4096]);  cat_304 = None
        view_1942 = torch.ops.aten.view.default(view_1941, [8192, 4096]);  view_1941 = None
        permute_844 = torch.ops.aten.permute.default(view_1942, [1, 0])
        mm_356 = torch.ops.aten.mm.default(permute_844, view_1189);  permute_844 = view_1189 = None
        convert_element_type_971 = torch.ops.prims.convert_element_type.default(primals_299, torch.bfloat16);  primals_299 = None
        all_gather_into_tensor_304 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_971, 128, '0');  convert_element_type_971 = None
        wait_tensor_372 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_304);  all_gather_into_tensor_304 = None
        permute_268 = torch.ops.aten.permute.default(wait_tensor_372, [1, 0]);  wait_tensor_372 = None
        permute_846 = torch.ops.aten.permute.default(permute_268, [1, 0]);  permute_268 = None
        mm_357 = torch.ops.aten.mm.default(view_1942, permute_846);  view_1942 = permute_846 = None
        view_1943 = torch.ops.aten.view.default(mm_357, [2, 4096, 512]);  mm_357 = None
        convert_element_type_2097 = torch.ops.prims.convert_element_type.default(mm_356, torch.float32);  mm_356 = None
        reduce_scatter_tensor_123 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2097, 'avg', 128, '0');  convert_element_type_2097 = None
        wait_tensor_700 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_123);  reduce_scatter_tensor_123 = None
        convert_element_type_2098 = torch.ops.prims.convert_element_type.default(view_1943, torch.float32);  view_1943 = None
        convert_element_type_968 = torch.ops.prims.convert_element_type.default(primals_298, torch.bfloat16);  primals_298 = None
        all_gather_into_tensor_303 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_968, 128, '0');  convert_element_type_968 = None
        wait_tensor_371 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_303);  all_gather_into_tensor_303 = None
        convert_element_type_2100 = torch.ops.prims.convert_element_type.default(wait_tensor_371, torch.float32);  wait_tensor_371 = None
        mul_1583 = torch.ops.aten.mul.Tensor(convert_element_type_2098, convert_element_type_2100);  convert_element_type_2100 = None
        convert_element_type_969 = torch.ops.prims.convert_element_type.default(getitem_1881, torch.float32);  getitem_1881 = None
        mul_846 = torch.ops.aten.mul.Tensor(convert_element_type_969, rsqrt_55);  convert_element_type_969 = None
        mul_1585 = torch.ops.aten.mul.Tensor(mul_846, mul_1583)
        sum_175 = torch.ops.aten.sum.dim_IntList(mul_1585, [2], True);  mul_1585 = None
        div_184 = torch.ops.aten.div.Tensor(mul_846, 512)
        mul_1586 = torch.ops.aten.mul.Tensor(div_184, sum_175);  div_184 = sum_175 = None
        sub_677 = torch.ops.aten.sub.Tensor(mul_1583, mul_1586);  mul_1583 = mul_1586 = None
        mul_1587 = torch.ops.aten.mul.Tensor(sub_677, rsqrt_55);  sub_677 = rsqrt_55 = None
        mul_1588 = torch.ops.aten.mul.Tensor(convert_element_type_2098, mul_846);  convert_element_type_2098 = mul_846 = None
        sum_176 = torch.ops.aten.sum.dim_IntList(mul_1588, [0, 1]);  mul_1588 = None
        convert_element_type_2101 = torch.ops.prims.convert_element_type.default(mul_1587, torch.bfloat16);  mul_1587 = None
        convert_element_type_default_56 = torch.ops.prims.convert_element_type.default(sum_176, torch.float32);  sum_176 = None
        reduce_scatter_tensor_124 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_56, 'avg', 128, '0');  convert_element_type_default_56 = None
        wait_tensor_701 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_124);  reduce_scatter_tensor_124 = None
        convert_element_type_2104 = torch.ops.prims.convert_element_type.default(sum_174, torch.float32);  sum_174 = None
        view_1944 = torch.ops.aten.view.default(convert_element_type_2104, [2, 4096, 1, 32, 2]);  convert_element_type_2104 = None
        view_as_complex_70 = torch.ops.aten.view_as_complex.default(view_1944);  view_1944 = None
        mul_1589 = torch.ops.aten.mul.Tensor(view_as_complex_70, clone_9);  view_as_complex_70 = None
        view_as_real_70 = torch.ops.aten.view_as_real.default(mul_1589);  mul_1589 = None
        view_1945 = torch.ops.aten.view.default(view_as_real_70, [2, 4096, 1, 64]);  view_as_real_70 = None
        convert_element_type_2105 = torch.ops.prims.convert_element_type.default(view_1945, torch.bfloat16);  view_1945 = None
        squeeze_34 = torch.ops.aten.squeeze.dim(convert_element_type_2105, 2);  convert_element_type_2105 = None
        cat_305 = torch.ops.aten.cat.default([convert_element_type_2101, squeeze_34], 2);  convert_element_type_2101 = squeeze_34 = None
        view_1946 = torch.ops.aten.view.default(cat_305, [8192, 576]);  cat_305 = None
        permute_848 = torch.ops.aten.permute.default(view_1946, [1, 0])
        mm_358 = torch.ops.aten.mm.default(permute_848, view_1175);  permute_848 = None
        convert_element_type_963 = torch.ops.prims.convert_element_type.default(primals_297, torch.bfloat16);  primals_297 = None
        all_gather_into_tensor_302 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_963, 128, '0');  convert_element_type_963 = None
        wait_tensor_370 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_302);  all_gather_into_tensor_302 = None
        slice_109 = torch.ops.aten.slice.Tensor(wait_tensor_370, 0, 0, 576);  wait_tensor_370 = None
        permute_267 = torch.ops.aten.permute.default(slice_109, [1, 0]);  slice_109 = None
        permute_850 = torch.ops.aten.permute.default(permute_267, [1, 0]);  permute_267 = None
        mm_359 = torch.ops.aten.mm.default(view_1946, permute_850);  view_1946 = permute_850 = None
        view_1947 = torch.ops.aten.view.default(mm_359, [2, 4096, 2048]);  mm_359 = None
        convert_element_type_2110 = torch.ops.prims.convert_element_type.default(mm_358, torch.float32);  mm_358 = None
        split_632 = torch.ops.aten.split.Tensor(convert_element_type_2110, 5);  convert_element_type_2110 = None
        getitem_11753 = split_632[0]
        getitem_11754 = split_632[1]
        getitem_11755 = split_632[2]
        getitem_11756 = split_632[3]
        getitem_11757 = split_632[4]
        getitem_11758 = split_632[5]
        getitem_11759 = split_632[6]
        getitem_11760 = split_632[7]
        getitem_11761 = split_632[8]
        getitem_11762 = split_632[9]
        getitem_11763 = split_632[10]
        getitem_11764 = split_632[11]
        getitem_11765 = split_632[12]
        getitem_11766 = split_632[13]
        getitem_11767 = split_632[14]
        getitem_11768 = split_632[15]
        getitem_11769 = split_632[16]
        getitem_11770 = split_632[17]
        getitem_11771 = split_632[18]
        getitem_11772 = split_632[19]
        getitem_11773 = split_632[20]
        getitem_11774 = split_632[21]
        getitem_11775 = split_632[22]
        getitem_11776 = split_632[23]
        getitem_11777 = split_632[24]
        getitem_11778 = split_632[25]
        getitem_11779 = split_632[26]
        getitem_11780 = split_632[27]
        getitem_11781 = split_632[28]
        getitem_11782 = split_632[29]
        getitem_11783 = split_632[30]
        getitem_11784 = split_632[31]
        getitem_11785 = split_632[32]
        getitem_11786 = split_632[33]
        getitem_11787 = split_632[34]
        getitem_11788 = split_632[35]
        getitem_11789 = split_632[36]
        getitem_11790 = split_632[37]
        getitem_11791 = split_632[38]
        getitem_11792 = split_632[39]
        getitem_11793 = split_632[40]
        getitem_11794 = split_632[41]
        getitem_11795 = split_632[42]
        getitem_11796 = split_632[43]
        getitem_11797 = split_632[44]
        getitem_11798 = split_632[45]
        getitem_11799 = split_632[46]
        getitem_11800 = split_632[47]
        getitem_11801 = split_632[48]
        getitem_11802 = split_632[49]
        getitem_11803 = split_632[50]
        getitem_11804 = split_632[51]
        getitem_11805 = split_632[52]
        getitem_11806 = split_632[53]
        getitem_11807 = split_632[54]
        getitem_11808 = split_632[55]
        getitem_11809 = split_632[56]
        getitem_11810 = split_632[57]
        getitem_11811 = split_632[58]
        getitem_11812 = split_632[59]
        getitem_11813 = split_632[60]
        getitem_11814 = split_632[61]
        getitem_11815 = split_632[62]
        getitem_11816 = split_632[63]
        getitem_11817 = split_632[64]
        getitem_11818 = split_632[65]
        getitem_11819 = split_632[66]
        getitem_11820 = split_632[67]
        getitem_11821 = split_632[68]
        getitem_11822 = split_632[69]
        getitem_11823 = split_632[70]
        getitem_11824 = split_632[71]
        getitem_11825 = split_632[72]
        getitem_11826 = split_632[73]
        getitem_11827 = split_632[74]
        getitem_11828 = split_632[75]
        getitem_11829 = split_632[76]
        getitem_11830 = split_632[77]
        getitem_11831 = split_632[78]
        getitem_11832 = split_632[79]
        getitem_11833 = split_632[80]
        getitem_11834 = split_632[81]
        getitem_11835 = split_632[82]
        getitem_11836 = split_632[83]
        getitem_11837 = split_632[84]
        getitem_11838 = split_632[85]
        getitem_11839 = split_632[86]
        getitem_11840 = split_632[87]
        getitem_11841 = split_632[88]
        getitem_11842 = split_632[89]
        getitem_11843 = split_632[90]
        getitem_11844 = split_632[91]
        getitem_11845 = split_632[92]
        getitem_11846 = split_632[93]
        getitem_11847 = split_632[94]
        getitem_11848 = split_632[95]
        getitem_11849 = split_632[96]
        getitem_11850 = split_632[97]
        getitem_11851 = split_632[98]
        getitem_11852 = split_632[99]
        getitem_11853 = split_632[100]
        getitem_11854 = split_632[101]
        getitem_11855 = split_632[102]
        getitem_11856 = split_632[103]
        getitem_11857 = split_632[104]
        getitem_11858 = split_632[105]
        getitem_11859 = split_632[106]
        getitem_11860 = split_632[107]
        getitem_11861 = split_632[108]
        getitem_11862 = split_632[109]
        getitem_11863 = split_632[110]
        getitem_11864 = split_632[111]
        getitem_11865 = split_632[112]
        getitem_11866 = split_632[113]
        getitem_11867 = split_632[114]
        getitem_11868 = split_632[115];  split_632 = None
        constant_pad_nd_680 = torch.ops.aten.constant_pad_nd.default(getitem_11868, [0, 0, 0, 4], 0.0);  getitem_11868 = None
        cat_306 = torch.ops.aten.cat.default([getitem_11753, getitem_11754, getitem_11755, getitem_11756, getitem_11757, getitem_11758, getitem_11759, getitem_11760, getitem_11761, getitem_11762, getitem_11763, getitem_11764, getitem_11765, getitem_11766, getitem_11767, getitem_11768, getitem_11769, getitem_11770, getitem_11771, getitem_11772, getitem_11773, getitem_11774, getitem_11775, getitem_11776, getitem_11777, getitem_11778, getitem_11779, getitem_11780, getitem_11781, getitem_11782, getitem_11783, getitem_11784, getitem_11785, getitem_11786, getitem_11787, getitem_11788, getitem_11789, getitem_11790, getitem_11791, getitem_11792, getitem_11793, getitem_11794, getitem_11795, getitem_11796, getitem_11797, getitem_11798, getitem_11799, getitem_11800, getitem_11801, getitem_11802, getitem_11803, getitem_11804, getitem_11805, getitem_11806, getitem_11807, getitem_11808, getitem_11809, getitem_11810, getitem_11811, getitem_11812, getitem_11813, getitem_11814, getitem_11815, getitem_11816, getitem_11817, getitem_11818, getitem_11819, getitem_11820, getitem_11821, getitem_11822, getitem_11823, getitem_11824, getitem_11825, getitem_11826, getitem_11827, getitem_11828, getitem_11829, getitem_11830, getitem_11831, getitem_11832, getitem_11833, getitem_11834, getitem_11835, getitem_11836, getitem_11837, getitem_11838, getitem_11839, getitem_11840, getitem_11841, getitem_11842, getitem_11843, getitem_11844, getitem_11845, getitem_11846, getitem_11847, getitem_11848, getitem_11849, getitem_11850, getitem_11851, getitem_11852, getitem_11853, getitem_11854, getitem_11855, getitem_11856, getitem_11857, getitem_11858, getitem_11859, getitem_11860, getitem_11861, getitem_11862, getitem_11863, getitem_11864, getitem_11865, getitem_11866, getitem_11867, constant_pad_nd_680, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_11753 = getitem_11754 = getitem_11755 = getitem_11756 = getitem_11757 = getitem_11758 = getitem_11759 = getitem_11760 = getitem_11761 = getitem_11762 = getitem_11763 = getitem_11764 = getitem_11765 = getitem_11766 = getitem_11767 = getitem_11768 = getitem_11769 = getitem_11770 = getitem_11771 = getitem_11772 = getitem_11773 = getitem_11774 = getitem_11775 = getitem_11776 = getitem_11777 = getitem_11778 = getitem_11779 = getitem_11780 = getitem_11781 = getitem_11782 = getitem_11783 = getitem_11784 = getitem_11785 = getitem_11786 = getitem_11787 = getitem_11788 = getitem_11789 = getitem_11790 = getitem_11791 = getitem_11792 = getitem_11793 = getitem_11794 = getitem_11795 = getitem_11796 = getitem_11797 = getitem_11798 = getitem_11799 = getitem_11800 = getitem_11801 = getitem_11802 = getitem_11803 = getitem_11804 = getitem_11805 = getitem_11806 = getitem_11807 = getitem_11808 = getitem_11809 = getitem_11810 = getitem_11811 = getitem_11812 = getitem_11813 = getitem_11814 = getitem_11815 = getitem_11816 = getitem_11817 = getitem_11818 = getitem_11819 = getitem_11820 = getitem_11821 = getitem_11822 = getitem_11823 = getitem_11824 = getitem_11825 = getitem_11826 = getitem_11827 = getitem_11828 = getitem_11829 = getitem_11830 = getitem_11831 = getitem_11832 = getitem_11833 = getitem_11834 = getitem_11835 = getitem_11836 = getitem_11837 = getitem_11838 = getitem_11839 = getitem_11840 = getitem_11841 = getitem_11842 = getitem_11843 = getitem_11844 = getitem_11845 = getitem_11846 = getitem_11847 = getitem_11848 = getitem_11849 = getitem_11850 = getitem_11851 = getitem_11852 = getitem_11853 = getitem_11854 = getitem_11855 = getitem_11856 = getitem_11857 = getitem_11858 = getitem_11859 = getitem_11860 = getitem_11861 = getitem_11862 = getitem_11863 = getitem_11864 = getitem_11865 = getitem_11866 = getitem_11867 = constant_pad_nd_680 = None
        reduce_scatter_tensor_125 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_306, 'avg', 128, '0');  cat_306 = None
        wait_tensor_702 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_125);  reduce_scatter_tensor_125 = None
        slice_214 = torch.ops.aten.slice.Tensor(permute_843, 3, 0, 128)
        slice_215 = torch.ops.aten.slice.Tensor(permute_843, 3, 128, 192);  permute_843 = None
        convert_element_type_2111 = torch.ops.prims.convert_element_type.default(slice_215, torch.float32);  slice_215 = None
        view_1948 = torch.ops.aten.view.default(convert_element_type_2111, [2, 4096, 16, 32, 2]);  convert_element_type_2111 = None
        view_as_complex_71 = torch.ops.aten.view_as_complex.default(view_1948);  view_1948 = None
        mul_1590 = torch.ops.aten.mul.Tensor(view_as_complex_71, clone_9);  view_as_complex_71 = None
        view_as_real_71 = torch.ops.aten.view_as_real.default(mul_1590);  mul_1590 = None
        view_1949 = torch.ops.aten.view.default(view_as_real_71, [2, 4096, 16, 64]);  view_as_real_71 = None
        convert_element_type_2112 = torch.ops.prims.convert_element_type.default(view_1949, torch.bfloat16);  view_1949 = None
        cat_307 = torch.ops.aten.cat.default([slice_214, convert_element_type_2112], 3);  slice_214 = convert_element_type_2112 = None
        view_1950 = torch.ops.aten.view.default(cat_307, [2, 4096, 3072]);  cat_307 = None
        view_1951 = torch.ops.aten.view.default(view_1950, [8192, 3072]);  view_1950 = None
        permute_852 = torch.ops.aten.permute.default(view_1951, [1, 0])
        mm_360 = torch.ops.aten.mm.default(permute_852, view_1175);  permute_852 = view_1175 = None
        convert_element_type_958 = torch.ops.prims.convert_element_type.default(primals_296, torch.bfloat16);  primals_296 = None
        all_gather_into_tensor_301 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_958, 128, '0');  convert_element_type_958 = None
        wait_tensor_369 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_301);  all_gather_into_tensor_301 = None
        permute_266 = torch.ops.aten.permute.default(wait_tensor_369, [1, 0]);  wait_tensor_369 = None
        permute_854 = torch.ops.aten.permute.default(permute_266, [1, 0]);  permute_266 = None
        mm_361 = torch.ops.aten.mm.default(view_1951, permute_854);  view_1951 = permute_854 = None
        view_1952 = torch.ops.aten.view.default(mm_361, [2, 4096, 2048]);  mm_361 = None
        add_1908 = torch.ops.aten.add.Tensor(view_1947, view_1952);  view_1947 = view_1952 = None
        convert_element_type_2117 = torch.ops.prims.convert_element_type.default(mm_360, torch.float32);  mm_360 = None
        reduce_scatter_tensor_126 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2117, 'avg', 128, '0');  convert_element_type_2117 = None
        wait_tensor_703 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_126);  reduce_scatter_tensor_126 = None
        convert_element_type_2118 = torch.ops.prims.convert_element_type.default(add_1908, torch.float32);  add_1908 = None
        convert_element_type_955 = torch.ops.prims.convert_element_type.default(primals_295, torch.bfloat16);  primals_295 = None
        all_gather_into_tensor_300 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_955, 128, '0');  convert_element_type_955 = None
        wait_tensor_368 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_300);  all_gather_into_tensor_300 = None
        convert_element_type_2120 = torch.ops.prims.convert_element_type.default(wait_tensor_368, torch.float32);  wait_tensor_368 = None
        mul_1591 = torch.ops.aten.mul.Tensor(convert_element_type_2118, convert_element_type_2120);  convert_element_type_2120 = None
        convert_element_type_956 = torch.ops.prims.convert_element_type.default(add_1161, torch.float32);  add_1161 = None
        mul_842 = torch.ops.aten.mul.Tensor(convert_element_type_956, rsqrt_54);  convert_element_type_956 = None
        mul_1593 = torch.ops.aten.mul.Tensor(mul_842, mul_1591)
        sum_177 = torch.ops.aten.sum.dim_IntList(mul_1593, [2], True);  mul_1593 = None
        div_185 = torch.ops.aten.div.Tensor(mul_842, 2048)
        mul_1594 = torch.ops.aten.mul.Tensor(div_185, sum_177);  div_185 = sum_177 = None
        sub_678 = torch.ops.aten.sub.Tensor(mul_1591, mul_1594);  mul_1591 = mul_1594 = None
        mul_1595 = torch.ops.aten.mul.Tensor(sub_678, rsqrt_54);  sub_678 = rsqrt_54 = None
        mul_1596 = torch.ops.aten.mul.Tensor(convert_element_type_2118, mul_842);  convert_element_type_2118 = mul_842 = None
        sum_178 = torch.ops.aten.sum.dim_IntList(mul_1596, [0, 1]);  mul_1596 = None
        convert_element_type_2121 = torch.ops.prims.convert_element_type.default(mul_1595, torch.bfloat16);  mul_1595 = None
        add_1909 = torch.ops.aten.add.Tensor(add_1907, convert_element_type_2121);  add_1907 = convert_element_type_2121 = None
        convert_element_type_default_55 = torch.ops.prims.convert_element_type.default(sum_178, torch.float32);  sum_178 = None
        reduce_scatter_tensor_127 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_55, 'avg', 128, '0');  convert_element_type_default_55 = None
        wait_tensor_704 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_127);  reduce_scatter_tensor_127 = None
        view_1953 = torch.ops.aten.view.default(add_1909, [8192, 2048])
        unsqueeze_62 = torch.ops.aten.unsqueeze.default(view_1953, 1)
        convert_element_type_2124 = torch.ops.prims.convert_element_type.default(unsqueeze_62, torch.float32);  unsqueeze_62 = None
        bmm_44 = torch.ops.aten.bmm.default(permute_856, convert_element_type_2124);  permute_856 = None
        bmm_45 = torch.ops.aten.bmm.default(convert_element_type_2124, permute_857);  convert_element_type_2124 = permute_857 = None
        convert_element_type_2125 = torch.ops.prims.convert_element_type.default(bmm_44, torch.bfloat16);  bmm_44 = None
        view_1954 = torch.ops.aten.view.default(bmm_45, [8192, 6]);  bmm_45 = None
        view_1955 = torch.ops.aten.view.default(convert_element_type_2125, [49152, 2048]);  convert_element_type_2125 = None
        index_70 = torch.ops.aten.index.Tensor(view_1955, [getitem_1781]);  view_1955 = getitem_1781 = None
        permute_858 = torch.ops.aten.permute.default(view_1953, [1, 0])
        mm_362 = torch.ops.aten.mm.default(permute_858, mul_839);  permute_858 = mul_839 = None
        convert_element_type_950 = torch.ops.prims.convert_element_type.default(primals_294, torch.bfloat16);  primals_294 = None
        all_gather_into_tensor_299 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_950, 128, '0');  convert_element_type_950 = None
        wait_tensor_367 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_299);  all_gather_into_tensor_299 = None
        permute_265 = torch.ops.aten.permute.default(wait_tensor_367, [1, 0]);  wait_tensor_367 = None
        permute_860 = torch.ops.aten.permute.default(permute_265, [1, 0]);  permute_265 = None
        mm_363 = torch.ops.aten.mm.default(view_1953, permute_860);  view_1953 = permute_860 = None
        convert_element_type_2130 = torch.ops.prims.convert_element_type.default(mm_362, torch.float32);  mm_362 = None
        reduce_scatter_tensor_128 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2130, 'avg', 128, '0');  convert_element_type_2130 = None
        wait_tensor_705 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_128);  reduce_scatter_tensor_128 = None
        convert_element_type_945 = torch.ops.prims.convert_element_type.default(mm_140, torch.float32);  mm_140 = None
        neg_34 = torch.ops.aten.neg.default(convert_element_type_945)
        exp_51 = torch.ops.aten.exp.default(neg_34);  neg_34 = None
        add_1156 = torch.ops.aten.add.Tensor(exp_51, 1);  exp_51 = None
        div_85 = torch.ops.aten.div.Tensor(convert_element_type_945, add_1156)
        convert_element_type_946 = torch.ops.prims.convert_element_type.default(div_85, torch.bfloat16);  div_85 = None
        mul_1597 = torch.ops.aten.mul.Tensor(mm_363, convert_element_type_946);  convert_element_type_946 = None
        mul_1598 = torch.ops.aten.mul.Tensor(mm_363, mm_141);  mm_363 = mm_141 = None
        permute_862 = torch.ops.aten.permute.default(mul_1597, [1, 0])
        mm_364 = torch.ops.aten.mm.default(permute_862, view_1130);  permute_862 = None
        convert_element_type_947 = torch.ops.prims.convert_element_type.default(primals_293, torch.bfloat16);  primals_293 = None
        all_gather_into_tensor_298 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_947, 128, '0');  convert_element_type_947 = None
        wait_tensor_366 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_298);  all_gather_into_tensor_298 = None
        permute_264 = torch.ops.aten.permute.default(wait_tensor_366, [1, 0]);  wait_tensor_366 = None
        permute_864 = torch.ops.aten.permute.default(permute_264, [1, 0]);  permute_264 = None
        mm_365 = torch.ops.aten.mm.default(mul_1597, permute_864);  mul_1597 = permute_864 = None
        convert_element_type_2135 = torch.ops.prims.convert_element_type.default(mm_364, torch.float32);  mm_364 = None
        reduce_scatter_tensor_129 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2135, 'avg', 128, '0');  convert_element_type_2135 = None
        wait_tensor_706 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_129);  reduce_scatter_tensor_129 = None
        convert_element_type_2136 = torch.ops.prims.convert_element_type.default(mul_1598, torch.float32);  mul_1598 = None
        reciprocal_18 = torch.ops.aten.reciprocal.default(add_1156);  add_1156 = None
        mul_1599 = torch.ops.aten.mul.Tensor(reciprocal_18, 1);  reciprocal_18 = None
        mul_1600 = torch.ops.aten.mul.Tensor(convert_element_type_2136, mul_1599);  convert_element_type_2136 = None
        sub_679 = torch.ops.aten.sub.Tensor(1, mul_1599);  mul_1599 = None
        mul_1601 = torch.ops.aten.mul.Tensor(convert_element_type_945, sub_679);  convert_element_type_945 = sub_679 = None
        add_1911 = torch.ops.aten.add.Tensor(mul_1601, 1);  mul_1601 = None
        mul_1602 = torch.ops.aten.mul.Tensor(mul_1600, add_1911);  mul_1600 = add_1911 = None
        convert_element_type_2138 = torch.ops.prims.convert_element_type.default(mul_1602, torch.bfloat16);  mul_1602 = None
        permute_866 = torch.ops.aten.permute.default(convert_element_type_2138, [1, 0])
        mm_366 = torch.ops.aten.mm.default(permute_866, view_1130);  permute_866 = None
        convert_element_type_942 = torch.ops.prims.convert_element_type.default(primals_292, torch.bfloat16);  primals_292 = None
        all_gather_into_tensor_297 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_942, 128, '0');  convert_element_type_942 = None
        wait_tensor_365 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_297);  all_gather_into_tensor_297 = None
        permute_263 = torch.ops.aten.permute.default(wait_tensor_365, [1, 0]);  wait_tensor_365 = None
        permute_868 = torch.ops.aten.permute.default(permute_263, [1, 0]);  permute_263 = None
        mm_367 = torch.ops.aten.mm.default(convert_element_type_2138, permute_868);  convert_element_type_2138 = permute_868 = None
        add_1912 = torch.ops.aten.add.Tensor(mm_365, mm_367);  mm_365 = mm_367 = None
        convert_element_type_2143 = torch.ops.prims.convert_element_type.default(mm_366, torch.float32);  mm_366 = None
        reduce_scatter_tensor_130 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2143, 'avg', 128, '0');  convert_element_type_2143 = None
        wait_tensor_707 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_130);  reduce_scatter_tensor_130 = None
        all_to_all_single_96 = torch.ops._c10d_functional.all_to_all_single.default(index_70, [_local_scalar_dense_264, _local_scalar_dense_265, _local_scalar_dense_266, _local_scalar_dense_267, _local_scalar_dense_268, _local_scalar_dense_269, _local_scalar_dense_270, _local_scalar_dense_271], [_local_scalar_dense_256, _local_scalar_dense_257, _local_scalar_dense_258, _local_scalar_dense_259, _local_scalar_dense_260, _local_scalar_dense_261, _local_scalar_dense_262, _local_scalar_dense_263], '1033');  index_70 = None
        wait_tensor_708 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_96);  all_to_all_single_96 = None
        full_402 = torch.ops.aten.full.default([sym_size_int_65, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_65 = None
        slice_scatter_9 = torch.ops.aten.slice_scatter.default(full_402, wait_tensor_708, 0, 0, -1);  wait_tensor_708 = None
        index_71 = torch.ops.aten.index.Tensor(slice_scatter_9, [getitem_1782]);  slice_scatter_9 = None
        permute_870 = torch.ops.aten.permute.default(index_71, [1, 0])
        _grouped_mm_132 = torch.ops.aten._grouped_mm.default(permute_870, mul_819, cumsum_50);  permute_870 = mul_819 = None
        _grouped_mm_133 = torch.ops.aten._grouped_mm.default(index_71, permute_872, cumsum_50);  index_71 = permute_872 = None
        convert_element_type_940 = torch.ops.prims.convert_element_type.default(_grouped_mm_48, torch.float32);  _grouped_mm_48 = None
        neg_33 = torch.ops.aten.neg.default(convert_element_type_940)
        exp_50 = torch.ops.aten.exp.default(neg_33);  neg_33 = None
        add_1120 = torch.ops.aten.add.Tensor(exp_50, 1);  exp_50 = None
        div_84 = torch.ops.aten.div.Tensor(convert_element_type_940, add_1120)
        convert_element_type_941 = torch.ops.prims.convert_element_type.default(div_84, torch.bfloat16);  div_84 = None
        mul_1603 = torch.ops.aten.mul.Tensor(_grouped_mm_133, convert_element_type_941);  convert_element_type_941 = None
        mul_1604 = torch.ops.aten.mul.Tensor(_grouped_mm_133, _grouped_mm_49);  _grouped_mm_133 = _grouped_mm_49 = None
        permute_874 = torch.ops.aten.permute.default(mul_1603, [1, 0])
        _grouped_mm_134 = torch.ops.aten._grouped_mm.default(permute_874, index_33, cumsum_50);  permute_874 = None
        _grouped_mm_135 = torch.ops.aten._grouped_mm.default(mul_1603, permute_876, cumsum_50);  mul_1603 = permute_876 = None
        convert_element_type_2144 = torch.ops.prims.convert_element_type.default(mul_1604, torch.float32);  mul_1604 = None
        reciprocal_19 = torch.ops.aten.reciprocal.default(add_1120);  add_1120 = None
        mul_1605 = torch.ops.aten.mul.Tensor(reciprocal_19, 1);  reciprocal_19 = None
        mul_1606 = torch.ops.aten.mul.Tensor(convert_element_type_2144, mul_1605);  convert_element_type_2144 = None
        sub_680 = torch.ops.aten.sub.Tensor(1, mul_1605);  mul_1605 = None
        mul_1607 = torch.ops.aten.mul.Tensor(convert_element_type_940, sub_680);  convert_element_type_940 = sub_680 = None
        add_1914 = torch.ops.aten.add.Tensor(mul_1607, 1);  mul_1607 = None
        mul_1608 = torch.ops.aten.mul.Tensor(mul_1606, add_1914);  mul_1606 = add_1914 = None
        convert_element_type_2146 = torch.ops.prims.convert_element_type.default(mul_1608, torch.bfloat16);  mul_1608 = None
        permute_878 = torch.ops.aten.permute.default(convert_element_type_2146, [1, 0])
        _grouped_mm_136 = torch.ops.aten._grouped_mm.default(permute_878, index_33, cumsum_50);  permute_878 = index_33 = None
        _grouped_mm_137 = torch.ops.aten._grouped_mm.default(convert_element_type_2146, permute_880, cumsum_50);  convert_element_type_2146 = permute_880 = cumsum_50 = None
        add_1915 = torch.ops.aten.add.Tensor(_grouped_mm_135, _grouped_mm_137);  _grouped_mm_135 = _grouped_mm_137 = None
        convert_element_type_2147 = torch.ops.prims.convert_element_type.default(_grouped_mm_134, torch.float32);  _grouped_mm_134 = None
        div_186 = torch.ops.aten.div.Tensor(convert_element_type_2147, 128);  convert_element_type_2147 = None
        split_634 = torch.ops.aten.split.Tensor(div_186, 88, 1);  div_186 = None
        getitem_11885 = split_634[0]
        getitem_11902 = split_634[1]
        getitem_11919 = split_634[2]
        getitem_11936 = split_634[3]
        getitem_11953 = split_634[4]
        getitem_11970 = split_634[5]
        getitem_11987 = split_634[6]
        getitem_12004 = split_634[7]
        getitem_12021 = split_634[8]
        getitem_12038 = split_634[9]
        getitem_12055 = split_634[10]
        getitem_12072 = split_634[11]
        getitem_12089 = split_634[12]
        getitem_12106 = split_634[13]
        getitem_12123 = split_634[14]
        getitem_12140 = split_634[15];  split_634 = None
        cat_308 = torch.ops.aten.cat.default([getitem_11885, getitem_11902, getitem_11919, getitem_11936, getitem_11953, getitem_11970, getitem_11987, getitem_12004, getitem_12021, getitem_12038, getitem_12055, getitem_12072, getitem_12089, getitem_12106, getitem_12123, getitem_12140]);  getitem_11885 = getitem_11902 = getitem_11919 = getitem_11936 = getitem_11953 = getitem_11970 = getitem_11987 = getitem_12004 = getitem_12021 = getitem_12038 = getitem_12055 = getitem_12072 = getitem_12089 = getitem_12106 = getitem_12123 = getitem_12140 = None
        reduce_scatter_tensor_131 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_308, 'sum', 16, '1025');  cat_308 = None
        wait_tensor_709 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_131);  reduce_scatter_tensor_131 = None
        convert_element_type_2148 = torch.ops.prims.convert_element_type.default(_grouped_mm_132, torch.float32);  _grouped_mm_132 = None
        div_187 = torch.ops.aten.div.Tensor(convert_element_type_2148, 128);  convert_element_type_2148 = None
        split_651 = torch.ops.aten.split.Tensor(div_187, 128, 1);  div_187 = None
        getitem_12157 = split_651[0]
        getitem_12174 = split_651[1]
        getitem_12191 = split_651[2]
        getitem_12208 = split_651[3]
        getitem_12225 = split_651[4]
        getitem_12242 = split_651[5]
        getitem_12259 = split_651[6]
        getitem_12276 = split_651[7]
        getitem_12293 = split_651[8]
        getitem_12310 = split_651[9]
        getitem_12327 = split_651[10]
        getitem_12344 = split_651[11]
        getitem_12361 = split_651[12]
        getitem_12378 = split_651[13]
        getitem_12395 = split_651[14]
        getitem_12412 = split_651[15];  split_651 = None
        cat_309 = torch.ops.aten.cat.default([getitem_12157, getitem_12174, getitem_12191, getitem_12208, getitem_12225, getitem_12242, getitem_12259, getitem_12276, getitem_12293, getitem_12310, getitem_12327, getitem_12344, getitem_12361, getitem_12378, getitem_12395, getitem_12412]);  getitem_12157 = getitem_12174 = getitem_12191 = getitem_12208 = getitem_12225 = getitem_12242 = getitem_12259 = getitem_12276 = getitem_12293 = getitem_12310 = getitem_12327 = getitem_12344 = getitem_12361 = getitem_12378 = getitem_12395 = getitem_12412 = None
        reduce_scatter_tensor_132 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_309, 'sum', 16, '1025');  cat_309 = None
        wait_tensor_710 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_132);  reduce_scatter_tensor_132 = None
        convert_element_type_2149 = torch.ops.prims.convert_element_type.default(_grouped_mm_136, torch.float32);  _grouped_mm_136 = None
        div_188 = torch.ops.aten.div.Tensor(convert_element_type_2149, 128);  convert_element_type_2149 = None
        split_668 = torch.ops.aten.split.Tensor(div_188, 88, 1);  div_188 = None
        getitem_12429 = split_668[0]
        getitem_12446 = split_668[1]
        getitem_12463 = split_668[2]
        getitem_12480 = split_668[3]
        getitem_12497 = split_668[4]
        getitem_12514 = split_668[5]
        getitem_12531 = split_668[6]
        getitem_12548 = split_668[7]
        getitem_12565 = split_668[8]
        getitem_12582 = split_668[9]
        getitem_12599 = split_668[10]
        getitem_12616 = split_668[11]
        getitem_12633 = split_668[12]
        getitem_12650 = split_668[13]
        getitem_12667 = split_668[14]
        getitem_12684 = split_668[15];  split_668 = None
        cat_310 = torch.ops.aten.cat.default([getitem_12429, getitem_12446, getitem_12463, getitem_12480, getitem_12497, getitem_12514, getitem_12531, getitem_12548, getitem_12565, getitem_12582, getitem_12599, getitem_12616, getitem_12633, getitem_12650, getitem_12667, getitem_12684]);  getitem_12429 = getitem_12446 = getitem_12463 = getitem_12480 = getitem_12497 = getitem_12514 = getitem_12531 = getitem_12548 = getitem_12565 = getitem_12582 = getitem_12599 = getitem_12616 = getitem_12633 = getitem_12650 = getitem_12667 = getitem_12684 = None
        reduce_scatter_tensor_133 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_310, 'sum', 16, '1025');  cat_310 = None
        wait_tensor_711 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_133);  reduce_scatter_tensor_133 = None
        index_put_70 = torch.ops.aten.index_put.default(full_402, [getitem_1782], add_1915, True);  full_402 = getitem_1782 = add_1915 = None
        slice_216 = torch.ops.aten.slice.Tensor(index_put_70, 0, 0, add_1916);  index_put_70 = add_1916 = None
        all_to_all_single_97 = torch.ops._c10d_functional.all_to_all_single.default(slice_216, [_local_scalar_dense_256, _local_scalar_dense_257, _local_scalar_dense_258, _local_scalar_dense_259, _local_scalar_dense_260, _local_scalar_dense_261, _local_scalar_dense_262, _local_scalar_dense_263], [_local_scalar_dense_264, _local_scalar_dense_265, _local_scalar_dense_266, _local_scalar_dense_267, _local_scalar_dense_268, _local_scalar_dense_269, _local_scalar_dense_270, _local_scalar_dense_271], '1033');  slice_216 = _local_scalar_dense_256 = _local_scalar_dense_257 = _local_scalar_dense_258 = _local_scalar_dense_259 = _local_scalar_dense_260 = _local_scalar_dense_261 = _local_scalar_dense_262 = _local_scalar_dense_263 = _local_scalar_dense_264 = _local_scalar_dense_265 = _local_scalar_dense_266 = _local_scalar_dense_267 = _local_scalar_dense_268 = _local_scalar_dense_269 = _local_scalar_dense_270 = _local_scalar_dense_271 = None
        wait_tensor_712 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_97);  all_to_all_single_97 = None
        index_put_71 = torch.ops.aten.index_put.default(full_default_52, [div_82], wait_tensor_712, True);  div_82 = wait_tensor_712 = None
        add_1920 = torch.ops.aten.add.Tensor(add_1912, index_put_71);  add_1912 = index_put_71 = None
        mul_1609 = torch.ops.aten.mul.Tensor(view_1954, 1.0);  view_1954 = None
        scatter_add_9 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_1779, mul_1609);  getitem_1779 = mul_1609 = None
        convert_element_type_929 = torch.ops.prims.convert_element_type.default(mm_139, torch.float32);  mm_139 = None
        sub_384 = torch.ops.aten.sub.Tensor(convert_element_type_929, amax_16);  convert_element_type_929 = amax_16 = None
        exp_49 = torch.ops.aten.exp.default(sub_384);  sub_384 = None
        div_81 = torch.ops.aten.div.Tensor(exp_49, sum_65);  exp_49 = sum_65 = None
        mul_1610 = torch.ops.aten.mul.Tensor(scatter_add_9, div_81);  scatter_add_9 = None
        sum_179 = torch.ops.aten.sum.dim_IntList(mul_1610, [1], True)
        neg_82 = torch.ops.aten.neg.default(div_81);  div_81 = None
        fma_9 = torch.ops.prims.fma.default(neg_82, sum_179, mul_1610);  neg_82 = sum_179 = mul_1610 = None
        convert_element_type_2150 = torch.ops.prims.convert_element_type.default(fma_9, torch.bfloat16);  fma_9 = None
        permute_882 = torch.ops.aten.permute.default(convert_element_type_2150, [1, 0])
        mm_368 = torch.ops.aten.mm.default(permute_882, view_1130);  permute_882 = view_1130 = None
        convert_element_type_926 = torch.ops.prims.convert_element_type.default(primals_287, torch.bfloat16);  primals_287 = None
        all_gather_into_tensor_290 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_926, 128, '0');  convert_element_type_926 = None
        wait_tensor_354 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_290);  all_gather_into_tensor_290 = None
        slice_105 = torch.ops.aten.slice.Tensor(wait_tensor_354, 0, 0, 64);  wait_tensor_354 = None
        permute_259 = torch.ops.aten.permute.default(slice_105, [1, 0]);  slice_105 = None
        permute_884 = torch.ops.aten.permute.default(permute_259, [1, 0]);  permute_259 = None
        mm_369 = torch.ops.aten.mm.default(convert_element_type_2150, permute_884);  convert_element_type_2150 = permute_884 = None
        add_1921 = torch.ops.aten.add.Tensor(add_1920, mm_369);  add_1920 = mm_369 = None
        convert_element_type_2155 = torch.ops.prims.convert_element_type.default(mm_368, torch.float32);  mm_368 = None
        split_684 = torch.ops.aten.split.Tensor(convert_element_type_2155, 1);  convert_element_type_2155 = None
        getitem_12685 = split_684[0]
        getitem_12686 = split_684[1]
        getitem_12687 = split_684[2]
        getitem_12688 = split_684[3]
        getitem_12689 = split_684[4]
        getitem_12690 = split_684[5]
        getitem_12691 = split_684[6]
        getitem_12692 = split_684[7]
        getitem_12693 = split_684[8]
        getitem_12694 = split_684[9]
        getitem_12695 = split_684[10]
        getitem_12696 = split_684[11]
        getitem_12697 = split_684[12]
        getitem_12698 = split_684[13]
        getitem_12699 = split_684[14]
        getitem_12700 = split_684[15]
        getitem_12701 = split_684[16]
        getitem_12702 = split_684[17]
        getitem_12703 = split_684[18]
        getitem_12704 = split_684[19]
        getitem_12705 = split_684[20]
        getitem_12706 = split_684[21]
        getitem_12707 = split_684[22]
        getitem_12708 = split_684[23]
        getitem_12709 = split_684[24]
        getitem_12710 = split_684[25]
        getitem_12711 = split_684[26]
        getitem_12712 = split_684[27]
        getitem_12713 = split_684[28]
        getitem_12714 = split_684[29]
        getitem_12715 = split_684[30]
        getitem_12716 = split_684[31]
        getitem_12717 = split_684[32]
        getitem_12718 = split_684[33]
        getitem_12719 = split_684[34]
        getitem_12720 = split_684[35]
        getitem_12721 = split_684[36]
        getitem_12722 = split_684[37]
        getitem_12723 = split_684[38]
        getitem_12724 = split_684[39]
        getitem_12725 = split_684[40]
        getitem_12726 = split_684[41]
        getitem_12727 = split_684[42]
        getitem_12728 = split_684[43]
        getitem_12729 = split_684[44]
        getitem_12730 = split_684[45]
        getitem_12731 = split_684[46]
        getitem_12732 = split_684[47]
        getitem_12733 = split_684[48]
        getitem_12734 = split_684[49]
        getitem_12735 = split_684[50]
        getitem_12736 = split_684[51]
        getitem_12737 = split_684[52]
        getitem_12738 = split_684[53]
        getitem_12739 = split_684[54]
        getitem_12740 = split_684[55]
        getitem_12741 = split_684[56]
        getitem_12742 = split_684[57]
        getitem_12743 = split_684[58]
        getitem_12744 = split_684[59]
        getitem_12745 = split_684[60]
        getitem_12746 = split_684[61]
        getitem_12747 = split_684[62]
        getitem_12748 = split_684[63];  split_684 = None
        cat_311 = torch.ops.aten.cat.default([getitem_12685, getitem_12686, getitem_12687, getitem_12688, getitem_12689, getitem_12690, getitem_12691, getitem_12692, getitem_12693, getitem_12694, getitem_12695, getitem_12696, getitem_12697, getitem_12698, getitem_12699, getitem_12700, getitem_12701, getitem_12702, getitem_12703, getitem_12704, getitem_12705, getitem_12706, getitem_12707, getitem_12708, getitem_12709, getitem_12710, getitem_12711, getitem_12712, getitem_12713, getitem_12714, getitem_12715, getitem_12716, getitem_12717, getitem_12718, getitem_12719, getitem_12720, getitem_12721, getitem_12722, getitem_12723, getitem_12724, getitem_12725, getitem_12726, getitem_12727, getitem_12728, getitem_12729, getitem_12730, getitem_12731, getitem_12732, getitem_12733, getitem_12734, getitem_12735, getitem_12736, getitem_12737, getitem_12738, getitem_12739, getitem_12740, getitem_12741, getitem_12742, getitem_12743, getitem_12744, getitem_12745, getitem_12746, getitem_12747, getitem_12748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_12685 = getitem_12686 = getitem_12687 = getitem_12688 = getitem_12689 = getitem_12690 = getitem_12691 = getitem_12692 = getitem_12693 = getitem_12694 = getitem_12695 = getitem_12696 = getitem_12697 = getitem_12698 = getitem_12699 = getitem_12700 = getitem_12701 = getitem_12702 = getitem_12703 = getitem_12704 = getitem_12705 = getitem_12706 = getitem_12707 = getitem_12708 = getitem_12709 = getitem_12710 = getitem_12711 = getitem_12712 = getitem_12713 = getitem_12714 = getitem_12715 = getitem_12716 = getitem_12717 = getitem_12718 = getitem_12719 = getitem_12720 = getitem_12721 = getitem_12722 = getitem_12723 = getitem_12724 = getitem_12725 = getitem_12726 = getitem_12727 = getitem_12728 = getitem_12729 = getitem_12730 = getitem_12731 = getitem_12732 = getitem_12733 = getitem_12734 = getitem_12735 = getitem_12736 = getitem_12737 = getitem_12738 = getitem_12739 = getitem_12740 = getitem_12741 = getitem_12742 = getitem_12743 = getitem_12744 = getitem_12745 = getitem_12746 = getitem_12747 = getitem_12748 = None
        reduce_scatter_tensor_134 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_311, 'avg', 128, '0');  cat_311 = None
        wait_tensor_713 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_134);  reduce_scatter_tensor_134 = None
        view_1956 = torch.ops.aten.view.default(add_1921, [2, 4096, 2048]);  add_1921 = None
        convert_element_type_2156 = torch.ops.prims.convert_element_type.default(view_1956, torch.float32);  view_1956 = None
        convert_element_type_923 = torch.ops.prims.convert_element_type.default(primals_285, torch.bfloat16);  primals_285 = None
        all_gather_into_tensor_289 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_923, 128, '0');  convert_element_type_923 = None
        wait_tensor_353 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_289);  all_gather_into_tensor_289 = None
        convert_element_type_2158 = torch.ops.prims.convert_element_type.default(wait_tensor_353, torch.float32);  wait_tensor_353 = None
        mul_1611 = torch.ops.aten.mul.Tensor(convert_element_type_2156, convert_element_type_2158);  convert_element_type_2158 = None
        convert_element_type_924 = torch.ops.prims.convert_element_type.default(add_1096, torch.float32);  add_1096 = None
        mul_799 = torch.ops.aten.mul.Tensor(convert_element_type_924, rsqrt_53);  convert_element_type_924 = None
        mul_1613 = torch.ops.aten.mul.Tensor(mul_799, mul_1611)
        sum_180 = torch.ops.aten.sum.dim_IntList(mul_1613, [2], True);  mul_1613 = None
        div_189 = torch.ops.aten.div.Tensor(mul_799, 2048)
        mul_1614 = torch.ops.aten.mul.Tensor(div_189, sum_180);  div_189 = sum_180 = None
        sub_682 = torch.ops.aten.sub.Tensor(mul_1611, mul_1614);  mul_1611 = mul_1614 = None
        mul_1615 = torch.ops.aten.mul.Tensor(sub_682, rsqrt_53);  sub_682 = rsqrt_53 = None
        mul_1616 = torch.ops.aten.mul.Tensor(convert_element_type_2156, mul_799);  convert_element_type_2156 = mul_799 = None
        sum_181 = torch.ops.aten.sum.dim_IntList(mul_1616, [0, 1]);  mul_1616 = None
        convert_element_type_2159 = torch.ops.prims.convert_element_type.default(mul_1615, torch.bfloat16);  mul_1615 = None
        add_1922 = torch.ops.aten.add.Tensor(add_1909, convert_element_type_2159);  add_1909 = convert_element_type_2159 = None
        convert_element_type_default_54 = torch.ops.prims.convert_element_type.default(sum_181, torch.float32);  sum_181 = None
        reduce_scatter_tensor_135 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_54, 'avg', 128, '0');  convert_element_type_default_54 = None
        wait_tensor_714 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_135);  reduce_scatter_tensor_135 = None
        view_1957 = torch.ops.aten.view.default(add_1922, [8192, 2048])
        permute_886 = torch.ops.aten.permute.default(view_1957, [1, 0])
        permute_257 = torch.ops.aten.permute.default(getitem_1775, [0, 2, 1, 3])
        view_1125 = torch.ops.aten.view.default(permute_257, [2, 4096, -1]);  permute_257 = None
        view_1127 = torch.ops.aten.view.default(view_1125, [8192, 2048]);  view_1125 = None
        mm_370 = torch.ops.aten.mm.default(permute_886, view_1127);  permute_886 = view_1127 = None
        convert_element_type_920 = torch.ops.prims.convert_element_type.default(primals_284, torch.bfloat16);  primals_284 = None
        all_gather_into_tensor_288 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_920, 128, '0');  convert_element_type_920 = None
        wait_tensor_352 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_288);  all_gather_into_tensor_288 = None
        permute_258 = torch.ops.aten.permute.default(wait_tensor_352, [1, 0]);  wait_tensor_352 = None
        permute_888 = torch.ops.aten.permute.default(permute_258, [1, 0]);  permute_258 = None
        mm_371 = torch.ops.aten.mm.default(view_1957, permute_888);  view_1957 = permute_888 = None
        view_1958 = torch.ops.aten.view.default(mm_371, [2, 4096, 2048]);  mm_371 = None
        convert_element_type_2166 = torch.ops.prims.convert_element_type.default(mm_370, torch.float32);  mm_370 = None
        reduce_scatter_tensor_136 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2166, 'avg', 128, '0');  convert_element_type_2166 = None
        wait_tensor_715 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_136);  reduce_scatter_tensor_136 = None
        view_1959 = torch.ops.aten.view.default(view_1958, [2, 4096, 16, 128]);  view_1958 = None
        permute_890 = torch.ops.aten.permute.default(view_1959, [0, 2, 1, 3]);  view_1959 = None
        fw_graph9 = self.fw_graph9
        joint_graph9 = self.joint_graph9
        mask_graph9 = self.mask_graph9
        flex_attention_backward_9 = torch.ops.higher_order.flex_attention_backward(permute_254, permute_255, permute_256, getitem_1775, getitem_1776, permute_890, None, fw_graph9, joint_graph9, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph9), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_254 = permute_255 = permute_256 = getitem_1775 = getitem_1776 = permute_890 = fw_graph9 = joint_graph9 = mask_graph9 = None
        getitem_12749 = flex_attention_backward_9[0]
        getitem_12750 = flex_attention_backward_9[1]
        getitem_12751 = flex_attention_backward_9[2];  flex_attention_backward_9 = None
        permute_891 = torch.ops.aten.permute.default(getitem_12751, [0, 2, 1, 3]);  getitem_12751 = None
        permute_892 = torch.ops.aten.permute.default(getitem_12750, [0, 2, 1, 3]);  getitem_12750 = None
        permute_893 = torch.ops.aten.permute.default(getitem_12749, [0, 2, 1, 3]);  getitem_12749 = None
        slice_218 = torch.ops.aten.slice.Tensor(permute_892, 3, 0, 128)
        slice_219 = torch.ops.aten.slice.Tensor(permute_892, 3, 128, 192);  permute_892 = None
        sum_182 = torch.ops.aten.sum.dim_IntList(slice_219, [2], True);  slice_219 = None
        cat_312 = torch.ops.aten.cat.default([slice_218, permute_891], 3);  slice_218 = permute_891 = None
        view_1960 = torch.ops.aten.view.default(cat_312, [2, 4096, 4096]);  cat_312 = None
        view_1961 = torch.ops.aten.view.default(view_1960, [8192, 4096]);  view_1960 = None
        permute_894 = torch.ops.aten.permute.default(view_1961, [1, 0])
        mm_372 = torch.ops.aten.mm.default(permute_894, view_1122);  permute_894 = view_1122 = None
        convert_element_type_917 = torch.ops.prims.convert_element_type.default(primals_283, torch.bfloat16);  primals_283 = None
        all_gather_into_tensor_287 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_917, 128, '0');  convert_element_type_917 = None
        wait_tensor_351 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_287);  all_gather_into_tensor_287 = None
        permute_253 = torch.ops.aten.permute.default(wait_tensor_351, [1, 0]);  wait_tensor_351 = None
        permute_896 = torch.ops.aten.permute.default(permute_253, [1, 0]);  permute_253 = None
        mm_373 = torch.ops.aten.mm.default(view_1961, permute_896);  view_1961 = permute_896 = None
        view_1962 = torch.ops.aten.view.default(mm_373, [2, 4096, 512]);  mm_373 = None
        convert_element_type_2171 = torch.ops.prims.convert_element_type.default(mm_372, torch.float32);  mm_372 = None
        reduce_scatter_tensor_137 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2171, 'avg', 128, '0');  convert_element_type_2171 = None
        wait_tensor_716 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_137);  reduce_scatter_tensor_137 = None
        convert_element_type_2172 = torch.ops.prims.convert_element_type.default(view_1962, torch.float32);  view_1962 = None
        convert_element_type_914 = torch.ops.prims.convert_element_type.default(primals_282, torch.bfloat16);  primals_282 = None
        all_gather_into_tensor_286 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_914, 128, '0');  convert_element_type_914 = None
        wait_tensor_350 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_286);  all_gather_into_tensor_286 = None
        convert_element_type_2174 = torch.ops.prims.convert_element_type.default(wait_tensor_350, torch.float32);  wait_tensor_350 = None
        mul_1617 = torch.ops.aten.mul.Tensor(convert_element_type_2172, convert_element_type_2174);  convert_element_type_2174 = None
        convert_element_type_915 = torch.ops.prims.convert_element_type.default(getitem_1771, torch.float32);  getitem_1771 = None
        mul_797 = torch.ops.aten.mul.Tensor(convert_element_type_915, rsqrt_52);  convert_element_type_915 = None
        mul_1619 = torch.ops.aten.mul.Tensor(mul_797, mul_1617)
        sum_183 = torch.ops.aten.sum.dim_IntList(mul_1619, [2], True);  mul_1619 = None
        div_190 = torch.ops.aten.div.Tensor(mul_797, 512)
        mul_1620 = torch.ops.aten.mul.Tensor(div_190, sum_183);  div_190 = sum_183 = None
        sub_683 = torch.ops.aten.sub.Tensor(mul_1617, mul_1620);  mul_1617 = mul_1620 = None
        mul_1621 = torch.ops.aten.mul.Tensor(sub_683, rsqrt_52);  sub_683 = rsqrt_52 = None
        mul_1622 = torch.ops.aten.mul.Tensor(convert_element_type_2172, mul_797);  convert_element_type_2172 = mul_797 = None
        sum_184 = torch.ops.aten.sum.dim_IntList(mul_1622, [0, 1]);  mul_1622 = None
        convert_element_type_2175 = torch.ops.prims.convert_element_type.default(mul_1621, torch.bfloat16);  mul_1621 = None
        convert_element_type_default_53 = torch.ops.prims.convert_element_type.default(sum_184, torch.float32);  sum_184 = None
        reduce_scatter_tensor_138 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_53, 'avg', 128, '0');  convert_element_type_default_53 = None
        wait_tensor_717 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_138);  reduce_scatter_tensor_138 = None
        convert_element_type_2178 = torch.ops.prims.convert_element_type.default(sum_182, torch.float32);  sum_182 = None
        view_1963 = torch.ops.aten.view.default(convert_element_type_2178, [2, 4096, 1, 32, 2]);  convert_element_type_2178 = None
        view_as_complex_72 = torch.ops.aten.view_as_complex.default(view_1963);  view_1963 = None
        mul_1623 = torch.ops.aten.mul.Tensor(view_as_complex_72, clone_9);  view_as_complex_72 = None
        view_as_real_72 = torch.ops.aten.view_as_real.default(mul_1623);  mul_1623 = None
        view_1964 = torch.ops.aten.view.default(view_as_real_72, [2, 4096, 1, 64]);  view_as_real_72 = None
        convert_element_type_2179 = torch.ops.prims.convert_element_type.default(view_1964, torch.bfloat16);  view_1964 = None
        squeeze_35 = torch.ops.aten.squeeze.dim(convert_element_type_2179, 2);  convert_element_type_2179 = None
        cat_313 = torch.ops.aten.cat.default([convert_element_type_2175, squeeze_35], 2);  convert_element_type_2175 = squeeze_35 = None
        view_1965 = torch.ops.aten.view.default(cat_313, [8192, 576]);  cat_313 = None
        permute_898 = torch.ops.aten.permute.default(view_1965, [1, 0])
        mm_374 = torch.ops.aten.mm.default(permute_898, view_1108);  permute_898 = None
        convert_element_type_909 = torch.ops.prims.convert_element_type.default(primals_281, torch.bfloat16);  primals_281 = None
        all_gather_into_tensor_285 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_909, 128, '0');  convert_element_type_909 = None
        wait_tensor_349 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_285);  all_gather_into_tensor_285 = None
        slice_103 = torch.ops.aten.slice.Tensor(wait_tensor_349, 0, 0, 576);  wait_tensor_349 = None
        permute_252 = torch.ops.aten.permute.default(slice_103, [1, 0]);  slice_103 = None
        permute_900 = torch.ops.aten.permute.default(permute_252, [1, 0]);  permute_252 = None
        mm_375 = torch.ops.aten.mm.default(view_1965, permute_900);  view_1965 = permute_900 = None
        view_1966 = torch.ops.aten.view.default(mm_375, [2, 4096, 2048]);  mm_375 = None
        convert_element_type_2184 = torch.ops.prims.convert_element_type.default(mm_374, torch.float32);  mm_374 = None
        split_685 = torch.ops.aten.split.Tensor(convert_element_type_2184, 5);  convert_element_type_2184 = None
        getitem_12753 = split_685[0]
        getitem_12754 = split_685[1]
        getitem_12755 = split_685[2]
        getitem_12756 = split_685[3]
        getitem_12757 = split_685[4]
        getitem_12758 = split_685[5]
        getitem_12759 = split_685[6]
        getitem_12760 = split_685[7]
        getitem_12761 = split_685[8]
        getitem_12762 = split_685[9]
        getitem_12763 = split_685[10]
        getitem_12764 = split_685[11]
        getitem_12765 = split_685[12]
        getitem_12766 = split_685[13]
        getitem_12767 = split_685[14]
        getitem_12768 = split_685[15]
        getitem_12769 = split_685[16]
        getitem_12770 = split_685[17]
        getitem_12771 = split_685[18]
        getitem_12772 = split_685[19]
        getitem_12773 = split_685[20]
        getitem_12774 = split_685[21]
        getitem_12775 = split_685[22]
        getitem_12776 = split_685[23]
        getitem_12777 = split_685[24]
        getitem_12778 = split_685[25]
        getitem_12779 = split_685[26]
        getitem_12780 = split_685[27]
        getitem_12781 = split_685[28]
        getitem_12782 = split_685[29]
        getitem_12783 = split_685[30]
        getitem_12784 = split_685[31]
        getitem_12785 = split_685[32]
        getitem_12786 = split_685[33]
        getitem_12787 = split_685[34]
        getitem_12788 = split_685[35]
        getitem_12789 = split_685[36]
        getitem_12790 = split_685[37]
        getitem_12791 = split_685[38]
        getitem_12792 = split_685[39]
        getitem_12793 = split_685[40]
        getitem_12794 = split_685[41]
        getitem_12795 = split_685[42]
        getitem_12796 = split_685[43]
        getitem_12797 = split_685[44]
        getitem_12798 = split_685[45]
        getitem_12799 = split_685[46]
        getitem_12800 = split_685[47]
        getitem_12801 = split_685[48]
        getitem_12802 = split_685[49]
        getitem_12803 = split_685[50]
        getitem_12804 = split_685[51]
        getitem_12805 = split_685[52]
        getitem_12806 = split_685[53]
        getitem_12807 = split_685[54]
        getitem_12808 = split_685[55]
        getitem_12809 = split_685[56]
        getitem_12810 = split_685[57]
        getitem_12811 = split_685[58]
        getitem_12812 = split_685[59]
        getitem_12813 = split_685[60]
        getitem_12814 = split_685[61]
        getitem_12815 = split_685[62]
        getitem_12816 = split_685[63]
        getitem_12817 = split_685[64]
        getitem_12818 = split_685[65]
        getitem_12819 = split_685[66]
        getitem_12820 = split_685[67]
        getitem_12821 = split_685[68]
        getitem_12822 = split_685[69]
        getitem_12823 = split_685[70]
        getitem_12824 = split_685[71]
        getitem_12825 = split_685[72]
        getitem_12826 = split_685[73]
        getitem_12827 = split_685[74]
        getitem_12828 = split_685[75]
        getitem_12829 = split_685[76]
        getitem_12830 = split_685[77]
        getitem_12831 = split_685[78]
        getitem_12832 = split_685[79]
        getitem_12833 = split_685[80]
        getitem_12834 = split_685[81]
        getitem_12835 = split_685[82]
        getitem_12836 = split_685[83]
        getitem_12837 = split_685[84]
        getitem_12838 = split_685[85]
        getitem_12839 = split_685[86]
        getitem_12840 = split_685[87]
        getitem_12841 = split_685[88]
        getitem_12842 = split_685[89]
        getitem_12843 = split_685[90]
        getitem_12844 = split_685[91]
        getitem_12845 = split_685[92]
        getitem_12846 = split_685[93]
        getitem_12847 = split_685[94]
        getitem_12848 = split_685[95]
        getitem_12849 = split_685[96]
        getitem_12850 = split_685[97]
        getitem_12851 = split_685[98]
        getitem_12852 = split_685[99]
        getitem_12853 = split_685[100]
        getitem_12854 = split_685[101]
        getitem_12855 = split_685[102]
        getitem_12856 = split_685[103]
        getitem_12857 = split_685[104]
        getitem_12858 = split_685[105]
        getitem_12859 = split_685[106]
        getitem_12860 = split_685[107]
        getitem_12861 = split_685[108]
        getitem_12862 = split_685[109]
        getitem_12863 = split_685[110]
        getitem_12864 = split_685[111]
        getitem_12865 = split_685[112]
        getitem_12866 = split_685[113]
        getitem_12867 = split_685[114]
        getitem_12868 = split_685[115];  split_685 = None
        constant_pad_nd_757 = torch.ops.aten.constant_pad_nd.default(getitem_12868, [0, 0, 0, 4], 0.0);  getitem_12868 = None
        cat_314 = torch.ops.aten.cat.default([getitem_12753, getitem_12754, getitem_12755, getitem_12756, getitem_12757, getitem_12758, getitem_12759, getitem_12760, getitem_12761, getitem_12762, getitem_12763, getitem_12764, getitem_12765, getitem_12766, getitem_12767, getitem_12768, getitem_12769, getitem_12770, getitem_12771, getitem_12772, getitem_12773, getitem_12774, getitem_12775, getitem_12776, getitem_12777, getitem_12778, getitem_12779, getitem_12780, getitem_12781, getitem_12782, getitem_12783, getitem_12784, getitem_12785, getitem_12786, getitem_12787, getitem_12788, getitem_12789, getitem_12790, getitem_12791, getitem_12792, getitem_12793, getitem_12794, getitem_12795, getitem_12796, getitem_12797, getitem_12798, getitem_12799, getitem_12800, getitem_12801, getitem_12802, getitem_12803, getitem_12804, getitem_12805, getitem_12806, getitem_12807, getitem_12808, getitem_12809, getitem_12810, getitem_12811, getitem_12812, getitem_12813, getitem_12814, getitem_12815, getitem_12816, getitem_12817, getitem_12818, getitem_12819, getitem_12820, getitem_12821, getitem_12822, getitem_12823, getitem_12824, getitem_12825, getitem_12826, getitem_12827, getitem_12828, getitem_12829, getitem_12830, getitem_12831, getitem_12832, getitem_12833, getitem_12834, getitem_12835, getitem_12836, getitem_12837, getitem_12838, getitem_12839, getitem_12840, getitem_12841, getitem_12842, getitem_12843, getitem_12844, getitem_12845, getitem_12846, getitem_12847, getitem_12848, getitem_12849, getitem_12850, getitem_12851, getitem_12852, getitem_12853, getitem_12854, getitem_12855, getitem_12856, getitem_12857, getitem_12858, getitem_12859, getitem_12860, getitem_12861, getitem_12862, getitem_12863, getitem_12864, getitem_12865, getitem_12866, getitem_12867, constant_pad_nd_757, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_12753 = getitem_12754 = getitem_12755 = getitem_12756 = getitem_12757 = getitem_12758 = getitem_12759 = getitem_12760 = getitem_12761 = getitem_12762 = getitem_12763 = getitem_12764 = getitem_12765 = getitem_12766 = getitem_12767 = getitem_12768 = getitem_12769 = getitem_12770 = getitem_12771 = getitem_12772 = getitem_12773 = getitem_12774 = getitem_12775 = getitem_12776 = getitem_12777 = getitem_12778 = getitem_12779 = getitem_12780 = getitem_12781 = getitem_12782 = getitem_12783 = getitem_12784 = getitem_12785 = getitem_12786 = getitem_12787 = getitem_12788 = getitem_12789 = getitem_12790 = getitem_12791 = getitem_12792 = getitem_12793 = getitem_12794 = getitem_12795 = getitem_12796 = getitem_12797 = getitem_12798 = getitem_12799 = getitem_12800 = getitem_12801 = getitem_12802 = getitem_12803 = getitem_12804 = getitem_12805 = getitem_12806 = getitem_12807 = getitem_12808 = getitem_12809 = getitem_12810 = getitem_12811 = getitem_12812 = getitem_12813 = getitem_12814 = getitem_12815 = getitem_12816 = getitem_12817 = getitem_12818 = getitem_12819 = getitem_12820 = getitem_12821 = getitem_12822 = getitem_12823 = getitem_12824 = getitem_12825 = getitem_12826 = getitem_12827 = getitem_12828 = getitem_12829 = getitem_12830 = getitem_12831 = getitem_12832 = getitem_12833 = getitem_12834 = getitem_12835 = getitem_12836 = getitem_12837 = getitem_12838 = getitem_12839 = getitem_12840 = getitem_12841 = getitem_12842 = getitem_12843 = getitem_12844 = getitem_12845 = getitem_12846 = getitem_12847 = getitem_12848 = getitem_12849 = getitem_12850 = getitem_12851 = getitem_12852 = getitem_12853 = getitem_12854 = getitem_12855 = getitem_12856 = getitem_12857 = getitem_12858 = getitem_12859 = getitem_12860 = getitem_12861 = getitem_12862 = getitem_12863 = getitem_12864 = getitem_12865 = getitem_12866 = getitem_12867 = constant_pad_nd_757 = None
        reduce_scatter_tensor_139 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_314, 'avg', 128, '0');  cat_314 = None
        wait_tensor_718 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_139);  reduce_scatter_tensor_139 = None
        slice_220 = torch.ops.aten.slice.Tensor(permute_893, 3, 0, 128)
        slice_221 = torch.ops.aten.slice.Tensor(permute_893, 3, 128, 192);  permute_893 = None
        convert_element_type_2185 = torch.ops.prims.convert_element_type.default(slice_221, torch.float32);  slice_221 = None
        view_1967 = torch.ops.aten.view.default(convert_element_type_2185, [2, 4096, 16, 32, 2]);  convert_element_type_2185 = None
        view_as_complex_73 = torch.ops.aten.view_as_complex.default(view_1967);  view_1967 = None
        mul_1624 = torch.ops.aten.mul.Tensor(view_as_complex_73, clone_9);  view_as_complex_73 = None
        view_as_real_73 = torch.ops.aten.view_as_real.default(mul_1624);  mul_1624 = None
        view_1968 = torch.ops.aten.view.default(view_as_real_73, [2, 4096, 16, 64]);  view_as_real_73 = None
        convert_element_type_2186 = torch.ops.prims.convert_element_type.default(view_1968, torch.bfloat16);  view_1968 = None
        cat_315 = torch.ops.aten.cat.default([slice_220, convert_element_type_2186], 3);  slice_220 = convert_element_type_2186 = None
        view_1969 = torch.ops.aten.view.default(cat_315, [2, 4096, 3072]);  cat_315 = None
        view_1970 = torch.ops.aten.view.default(view_1969, [8192, 3072]);  view_1969 = None
        permute_902 = torch.ops.aten.permute.default(view_1970, [1, 0])
        mm_376 = torch.ops.aten.mm.default(permute_902, view_1108);  permute_902 = view_1108 = None
        convert_element_type_904 = torch.ops.prims.convert_element_type.default(primals_280, torch.bfloat16);  primals_280 = None
        all_gather_into_tensor_284 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_904, 128, '0');  convert_element_type_904 = None
        wait_tensor_348 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_284);  all_gather_into_tensor_284 = None
        permute_251 = torch.ops.aten.permute.default(wait_tensor_348, [1, 0]);  wait_tensor_348 = None
        permute_904 = torch.ops.aten.permute.default(permute_251, [1, 0]);  permute_251 = None
        mm_377 = torch.ops.aten.mm.default(view_1970, permute_904);  view_1970 = permute_904 = None
        view_1971 = torch.ops.aten.view.default(mm_377, [2, 4096, 2048]);  mm_377 = None
        add_1923 = torch.ops.aten.add.Tensor(view_1966, view_1971);  view_1966 = view_1971 = None
        convert_element_type_2191 = torch.ops.prims.convert_element_type.default(mm_376, torch.float32);  mm_376 = None
        reduce_scatter_tensor_140 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2191, 'avg', 128, '0');  convert_element_type_2191 = None
        wait_tensor_719 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_140);  reduce_scatter_tensor_140 = None
        convert_element_type_2192 = torch.ops.prims.convert_element_type.default(add_1923, torch.float32);  add_1923 = None
        convert_element_type_901 = torch.ops.prims.convert_element_type.default(primals_279, torch.bfloat16);  primals_279 = None
        all_gather_into_tensor_283 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_901, 128, '0');  convert_element_type_901 = None
        wait_tensor_347 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_283);  all_gather_into_tensor_283 = None
        convert_element_type_2194 = torch.ops.prims.convert_element_type.default(wait_tensor_347, torch.float32);  wait_tensor_347 = None
        mul_1625 = torch.ops.aten.mul.Tensor(convert_element_type_2192, convert_element_type_2194);  convert_element_type_2194 = None
        convert_element_type_902 = torch.ops.prims.convert_element_type.default(add_1093, torch.float32);  add_1093 = None
        mul_793 = torch.ops.aten.mul.Tensor(convert_element_type_902, rsqrt_51);  convert_element_type_902 = None
        mul_1627 = torch.ops.aten.mul.Tensor(mul_793, mul_1625)
        sum_185 = torch.ops.aten.sum.dim_IntList(mul_1627, [2], True);  mul_1627 = None
        div_191 = torch.ops.aten.div.Tensor(mul_793, 2048)
        mul_1628 = torch.ops.aten.mul.Tensor(div_191, sum_185);  div_191 = sum_185 = None
        sub_684 = torch.ops.aten.sub.Tensor(mul_1625, mul_1628);  mul_1625 = mul_1628 = None
        mul_1629 = torch.ops.aten.mul.Tensor(sub_684, rsqrt_51);  sub_684 = rsqrt_51 = None
        mul_1630 = torch.ops.aten.mul.Tensor(convert_element_type_2192, mul_793);  convert_element_type_2192 = mul_793 = None
        sum_186 = torch.ops.aten.sum.dim_IntList(mul_1630, [0, 1]);  mul_1630 = None
        convert_element_type_2195 = torch.ops.prims.convert_element_type.default(mul_1629, torch.bfloat16);  mul_1629 = None
        add_1924 = torch.ops.aten.add.Tensor(add_1922, convert_element_type_2195);  add_1922 = convert_element_type_2195 = None
        convert_element_type_default_52 = torch.ops.prims.convert_element_type.default(sum_186, torch.float32);  sum_186 = None
        reduce_scatter_tensor_141 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_52, 'avg', 128, '0');  convert_element_type_default_52 = None
        wait_tensor_720 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_141);  reduce_scatter_tensor_141 = None
        view_1972 = torch.ops.aten.view.default(add_1924, [8192, 2048])
        unsqueeze_63 = torch.ops.aten.unsqueeze.default(view_1972, 1)
        convert_element_type_2198 = torch.ops.prims.convert_element_type.default(unsqueeze_63, torch.float32);  unsqueeze_63 = None
        bmm_46 = torch.ops.aten.bmm.default(permute_906, convert_element_type_2198);  permute_906 = None
        bmm_47 = torch.ops.aten.bmm.default(convert_element_type_2198, permute_907);  convert_element_type_2198 = permute_907 = None
        convert_element_type_2199 = torch.ops.prims.convert_element_type.default(bmm_46, torch.bfloat16);  bmm_46 = None
        view_1973 = torch.ops.aten.view.default(bmm_47, [8192, 6]);  bmm_47 = None
        view_1974 = torch.ops.aten.view.default(convert_element_type_2199, [49152, 2048]);  convert_element_type_2199 = None
        index_72 = torch.ops.aten.index.Tensor(view_1974, [getitem_1671]);  view_1974 = getitem_1671 = None
        permute_908 = torch.ops.aten.permute.default(view_1972, [1, 0])
        mm_378 = torch.ops.aten.mm.default(permute_908, mul_790);  permute_908 = mul_790 = None
        convert_element_type_896 = torch.ops.prims.convert_element_type.default(primals_278, torch.bfloat16);  primals_278 = None
        all_gather_into_tensor_282 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_896, 128, '0');  convert_element_type_896 = None
        wait_tensor_346 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_282);  all_gather_into_tensor_282 = None
        permute_250 = torch.ops.aten.permute.default(wait_tensor_346, [1, 0]);  wait_tensor_346 = None
        permute_910 = torch.ops.aten.permute.default(permute_250, [1, 0]);  permute_250 = None
        mm_379 = torch.ops.aten.mm.default(view_1972, permute_910);  view_1972 = permute_910 = None
        convert_element_type_2204 = torch.ops.prims.convert_element_type.default(mm_378, torch.float32);  mm_378 = None
        reduce_scatter_tensor_142 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2204, 'avg', 128, '0');  convert_element_type_2204 = None
        wait_tensor_721 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_142);  reduce_scatter_tensor_142 = None
        convert_element_type_891 = torch.ops.prims.convert_element_type.default(mm_132, torch.float32);  mm_132 = None
        neg_32 = torch.ops.aten.neg.default(convert_element_type_891)
        exp_48 = torch.ops.aten.exp.default(neg_32);  neg_32 = None
        add_1088 = torch.ops.aten.add.Tensor(exp_48, 1);  exp_48 = None
        div_80 = torch.ops.aten.div.Tensor(convert_element_type_891, add_1088)
        convert_element_type_892 = torch.ops.prims.convert_element_type.default(div_80, torch.bfloat16);  div_80 = None
        mul_1631 = torch.ops.aten.mul.Tensor(mm_379, convert_element_type_892);  convert_element_type_892 = None
        mul_1632 = torch.ops.aten.mul.Tensor(mm_379, mm_133);  mm_379 = mm_133 = None
        permute_912 = torch.ops.aten.permute.default(mul_1631, [1, 0])
        mm_380 = torch.ops.aten.mm.default(permute_912, view_1063);  permute_912 = None
        convert_element_type_893 = torch.ops.prims.convert_element_type.default(primals_277, torch.bfloat16);  primals_277 = None
        all_gather_into_tensor_281 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_893, 128, '0');  convert_element_type_893 = None
        wait_tensor_345 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_281);  all_gather_into_tensor_281 = None
        permute_249 = torch.ops.aten.permute.default(wait_tensor_345, [1, 0]);  wait_tensor_345 = None
        permute_914 = torch.ops.aten.permute.default(permute_249, [1, 0]);  permute_249 = None
        mm_381 = torch.ops.aten.mm.default(mul_1631, permute_914);  mul_1631 = permute_914 = None
        convert_element_type_2209 = torch.ops.prims.convert_element_type.default(mm_380, torch.float32);  mm_380 = None
        reduce_scatter_tensor_143 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2209, 'avg', 128, '0');  convert_element_type_2209 = None
        wait_tensor_722 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_143);  reduce_scatter_tensor_143 = None
        convert_element_type_2210 = torch.ops.prims.convert_element_type.default(mul_1632, torch.float32);  mul_1632 = None
        reciprocal_20 = torch.ops.aten.reciprocal.default(add_1088);  add_1088 = None
        mul_1633 = torch.ops.aten.mul.Tensor(reciprocal_20, 1);  reciprocal_20 = None
        mul_1634 = torch.ops.aten.mul.Tensor(convert_element_type_2210, mul_1633);  convert_element_type_2210 = None
        sub_685 = torch.ops.aten.sub.Tensor(1, mul_1633);  mul_1633 = None
        mul_1635 = torch.ops.aten.mul.Tensor(convert_element_type_891, sub_685);  convert_element_type_891 = sub_685 = None
        add_1926 = torch.ops.aten.add.Tensor(mul_1635, 1);  mul_1635 = None
        mul_1636 = torch.ops.aten.mul.Tensor(mul_1634, add_1926);  mul_1634 = add_1926 = None
        convert_element_type_2212 = torch.ops.prims.convert_element_type.default(mul_1636, torch.bfloat16);  mul_1636 = None
        permute_916 = torch.ops.aten.permute.default(convert_element_type_2212, [1, 0])
        mm_382 = torch.ops.aten.mm.default(permute_916, view_1063);  permute_916 = None
        convert_element_type_888 = torch.ops.prims.convert_element_type.default(primals_276, torch.bfloat16);  primals_276 = None
        all_gather_into_tensor_280 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_888, 128, '0');  convert_element_type_888 = None
        wait_tensor_344 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_280);  all_gather_into_tensor_280 = None
        permute_248 = torch.ops.aten.permute.default(wait_tensor_344, [1, 0]);  wait_tensor_344 = None
        permute_918 = torch.ops.aten.permute.default(permute_248, [1, 0]);  permute_248 = None
        mm_383 = torch.ops.aten.mm.default(convert_element_type_2212, permute_918);  convert_element_type_2212 = permute_918 = None
        add_1927 = torch.ops.aten.add.Tensor(mm_381, mm_383);  mm_381 = mm_383 = None
        convert_element_type_2217 = torch.ops.prims.convert_element_type.default(mm_382, torch.float32);  mm_382 = None
        reduce_scatter_tensor_144 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2217, 'avg', 128, '0');  convert_element_type_2217 = None
        wait_tensor_723 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_144);  reduce_scatter_tensor_144 = None
        all_to_all_single_98 = torch.ops._c10d_functional.all_to_all_single.default(index_72, [_local_scalar_dense_248, _local_scalar_dense_249, _local_scalar_dense_250, _local_scalar_dense_251, _local_scalar_dense_252, _local_scalar_dense_253, _local_scalar_dense_254, _local_scalar_dense_255], [_local_scalar_dense_240, _local_scalar_dense_241, _local_scalar_dense_242, _local_scalar_dense_243, _local_scalar_dense_244, _local_scalar_dense_245, _local_scalar_dense_246, _local_scalar_dense_247], '1033');  index_72 = None
        wait_tensor_724 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_98);  all_to_all_single_98 = None
        full_408 = torch.ops.aten.full.default([sym_size_int_61, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_61 = None
        slice_scatter_10 = torch.ops.aten.slice_scatter.default(full_408, wait_tensor_724, 0, 0, -1);  wait_tensor_724 = None
        index_73 = torch.ops.aten.index.Tensor(slice_scatter_10, [getitem_1672]);  slice_scatter_10 = None
        permute_920 = torch.ops.aten.permute.default(index_73, [1, 0])
        _grouped_mm_138 = torch.ops.aten._grouped_mm.default(permute_920, mul_770, cumsum_47);  permute_920 = mul_770 = None
        _grouped_mm_139 = torch.ops.aten._grouped_mm.default(index_73, permute_922, cumsum_47);  index_73 = permute_922 = None
        convert_element_type_886 = torch.ops.prims.convert_element_type.default(_grouped_mm_45, torch.float32);  _grouped_mm_45 = None
        neg_31 = torch.ops.aten.neg.default(convert_element_type_886)
        exp_47 = torch.ops.aten.exp.default(neg_31);  neg_31 = None
        add_1052 = torch.ops.aten.add.Tensor(exp_47, 1);  exp_47 = None
        div_79 = torch.ops.aten.div.Tensor(convert_element_type_886, add_1052)
        convert_element_type_887 = torch.ops.prims.convert_element_type.default(div_79, torch.bfloat16);  div_79 = None
        mul_1637 = torch.ops.aten.mul.Tensor(_grouped_mm_139, convert_element_type_887);  convert_element_type_887 = None
        mul_1638 = torch.ops.aten.mul.Tensor(_grouped_mm_139, _grouped_mm_46);  _grouped_mm_139 = _grouped_mm_46 = None
        permute_924 = torch.ops.aten.permute.default(mul_1637, [1, 0])
        _grouped_mm_140 = torch.ops.aten._grouped_mm.default(permute_924, index_31, cumsum_47);  permute_924 = None
        _grouped_mm_141 = torch.ops.aten._grouped_mm.default(mul_1637, permute_926, cumsum_47);  mul_1637 = permute_926 = None
        convert_element_type_2218 = torch.ops.prims.convert_element_type.default(mul_1638, torch.float32);  mul_1638 = None
        reciprocal_21 = torch.ops.aten.reciprocal.default(add_1052);  add_1052 = None
        mul_1639 = torch.ops.aten.mul.Tensor(reciprocal_21, 1);  reciprocal_21 = None
        mul_1640 = torch.ops.aten.mul.Tensor(convert_element_type_2218, mul_1639);  convert_element_type_2218 = None
        sub_686 = torch.ops.aten.sub.Tensor(1, mul_1639);  mul_1639 = None
        mul_1641 = torch.ops.aten.mul.Tensor(convert_element_type_886, sub_686);  convert_element_type_886 = sub_686 = None
        add_1929 = torch.ops.aten.add.Tensor(mul_1641, 1);  mul_1641 = None
        mul_1642 = torch.ops.aten.mul.Tensor(mul_1640, add_1929);  mul_1640 = add_1929 = None
        convert_element_type_2220 = torch.ops.prims.convert_element_type.default(mul_1642, torch.bfloat16);  mul_1642 = None
        permute_928 = torch.ops.aten.permute.default(convert_element_type_2220, [1, 0])
        _grouped_mm_142 = torch.ops.aten._grouped_mm.default(permute_928, index_31, cumsum_47);  permute_928 = index_31 = None
        _grouped_mm_143 = torch.ops.aten._grouped_mm.default(convert_element_type_2220, permute_930, cumsum_47);  convert_element_type_2220 = permute_930 = cumsum_47 = None
        add_1930 = torch.ops.aten.add.Tensor(_grouped_mm_141, _grouped_mm_143);  _grouped_mm_141 = _grouped_mm_143 = None
        convert_element_type_2221 = torch.ops.prims.convert_element_type.default(_grouped_mm_140, torch.float32);  _grouped_mm_140 = None
        div_192 = torch.ops.aten.div.Tensor(convert_element_type_2221, 128);  convert_element_type_2221 = None
        split_687 = torch.ops.aten.split.Tensor(div_192, 88, 1);  div_192 = None
        getitem_12885 = split_687[0]
        getitem_12902 = split_687[1]
        getitem_12919 = split_687[2]
        getitem_12936 = split_687[3]
        getitem_12953 = split_687[4]
        getitem_12970 = split_687[5]
        getitem_12987 = split_687[6]
        getitem_13004 = split_687[7]
        getitem_13021 = split_687[8]
        getitem_13038 = split_687[9]
        getitem_13055 = split_687[10]
        getitem_13072 = split_687[11]
        getitem_13089 = split_687[12]
        getitem_13106 = split_687[13]
        getitem_13123 = split_687[14]
        getitem_13140 = split_687[15];  split_687 = None
        cat_316 = torch.ops.aten.cat.default([getitem_12885, getitem_12902, getitem_12919, getitem_12936, getitem_12953, getitem_12970, getitem_12987, getitem_13004, getitem_13021, getitem_13038, getitem_13055, getitem_13072, getitem_13089, getitem_13106, getitem_13123, getitem_13140]);  getitem_12885 = getitem_12902 = getitem_12919 = getitem_12936 = getitem_12953 = getitem_12970 = getitem_12987 = getitem_13004 = getitem_13021 = getitem_13038 = getitem_13055 = getitem_13072 = getitem_13089 = getitem_13106 = getitem_13123 = getitem_13140 = None
        reduce_scatter_tensor_145 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_316, 'sum', 16, '1025');  cat_316 = None
        wait_tensor_725 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_145);  reduce_scatter_tensor_145 = None
        convert_element_type_2222 = torch.ops.prims.convert_element_type.default(_grouped_mm_138, torch.float32);  _grouped_mm_138 = None
        div_193 = torch.ops.aten.div.Tensor(convert_element_type_2222, 128);  convert_element_type_2222 = None
        split_704 = torch.ops.aten.split.Tensor(div_193, 128, 1);  div_193 = None
        getitem_13157 = split_704[0]
        getitem_13174 = split_704[1]
        getitem_13191 = split_704[2]
        getitem_13208 = split_704[3]
        getitem_13225 = split_704[4]
        getitem_13242 = split_704[5]
        getitem_13259 = split_704[6]
        getitem_13276 = split_704[7]
        getitem_13293 = split_704[8]
        getitem_13310 = split_704[9]
        getitem_13327 = split_704[10]
        getitem_13344 = split_704[11]
        getitem_13361 = split_704[12]
        getitem_13378 = split_704[13]
        getitem_13395 = split_704[14]
        getitem_13412 = split_704[15];  split_704 = None
        cat_317 = torch.ops.aten.cat.default([getitem_13157, getitem_13174, getitem_13191, getitem_13208, getitem_13225, getitem_13242, getitem_13259, getitem_13276, getitem_13293, getitem_13310, getitem_13327, getitem_13344, getitem_13361, getitem_13378, getitem_13395, getitem_13412]);  getitem_13157 = getitem_13174 = getitem_13191 = getitem_13208 = getitem_13225 = getitem_13242 = getitem_13259 = getitem_13276 = getitem_13293 = getitem_13310 = getitem_13327 = getitem_13344 = getitem_13361 = getitem_13378 = getitem_13395 = getitem_13412 = None
        reduce_scatter_tensor_146 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_317, 'sum', 16, '1025');  cat_317 = None
        wait_tensor_726 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_146);  reduce_scatter_tensor_146 = None
        convert_element_type_2223 = torch.ops.prims.convert_element_type.default(_grouped_mm_142, torch.float32);  _grouped_mm_142 = None
        div_194 = torch.ops.aten.div.Tensor(convert_element_type_2223, 128);  convert_element_type_2223 = None
        split_721 = torch.ops.aten.split.Tensor(div_194, 88, 1);  div_194 = None
        getitem_13429 = split_721[0]
        getitem_13446 = split_721[1]
        getitem_13463 = split_721[2]
        getitem_13480 = split_721[3]
        getitem_13497 = split_721[4]
        getitem_13514 = split_721[5]
        getitem_13531 = split_721[6]
        getitem_13548 = split_721[7]
        getitem_13565 = split_721[8]
        getitem_13582 = split_721[9]
        getitem_13599 = split_721[10]
        getitem_13616 = split_721[11]
        getitem_13633 = split_721[12]
        getitem_13650 = split_721[13]
        getitem_13667 = split_721[14]
        getitem_13684 = split_721[15];  split_721 = None
        cat_318 = torch.ops.aten.cat.default([getitem_13429, getitem_13446, getitem_13463, getitem_13480, getitem_13497, getitem_13514, getitem_13531, getitem_13548, getitem_13565, getitem_13582, getitem_13599, getitem_13616, getitem_13633, getitem_13650, getitem_13667, getitem_13684]);  getitem_13429 = getitem_13446 = getitem_13463 = getitem_13480 = getitem_13497 = getitem_13514 = getitem_13531 = getitem_13548 = getitem_13565 = getitem_13582 = getitem_13599 = getitem_13616 = getitem_13633 = getitem_13650 = getitem_13667 = getitem_13684 = None
        reduce_scatter_tensor_147 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_318, 'sum', 16, '1025');  cat_318 = None
        wait_tensor_727 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_147);  reduce_scatter_tensor_147 = None
        index_put_72 = torch.ops.aten.index_put.default(full_408, [getitem_1672], add_1930, True);  full_408 = getitem_1672 = add_1930 = None
        slice_222 = torch.ops.aten.slice.Tensor(index_put_72, 0, 0, add_1931);  index_put_72 = add_1931 = None
        all_to_all_single_99 = torch.ops._c10d_functional.all_to_all_single.default(slice_222, [_local_scalar_dense_240, _local_scalar_dense_241, _local_scalar_dense_242, _local_scalar_dense_243, _local_scalar_dense_244, _local_scalar_dense_245, _local_scalar_dense_246, _local_scalar_dense_247], [_local_scalar_dense_248, _local_scalar_dense_249, _local_scalar_dense_250, _local_scalar_dense_251, _local_scalar_dense_252, _local_scalar_dense_253, _local_scalar_dense_254, _local_scalar_dense_255], '1033');  slice_222 = _local_scalar_dense_240 = _local_scalar_dense_241 = _local_scalar_dense_242 = _local_scalar_dense_243 = _local_scalar_dense_244 = _local_scalar_dense_245 = _local_scalar_dense_246 = _local_scalar_dense_247 = _local_scalar_dense_248 = _local_scalar_dense_249 = _local_scalar_dense_250 = _local_scalar_dense_251 = _local_scalar_dense_252 = _local_scalar_dense_253 = _local_scalar_dense_254 = _local_scalar_dense_255 = None
        wait_tensor_728 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_99);  all_to_all_single_99 = None
        index_put_73 = torch.ops.aten.index_put.default(full_default_52, [div_77], wait_tensor_728, True);  div_77 = wait_tensor_728 = None
        add_1935 = torch.ops.aten.add.Tensor(add_1927, index_put_73);  add_1927 = index_put_73 = None
        mul_1643 = torch.ops.aten.mul.Tensor(view_1973, 1.0);  view_1973 = None
        scatter_add_10 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_1669, mul_1643);  getitem_1669 = mul_1643 = None
        convert_element_type_875 = torch.ops.prims.convert_element_type.default(mm_131, torch.float32);  mm_131 = None
        sub_360 = torch.ops.aten.sub.Tensor(convert_element_type_875, amax_15);  convert_element_type_875 = amax_15 = None
        exp_46 = torch.ops.aten.exp.default(sub_360);  sub_360 = None
        div_76 = torch.ops.aten.div.Tensor(exp_46, sum_61);  exp_46 = sum_61 = None
        mul_1644 = torch.ops.aten.mul.Tensor(scatter_add_10, div_76);  scatter_add_10 = None
        sum_187 = torch.ops.aten.sum.dim_IntList(mul_1644, [1], True)
        neg_85 = torch.ops.aten.neg.default(div_76);  div_76 = None
        fma_10 = torch.ops.prims.fma.default(neg_85, sum_187, mul_1644);  neg_85 = sum_187 = mul_1644 = None
        convert_element_type_2224 = torch.ops.prims.convert_element_type.default(fma_10, torch.bfloat16);  fma_10 = None
        permute_932 = torch.ops.aten.permute.default(convert_element_type_2224, [1, 0])
        mm_384 = torch.ops.aten.mm.default(permute_932, view_1063);  permute_932 = view_1063 = None
        convert_element_type_872 = torch.ops.prims.convert_element_type.default(primals_271, torch.bfloat16);  primals_271 = None
        all_gather_into_tensor_273 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_872, 128, '0');  convert_element_type_872 = None
        wait_tensor_333 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_273);  all_gather_into_tensor_273 = None
        slice_99 = torch.ops.aten.slice.Tensor(wait_tensor_333, 0, 0, 64);  wait_tensor_333 = None
        permute_244 = torch.ops.aten.permute.default(slice_99, [1, 0]);  slice_99 = None
        permute_934 = torch.ops.aten.permute.default(permute_244, [1, 0]);  permute_244 = None
        mm_385 = torch.ops.aten.mm.default(convert_element_type_2224, permute_934);  convert_element_type_2224 = permute_934 = None
        add_1936 = torch.ops.aten.add.Tensor(add_1935, mm_385);  add_1935 = mm_385 = None
        convert_element_type_2229 = torch.ops.prims.convert_element_type.default(mm_384, torch.float32);  mm_384 = None
        split_737 = torch.ops.aten.split.Tensor(convert_element_type_2229, 1);  convert_element_type_2229 = None
        getitem_13685 = split_737[0]
        getitem_13686 = split_737[1]
        getitem_13687 = split_737[2]
        getitem_13688 = split_737[3]
        getitem_13689 = split_737[4]
        getitem_13690 = split_737[5]
        getitem_13691 = split_737[6]
        getitem_13692 = split_737[7]
        getitem_13693 = split_737[8]
        getitem_13694 = split_737[9]
        getitem_13695 = split_737[10]
        getitem_13696 = split_737[11]
        getitem_13697 = split_737[12]
        getitem_13698 = split_737[13]
        getitem_13699 = split_737[14]
        getitem_13700 = split_737[15]
        getitem_13701 = split_737[16]
        getitem_13702 = split_737[17]
        getitem_13703 = split_737[18]
        getitem_13704 = split_737[19]
        getitem_13705 = split_737[20]
        getitem_13706 = split_737[21]
        getitem_13707 = split_737[22]
        getitem_13708 = split_737[23]
        getitem_13709 = split_737[24]
        getitem_13710 = split_737[25]
        getitem_13711 = split_737[26]
        getitem_13712 = split_737[27]
        getitem_13713 = split_737[28]
        getitem_13714 = split_737[29]
        getitem_13715 = split_737[30]
        getitem_13716 = split_737[31]
        getitem_13717 = split_737[32]
        getitem_13718 = split_737[33]
        getitem_13719 = split_737[34]
        getitem_13720 = split_737[35]
        getitem_13721 = split_737[36]
        getitem_13722 = split_737[37]
        getitem_13723 = split_737[38]
        getitem_13724 = split_737[39]
        getitem_13725 = split_737[40]
        getitem_13726 = split_737[41]
        getitem_13727 = split_737[42]
        getitem_13728 = split_737[43]
        getitem_13729 = split_737[44]
        getitem_13730 = split_737[45]
        getitem_13731 = split_737[46]
        getitem_13732 = split_737[47]
        getitem_13733 = split_737[48]
        getitem_13734 = split_737[49]
        getitem_13735 = split_737[50]
        getitem_13736 = split_737[51]
        getitem_13737 = split_737[52]
        getitem_13738 = split_737[53]
        getitem_13739 = split_737[54]
        getitem_13740 = split_737[55]
        getitem_13741 = split_737[56]
        getitem_13742 = split_737[57]
        getitem_13743 = split_737[58]
        getitem_13744 = split_737[59]
        getitem_13745 = split_737[60]
        getitem_13746 = split_737[61]
        getitem_13747 = split_737[62]
        getitem_13748 = split_737[63];  split_737 = None
        cat_319 = torch.ops.aten.cat.default([getitem_13685, getitem_13686, getitem_13687, getitem_13688, getitem_13689, getitem_13690, getitem_13691, getitem_13692, getitem_13693, getitem_13694, getitem_13695, getitem_13696, getitem_13697, getitem_13698, getitem_13699, getitem_13700, getitem_13701, getitem_13702, getitem_13703, getitem_13704, getitem_13705, getitem_13706, getitem_13707, getitem_13708, getitem_13709, getitem_13710, getitem_13711, getitem_13712, getitem_13713, getitem_13714, getitem_13715, getitem_13716, getitem_13717, getitem_13718, getitem_13719, getitem_13720, getitem_13721, getitem_13722, getitem_13723, getitem_13724, getitem_13725, getitem_13726, getitem_13727, getitem_13728, getitem_13729, getitem_13730, getitem_13731, getitem_13732, getitem_13733, getitem_13734, getitem_13735, getitem_13736, getitem_13737, getitem_13738, getitem_13739, getitem_13740, getitem_13741, getitem_13742, getitem_13743, getitem_13744, getitem_13745, getitem_13746, getitem_13747, getitem_13748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_13685 = getitem_13686 = getitem_13687 = getitem_13688 = getitem_13689 = getitem_13690 = getitem_13691 = getitem_13692 = getitem_13693 = getitem_13694 = getitem_13695 = getitem_13696 = getitem_13697 = getitem_13698 = getitem_13699 = getitem_13700 = getitem_13701 = getitem_13702 = getitem_13703 = getitem_13704 = getitem_13705 = getitem_13706 = getitem_13707 = getitem_13708 = getitem_13709 = getitem_13710 = getitem_13711 = getitem_13712 = getitem_13713 = getitem_13714 = getitem_13715 = getitem_13716 = getitem_13717 = getitem_13718 = getitem_13719 = getitem_13720 = getitem_13721 = getitem_13722 = getitem_13723 = getitem_13724 = getitem_13725 = getitem_13726 = getitem_13727 = getitem_13728 = getitem_13729 = getitem_13730 = getitem_13731 = getitem_13732 = getitem_13733 = getitem_13734 = getitem_13735 = getitem_13736 = getitem_13737 = getitem_13738 = getitem_13739 = getitem_13740 = getitem_13741 = getitem_13742 = getitem_13743 = getitem_13744 = getitem_13745 = getitem_13746 = getitem_13747 = getitem_13748 = None
        reduce_scatter_tensor_148 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_319, 'avg', 128, '0');  cat_319 = None
        wait_tensor_729 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_148);  reduce_scatter_tensor_148 = None
        view_1975 = torch.ops.aten.view.default(add_1936, [2, 4096, 2048]);  add_1936 = None
        convert_element_type_2230 = torch.ops.prims.convert_element_type.default(view_1975, torch.float32);  view_1975 = None
        convert_element_type_869 = torch.ops.prims.convert_element_type.default(primals_269, torch.bfloat16);  primals_269 = None
        all_gather_into_tensor_272 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_869, 128, '0');  convert_element_type_869 = None
        wait_tensor_332 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_272);  all_gather_into_tensor_272 = None
        convert_element_type_2232 = torch.ops.prims.convert_element_type.default(wait_tensor_332, torch.float32);  wait_tensor_332 = None
        mul_1645 = torch.ops.aten.mul.Tensor(convert_element_type_2230, convert_element_type_2232);  convert_element_type_2232 = None
        convert_element_type_870 = torch.ops.prims.convert_element_type.default(add_1028, torch.float32);  add_1028 = None
        mul_750 = torch.ops.aten.mul.Tensor(convert_element_type_870, rsqrt_50);  convert_element_type_870 = None
        mul_1647 = torch.ops.aten.mul.Tensor(mul_750, mul_1645)
        sum_188 = torch.ops.aten.sum.dim_IntList(mul_1647, [2], True);  mul_1647 = None
        div_195 = torch.ops.aten.div.Tensor(mul_750, 2048)
        mul_1648 = torch.ops.aten.mul.Tensor(div_195, sum_188);  div_195 = sum_188 = None
        sub_688 = torch.ops.aten.sub.Tensor(mul_1645, mul_1648);  mul_1645 = mul_1648 = None
        mul_1649 = torch.ops.aten.mul.Tensor(sub_688, rsqrt_50);  sub_688 = rsqrt_50 = None
        mul_1650 = torch.ops.aten.mul.Tensor(convert_element_type_2230, mul_750);  convert_element_type_2230 = mul_750 = None
        sum_189 = torch.ops.aten.sum.dim_IntList(mul_1650, [0, 1]);  mul_1650 = None
        convert_element_type_2233 = torch.ops.prims.convert_element_type.default(mul_1649, torch.bfloat16);  mul_1649 = None
        add_1937 = torch.ops.aten.add.Tensor(add_1924, convert_element_type_2233);  add_1924 = convert_element_type_2233 = None
        convert_element_type_default_51 = torch.ops.prims.convert_element_type.default(sum_189, torch.float32);  sum_189 = None
        reduce_scatter_tensor_149 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_51, 'avg', 128, '0');  convert_element_type_default_51 = None
        wait_tensor_730 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_149);  reduce_scatter_tensor_149 = None
        view_1976 = torch.ops.aten.view.default(add_1937, [8192, 2048])
        permute_936 = torch.ops.aten.permute.default(view_1976, [1, 0])
        permute_242 = torch.ops.aten.permute.default(getitem_1665, [0, 2, 1, 3])
        view_1058 = torch.ops.aten.view.default(permute_242, [2, 4096, -1]);  permute_242 = None
        view_1060 = torch.ops.aten.view.default(view_1058, [8192, 2048]);  view_1058 = None
        mm_386 = torch.ops.aten.mm.default(permute_936, view_1060);  permute_936 = view_1060 = None
        convert_element_type_866 = torch.ops.prims.convert_element_type.default(primals_268, torch.bfloat16);  primals_268 = None
        all_gather_into_tensor_271 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_866, 128, '0');  convert_element_type_866 = None
        wait_tensor_331 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_271);  all_gather_into_tensor_271 = None
        permute_243 = torch.ops.aten.permute.default(wait_tensor_331, [1, 0]);  wait_tensor_331 = None
        permute_938 = torch.ops.aten.permute.default(permute_243, [1, 0]);  permute_243 = None
        mm_387 = torch.ops.aten.mm.default(view_1976, permute_938);  view_1976 = permute_938 = None
        view_1977 = torch.ops.aten.view.default(mm_387, [2, 4096, 2048]);  mm_387 = None
        convert_element_type_2240 = torch.ops.prims.convert_element_type.default(mm_386, torch.float32);  mm_386 = None
        reduce_scatter_tensor_150 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2240, 'avg', 128, '0');  convert_element_type_2240 = None
        wait_tensor_731 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_150);  reduce_scatter_tensor_150 = None
        view_1978 = torch.ops.aten.view.default(view_1977, [2, 4096, 16, 128]);  view_1977 = None
        permute_940 = torch.ops.aten.permute.default(view_1978, [0, 2, 1, 3]);  view_1978 = None
        fw_graph10 = self.fw_graph10
        joint_graph10 = self.joint_graph10
        mask_graph10 = self.mask_graph10
        flex_attention_backward_10 = torch.ops.higher_order.flex_attention_backward(permute_239, permute_240, permute_241, getitem_1665, getitem_1666, permute_940, None, fw_graph10, joint_graph10, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph10), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_239 = permute_240 = permute_241 = getitem_1665 = getitem_1666 = permute_940 = fw_graph10 = joint_graph10 = mask_graph10 = None
        getitem_13749 = flex_attention_backward_10[0]
        getitem_13750 = flex_attention_backward_10[1]
        getitem_13751 = flex_attention_backward_10[2];  flex_attention_backward_10 = None
        permute_941 = torch.ops.aten.permute.default(getitem_13751, [0, 2, 1, 3]);  getitem_13751 = None
        permute_942 = torch.ops.aten.permute.default(getitem_13750, [0, 2, 1, 3]);  getitem_13750 = None
        permute_943 = torch.ops.aten.permute.default(getitem_13749, [0, 2, 1, 3]);  getitem_13749 = None
        slice_224 = torch.ops.aten.slice.Tensor(permute_942, 3, 0, 128)
        slice_225 = torch.ops.aten.slice.Tensor(permute_942, 3, 128, 192);  permute_942 = None
        sum_190 = torch.ops.aten.sum.dim_IntList(slice_225, [2], True);  slice_225 = None
        cat_320 = torch.ops.aten.cat.default([slice_224, permute_941], 3);  slice_224 = permute_941 = None
        view_1979 = torch.ops.aten.view.default(cat_320, [2, 4096, 4096]);  cat_320 = None
        view_1980 = torch.ops.aten.view.default(view_1979, [8192, 4096]);  view_1979 = None
        permute_944 = torch.ops.aten.permute.default(view_1980, [1, 0])
        mm_388 = torch.ops.aten.mm.default(permute_944, view_1055);  permute_944 = view_1055 = None
        convert_element_type_863 = torch.ops.prims.convert_element_type.default(primals_267, torch.bfloat16);  primals_267 = None
        all_gather_into_tensor_270 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_863, 128, '0');  convert_element_type_863 = None
        wait_tensor_330 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_270);  all_gather_into_tensor_270 = None
        permute_238 = torch.ops.aten.permute.default(wait_tensor_330, [1, 0]);  wait_tensor_330 = None
        permute_946 = torch.ops.aten.permute.default(permute_238, [1, 0]);  permute_238 = None
        mm_389 = torch.ops.aten.mm.default(view_1980, permute_946);  view_1980 = permute_946 = None
        view_1981 = torch.ops.aten.view.default(mm_389, [2, 4096, 512]);  mm_389 = None
        convert_element_type_2245 = torch.ops.prims.convert_element_type.default(mm_388, torch.float32);  mm_388 = None
        reduce_scatter_tensor_151 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2245, 'avg', 128, '0');  convert_element_type_2245 = None
        wait_tensor_732 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_151);  reduce_scatter_tensor_151 = None
        convert_element_type_2246 = torch.ops.prims.convert_element_type.default(view_1981, torch.float32);  view_1981 = None
        convert_element_type_860 = torch.ops.prims.convert_element_type.default(primals_266, torch.bfloat16);  primals_266 = None
        all_gather_into_tensor_269 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_860, 128, '0');  convert_element_type_860 = None
        wait_tensor_329 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_269);  all_gather_into_tensor_269 = None
        convert_element_type_2248 = torch.ops.prims.convert_element_type.default(wait_tensor_329, torch.float32);  wait_tensor_329 = None
        mul_1651 = torch.ops.aten.mul.Tensor(convert_element_type_2246, convert_element_type_2248);  convert_element_type_2248 = None
        convert_element_type_861 = torch.ops.prims.convert_element_type.default(getitem_1661, torch.float32);  getitem_1661 = None
        mul_748 = torch.ops.aten.mul.Tensor(convert_element_type_861, rsqrt_49);  convert_element_type_861 = None
        mul_1653 = torch.ops.aten.mul.Tensor(mul_748, mul_1651)
        sum_191 = torch.ops.aten.sum.dim_IntList(mul_1653, [2], True);  mul_1653 = None
        div_196 = torch.ops.aten.div.Tensor(mul_748, 512)
        mul_1654 = torch.ops.aten.mul.Tensor(div_196, sum_191);  div_196 = sum_191 = None
        sub_689 = torch.ops.aten.sub.Tensor(mul_1651, mul_1654);  mul_1651 = mul_1654 = None
        mul_1655 = torch.ops.aten.mul.Tensor(sub_689, rsqrt_49);  sub_689 = rsqrt_49 = None
        mul_1656 = torch.ops.aten.mul.Tensor(convert_element_type_2246, mul_748);  convert_element_type_2246 = mul_748 = None
        sum_192 = torch.ops.aten.sum.dim_IntList(mul_1656, [0, 1]);  mul_1656 = None
        convert_element_type_2249 = torch.ops.prims.convert_element_type.default(mul_1655, torch.bfloat16);  mul_1655 = None
        convert_element_type_default_50 = torch.ops.prims.convert_element_type.default(sum_192, torch.float32);  sum_192 = None
        reduce_scatter_tensor_152 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_50, 'avg', 128, '0');  convert_element_type_default_50 = None
        wait_tensor_733 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_152);  reduce_scatter_tensor_152 = None
        convert_element_type_2252 = torch.ops.prims.convert_element_type.default(sum_190, torch.float32);  sum_190 = None
        view_1982 = torch.ops.aten.view.default(convert_element_type_2252, [2, 4096, 1, 32, 2]);  convert_element_type_2252 = None
        view_as_complex_74 = torch.ops.aten.view_as_complex.default(view_1982);  view_1982 = None
        mul_1657 = torch.ops.aten.mul.Tensor(view_as_complex_74, clone_9);  view_as_complex_74 = None
        view_as_real_74 = torch.ops.aten.view_as_real.default(mul_1657);  mul_1657 = None
        view_1983 = torch.ops.aten.view.default(view_as_real_74, [2, 4096, 1, 64]);  view_as_real_74 = None
        convert_element_type_2253 = torch.ops.prims.convert_element_type.default(view_1983, torch.bfloat16);  view_1983 = None
        squeeze_36 = torch.ops.aten.squeeze.dim(convert_element_type_2253, 2);  convert_element_type_2253 = None
        cat_321 = torch.ops.aten.cat.default([convert_element_type_2249, squeeze_36], 2);  convert_element_type_2249 = squeeze_36 = None
        view_1984 = torch.ops.aten.view.default(cat_321, [8192, 576]);  cat_321 = None
        permute_948 = torch.ops.aten.permute.default(view_1984, [1, 0])
        mm_390 = torch.ops.aten.mm.default(permute_948, view_1041);  permute_948 = None
        convert_element_type_855 = torch.ops.prims.convert_element_type.default(primals_265, torch.bfloat16);  primals_265 = None
        all_gather_into_tensor_268 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_855, 128, '0');  convert_element_type_855 = None
        wait_tensor_328 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_268);  all_gather_into_tensor_268 = None
        slice_97 = torch.ops.aten.slice.Tensor(wait_tensor_328, 0, 0, 576);  wait_tensor_328 = None
        permute_237 = torch.ops.aten.permute.default(slice_97, [1, 0]);  slice_97 = None
        permute_950 = torch.ops.aten.permute.default(permute_237, [1, 0]);  permute_237 = None
        mm_391 = torch.ops.aten.mm.default(view_1984, permute_950);  view_1984 = permute_950 = None
        view_1985 = torch.ops.aten.view.default(mm_391, [2, 4096, 2048]);  mm_391 = None
        convert_element_type_2258 = torch.ops.prims.convert_element_type.default(mm_390, torch.float32);  mm_390 = None
        split_738 = torch.ops.aten.split.Tensor(convert_element_type_2258, 5);  convert_element_type_2258 = None
        getitem_13753 = split_738[0]
        getitem_13754 = split_738[1]
        getitem_13755 = split_738[2]
        getitem_13756 = split_738[3]
        getitem_13757 = split_738[4]
        getitem_13758 = split_738[5]
        getitem_13759 = split_738[6]
        getitem_13760 = split_738[7]
        getitem_13761 = split_738[8]
        getitem_13762 = split_738[9]
        getitem_13763 = split_738[10]
        getitem_13764 = split_738[11]
        getitem_13765 = split_738[12]
        getitem_13766 = split_738[13]
        getitem_13767 = split_738[14]
        getitem_13768 = split_738[15]
        getitem_13769 = split_738[16]
        getitem_13770 = split_738[17]
        getitem_13771 = split_738[18]
        getitem_13772 = split_738[19]
        getitem_13773 = split_738[20]
        getitem_13774 = split_738[21]
        getitem_13775 = split_738[22]
        getitem_13776 = split_738[23]
        getitem_13777 = split_738[24]
        getitem_13778 = split_738[25]
        getitem_13779 = split_738[26]
        getitem_13780 = split_738[27]
        getitem_13781 = split_738[28]
        getitem_13782 = split_738[29]
        getitem_13783 = split_738[30]
        getitem_13784 = split_738[31]
        getitem_13785 = split_738[32]
        getitem_13786 = split_738[33]
        getitem_13787 = split_738[34]
        getitem_13788 = split_738[35]
        getitem_13789 = split_738[36]
        getitem_13790 = split_738[37]
        getitem_13791 = split_738[38]
        getitem_13792 = split_738[39]
        getitem_13793 = split_738[40]
        getitem_13794 = split_738[41]
        getitem_13795 = split_738[42]
        getitem_13796 = split_738[43]
        getitem_13797 = split_738[44]
        getitem_13798 = split_738[45]
        getitem_13799 = split_738[46]
        getitem_13800 = split_738[47]
        getitem_13801 = split_738[48]
        getitem_13802 = split_738[49]
        getitem_13803 = split_738[50]
        getitem_13804 = split_738[51]
        getitem_13805 = split_738[52]
        getitem_13806 = split_738[53]
        getitem_13807 = split_738[54]
        getitem_13808 = split_738[55]
        getitem_13809 = split_738[56]
        getitem_13810 = split_738[57]
        getitem_13811 = split_738[58]
        getitem_13812 = split_738[59]
        getitem_13813 = split_738[60]
        getitem_13814 = split_738[61]
        getitem_13815 = split_738[62]
        getitem_13816 = split_738[63]
        getitem_13817 = split_738[64]
        getitem_13818 = split_738[65]
        getitem_13819 = split_738[66]
        getitem_13820 = split_738[67]
        getitem_13821 = split_738[68]
        getitem_13822 = split_738[69]
        getitem_13823 = split_738[70]
        getitem_13824 = split_738[71]
        getitem_13825 = split_738[72]
        getitem_13826 = split_738[73]
        getitem_13827 = split_738[74]
        getitem_13828 = split_738[75]
        getitem_13829 = split_738[76]
        getitem_13830 = split_738[77]
        getitem_13831 = split_738[78]
        getitem_13832 = split_738[79]
        getitem_13833 = split_738[80]
        getitem_13834 = split_738[81]
        getitem_13835 = split_738[82]
        getitem_13836 = split_738[83]
        getitem_13837 = split_738[84]
        getitem_13838 = split_738[85]
        getitem_13839 = split_738[86]
        getitem_13840 = split_738[87]
        getitem_13841 = split_738[88]
        getitem_13842 = split_738[89]
        getitem_13843 = split_738[90]
        getitem_13844 = split_738[91]
        getitem_13845 = split_738[92]
        getitem_13846 = split_738[93]
        getitem_13847 = split_738[94]
        getitem_13848 = split_738[95]
        getitem_13849 = split_738[96]
        getitem_13850 = split_738[97]
        getitem_13851 = split_738[98]
        getitem_13852 = split_738[99]
        getitem_13853 = split_738[100]
        getitem_13854 = split_738[101]
        getitem_13855 = split_738[102]
        getitem_13856 = split_738[103]
        getitem_13857 = split_738[104]
        getitem_13858 = split_738[105]
        getitem_13859 = split_738[106]
        getitem_13860 = split_738[107]
        getitem_13861 = split_738[108]
        getitem_13862 = split_738[109]
        getitem_13863 = split_738[110]
        getitem_13864 = split_738[111]
        getitem_13865 = split_738[112]
        getitem_13866 = split_738[113]
        getitem_13867 = split_738[114]
        getitem_13868 = split_738[115];  split_738 = None
        constant_pad_nd_834 = torch.ops.aten.constant_pad_nd.default(getitem_13868, [0, 0, 0, 4], 0.0);  getitem_13868 = None
        cat_322 = torch.ops.aten.cat.default([getitem_13753, getitem_13754, getitem_13755, getitem_13756, getitem_13757, getitem_13758, getitem_13759, getitem_13760, getitem_13761, getitem_13762, getitem_13763, getitem_13764, getitem_13765, getitem_13766, getitem_13767, getitem_13768, getitem_13769, getitem_13770, getitem_13771, getitem_13772, getitem_13773, getitem_13774, getitem_13775, getitem_13776, getitem_13777, getitem_13778, getitem_13779, getitem_13780, getitem_13781, getitem_13782, getitem_13783, getitem_13784, getitem_13785, getitem_13786, getitem_13787, getitem_13788, getitem_13789, getitem_13790, getitem_13791, getitem_13792, getitem_13793, getitem_13794, getitem_13795, getitem_13796, getitem_13797, getitem_13798, getitem_13799, getitem_13800, getitem_13801, getitem_13802, getitem_13803, getitem_13804, getitem_13805, getitem_13806, getitem_13807, getitem_13808, getitem_13809, getitem_13810, getitem_13811, getitem_13812, getitem_13813, getitem_13814, getitem_13815, getitem_13816, getitem_13817, getitem_13818, getitem_13819, getitem_13820, getitem_13821, getitem_13822, getitem_13823, getitem_13824, getitem_13825, getitem_13826, getitem_13827, getitem_13828, getitem_13829, getitem_13830, getitem_13831, getitem_13832, getitem_13833, getitem_13834, getitem_13835, getitem_13836, getitem_13837, getitem_13838, getitem_13839, getitem_13840, getitem_13841, getitem_13842, getitem_13843, getitem_13844, getitem_13845, getitem_13846, getitem_13847, getitem_13848, getitem_13849, getitem_13850, getitem_13851, getitem_13852, getitem_13853, getitem_13854, getitem_13855, getitem_13856, getitem_13857, getitem_13858, getitem_13859, getitem_13860, getitem_13861, getitem_13862, getitem_13863, getitem_13864, getitem_13865, getitem_13866, getitem_13867, constant_pad_nd_834, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_13753 = getitem_13754 = getitem_13755 = getitem_13756 = getitem_13757 = getitem_13758 = getitem_13759 = getitem_13760 = getitem_13761 = getitem_13762 = getitem_13763 = getitem_13764 = getitem_13765 = getitem_13766 = getitem_13767 = getitem_13768 = getitem_13769 = getitem_13770 = getitem_13771 = getitem_13772 = getitem_13773 = getitem_13774 = getitem_13775 = getitem_13776 = getitem_13777 = getitem_13778 = getitem_13779 = getitem_13780 = getitem_13781 = getitem_13782 = getitem_13783 = getitem_13784 = getitem_13785 = getitem_13786 = getitem_13787 = getitem_13788 = getitem_13789 = getitem_13790 = getitem_13791 = getitem_13792 = getitem_13793 = getitem_13794 = getitem_13795 = getitem_13796 = getitem_13797 = getitem_13798 = getitem_13799 = getitem_13800 = getitem_13801 = getitem_13802 = getitem_13803 = getitem_13804 = getitem_13805 = getitem_13806 = getitem_13807 = getitem_13808 = getitem_13809 = getitem_13810 = getitem_13811 = getitem_13812 = getitem_13813 = getitem_13814 = getitem_13815 = getitem_13816 = getitem_13817 = getitem_13818 = getitem_13819 = getitem_13820 = getitem_13821 = getitem_13822 = getitem_13823 = getitem_13824 = getitem_13825 = getitem_13826 = getitem_13827 = getitem_13828 = getitem_13829 = getitem_13830 = getitem_13831 = getitem_13832 = getitem_13833 = getitem_13834 = getitem_13835 = getitem_13836 = getitem_13837 = getitem_13838 = getitem_13839 = getitem_13840 = getitem_13841 = getitem_13842 = getitem_13843 = getitem_13844 = getitem_13845 = getitem_13846 = getitem_13847 = getitem_13848 = getitem_13849 = getitem_13850 = getitem_13851 = getitem_13852 = getitem_13853 = getitem_13854 = getitem_13855 = getitem_13856 = getitem_13857 = getitem_13858 = getitem_13859 = getitem_13860 = getitem_13861 = getitem_13862 = getitem_13863 = getitem_13864 = getitem_13865 = getitem_13866 = getitem_13867 = constant_pad_nd_834 = None
        reduce_scatter_tensor_153 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_322, 'avg', 128, '0');  cat_322 = None
        wait_tensor_734 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_153);  reduce_scatter_tensor_153 = None
        slice_226 = torch.ops.aten.slice.Tensor(permute_943, 3, 0, 128)
        slice_227 = torch.ops.aten.slice.Tensor(permute_943, 3, 128, 192);  permute_943 = None
        convert_element_type_2259 = torch.ops.prims.convert_element_type.default(slice_227, torch.float32);  slice_227 = None
        view_1986 = torch.ops.aten.view.default(convert_element_type_2259, [2, 4096, 16, 32, 2]);  convert_element_type_2259 = None
        view_as_complex_75 = torch.ops.aten.view_as_complex.default(view_1986);  view_1986 = None
        mul_1658 = torch.ops.aten.mul.Tensor(view_as_complex_75, clone_9);  view_as_complex_75 = None
        view_as_real_75 = torch.ops.aten.view_as_real.default(mul_1658);  mul_1658 = None
        view_1987 = torch.ops.aten.view.default(view_as_real_75, [2, 4096, 16, 64]);  view_as_real_75 = None
        convert_element_type_2260 = torch.ops.prims.convert_element_type.default(view_1987, torch.bfloat16);  view_1987 = None
        cat_323 = torch.ops.aten.cat.default([slice_226, convert_element_type_2260], 3);  slice_226 = convert_element_type_2260 = None
        view_1988 = torch.ops.aten.view.default(cat_323, [2, 4096, 3072]);  cat_323 = None
        view_1989 = torch.ops.aten.view.default(view_1988, [8192, 3072]);  view_1988 = None
        permute_952 = torch.ops.aten.permute.default(view_1989, [1, 0])
        mm_392 = torch.ops.aten.mm.default(permute_952, view_1041);  permute_952 = view_1041 = None
        convert_element_type_850 = torch.ops.prims.convert_element_type.default(primals_264, torch.bfloat16);  primals_264 = None
        all_gather_into_tensor_267 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_850, 128, '0');  convert_element_type_850 = None
        wait_tensor_327 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_267);  all_gather_into_tensor_267 = None
        permute_236 = torch.ops.aten.permute.default(wait_tensor_327, [1, 0]);  wait_tensor_327 = None
        permute_954 = torch.ops.aten.permute.default(permute_236, [1, 0]);  permute_236 = None
        mm_393 = torch.ops.aten.mm.default(view_1989, permute_954);  view_1989 = permute_954 = None
        view_1990 = torch.ops.aten.view.default(mm_393, [2, 4096, 2048]);  mm_393 = None
        add_1938 = torch.ops.aten.add.Tensor(view_1985, view_1990);  view_1985 = view_1990 = None
        convert_element_type_2265 = torch.ops.prims.convert_element_type.default(mm_392, torch.float32);  mm_392 = None
        reduce_scatter_tensor_154 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2265, 'avg', 128, '0');  convert_element_type_2265 = None
        wait_tensor_735 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_154);  reduce_scatter_tensor_154 = None
        convert_element_type_2266 = torch.ops.prims.convert_element_type.default(add_1938, torch.float32);  add_1938 = None
        convert_element_type_847 = torch.ops.prims.convert_element_type.default(primals_263, torch.bfloat16);  primals_263 = None
        all_gather_into_tensor_266 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_847, 128, '0');  convert_element_type_847 = None
        wait_tensor_326 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_266);  all_gather_into_tensor_266 = None
        convert_element_type_2268 = torch.ops.prims.convert_element_type.default(wait_tensor_326, torch.float32);  wait_tensor_326 = None
        mul_1659 = torch.ops.aten.mul.Tensor(convert_element_type_2266, convert_element_type_2268);  convert_element_type_2268 = None
        convert_element_type_848 = torch.ops.prims.convert_element_type.default(add_1025, torch.float32);  add_1025 = None
        mul_744 = torch.ops.aten.mul.Tensor(convert_element_type_848, rsqrt_48);  convert_element_type_848 = None
        mul_1661 = torch.ops.aten.mul.Tensor(mul_744, mul_1659)
        sum_193 = torch.ops.aten.sum.dim_IntList(mul_1661, [2], True);  mul_1661 = None
        div_197 = torch.ops.aten.div.Tensor(mul_744, 2048)
        mul_1662 = torch.ops.aten.mul.Tensor(div_197, sum_193);  div_197 = sum_193 = None
        sub_690 = torch.ops.aten.sub.Tensor(mul_1659, mul_1662);  mul_1659 = mul_1662 = None
        mul_1663 = torch.ops.aten.mul.Tensor(sub_690, rsqrt_48);  sub_690 = rsqrt_48 = None
        mul_1664 = torch.ops.aten.mul.Tensor(convert_element_type_2266, mul_744);  convert_element_type_2266 = mul_744 = None
        sum_194 = torch.ops.aten.sum.dim_IntList(mul_1664, [0, 1]);  mul_1664 = None
        convert_element_type_2269 = torch.ops.prims.convert_element_type.default(mul_1663, torch.bfloat16);  mul_1663 = None
        add_1939 = torch.ops.aten.add.Tensor(add_1937, convert_element_type_2269);  add_1937 = convert_element_type_2269 = None
        convert_element_type_default_49 = torch.ops.prims.convert_element_type.default(sum_194, torch.float32);  sum_194 = None
        reduce_scatter_tensor_155 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_49, 'avg', 128, '0');  convert_element_type_default_49 = None
        wait_tensor_736 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_155);  reduce_scatter_tensor_155 = None
        view_1991 = torch.ops.aten.view.default(add_1939, [8192, 2048])
        unsqueeze_64 = torch.ops.aten.unsqueeze.default(view_1991, 1)
        convert_element_type_2272 = torch.ops.prims.convert_element_type.default(unsqueeze_64, torch.float32);  unsqueeze_64 = None
        bmm_48 = torch.ops.aten.bmm.default(permute_956, convert_element_type_2272);  permute_956 = None
        bmm_49 = torch.ops.aten.bmm.default(convert_element_type_2272, permute_957);  convert_element_type_2272 = permute_957 = None
        convert_element_type_2273 = torch.ops.prims.convert_element_type.default(bmm_48, torch.bfloat16);  bmm_48 = None
        view_1992 = torch.ops.aten.view.default(bmm_49, [8192, 6]);  bmm_49 = None
        view_1993 = torch.ops.aten.view.default(convert_element_type_2273, [49152, 2048]);  convert_element_type_2273 = None
        index_74 = torch.ops.aten.index.Tensor(view_1993, [getitem_1561]);  view_1993 = getitem_1561 = None
        permute_958 = torch.ops.aten.permute.default(view_1991, [1, 0])
        mm_394 = torch.ops.aten.mm.default(permute_958, mul_741);  permute_958 = mul_741 = None
        convert_element_type_842 = torch.ops.prims.convert_element_type.default(primals_262, torch.bfloat16);  primals_262 = None
        all_gather_into_tensor_265 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_842, 128, '0');  convert_element_type_842 = None
        wait_tensor_325 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_265);  all_gather_into_tensor_265 = None
        permute_235 = torch.ops.aten.permute.default(wait_tensor_325, [1, 0]);  wait_tensor_325 = None
        permute_960 = torch.ops.aten.permute.default(permute_235, [1, 0]);  permute_235 = None
        mm_395 = torch.ops.aten.mm.default(view_1991, permute_960);  view_1991 = permute_960 = None
        convert_element_type_2278 = torch.ops.prims.convert_element_type.default(mm_394, torch.float32);  mm_394 = None
        reduce_scatter_tensor_156 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2278, 'avg', 128, '0');  convert_element_type_2278 = None
        wait_tensor_737 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_156);  reduce_scatter_tensor_156 = None
        convert_element_type_837 = torch.ops.prims.convert_element_type.default(mm_124, torch.float32);  mm_124 = None
        neg_30 = torch.ops.aten.neg.default(convert_element_type_837)
        exp_45 = torch.ops.aten.exp.default(neg_30);  neg_30 = None
        add_1020 = torch.ops.aten.add.Tensor(exp_45, 1);  exp_45 = None
        div_75 = torch.ops.aten.div.Tensor(convert_element_type_837, add_1020)
        convert_element_type_838 = torch.ops.prims.convert_element_type.default(div_75, torch.bfloat16);  div_75 = None
        mul_1665 = torch.ops.aten.mul.Tensor(mm_395, convert_element_type_838);  convert_element_type_838 = None
        mul_1666 = torch.ops.aten.mul.Tensor(mm_395, mm_125);  mm_395 = mm_125 = None
        permute_962 = torch.ops.aten.permute.default(mul_1665, [1, 0])
        mm_396 = torch.ops.aten.mm.default(permute_962, view_996);  permute_962 = None
        convert_element_type_839 = torch.ops.prims.convert_element_type.default(primals_261, torch.bfloat16);  primals_261 = None
        all_gather_into_tensor_264 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_839, 128, '0');  convert_element_type_839 = None
        wait_tensor_324 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_264);  all_gather_into_tensor_264 = None
        permute_234 = torch.ops.aten.permute.default(wait_tensor_324, [1, 0]);  wait_tensor_324 = None
        permute_964 = torch.ops.aten.permute.default(permute_234, [1, 0]);  permute_234 = None
        mm_397 = torch.ops.aten.mm.default(mul_1665, permute_964);  mul_1665 = permute_964 = None
        convert_element_type_2283 = torch.ops.prims.convert_element_type.default(mm_396, torch.float32);  mm_396 = None
        reduce_scatter_tensor_157 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2283, 'avg', 128, '0');  convert_element_type_2283 = None
        wait_tensor_738 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_157);  reduce_scatter_tensor_157 = None
        convert_element_type_2284 = torch.ops.prims.convert_element_type.default(mul_1666, torch.float32);  mul_1666 = None
        reciprocal_22 = torch.ops.aten.reciprocal.default(add_1020);  add_1020 = None
        mul_1667 = torch.ops.aten.mul.Tensor(reciprocal_22, 1);  reciprocal_22 = None
        mul_1668 = torch.ops.aten.mul.Tensor(convert_element_type_2284, mul_1667);  convert_element_type_2284 = None
        sub_691 = torch.ops.aten.sub.Tensor(1, mul_1667);  mul_1667 = None
        mul_1669 = torch.ops.aten.mul.Tensor(convert_element_type_837, sub_691);  convert_element_type_837 = sub_691 = None
        add_1941 = torch.ops.aten.add.Tensor(mul_1669, 1);  mul_1669 = None
        mul_1670 = torch.ops.aten.mul.Tensor(mul_1668, add_1941);  mul_1668 = add_1941 = None
        convert_element_type_2286 = torch.ops.prims.convert_element_type.default(mul_1670, torch.bfloat16);  mul_1670 = None
        permute_966 = torch.ops.aten.permute.default(convert_element_type_2286, [1, 0])
        mm_398 = torch.ops.aten.mm.default(permute_966, view_996);  permute_966 = None
        convert_element_type_834 = torch.ops.prims.convert_element_type.default(primals_260, torch.bfloat16);  primals_260 = None
        all_gather_into_tensor_263 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_834, 128, '0');  convert_element_type_834 = None
        wait_tensor_323 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_263);  all_gather_into_tensor_263 = None
        permute_233 = torch.ops.aten.permute.default(wait_tensor_323, [1, 0]);  wait_tensor_323 = None
        permute_968 = torch.ops.aten.permute.default(permute_233, [1, 0]);  permute_233 = None
        mm_399 = torch.ops.aten.mm.default(convert_element_type_2286, permute_968);  convert_element_type_2286 = permute_968 = None
        add_1942 = torch.ops.aten.add.Tensor(mm_397, mm_399);  mm_397 = mm_399 = None
        convert_element_type_2291 = torch.ops.prims.convert_element_type.default(mm_398, torch.float32);  mm_398 = None
        reduce_scatter_tensor_158 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2291, 'avg', 128, '0');  convert_element_type_2291 = None
        wait_tensor_739 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_158);  reduce_scatter_tensor_158 = None
        all_to_all_single_100 = torch.ops._c10d_functional.all_to_all_single.default(index_74, [_local_scalar_dense_232, _local_scalar_dense_233, _local_scalar_dense_234, _local_scalar_dense_235, _local_scalar_dense_236, _local_scalar_dense_237, _local_scalar_dense_238, _local_scalar_dense_239], [_local_scalar_dense_224, _local_scalar_dense_225, _local_scalar_dense_226, _local_scalar_dense_227, _local_scalar_dense_228, _local_scalar_dense_229, _local_scalar_dense_230, _local_scalar_dense_231], '1033');  index_74 = None
        wait_tensor_740 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_100);  all_to_all_single_100 = None
        full_414 = torch.ops.aten.full.default([sym_size_int_57, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_57 = None
        slice_scatter_11 = torch.ops.aten.slice_scatter.default(full_414, wait_tensor_740, 0, 0, -1);  wait_tensor_740 = None
        index_75 = torch.ops.aten.index.Tensor(slice_scatter_11, [getitem_1562]);  slice_scatter_11 = None
        permute_970 = torch.ops.aten.permute.default(index_75, [1, 0])
        _grouped_mm_144 = torch.ops.aten._grouped_mm.default(permute_970, mul_721, cumsum_44);  permute_970 = mul_721 = None
        _grouped_mm_145 = torch.ops.aten._grouped_mm.default(index_75, permute_972, cumsum_44);  index_75 = permute_972 = None
        convert_element_type_832 = torch.ops.prims.convert_element_type.default(_grouped_mm_42, torch.float32);  _grouped_mm_42 = None
        neg_29 = torch.ops.aten.neg.default(convert_element_type_832)
        exp_44 = torch.ops.aten.exp.default(neg_29);  neg_29 = None
        add_984 = torch.ops.aten.add.Tensor(exp_44, 1);  exp_44 = None
        div_74 = torch.ops.aten.div.Tensor(convert_element_type_832, add_984)
        convert_element_type_833 = torch.ops.prims.convert_element_type.default(div_74, torch.bfloat16);  div_74 = None
        mul_1671 = torch.ops.aten.mul.Tensor(_grouped_mm_145, convert_element_type_833);  convert_element_type_833 = None
        mul_1672 = torch.ops.aten.mul.Tensor(_grouped_mm_145, _grouped_mm_43);  _grouped_mm_145 = _grouped_mm_43 = None
        permute_974 = torch.ops.aten.permute.default(mul_1671, [1, 0])
        _grouped_mm_146 = torch.ops.aten._grouped_mm.default(permute_974, index_29, cumsum_44);  permute_974 = None
        _grouped_mm_147 = torch.ops.aten._grouped_mm.default(mul_1671, permute_976, cumsum_44);  mul_1671 = permute_976 = None
        convert_element_type_2292 = torch.ops.prims.convert_element_type.default(mul_1672, torch.float32);  mul_1672 = None
        reciprocal_23 = torch.ops.aten.reciprocal.default(add_984);  add_984 = None
        mul_1673 = torch.ops.aten.mul.Tensor(reciprocal_23, 1);  reciprocal_23 = None
        mul_1674 = torch.ops.aten.mul.Tensor(convert_element_type_2292, mul_1673);  convert_element_type_2292 = None
        sub_692 = torch.ops.aten.sub.Tensor(1, mul_1673);  mul_1673 = None
        mul_1675 = torch.ops.aten.mul.Tensor(convert_element_type_832, sub_692);  convert_element_type_832 = sub_692 = None
        add_1944 = torch.ops.aten.add.Tensor(mul_1675, 1);  mul_1675 = None
        mul_1676 = torch.ops.aten.mul.Tensor(mul_1674, add_1944);  mul_1674 = add_1944 = None
        convert_element_type_2294 = torch.ops.prims.convert_element_type.default(mul_1676, torch.bfloat16);  mul_1676 = None
        permute_978 = torch.ops.aten.permute.default(convert_element_type_2294, [1, 0])
        _grouped_mm_148 = torch.ops.aten._grouped_mm.default(permute_978, index_29, cumsum_44);  permute_978 = index_29 = None
        _grouped_mm_149 = torch.ops.aten._grouped_mm.default(convert_element_type_2294, permute_980, cumsum_44);  convert_element_type_2294 = permute_980 = cumsum_44 = None
        add_1945 = torch.ops.aten.add.Tensor(_grouped_mm_147, _grouped_mm_149);  _grouped_mm_147 = _grouped_mm_149 = None
        convert_element_type_2295 = torch.ops.prims.convert_element_type.default(_grouped_mm_146, torch.float32);  _grouped_mm_146 = None
        div_198 = torch.ops.aten.div.Tensor(convert_element_type_2295, 128);  convert_element_type_2295 = None
        split_740 = torch.ops.aten.split.Tensor(div_198, 88, 1);  div_198 = None
        getitem_13885 = split_740[0]
        getitem_13902 = split_740[1]
        getitem_13919 = split_740[2]
        getitem_13936 = split_740[3]
        getitem_13953 = split_740[4]
        getitem_13970 = split_740[5]
        getitem_13987 = split_740[6]
        getitem_14004 = split_740[7]
        getitem_14021 = split_740[8]
        getitem_14038 = split_740[9]
        getitem_14055 = split_740[10]
        getitem_14072 = split_740[11]
        getitem_14089 = split_740[12]
        getitem_14106 = split_740[13]
        getitem_14123 = split_740[14]
        getitem_14140 = split_740[15];  split_740 = None
        cat_324 = torch.ops.aten.cat.default([getitem_13885, getitem_13902, getitem_13919, getitem_13936, getitem_13953, getitem_13970, getitem_13987, getitem_14004, getitem_14021, getitem_14038, getitem_14055, getitem_14072, getitem_14089, getitem_14106, getitem_14123, getitem_14140]);  getitem_13885 = getitem_13902 = getitem_13919 = getitem_13936 = getitem_13953 = getitem_13970 = getitem_13987 = getitem_14004 = getitem_14021 = getitem_14038 = getitem_14055 = getitem_14072 = getitem_14089 = getitem_14106 = getitem_14123 = getitem_14140 = None
        reduce_scatter_tensor_159 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_324, 'sum', 16, '1025');  cat_324 = None
        wait_tensor_741 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_159);  reduce_scatter_tensor_159 = None
        convert_element_type_2296 = torch.ops.prims.convert_element_type.default(_grouped_mm_144, torch.float32);  _grouped_mm_144 = None
        div_199 = torch.ops.aten.div.Tensor(convert_element_type_2296, 128);  convert_element_type_2296 = None
        split_757 = torch.ops.aten.split.Tensor(div_199, 128, 1);  div_199 = None
        getitem_14157 = split_757[0]
        getitem_14174 = split_757[1]
        getitem_14191 = split_757[2]
        getitem_14208 = split_757[3]
        getitem_14225 = split_757[4]
        getitem_14242 = split_757[5]
        getitem_14259 = split_757[6]
        getitem_14276 = split_757[7]
        getitem_14293 = split_757[8]
        getitem_14310 = split_757[9]
        getitem_14327 = split_757[10]
        getitem_14344 = split_757[11]
        getitem_14361 = split_757[12]
        getitem_14378 = split_757[13]
        getitem_14395 = split_757[14]
        getitem_14412 = split_757[15];  split_757 = None
        cat_325 = torch.ops.aten.cat.default([getitem_14157, getitem_14174, getitem_14191, getitem_14208, getitem_14225, getitem_14242, getitem_14259, getitem_14276, getitem_14293, getitem_14310, getitem_14327, getitem_14344, getitem_14361, getitem_14378, getitem_14395, getitem_14412]);  getitem_14157 = getitem_14174 = getitem_14191 = getitem_14208 = getitem_14225 = getitem_14242 = getitem_14259 = getitem_14276 = getitem_14293 = getitem_14310 = getitem_14327 = getitem_14344 = getitem_14361 = getitem_14378 = getitem_14395 = getitem_14412 = None
        reduce_scatter_tensor_160 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_325, 'sum', 16, '1025');  cat_325 = None
        wait_tensor_742 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_160);  reduce_scatter_tensor_160 = None
        convert_element_type_2297 = torch.ops.prims.convert_element_type.default(_grouped_mm_148, torch.float32);  _grouped_mm_148 = None
        div_200 = torch.ops.aten.div.Tensor(convert_element_type_2297, 128);  convert_element_type_2297 = None
        split_774 = torch.ops.aten.split.Tensor(div_200, 88, 1);  div_200 = None
        getitem_14429 = split_774[0]
        getitem_14446 = split_774[1]
        getitem_14463 = split_774[2]
        getitem_14480 = split_774[3]
        getitem_14497 = split_774[4]
        getitem_14514 = split_774[5]
        getitem_14531 = split_774[6]
        getitem_14548 = split_774[7]
        getitem_14565 = split_774[8]
        getitem_14582 = split_774[9]
        getitem_14599 = split_774[10]
        getitem_14616 = split_774[11]
        getitem_14633 = split_774[12]
        getitem_14650 = split_774[13]
        getitem_14667 = split_774[14]
        getitem_14684 = split_774[15];  split_774 = None
        cat_326 = torch.ops.aten.cat.default([getitem_14429, getitem_14446, getitem_14463, getitem_14480, getitem_14497, getitem_14514, getitem_14531, getitem_14548, getitem_14565, getitem_14582, getitem_14599, getitem_14616, getitem_14633, getitem_14650, getitem_14667, getitem_14684]);  getitem_14429 = getitem_14446 = getitem_14463 = getitem_14480 = getitem_14497 = getitem_14514 = getitem_14531 = getitem_14548 = getitem_14565 = getitem_14582 = getitem_14599 = getitem_14616 = getitem_14633 = getitem_14650 = getitem_14667 = getitem_14684 = None
        reduce_scatter_tensor_161 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_326, 'sum', 16, '1025');  cat_326 = None
        wait_tensor_743 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_161);  reduce_scatter_tensor_161 = None
        index_put_74 = torch.ops.aten.index_put.default(full_414, [getitem_1562], add_1945, True);  full_414 = getitem_1562 = add_1945 = None
        slice_228 = torch.ops.aten.slice.Tensor(index_put_74, 0, 0, add_1946);  index_put_74 = add_1946 = None
        all_to_all_single_101 = torch.ops._c10d_functional.all_to_all_single.default(slice_228, [_local_scalar_dense_224, _local_scalar_dense_225, _local_scalar_dense_226, _local_scalar_dense_227, _local_scalar_dense_228, _local_scalar_dense_229, _local_scalar_dense_230, _local_scalar_dense_231], [_local_scalar_dense_232, _local_scalar_dense_233, _local_scalar_dense_234, _local_scalar_dense_235, _local_scalar_dense_236, _local_scalar_dense_237, _local_scalar_dense_238, _local_scalar_dense_239], '1033');  slice_228 = _local_scalar_dense_224 = _local_scalar_dense_225 = _local_scalar_dense_226 = _local_scalar_dense_227 = _local_scalar_dense_228 = _local_scalar_dense_229 = _local_scalar_dense_230 = _local_scalar_dense_231 = _local_scalar_dense_232 = _local_scalar_dense_233 = _local_scalar_dense_234 = _local_scalar_dense_235 = _local_scalar_dense_236 = _local_scalar_dense_237 = _local_scalar_dense_238 = _local_scalar_dense_239 = None
        wait_tensor_744 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_101);  all_to_all_single_101 = None
        index_put_75 = torch.ops.aten.index_put.default(full_default_52, [div_72], wait_tensor_744, True);  div_72 = wait_tensor_744 = None
        add_1950 = torch.ops.aten.add.Tensor(add_1942, index_put_75);  add_1942 = index_put_75 = None
        mul_1677 = torch.ops.aten.mul.Tensor(view_1992, 1.0);  view_1992 = None
        scatter_add_11 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_1559, mul_1677);  getitem_1559 = mul_1677 = None
        convert_element_type_821 = torch.ops.prims.convert_element_type.default(mm_123, torch.float32);  mm_123 = None
        sub_336 = torch.ops.aten.sub.Tensor(convert_element_type_821, amax_14);  convert_element_type_821 = amax_14 = None
        exp_43 = torch.ops.aten.exp.default(sub_336);  sub_336 = None
        div_71 = torch.ops.aten.div.Tensor(exp_43, sum_57);  exp_43 = sum_57 = None
        mul_1678 = torch.ops.aten.mul.Tensor(scatter_add_11, div_71);  scatter_add_11 = None
        sum_195 = torch.ops.aten.sum.dim_IntList(mul_1678, [1], True)
        neg_88 = torch.ops.aten.neg.default(div_71);  div_71 = None
        fma_11 = torch.ops.prims.fma.default(neg_88, sum_195, mul_1678);  neg_88 = sum_195 = mul_1678 = None
        convert_element_type_2298 = torch.ops.prims.convert_element_type.default(fma_11, torch.bfloat16);  fma_11 = None
        permute_982 = torch.ops.aten.permute.default(convert_element_type_2298, [1, 0])
        mm_400 = torch.ops.aten.mm.default(permute_982, view_996);  permute_982 = view_996 = None
        convert_element_type_818 = torch.ops.prims.convert_element_type.default(primals_255, torch.bfloat16);  primals_255 = None
        all_gather_into_tensor_256 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_818, 128, '0');  convert_element_type_818 = None
        wait_tensor_312 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_256);  all_gather_into_tensor_256 = None
        slice_93 = torch.ops.aten.slice.Tensor(wait_tensor_312, 0, 0, 64);  wait_tensor_312 = None
        permute_229 = torch.ops.aten.permute.default(slice_93, [1, 0]);  slice_93 = None
        permute_984 = torch.ops.aten.permute.default(permute_229, [1, 0]);  permute_229 = None
        mm_401 = torch.ops.aten.mm.default(convert_element_type_2298, permute_984);  convert_element_type_2298 = permute_984 = None
        add_1951 = torch.ops.aten.add.Tensor(add_1950, mm_401);  add_1950 = mm_401 = None
        convert_element_type_2303 = torch.ops.prims.convert_element_type.default(mm_400, torch.float32);  mm_400 = None
        split_790 = torch.ops.aten.split.Tensor(convert_element_type_2303, 1);  convert_element_type_2303 = None
        getitem_14685 = split_790[0]
        getitem_14686 = split_790[1]
        getitem_14687 = split_790[2]
        getitem_14688 = split_790[3]
        getitem_14689 = split_790[4]
        getitem_14690 = split_790[5]
        getitem_14691 = split_790[6]
        getitem_14692 = split_790[7]
        getitem_14693 = split_790[8]
        getitem_14694 = split_790[9]
        getitem_14695 = split_790[10]
        getitem_14696 = split_790[11]
        getitem_14697 = split_790[12]
        getitem_14698 = split_790[13]
        getitem_14699 = split_790[14]
        getitem_14700 = split_790[15]
        getitem_14701 = split_790[16]
        getitem_14702 = split_790[17]
        getitem_14703 = split_790[18]
        getitem_14704 = split_790[19]
        getitem_14705 = split_790[20]
        getitem_14706 = split_790[21]
        getitem_14707 = split_790[22]
        getitem_14708 = split_790[23]
        getitem_14709 = split_790[24]
        getitem_14710 = split_790[25]
        getitem_14711 = split_790[26]
        getitem_14712 = split_790[27]
        getitem_14713 = split_790[28]
        getitem_14714 = split_790[29]
        getitem_14715 = split_790[30]
        getitem_14716 = split_790[31]
        getitem_14717 = split_790[32]
        getitem_14718 = split_790[33]
        getitem_14719 = split_790[34]
        getitem_14720 = split_790[35]
        getitem_14721 = split_790[36]
        getitem_14722 = split_790[37]
        getitem_14723 = split_790[38]
        getitem_14724 = split_790[39]
        getitem_14725 = split_790[40]
        getitem_14726 = split_790[41]
        getitem_14727 = split_790[42]
        getitem_14728 = split_790[43]
        getitem_14729 = split_790[44]
        getitem_14730 = split_790[45]
        getitem_14731 = split_790[46]
        getitem_14732 = split_790[47]
        getitem_14733 = split_790[48]
        getitem_14734 = split_790[49]
        getitem_14735 = split_790[50]
        getitem_14736 = split_790[51]
        getitem_14737 = split_790[52]
        getitem_14738 = split_790[53]
        getitem_14739 = split_790[54]
        getitem_14740 = split_790[55]
        getitem_14741 = split_790[56]
        getitem_14742 = split_790[57]
        getitem_14743 = split_790[58]
        getitem_14744 = split_790[59]
        getitem_14745 = split_790[60]
        getitem_14746 = split_790[61]
        getitem_14747 = split_790[62]
        getitem_14748 = split_790[63];  split_790 = None
        cat_327 = torch.ops.aten.cat.default([getitem_14685, getitem_14686, getitem_14687, getitem_14688, getitem_14689, getitem_14690, getitem_14691, getitem_14692, getitem_14693, getitem_14694, getitem_14695, getitem_14696, getitem_14697, getitem_14698, getitem_14699, getitem_14700, getitem_14701, getitem_14702, getitem_14703, getitem_14704, getitem_14705, getitem_14706, getitem_14707, getitem_14708, getitem_14709, getitem_14710, getitem_14711, getitem_14712, getitem_14713, getitem_14714, getitem_14715, getitem_14716, getitem_14717, getitem_14718, getitem_14719, getitem_14720, getitem_14721, getitem_14722, getitem_14723, getitem_14724, getitem_14725, getitem_14726, getitem_14727, getitem_14728, getitem_14729, getitem_14730, getitem_14731, getitem_14732, getitem_14733, getitem_14734, getitem_14735, getitem_14736, getitem_14737, getitem_14738, getitem_14739, getitem_14740, getitem_14741, getitem_14742, getitem_14743, getitem_14744, getitem_14745, getitem_14746, getitem_14747, getitem_14748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_14685 = getitem_14686 = getitem_14687 = getitem_14688 = getitem_14689 = getitem_14690 = getitem_14691 = getitem_14692 = getitem_14693 = getitem_14694 = getitem_14695 = getitem_14696 = getitem_14697 = getitem_14698 = getitem_14699 = getitem_14700 = getitem_14701 = getitem_14702 = getitem_14703 = getitem_14704 = getitem_14705 = getitem_14706 = getitem_14707 = getitem_14708 = getitem_14709 = getitem_14710 = getitem_14711 = getitem_14712 = getitem_14713 = getitem_14714 = getitem_14715 = getitem_14716 = getitem_14717 = getitem_14718 = getitem_14719 = getitem_14720 = getitem_14721 = getitem_14722 = getitem_14723 = getitem_14724 = getitem_14725 = getitem_14726 = getitem_14727 = getitem_14728 = getitem_14729 = getitem_14730 = getitem_14731 = getitem_14732 = getitem_14733 = getitem_14734 = getitem_14735 = getitem_14736 = getitem_14737 = getitem_14738 = getitem_14739 = getitem_14740 = getitem_14741 = getitem_14742 = getitem_14743 = getitem_14744 = getitem_14745 = getitem_14746 = getitem_14747 = getitem_14748 = None
        reduce_scatter_tensor_162 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_327, 'avg', 128, '0');  cat_327 = None
        wait_tensor_745 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_162);  reduce_scatter_tensor_162 = None
        view_1994 = torch.ops.aten.view.default(add_1951, [2, 4096, 2048]);  add_1951 = None
        convert_element_type_2304 = torch.ops.prims.convert_element_type.default(view_1994, torch.float32);  view_1994 = None
        convert_element_type_815 = torch.ops.prims.convert_element_type.default(primals_253, torch.bfloat16);  primals_253 = None
        all_gather_into_tensor_255 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_815, 128, '0');  convert_element_type_815 = None
        wait_tensor_311 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_255);  all_gather_into_tensor_255 = None
        convert_element_type_2306 = torch.ops.prims.convert_element_type.default(wait_tensor_311, torch.float32);  wait_tensor_311 = None
        mul_1679 = torch.ops.aten.mul.Tensor(convert_element_type_2304, convert_element_type_2306);  convert_element_type_2306 = None
        convert_element_type_816 = torch.ops.prims.convert_element_type.default(add_960, torch.float32);  add_960 = None
        mul_701 = torch.ops.aten.mul.Tensor(convert_element_type_816, rsqrt_47);  convert_element_type_816 = None
        mul_1681 = torch.ops.aten.mul.Tensor(mul_701, mul_1679)
        sum_196 = torch.ops.aten.sum.dim_IntList(mul_1681, [2], True);  mul_1681 = None
        div_201 = torch.ops.aten.div.Tensor(mul_701, 2048)
        mul_1682 = torch.ops.aten.mul.Tensor(div_201, sum_196);  div_201 = sum_196 = None
        sub_694 = torch.ops.aten.sub.Tensor(mul_1679, mul_1682);  mul_1679 = mul_1682 = None
        mul_1683 = torch.ops.aten.mul.Tensor(sub_694, rsqrt_47);  sub_694 = rsqrt_47 = None
        mul_1684 = torch.ops.aten.mul.Tensor(convert_element_type_2304, mul_701);  convert_element_type_2304 = mul_701 = None
        sum_197 = torch.ops.aten.sum.dim_IntList(mul_1684, [0, 1]);  mul_1684 = None
        convert_element_type_2307 = torch.ops.prims.convert_element_type.default(mul_1683, torch.bfloat16);  mul_1683 = None
        add_1952 = torch.ops.aten.add.Tensor(add_1939, convert_element_type_2307);  add_1939 = convert_element_type_2307 = None
        convert_element_type_default_48 = torch.ops.prims.convert_element_type.default(sum_197, torch.float32);  sum_197 = None
        reduce_scatter_tensor_163 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_48, 'avg', 128, '0');  convert_element_type_default_48 = None
        wait_tensor_746 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_163);  reduce_scatter_tensor_163 = None
        view_1995 = torch.ops.aten.view.default(add_1952, [8192, 2048])
        permute_986 = torch.ops.aten.permute.default(view_1995, [1, 0])
        permute_227 = torch.ops.aten.permute.default(getitem_1555, [0, 2, 1, 3])
        view_991 = torch.ops.aten.view.default(permute_227, [2, 4096, -1]);  permute_227 = None
        view_993 = torch.ops.aten.view.default(view_991, [8192, 2048]);  view_991 = None
        mm_402 = torch.ops.aten.mm.default(permute_986, view_993);  permute_986 = view_993 = None
        convert_element_type_812 = torch.ops.prims.convert_element_type.default(primals_252, torch.bfloat16);  primals_252 = None
        all_gather_into_tensor_254 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_812, 128, '0');  convert_element_type_812 = None
        wait_tensor_310 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_254);  all_gather_into_tensor_254 = None
        permute_228 = torch.ops.aten.permute.default(wait_tensor_310, [1, 0]);  wait_tensor_310 = None
        permute_988 = torch.ops.aten.permute.default(permute_228, [1, 0]);  permute_228 = None
        mm_403 = torch.ops.aten.mm.default(view_1995, permute_988);  view_1995 = permute_988 = None
        view_1996 = torch.ops.aten.view.default(mm_403, [2, 4096, 2048]);  mm_403 = None
        convert_element_type_2314 = torch.ops.prims.convert_element_type.default(mm_402, torch.float32);  mm_402 = None
        reduce_scatter_tensor_164 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2314, 'avg', 128, '0');  convert_element_type_2314 = None
        wait_tensor_747 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_164);  reduce_scatter_tensor_164 = None
        view_1997 = torch.ops.aten.view.default(view_1996, [2, 4096, 16, 128]);  view_1996 = None
        permute_990 = torch.ops.aten.permute.default(view_1997, [0, 2, 1, 3]);  view_1997 = None
        fw_graph11 = self.fw_graph11
        joint_graph11 = self.joint_graph11
        mask_graph11 = self.mask_graph11
        flex_attention_backward_11 = torch.ops.higher_order.flex_attention_backward(permute_224, permute_225, permute_226, getitem_1555, getitem_1556, permute_990, None, fw_graph11, joint_graph11, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph11), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_224 = permute_225 = permute_226 = getitem_1555 = getitem_1556 = permute_990 = fw_graph11 = joint_graph11 = mask_graph11 = None
        getitem_14749 = flex_attention_backward_11[0]
        getitem_14750 = flex_attention_backward_11[1]
        getitem_14751 = flex_attention_backward_11[2];  flex_attention_backward_11 = None
        permute_991 = torch.ops.aten.permute.default(getitem_14751, [0, 2, 1, 3]);  getitem_14751 = None
        permute_992 = torch.ops.aten.permute.default(getitem_14750, [0, 2, 1, 3]);  getitem_14750 = None
        permute_993 = torch.ops.aten.permute.default(getitem_14749, [0, 2, 1, 3]);  getitem_14749 = None
        slice_230 = torch.ops.aten.slice.Tensor(permute_992, 3, 0, 128)
        slice_231 = torch.ops.aten.slice.Tensor(permute_992, 3, 128, 192);  permute_992 = None
        sum_198 = torch.ops.aten.sum.dim_IntList(slice_231, [2], True);  slice_231 = None
        cat_328 = torch.ops.aten.cat.default([slice_230, permute_991], 3);  slice_230 = permute_991 = None
        view_1998 = torch.ops.aten.view.default(cat_328, [2, 4096, 4096]);  cat_328 = None
        view_1999 = torch.ops.aten.view.default(view_1998, [8192, 4096]);  view_1998 = None
        permute_994 = torch.ops.aten.permute.default(view_1999, [1, 0])
        mm_404 = torch.ops.aten.mm.default(permute_994, view_988);  permute_994 = view_988 = None
        convert_element_type_809 = torch.ops.prims.convert_element_type.default(primals_251, torch.bfloat16);  primals_251 = None
        all_gather_into_tensor_253 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_809, 128, '0');  convert_element_type_809 = None
        wait_tensor_309 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_253);  all_gather_into_tensor_253 = None
        permute_223 = torch.ops.aten.permute.default(wait_tensor_309, [1, 0]);  wait_tensor_309 = None
        permute_996 = torch.ops.aten.permute.default(permute_223, [1, 0]);  permute_223 = None
        mm_405 = torch.ops.aten.mm.default(view_1999, permute_996);  view_1999 = permute_996 = None
        view_2000 = torch.ops.aten.view.default(mm_405, [2, 4096, 512]);  mm_405 = None
        convert_element_type_2319 = torch.ops.prims.convert_element_type.default(mm_404, torch.float32);  mm_404 = None
        reduce_scatter_tensor_165 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2319, 'avg', 128, '0');  convert_element_type_2319 = None
        wait_tensor_748 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_165);  reduce_scatter_tensor_165 = None
        convert_element_type_2320 = torch.ops.prims.convert_element_type.default(view_2000, torch.float32);  view_2000 = None
        convert_element_type_806 = torch.ops.prims.convert_element_type.default(primals_250, torch.bfloat16);  primals_250 = None
        all_gather_into_tensor_252 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_806, 128, '0');  convert_element_type_806 = None
        wait_tensor_308 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_252);  all_gather_into_tensor_252 = None
        convert_element_type_2322 = torch.ops.prims.convert_element_type.default(wait_tensor_308, torch.float32);  wait_tensor_308 = None
        mul_1685 = torch.ops.aten.mul.Tensor(convert_element_type_2320, convert_element_type_2322);  convert_element_type_2322 = None
        convert_element_type_807 = torch.ops.prims.convert_element_type.default(getitem_1551, torch.float32);  getitem_1551 = None
        mul_699 = torch.ops.aten.mul.Tensor(convert_element_type_807, rsqrt_46);  convert_element_type_807 = None
        mul_1687 = torch.ops.aten.mul.Tensor(mul_699, mul_1685)
        sum_199 = torch.ops.aten.sum.dim_IntList(mul_1687, [2], True);  mul_1687 = None
        div_202 = torch.ops.aten.div.Tensor(mul_699, 512)
        mul_1688 = torch.ops.aten.mul.Tensor(div_202, sum_199);  div_202 = sum_199 = None
        sub_695 = torch.ops.aten.sub.Tensor(mul_1685, mul_1688);  mul_1685 = mul_1688 = None
        mul_1689 = torch.ops.aten.mul.Tensor(sub_695, rsqrt_46);  sub_695 = rsqrt_46 = None
        mul_1690 = torch.ops.aten.mul.Tensor(convert_element_type_2320, mul_699);  convert_element_type_2320 = mul_699 = None
        sum_200 = torch.ops.aten.sum.dim_IntList(mul_1690, [0, 1]);  mul_1690 = None
        convert_element_type_2323 = torch.ops.prims.convert_element_type.default(mul_1689, torch.bfloat16);  mul_1689 = None
        convert_element_type_default_47 = torch.ops.prims.convert_element_type.default(sum_200, torch.float32);  sum_200 = None
        reduce_scatter_tensor_166 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_47, 'avg', 128, '0');  convert_element_type_default_47 = None
        wait_tensor_749 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_166);  reduce_scatter_tensor_166 = None
        convert_element_type_2326 = torch.ops.prims.convert_element_type.default(sum_198, torch.float32);  sum_198 = None
        view_2001 = torch.ops.aten.view.default(convert_element_type_2326, [2, 4096, 1, 32, 2]);  convert_element_type_2326 = None
        view_as_complex_76 = torch.ops.aten.view_as_complex.default(view_2001);  view_2001 = None
        mul_1691 = torch.ops.aten.mul.Tensor(view_as_complex_76, clone_9);  view_as_complex_76 = None
        view_as_real_76 = torch.ops.aten.view_as_real.default(mul_1691);  mul_1691 = None
        view_2002 = torch.ops.aten.view.default(view_as_real_76, [2, 4096, 1, 64]);  view_as_real_76 = None
        convert_element_type_2327 = torch.ops.prims.convert_element_type.default(view_2002, torch.bfloat16);  view_2002 = None
        squeeze_37 = torch.ops.aten.squeeze.dim(convert_element_type_2327, 2);  convert_element_type_2327 = None
        cat_329 = torch.ops.aten.cat.default([convert_element_type_2323, squeeze_37], 2);  convert_element_type_2323 = squeeze_37 = None
        view_2003 = torch.ops.aten.view.default(cat_329, [8192, 576]);  cat_329 = None
        permute_998 = torch.ops.aten.permute.default(view_2003, [1, 0])
        mm_406 = torch.ops.aten.mm.default(permute_998, view_974);  permute_998 = None
        convert_element_type_801 = torch.ops.prims.convert_element_type.default(primals_249, torch.bfloat16);  primals_249 = None
        all_gather_into_tensor_251 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_801, 128, '0');  convert_element_type_801 = None
        wait_tensor_307 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_251);  all_gather_into_tensor_251 = None
        slice_91 = torch.ops.aten.slice.Tensor(wait_tensor_307, 0, 0, 576);  wait_tensor_307 = None
        permute_222 = torch.ops.aten.permute.default(slice_91, [1, 0]);  slice_91 = None
        permute_1000 = torch.ops.aten.permute.default(permute_222, [1, 0]);  permute_222 = None
        mm_407 = torch.ops.aten.mm.default(view_2003, permute_1000);  view_2003 = permute_1000 = None
        view_2004 = torch.ops.aten.view.default(mm_407, [2, 4096, 2048]);  mm_407 = None
        convert_element_type_2332 = torch.ops.prims.convert_element_type.default(mm_406, torch.float32);  mm_406 = None
        split_791 = torch.ops.aten.split.Tensor(convert_element_type_2332, 5);  convert_element_type_2332 = None
        getitem_14753 = split_791[0]
        getitem_14754 = split_791[1]
        getitem_14755 = split_791[2]
        getitem_14756 = split_791[3]
        getitem_14757 = split_791[4]
        getitem_14758 = split_791[5]
        getitem_14759 = split_791[6]
        getitem_14760 = split_791[7]
        getitem_14761 = split_791[8]
        getitem_14762 = split_791[9]
        getitem_14763 = split_791[10]
        getitem_14764 = split_791[11]
        getitem_14765 = split_791[12]
        getitem_14766 = split_791[13]
        getitem_14767 = split_791[14]
        getitem_14768 = split_791[15]
        getitem_14769 = split_791[16]
        getitem_14770 = split_791[17]
        getitem_14771 = split_791[18]
        getitem_14772 = split_791[19]
        getitem_14773 = split_791[20]
        getitem_14774 = split_791[21]
        getitem_14775 = split_791[22]
        getitem_14776 = split_791[23]
        getitem_14777 = split_791[24]
        getitem_14778 = split_791[25]
        getitem_14779 = split_791[26]
        getitem_14780 = split_791[27]
        getitem_14781 = split_791[28]
        getitem_14782 = split_791[29]
        getitem_14783 = split_791[30]
        getitem_14784 = split_791[31]
        getitem_14785 = split_791[32]
        getitem_14786 = split_791[33]
        getitem_14787 = split_791[34]
        getitem_14788 = split_791[35]
        getitem_14789 = split_791[36]
        getitem_14790 = split_791[37]
        getitem_14791 = split_791[38]
        getitem_14792 = split_791[39]
        getitem_14793 = split_791[40]
        getitem_14794 = split_791[41]
        getitem_14795 = split_791[42]
        getitem_14796 = split_791[43]
        getitem_14797 = split_791[44]
        getitem_14798 = split_791[45]
        getitem_14799 = split_791[46]
        getitem_14800 = split_791[47]
        getitem_14801 = split_791[48]
        getitem_14802 = split_791[49]
        getitem_14803 = split_791[50]
        getitem_14804 = split_791[51]
        getitem_14805 = split_791[52]
        getitem_14806 = split_791[53]
        getitem_14807 = split_791[54]
        getitem_14808 = split_791[55]
        getitem_14809 = split_791[56]
        getitem_14810 = split_791[57]
        getitem_14811 = split_791[58]
        getitem_14812 = split_791[59]
        getitem_14813 = split_791[60]
        getitem_14814 = split_791[61]
        getitem_14815 = split_791[62]
        getitem_14816 = split_791[63]
        getitem_14817 = split_791[64]
        getitem_14818 = split_791[65]
        getitem_14819 = split_791[66]
        getitem_14820 = split_791[67]
        getitem_14821 = split_791[68]
        getitem_14822 = split_791[69]
        getitem_14823 = split_791[70]
        getitem_14824 = split_791[71]
        getitem_14825 = split_791[72]
        getitem_14826 = split_791[73]
        getitem_14827 = split_791[74]
        getitem_14828 = split_791[75]
        getitem_14829 = split_791[76]
        getitem_14830 = split_791[77]
        getitem_14831 = split_791[78]
        getitem_14832 = split_791[79]
        getitem_14833 = split_791[80]
        getitem_14834 = split_791[81]
        getitem_14835 = split_791[82]
        getitem_14836 = split_791[83]
        getitem_14837 = split_791[84]
        getitem_14838 = split_791[85]
        getitem_14839 = split_791[86]
        getitem_14840 = split_791[87]
        getitem_14841 = split_791[88]
        getitem_14842 = split_791[89]
        getitem_14843 = split_791[90]
        getitem_14844 = split_791[91]
        getitem_14845 = split_791[92]
        getitem_14846 = split_791[93]
        getitem_14847 = split_791[94]
        getitem_14848 = split_791[95]
        getitem_14849 = split_791[96]
        getitem_14850 = split_791[97]
        getitem_14851 = split_791[98]
        getitem_14852 = split_791[99]
        getitem_14853 = split_791[100]
        getitem_14854 = split_791[101]
        getitem_14855 = split_791[102]
        getitem_14856 = split_791[103]
        getitem_14857 = split_791[104]
        getitem_14858 = split_791[105]
        getitem_14859 = split_791[106]
        getitem_14860 = split_791[107]
        getitem_14861 = split_791[108]
        getitem_14862 = split_791[109]
        getitem_14863 = split_791[110]
        getitem_14864 = split_791[111]
        getitem_14865 = split_791[112]
        getitem_14866 = split_791[113]
        getitem_14867 = split_791[114]
        getitem_14868 = split_791[115];  split_791 = None
        constant_pad_nd_911 = torch.ops.aten.constant_pad_nd.default(getitem_14868, [0, 0, 0, 4], 0.0);  getitem_14868 = None
        cat_330 = torch.ops.aten.cat.default([getitem_14753, getitem_14754, getitem_14755, getitem_14756, getitem_14757, getitem_14758, getitem_14759, getitem_14760, getitem_14761, getitem_14762, getitem_14763, getitem_14764, getitem_14765, getitem_14766, getitem_14767, getitem_14768, getitem_14769, getitem_14770, getitem_14771, getitem_14772, getitem_14773, getitem_14774, getitem_14775, getitem_14776, getitem_14777, getitem_14778, getitem_14779, getitem_14780, getitem_14781, getitem_14782, getitem_14783, getitem_14784, getitem_14785, getitem_14786, getitem_14787, getitem_14788, getitem_14789, getitem_14790, getitem_14791, getitem_14792, getitem_14793, getitem_14794, getitem_14795, getitem_14796, getitem_14797, getitem_14798, getitem_14799, getitem_14800, getitem_14801, getitem_14802, getitem_14803, getitem_14804, getitem_14805, getitem_14806, getitem_14807, getitem_14808, getitem_14809, getitem_14810, getitem_14811, getitem_14812, getitem_14813, getitem_14814, getitem_14815, getitem_14816, getitem_14817, getitem_14818, getitem_14819, getitem_14820, getitem_14821, getitem_14822, getitem_14823, getitem_14824, getitem_14825, getitem_14826, getitem_14827, getitem_14828, getitem_14829, getitem_14830, getitem_14831, getitem_14832, getitem_14833, getitem_14834, getitem_14835, getitem_14836, getitem_14837, getitem_14838, getitem_14839, getitem_14840, getitem_14841, getitem_14842, getitem_14843, getitem_14844, getitem_14845, getitem_14846, getitem_14847, getitem_14848, getitem_14849, getitem_14850, getitem_14851, getitem_14852, getitem_14853, getitem_14854, getitem_14855, getitem_14856, getitem_14857, getitem_14858, getitem_14859, getitem_14860, getitem_14861, getitem_14862, getitem_14863, getitem_14864, getitem_14865, getitem_14866, getitem_14867, constant_pad_nd_911, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_14753 = getitem_14754 = getitem_14755 = getitem_14756 = getitem_14757 = getitem_14758 = getitem_14759 = getitem_14760 = getitem_14761 = getitem_14762 = getitem_14763 = getitem_14764 = getitem_14765 = getitem_14766 = getitem_14767 = getitem_14768 = getitem_14769 = getitem_14770 = getitem_14771 = getitem_14772 = getitem_14773 = getitem_14774 = getitem_14775 = getitem_14776 = getitem_14777 = getitem_14778 = getitem_14779 = getitem_14780 = getitem_14781 = getitem_14782 = getitem_14783 = getitem_14784 = getitem_14785 = getitem_14786 = getitem_14787 = getitem_14788 = getitem_14789 = getitem_14790 = getitem_14791 = getitem_14792 = getitem_14793 = getitem_14794 = getitem_14795 = getitem_14796 = getitem_14797 = getitem_14798 = getitem_14799 = getitem_14800 = getitem_14801 = getitem_14802 = getitem_14803 = getitem_14804 = getitem_14805 = getitem_14806 = getitem_14807 = getitem_14808 = getitem_14809 = getitem_14810 = getitem_14811 = getitem_14812 = getitem_14813 = getitem_14814 = getitem_14815 = getitem_14816 = getitem_14817 = getitem_14818 = getitem_14819 = getitem_14820 = getitem_14821 = getitem_14822 = getitem_14823 = getitem_14824 = getitem_14825 = getitem_14826 = getitem_14827 = getitem_14828 = getitem_14829 = getitem_14830 = getitem_14831 = getitem_14832 = getitem_14833 = getitem_14834 = getitem_14835 = getitem_14836 = getitem_14837 = getitem_14838 = getitem_14839 = getitem_14840 = getitem_14841 = getitem_14842 = getitem_14843 = getitem_14844 = getitem_14845 = getitem_14846 = getitem_14847 = getitem_14848 = getitem_14849 = getitem_14850 = getitem_14851 = getitem_14852 = getitem_14853 = getitem_14854 = getitem_14855 = getitem_14856 = getitem_14857 = getitem_14858 = getitem_14859 = getitem_14860 = getitem_14861 = getitem_14862 = getitem_14863 = getitem_14864 = getitem_14865 = getitem_14866 = getitem_14867 = constant_pad_nd_911 = None
        reduce_scatter_tensor_167 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_330, 'avg', 128, '0');  cat_330 = None
        wait_tensor_750 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_167);  reduce_scatter_tensor_167 = None
        slice_232 = torch.ops.aten.slice.Tensor(permute_993, 3, 0, 128)
        slice_233 = torch.ops.aten.slice.Tensor(permute_993, 3, 128, 192);  permute_993 = None
        convert_element_type_2333 = torch.ops.prims.convert_element_type.default(slice_233, torch.float32);  slice_233 = None
        view_2005 = torch.ops.aten.view.default(convert_element_type_2333, [2, 4096, 16, 32, 2]);  convert_element_type_2333 = None
        view_as_complex_77 = torch.ops.aten.view_as_complex.default(view_2005);  view_2005 = None
        mul_1692 = torch.ops.aten.mul.Tensor(view_as_complex_77, clone_9);  view_as_complex_77 = None
        view_as_real_77 = torch.ops.aten.view_as_real.default(mul_1692);  mul_1692 = None
        view_2006 = torch.ops.aten.view.default(view_as_real_77, [2, 4096, 16, 64]);  view_as_real_77 = None
        convert_element_type_2334 = torch.ops.prims.convert_element_type.default(view_2006, torch.bfloat16);  view_2006 = None
        cat_331 = torch.ops.aten.cat.default([slice_232, convert_element_type_2334], 3);  slice_232 = convert_element_type_2334 = None
        view_2007 = torch.ops.aten.view.default(cat_331, [2, 4096, 3072]);  cat_331 = None
        view_2008 = torch.ops.aten.view.default(view_2007, [8192, 3072]);  view_2007 = None
        permute_1002 = torch.ops.aten.permute.default(view_2008, [1, 0])
        mm_408 = torch.ops.aten.mm.default(permute_1002, view_974);  permute_1002 = view_974 = None
        convert_element_type_796 = torch.ops.prims.convert_element_type.default(primals_248, torch.bfloat16);  primals_248 = None
        all_gather_into_tensor_250 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_796, 128, '0');  convert_element_type_796 = None
        wait_tensor_306 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_250);  all_gather_into_tensor_250 = None
        permute_221 = torch.ops.aten.permute.default(wait_tensor_306, [1, 0]);  wait_tensor_306 = None
        permute_1004 = torch.ops.aten.permute.default(permute_221, [1, 0]);  permute_221 = None
        mm_409 = torch.ops.aten.mm.default(view_2008, permute_1004);  view_2008 = permute_1004 = None
        view_2009 = torch.ops.aten.view.default(mm_409, [2, 4096, 2048]);  mm_409 = None
        add_1953 = torch.ops.aten.add.Tensor(view_2004, view_2009);  view_2004 = view_2009 = None
        convert_element_type_2339 = torch.ops.prims.convert_element_type.default(mm_408, torch.float32);  mm_408 = None
        reduce_scatter_tensor_168 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2339, 'avg', 128, '0');  convert_element_type_2339 = None
        wait_tensor_751 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_168);  reduce_scatter_tensor_168 = None
        convert_element_type_2340 = torch.ops.prims.convert_element_type.default(add_1953, torch.float32);  add_1953 = None
        convert_element_type_793 = torch.ops.prims.convert_element_type.default(primals_247, torch.bfloat16);  primals_247 = None
        all_gather_into_tensor_249 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_793, 128, '0');  convert_element_type_793 = None
        wait_tensor_305 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_249);  all_gather_into_tensor_249 = None
        convert_element_type_2342 = torch.ops.prims.convert_element_type.default(wait_tensor_305, torch.float32);  wait_tensor_305 = None
        mul_1693 = torch.ops.aten.mul.Tensor(convert_element_type_2340, convert_element_type_2342);  convert_element_type_2342 = None
        convert_element_type_794 = torch.ops.prims.convert_element_type.default(add_957, torch.float32);  add_957 = None
        mul_695 = torch.ops.aten.mul.Tensor(convert_element_type_794, rsqrt_45);  convert_element_type_794 = None
        mul_1695 = torch.ops.aten.mul.Tensor(mul_695, mul_1693)
        sum_201 = torch.ops.aten.sum.dim_IntList(mul_1695, [2], True);  mul_1695 = None
        div_203 = torch.ops.aten.div.Tensor(mul_695, 2048)
        mul_1696 = torch.ops.aten.mul.Tensor(div_203, sum_201);  div_203 = sum_201 = None
        sub_696 = torch.ops.aten.sub.Tensor(mul_1693, mul_1696);  mul_1693 = mul_1696 = None
        mul_1697 = torch.ops.aten.mul.Tensor(sub_696, rsqrt_45);  sub_696 = rsqrt_45 = None
        mul_1698 = torch.ops.aten.mul.Tensor(convert_element_type_2340, mul_695);  convert_element_type_2340 = mul_695 = None
        sum_202 = torch.ops.aten.sum.dim_IntList(mul_1698, [0, 1]);  mul_1698 = None
        convert_element_type_2343 = torch.ops.prims.convert_element_type.default(mul_1697, torch.bfloat16);  mul_1697 = None
        add_1954 = torch.ops.aten.add.Tensor(add_1952, convert_element_type_2343);  add_1952 = convert_element_type_2343 = None
        convert_element_type_default_46 = torch.ops.prims.convert_element_type.default(sum_202, torch.float32);  sum_202 = None
        reduce_scatter_tensor_169 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_46, 'avg', 128, '0');  convert_element_type_default_46 = None
        wait_tensor_752 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_169);  reduce_scatter_tensor_169 = None
        view_2010 = torch.ops.aten.view.default(add_1954, [8192, 2048])
        unsqueeze_65 = torch.ops.aten.unsqueeze.default(view_2010, 1)
        convert_element_type_2346 = torch.ops.prims.convert_element_type.default(unsqueeze_65, torch.float32);  unsqueeze_65 = None
        bmm_50 = torch.ops.aten.bmm.default(permute_1006, convert_element_type_2346);  permute_1006 = None
        bmm_51 = torch.ops.aten.bmm.default(convert_element_type_2346, permute_1007);  convert_element_type_2346 = permute_1007 = None
        convert_element_type_2347 = torch.ops.prims.convert_element_type.default(bmm_50, torch.bfloat16);  bmm_50 = None
        view_2011 = torch.ops.aten.view.default(bmm_51, [8192, 6]);  bmm_51 = None
        view_2012 = torch.ops.aten.view.default(convert_element_type_2347, [49152, 2048]);  convert_element_type_2347 = None
        index_76 = torch.ops.aten.index.Tensor(view_2012, [getitem_1451]);  view_2012 = getitem_1451 = None
        permute_1008 = torch.ops.aten.permute.default(view_2010, [1, 0])
        mm_410 = torch.ops.aten.mm.default(permute_1008, mul_692);  permute_1008 = mul_692 = None
        convert_element_type_788 = torch.ops.prims.convert_element_type.default(primals_246, torch.bfloat16);  primals_246 = None
        all_gather_into_tensor_248 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_788, 128, '0');  convert_element_type_788 = None
        wait_tensor_304 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_248);  all_gather_into_tensor_248 = None
        permute_220 = torch.ops.aten.permute.default(wait_tensor_304, [1, 0]);  wait_tensor_304 = None
        permute_1010 = torch.ops.aten.permute.default(permute_220, [1, 0]);  permute_220 = None
        mm_411 = torch.ops.aten.mm.default(view_2010, permute_1010);  view_2010 = permute_1010 = None
        convert_element_type_2352 = torch.ops.prims.convert_element_type.default(mm_410, torch.float32);  mm_410 = None
        reduce_scatter_tensor_170 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2352, 'avg', 128, '0');  convert_element_type_2352 = None
        wait_tensor_753 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_170);  reduce_scatter_tensor_170 = None
        convert_element_type_783 = torch.ops.prims.convert_element_type.default(mm_116, torch.float32);  mm_116 = None
        neg_28 = torch.ops.aten.neg.default(convert_element_type_783)
        exp_42 = torch.ops.aten.exp.default(neg_28);  neg_28 = None
        add_952 = torch.ops.aten.add.Tensor(exp_42, 1);  exp_42 = None
        div_70 = torch.ops.aten.div.Tensor(convert_element_type_783, add_952)
        convert_element_type_784 = torch.ops.prims.convert_element_type.default(div_70, torch.bfloat16);  div_70 = None
        mul_1699 = torch.ops.aten.mul.Tensor(mm_411, convert_element_type_784);  convert_element_type_784 = None
        mul_1700 = torch.ops.aten.mul.Tensor(mm_411, mm_117);  mm_411 = mm_117 = None
        permute_1012 = torch.ops.aten.permute.default(mul_1699, [1, 0])
        mm_412 = torch.ops.aten.mm.default(permute_1012, view_929);  permute_1012 = None
        convert_element_type_785 = torch.ops.prims.convert_element_type.default(primals_245, torch.bfloat16);  primals_245 = None
        all_gather_into_tensor_247 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_785, 128, '0');  convert_element_type_785 = None
        wait_tensor_303 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_247);  all_gather_into_tensor_247 = None
        permute_219 = torch.ops.aten.permute.default(wait_tensor_303, [1, 0]);  wait_tensor_303 = None
        permute_1014 = torch.ops.aten.permute.default(permute_219, [1, 0]);  permute_219 = None
        mm_413 = torch.ops.aten.mm.default(mul_1699, permute_1014);  mul_1699 = permute_1014 = None
        convert_element_type_2357 = torch.ops.prims.convert_element_type.default(mm_412, torch.float32);  mm_412 = None
        reduce_scatter_tensor_171 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2357, 'avg', 128, '0');  convert_element_type_2357 = None
        wait_tensor_754 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_171);  reduce_scatter_tensor_171 = None
        convert_element_type_2358 = torch.ops.prims.convert_element_type.default(mul_1700, torch.float32);  mul_1700 = None
        reciprocal_24 = torch.ops.aten.reciprocal.default(add_952);  add_952 = None
        mul_1701 = torch.ops.aten.mul.Tensor(reciprocal_24, 1);  reciprocal_24 = None
        mul_1702 = torch.ops.aten.mul.Tensor(convert_element_type_2358, mul_1701);  convert_element_type_2358 = None
        sub_697 = torch.ops.aten.sub.Tensor(1, mul_1701);  mul_1701 = None
        mul_1703 = torch.ops.aten.mul.Tensor(convert_element_type_783, sub_697);  convert_element_type_783 = sub_697 = None
        add_1956 = torch.ops.aten.add.Tensor(mul_1703, 1);  mul_1703 = None
        mul_1704 = torch.ops.aten.mul.Tensor(mul_1702, add_1956);  mul_1702 = add_1956 = None
        convert_element_type_2360 = torch.ops.prims.convert_element_type.default(mul_1704, torch.bfloat16);  mul_1704 = None
        permute_1016 = torch.ops.aten.permute.default(convert_element_type_2360, [1, 0])
        mm_414 = torch.ops.aten.mm.default(permute_1016, view_929);  permute_1016 = None
        convert_element_type_780 = torch.ops.prims.convert_element_type.default(primals_244, torch.bfloat16);  primals_244 = None
        all_gather_into_tensor_246 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_780, 128, '0');  convert_element_type_780 = None
        wait_tensor_302 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_246);  all_gather_into_tensor_246 = None
        permute_218 = torch.ops.aten.permute.default(wait_tensor_302, [1, 0]);  wait_tensor_302 = None
        permute_1018 = torch.ops.aten.permute.default(permute_218, [1, 0]);  permute_218 = None
        mm_415 = torch.ops.aten.mm.default(convert_element_type_2360, permute_1018);  convert_element_type_2360 = permute_1018 = None
        add_1957 = torch.ops.aten.add.Tensor(mm_413, mm_415);  mm_413 = mm_415 = None
        convert_element_type_2365 = torch.ops.prims.convert_element_type.default(mm_414, torch.float32);  mm_414 = None
        reduce_scatter_tensor_172 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2365, 'avg', 128, '0');  convert_element_type_2365 = None
        wait_tensor_755 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_172);  reduce_scatter_tensor_172 = None
        all_to_all_single_102 = torch.ops._c10d_functional.all_to_all_single.default(index_76, [_local_scalar_dense_216, _local_scalar_dense_217, _local_scalar_dense_218, _local_scalar_dense_219, _local_scalar_dense_220, _local_scalar_dense_221, _local_scalar_dense_222, _local_scalar_dense_223], [_local_scalar_dense_208, _local_scalar_dense_209, _local_scalar_dense_210, _local_scalar_dense_211, _local_scalar_dense_212, _local_scalar_dense_213, _local_scalar_dense_214, _local_scalar_dense_215], '1033');  index_76 = None
        wait_tensor_756 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_102);  all_to_all_single_102 = None
        full_420 = torch.ops.aten.full.default([sym_size_int_53, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_53 = None
        slice_scatter_12 = torch.ops.aten.slice_scatter.default(full_420, wait_tensor_756, 0, 0, -1);  wait_tensor_756 = None
        index_77 = torch.ops.aten.index.Tensor(slice_scatter_12, [getitem_1452]);  slice_scatter_12 = None
        permute_1020 = torch.ops.aten.permute.default(index_77, [1, 0])
        _grouped_mm_150 = torch.ops.aten._grouped_mm.default(permute_1020, mul_672, cumsum_41);  permute_1020 = mul_672 = None
        _grouped_mm_151 = torch.ops.aten._grouped_mm.default(index_77, permute_1022, cumsum_41);  index_77 = permute_1022 = None
        convert_element_type_778 = torch.ops.prims.convert_element_type.default(_grouped_mm_39, torch.float32);  _grouped_mm_39 = None
        neg_27 = torch.ops.aten.neg.default(convert_element_type_778)
        exp_41 = torch.ops.aten.exp.default(neg_27);  neg_27 = None
        add_916 = torch.ops.aten.add.Tensor(exp_41, 1);  exp_41 = None
        div_69 = torch.ops.aten.div.Tensor(convert_element_type_778, add_916)
        convert_element_type_779 = torch.ops.prims.convert_element_type.default(div_69, torch.bfloat16);  div_69 = None
        mul_1705 = torch.ops.aten.mul.Tensor(_grouped_mm_151, convert_element_type_779);  convert_element_type_779 = None
        mul_1706 = torch.ops.aten.mul.Tensor(_grouped_mm_151, _grouped_mm_40);  _grouped_mm_151 = _grouped_mm_40 = None
        permute_1024 = torch.ops.aten.permute.default(mul_1705, [1, 0])
        _grouped_mm_152 = torch.ops.aten._grouped_mm.default(permute_1024, index_27, cumsum_41);  permute_1024 = None
        _grouped_mm_153 = torch.ops.aten._grouped_mm.default(mul_1705, permute_1026, cumsum_41);  mul_1705 = permute_1026 = None
        convert_element_type_2366 = torch.ops.prims.convert_element_type.default(mul_1706, torch.float32);  mul_1706 = None
        reciprocal_25 = torch.ops.aten.reciprocal.default(add_916);  add_916 = None
        mul_1707 = torch.ops.aten.mul.Tensor(reciprocal_25, 1);  reciprocal_25 = None
        mul_1708 = torch.ops.aten.mul.Tensor(convert_element_type_2366, mul_1707);  convert_element_type_2366 = None
        sub_698 = torch.ops.aten.sub.Tensor(1, mul_1707);  mul_1707 = None
        mul_1709 = torch.ops.aten.mul.Tensor(convert_element_type_778, sub_698);  convert_element_type_778 = sub_698 = None
        add_1959 = torch.ops.aten.add.Tensor(mul_1709, 1);  mul_1709 = None
        mul_1710 = torch.ops.aten.mul.Tensor(mul_1708, add_1959);  mul_1708 = add_1959 = None
        convert_element_type_2368 = torch.ops.prims.convert_element_type.default(mul_1710, torch.bfloat16);  mul_1710 = None
        permute_1028 = torch.ops.aten.permute.default(convert_element_type_2368, [1, 0])
        _grouped_mm_154 = torch.ops.aten._grouped_mm.default(permute_1028, index_27, cumsum_41);  permute_1028 = index_27 = None
        _grouped_mm_155 = torch.ops.aten._grouped_mm.default(convert_element_type_2368, permute_1030, cumsum_41);  convert_element_type_2368 = permute_1030 = cumsum_41 = None
        add_1960 = torch.ops.aten.add.Tensor(_grouped_mm_153, _grouped_mm_155);  _grouped_mm_153 = _grouped_mm_155 = None
        convert_element_type_2369 = torch.ops.prims.convert_element_type.default(_grouped_mm_152, torch.float32);  _grouped_mm_152 = None
        div_204 = torch.ops.aten.div.Tensor(convert_element_type_2369, 128);  convert_element_type_2369 = None
        split_793 = torch.ops.aten.split.Tensor(div_204, 88, 1);  div_204 = None
        getitem_14885 = split_793[0]
        getitem_14902 = split_793[1]
        getitem_14919 = split_793[2]
        getitem_14936 = split_793[3]
        getitem_14953 = split_793[4]
        getitem_14970 = split_793[5]
        getitem_14987 = split_793[6]
        getitem_15004 = split_793[7]
        getitem_15021 = split_793[8]
        getitem_15038 = split_793[9]
        getitem_15055 = split_793[10]
        getitem_15072 = split_793[11]
        getitem_15089 = split_793[12]
        getitem_15106 = split_793[13]
        getitem_15123 = split_793[14]
        getitem_15140 = split_793[15];  split_793 = None
        cat_332 = torch.ops.aten.cat.default([getitem_14885, getitem_14902, getitem_14919, getitem_14936, getitem_14953, getitem_14970, getitem_14987, getitem_15004, getitem_15021, getitem_15038, getitem_15055, getitem_15072, getitem_15089, getitem_15106, getitem_15123, getitem_15140]);  getitem_14885 = getitem_14902 = getitem_14919 = getitem_14936 = getitem_14953 = getitem_14970 = getitem_14987 = getitem_15004 = getitem_15021 = getitem_15038 = getitem_15055 = getitem_15072 = getitem_15089 = getitem_15106 = getitem_15123 = getitem_15140 = None
        reduce_scatter_tensor_173 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_332, 'sum', 16, '1025');  cat_332 = None
        wait_tensor_757 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_173);  reduce_scatter_tensor_173 = None
        convert_element_type_2370 = torch.ops.prims.convert_element_type.default(_grouped_mm_150, torch.float32);  _grouped_mm_150 = None
        div_205 = torch.ops.aten.div.Tensor(convert_element_type_2370, 128);  convert_element_type_2370 = None
        split_810 = torch.ops.aten.split.Tensor(div_205, 128, 1);  div_205 = None
        getitem_15157 = split_810[0]
        getitem_15174 = split_810[1]
        getitem_15191 = split_810[2]
        getitem_15208 = split_810[3]
        getitem_15225 = split_810[4]
        getitem_15242 = split_810[5]
        getitem_15259 = split_810[6]
        getitem_15276 = split_810[7]
        getitem_15293 = split_810[8]
        getitem_15310 = split_810[9]
        getitem_15327 = split_810[10]
        getitem_15344 = split_810[11]
        getitem_15361 = split_810[12]
        getitem_15378 = split_810[13]
        getitem_15395 = split_810[14]
        getitem_15412 = split_810[15];  split_810 = None
        cat_333 = torch.ops.aten.cat.default([getitem_15157, getitem_15174, getitem_15191, getitem_15208, getitem_15225, getitem_15242, getitem_15259, getitem_15276, getitem_15293, getitem_15310, getitem_15327, getitem_15344, getitem_15361, getitem_15378, getitem_15395, getitem_15412]);  getitem_15157 = getitem_15174 = getitem_15191 = getitem_15208 = getitem_15225 = getitem_15242 = getitem_15259 = getitem_15276 = getitem_15293 = getitem_15310 = getitem_15327 = getitem_15344 = getitem_15361 = getitem_15378 = getitem_15395 = getitem_15412 = None
        reduce_scatter_tensor_174 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_333, 'sum', 16, '1025');  cat_333 = None
        wait_tensor_758 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_174);  reduce_scatter_tensor_174 = None
        convert_element_type_2371 = torch.ops.prims.convert_element_type.default(_grouped_mm_154, torch.float32);  _grouped_mm_154 = None
        div_206 = torch.ops.aten.div.Tensor(convert_element_type_2371, 128);  convert_element_type_2371 = None
        split_827 = torch.ops.aten.split.Tensor(div_206, 88, 1);  div_206 = None
        getitem_15429 = split_827[0]
        getitem_15446 = split_827[1]
        getitem_15463 = split_827[2]
        getitem_15480 = split_827[3]
        getitem_15497 = split_827[4]
        getitem_15514 = split_827[5]
        getitem_15531 = split_827[6]
        getitem_15548 = split_827[7]
        getitem_15565 = split_827[8]
        getitem_15582 = split_827[9]
        getitem_15599 = split_827[10]
        getitem_15616 = split_827[11]
        getitem_15633 = split_827[12]
        getitem_15650 = split_827[13]
        getitem_15667 = split_827[14]
        getitem_15684 = split_827[15];  split_827 = None
        cat_334 = torch.ops.aten.cat.default([getitem_15429, getitem_15446, getitem_15463, getitem_15480, getitem_15497, getitem_15514, getitem_15531, getitem_15548, getitem_15565, getitem_15582, getitem_15599, getitem_15616, getitem_15633, getitem_15650, getitem_15667, getitem_15684]);  getitem_15429 = getitem_15446 = getitem_15463 = getitem_15480 = getitem_15497 = getitem_15514 = getitem_15531 = getitem_15548 = getitem_15565 = getitem_15582 = getitem_15599 = getitem_15616 = getitem_15633 = getitem_15650 = getitem_15667 = getitem_15684 = None
        reduce_scatter_tensor_175 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_334, 'sum', 16, '1025');  cat_334 = None
        wait_tensor_759 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_175);  reduce_scatter_tensor_175 = None
        index_put_76 = torch.ops.aten.index_put.default(full_420, [getitem_1452], add_1960, True);  full_420 = getitem_1452 = add_1960 = None
        slice_234 = torch.ops.aten.slice.Tensor(index_put_76, 0, 0, add_1961);  index_put_76 = add_1961 = None
        all_to_all_single_103 = torch.ops._c10d_functional.all_to_all_single.default(slice_234, [_local_scalar_dense_208, _local_scalar_dense_209, _local_scalar_dense_210, _local_scalar_dense_211, _local_scalar_dense_212, _local_scalar_dense_213, _local_scalar_dense_214, _local_scalar_dense_215], [_local_scalar_dense_216, _local_scalar_dense_217, _local_scalar_dense_218, _local_scalar_dense_219, _local_scalar_dense_220, _local_scalar_dense_221, _local_scalar_dense_222, _local_scalar_dense_223], '1033');  slice_234 = _local_scalar_dense_208 = _local_scalar_dense_209 = _local_scalar_dense_210 = _local_scalar_dense_211 = _local_scalar_dense_212 = _local_scalar_dense_213 = _local_scalar_dense_214 = _local_scalar_dense_215 = _local_scalar_dense_216 = _local_scalar_dense_217 = _local_scalar_dense_218 = _local_scalar_dense_219 = _local_scalar_dense_220 = _local_scalar_dense_221 = _local_scalar_dense_222 = _local_scalar_dense_223 = None
        wait_tensor_760 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_103);  all_to_all_single_103 = None
        index_put_77 = torch.ops.aten.index_put.default(full_default_52, [div_67], wait_tensor_760, True);  div_67 = wait_tensor_760 = None
        add_1965 = torch.ops.aten.add.Tensor(add_1957, index_put_77);  add_1957 = index_put_77 = None
        mul_1711 = torch.ops.aten.mul.Tensor(view_2011, 1.0);  view_2011 = None
        scatter_add_12 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_1449, mul_1711);  getitem_1449 = mul_1711 = None
        convert_element_type_767 = torch.ops.prims.convert_element_type.default(mm_115, torch.float32);  mm_115 = None
        sub_312 = torch.ops.aten.sub.Tensor(convert_element_type_767, amax_13);  convert_element_type_767 = amax_13 = None
        exp_40 = torch.ops.aten.exp.default(sub_312);  sub_312 = None
        div_66 = torch.ops.aten.div.Tensor(exp_40, sum_53);  exp_40 = sum_53 = None
        mul_1712 = torch.ops.aten.mul.Tensor(scatter_add_12, div_66);  scatter_add_12 = None
        sum_203 = torch.ops.aten.sum.dim_IntList(mul_1712, [1], True)
        neg_91 = torch.ops.aten.neg.default(div_66);  div_66 = None
        fma_12 = torch.ops.prims.fma.default(neg_91, sum_203, mul_1712);  neg_91 = sum_203 = mul_1712 = None
        convert_element_type_2372 = torch.ops.prims.convert_element_type.default(fma_12, torch.bfloat16);  fma_12 = None
        permute_1032 = torch.ops.aten.permute.default(convert_element_type_2372, [1, 0])
        mm_416 = torch.ops.aten.mm.default(permute_1032, view_929);  permute_1032 = view_929 = None
        convert_element_type_764 = torch.ops.prims.convert_element_type.default(primals_239, torch.bfloat16);  primals_239 = None
        all_gather_into_tensor_239 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_764, 128, '0');  convert_element_type_764 = None
        wait_tensor_291 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_239);  all_gather_into_tensor_239 = None
        slice_87 = torch.ops.aten.slice.Tensor(wait_tensor_291, 0, 0, 64);  wait_tensor_291 = None
        permute_214 = torch.ops.aten.permute.default(slice_87, [1, 0]);  slice_87 = None
        permute_1034 = torch.ops.aten.permute.default(permute_214, [1, 0]);  permute_214 = None
        mm_417 = torch.ops.aten.mm.default(convert_element_type_2372, permute_1034);  convert_element_type_2372 = permute_1034 = None
        add_1966 = torch.ops.aten.add.Tensor(add_1965, mm_417);  add_1965 = mm_417 = None
        convert_element_type_2377 = torch.ops.prims.convert_element_type.default(mm_416, torch.float32);  mm_416 = None
        split_843 = torch.ops.aten.split.Tensor(convert_element_type_2377, 1);  convert_element_type_2377 = None
        getitem_15685 = split_843[0]
        getitem_15686 = split_843[1]
        getitem_15687 = split_843[2]
        getitem_15688 = split_843[3]
        getitem_15689 = split_843[4]
        getitem_15690 = split_843[5]
        getitem_15691 = split_843[6]
        getitem_15692 = split_843[7]
        getitem_15693 = split_843[8]
        getitem_15694 = split_843[9]
        getitem_15695 = split_843[10]
        getitem_15696 = split_843[11]
        getitem_15697 = split_843[12]
        getitem_15698 = split_843[13]
        getitem_15699 = split_843[14]
        getitem_15700 = split_843[15]
        getitem_15701 = split_843[16]
        getitem_15702 = split_843[17]
        getitem_15703 = split_843[18]
        getitem_15704 = split_843[19]
        getitem_15705 = split_843[20]
        getitem_15706 = split_843[21]
        getitem_15707 = split_843[22]
        getitem_15708 = split_843[23]
        getitem_15709 = split_843[24]
        getitem_15710 = split_843[25]
        getitem_15711 = split_843[26]
        getitem_15712 = split_843[27]
        getitem_15713 = split_843[28]
        getitem_15714 = split_843[29]
        getitem_15715 = split_843[30]
        getitem_15716 = split_843[31]
        getitem_15717 = split_843[32]
        getitem_15718 = split_843[33]
        getitem_15719 = split_843[34]
        getitem_15720 = split_843[35]
        getitem_15721 = split_843[36]
        getitem_15722 = split_843[37]
        getitem_15723 = split_843[38]
        getitem_15724 = split_843[39]
        getitem_15725 = split_843[40]
        getitem_15726 = split_843[41]
        getitem_15727 = split_843[42]
        getitem_15728 = split_843[43]
        getitem_15729 = split_843[44]
        getitem_15730 = split_843[45]
        getitem_15731 = split_843[46]
        getitem_15732 = split_843[47]
        getitem_15733 = split_843[48]
        getitem_15734 = split_843[49]
        getitem_15735 = split_843[50]
        getitem_15736 = split_843[51]
        getitem_15737 = split_843[52]
        getitem_15738 = split_843[53]
        getitem_15739 = split_843[54]
        getitem_15740 = split_843[55]
        getitem_15741 = split_843[56]
        getitem_15742 = split_843[57]
        getitem_15743 = split_843[58]
        getitem_15744 = split_843[59]
        getitem_15745 = split_843[60]
        getitem_15746 = split_843[61]
        getitem_15747 = split_843[62]
        getitem_15748 = split_843[63];  split_843 = None
        cat_335 = torch.ops.aten.cat.default([getitem_15685, getitem_15686, getitem_15687, getitem_15688, getitem_15689, getitem_15690, getitem_15691, getitem_15692, getitem_15693, getitem_15694, getitem_15695, getitem_15696, getitem_15697, getitem_15698, getitem_15699, getitem_15700, getitem_15701, getitem_15702, getitem_15703, getitem_15704, getitem_15705, getitem_15706, getitem_15707, getitem_15708, getitem_15709, getitem_15710, getitem_15711, getitem_15712, getitem_15713, getitem_15714, getitem_15715, getitem_15716, getitem_15717, getitem_15718, getitem_15719, getitem_15720, getitem_15721, getitem_15722, getitem_15723, getitem_15724, getitem_15725, getitem_15726, getitem_15727, getitem_15728, getitem_15729, getitem_15730, getitem_15731, getitem_15732, getitem_15733, getitem_15734, getitem_15735, getitem_15736, getitem_15737, getitem_15738, getitem_15739, getitem_15740, getitem_15741, getitem_15742, getitem_15743, getitem_15744, getitem_15745, getitem_15746, getitem_15747, getitem_15748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_15685 = getitem_15686 = getitem_15687 = getitem_15688 = getitem_15689 = getitem_15690 = getitem_15691 = getitem_15692 = getitem_15693 = getitem_15694 = getitem_15695 = getitem_15696 = getitem_15697 = getitem_15698 = getitem_15699 = getitem_15700 = getitem_15701 = getitem_15702 = getitem_15703 = getitem_15704 = getitem_15705 = getitem_15706 = getitem_15707 = getitem_15708 = getitem_15709 = getitem_15710 = getitem_15711 = getitem_15712 = getitem_15713 = getitem_15714 = getitem_15715 = getitem_15716 = getitem_15717 = getitem_15718 = getitem_15719 = getitem_15720 = getitem_15721 = getitem_15722 = getitem_15723 = getitem_15724 = getitem_15725 = getitem_15726 = getitem_15727 = getitem_15728 = getitem_15729 = getitem_15730 = getitem_15731 = getitem_15732 = getitem_15733 = getitem_15734 = getitem_15735 = getitem_15736 = getitem_15737 = getitem_15738 = getitem_15739 = getitem_15740 = getitem_15741 = getitem_15742 = getitem_15743 = getitem_15744 = getitem_15745 = getitem_15746 = getitem_15747 = getitem_15748 = None
        reduce_scatter_tensor_176 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_335, 'avg', 128, '0');  cat_335 = None
        wait_tensor_761 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_176);  reduce_scatter_tensor_176 = None
        view_2013 = torch.ops.aten.view.default(add_1966, [2, 4096, 2048]);  add_1966 = None
        convert_element_type_2378 = torch.ops.prims.convert_element_type.default(view_2013, torch.float32);  view_2013 = None
        convert_element_type_761 = torch.ops.prims.convert_element_type.default(primals_237, torch.bfloat16);  primals_237 = None
        all_gather_into_tensor_238 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_761, 128, '0');  convert_element_type_761 = None
        wait_tensor_290 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_238);  all_gather_into_tensor_238 = None
        convert_element_type_2380 = torch.ops.prims.convert_element_type.default(wait_tensor_290, torch.float32);  wait_tensor_290 = None
        mul_1713 = torch.ops.aten.mul.Tensor(convert_element_type_2378, convert_element_type_2380);  convert_element_type_2380 = None
        convert_element_type_762 = torch.ops.prims.convert_element_type.default(add_892, torch.float32);  add_892 = None
        mul_652 = torch.ops.aten.mul.Tensor(convert_element_type_762, rsqrt_44);  convert_element_type_762 = None
        mul_1715 = torch.ops.aten.mul.Tensor(mul_652, mul_1713)
        sum_204 = torch.ops.aten.sum.dim_IntList(mul_1715, [2], True);  mul_1715 = None
        div_207 = torch.ops.aten.div.Tensor(mul_652, 2048)
        mul_1716 = torch.ops.aten.mul.Tensor(div_207, sum_204);  div_207 = sum_204 = None
        sub_700 = torch.ops.aten.sub.Tensor(mul_1713, mul_1716);  mul_1713 = mul_1716 = None
        mul_1717 = torch.ops.aten.mul.Tensor(sub_700, rsqrt_44);  sub_700 = rsqrt_44 = None
        mul_1718 = torch.ops.aten.mul.Tensor(convert_element_type_2378, mul_652);  convert_element_type_2378 = mul_652 = None
        sum_205 = torch.ops.aten.sum.dim_IntList(mul_1718, [0, 1]);  mul_1718 = None
        convert_element_type_2381 = torch.ops.prims.convert_element_type.default(mul_1717, torch.bfloat16);  mul_1717 = None
        add_1967 = torch.ops.aten.add.Tensor(add_1954, convert_element_type_2381);  add_1954 = convert_element_type_2381 = None
        convert_element_type_default_45 = torch.ops.prims.convert_element_type.default(sum_205, torch.float32);  sum_205 = None
        reduce_scatter_tensor_177 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_45, 'avg', 128, '0');  convert_element_type_default_45 = None
        wait_tensor_762 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_177);  reduce_scatter_tensor_177 = None
        view_2014 = torch.ops.aten.view.default(add_1967, [8192, 2048])
        permute_1036 = torch.ops.aten.permute.default(view_2014, [1, 0])
        permute_212 = torch.ops.aten.permute.default(getitem_1445, [0, 2, 1, 3])
        view_924 = torch.ops.aten.view.default(permute_212, [2, 4096, -1]);  permute_212 = None
        view_926 = torch.ops.aten.view.default(view_924, [8192, 2048]);  view_924 = None
        mm_418 = torch.ops.aten.mm.default(permute_1036, view_926);  permute_1036 = view_926 = None
        convert_element_type_758 = torch.ops.prims.convert_element_type.default(primals_236, torch.bfloat16);  primals_236 = None
        all_gather_into_tensor_237 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_758, 128, '0');  convert_element_type_758 = None
        wait_tensor_289 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_237);  all_gather_into_tensor_237 = None
        permute_213 = torch.ops.aten.permute.default(wait_tensor_289, [1, 0]);  wait_tensor_289 = None
        permute_1038 = torch.ops.aten.permute.default(permute_213, [1, 0]);  permute_213 = None
        mm_419 = torch.ops.aten.mm.default(view_2014, permute_1038);  view_2014 = permute_1038 = None
        view_2015 = torch.ops.aten.view.default(mm_419, [2, 4096, 2048]);  mm_419 = None
        convert_element_type_2388 = torch.ops.prims.convert_element_type.default(mm_418, torch.float32);  mm_418 = None
        reduce_scatter_tensor_178 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2388, 'avg', 128, '0');  convert_element_type_2388 = None
        wait_tensor_763 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_178);  reduce_scatter_tensor_178 = None
        view_2016 = torch.ops.aten.view.default(view_2015, [2, 4096, 16, 128]);  view_2015 = None
        permute_1040 = torch.ops.aten.permute.default(view_2016, [0, 2, 1, 3]);  view_2016 = None
        fw_graph12 = self.fw_graph12
        joint_graph12 = self.joint_graph12
        mask_graph12 = self.mask_graph12
        flex_attention_backward_12 = torch.ops.higher_order.flex_attention_backward(permute_209, permute_210, permute_211, getitem_1445, getitem_1446, permute_1040, None, fw_graph12, joint_graph12, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph12), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_209 = permute_210 = permute_211 = getitem_1445 = getitem_1446 = permute_1040 = fw_graph12 = joint_graph12 = mask_graph12 = None
        getitem_15749 = flex_attention_backward_12[0]
        getitem_15750 = flex_attention_backward_12[1]
        getitem_15751 = flex_attention_backward_12[2];  flex_attention_backward_12 = None
        permute_1041 = torch.ops.aten.permute.default(getitem_15751, [0, 2, 1, 3]);  getitem_15751 = None
        permute_1042 = torch.ops.aten.permute.default(getitem_15750, [0, 2, 1, 3]);  getitem_15750 = None
        permute_1043 = torch.ops.aten.permute.default(getitem_15749, [0, 2, 1, 3]);  getitem_15749 = None
        slice_236 = torch.ops.aten.slice.Tensor(permute_1042, 3, 0, 128)
        slice_237 = torch.ops.aten.slice.Tensor(permute_1042, 3, 128, 192);  permute_1042 = None
        sum_206 = torch.ops.aten.sum.dim_IntList(slice_237, [2], True);  slice_237 = None
        cat_336 = torch.ops.aten.cat.default([slice_236, permute_1041], 3);  slice_236 = permute_1041 = None
        view_2017 = torch.ops.aten.view.default(cat_336, [2, 4096, 4096]);  cat_336 = None
        view_2018 = torch.ops.aten.view.default(view_2017, [8192, 4096]);  view_2017 = None
        permute_1044 = torch.ops.aten.permute.default(view_2018, [1, 0])
        mm_420 = torch.ops.aten.mm.default(permute_1044, view_921);  permute_1044 = view_921 = None
        convert_element_type_755 = torch.ops.prims.convert_element_type.default(primals_235, torch.bfloat16);  primals_235 = None
        all_gather_into_tensor_236 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_755, 128, '0');  convert_element_type_755 = None
        wait_tensor_288 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_236);  all_gather_into_tensor_236 = None
        permute_208 = torch.ops.aten.permute.default(wait_tensor_288, [1, 0]);  wait_tensor_288 = None
        permute_1046 = torch.ops.aten.permute.default(permute_208, [1, 0]);  permute_208 = None
        mm_421 = torch.ops.aten.mm.default(view_2018, permute_1046);  view_2018 = permute_1046 = None
        view_2019 = torch.ops.aten.view.default(mm_421, [2, 4096, 512]);  mm_421 = None
        convert_element_type_2393 = torch.ops.prims.convert_element_type.default(mm_420, torch.float32);  mm_420 = None
        reduce_scatter_tensor_179 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2393, 'avg', 128, '0');  convert_element_type_2393 = None
        wait_tensor_764 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_179);  reduce_scatter_tensor_179 = None
        convert_element_type_2394 = torch.ops.prims.convert_element_type.default(view_2019, torch.float32);  view_2019 = None
        convert_element_type_752 = torch.ops.prims.convert_element_type.default(primals_234, torch.bfloat16);  primals_234 = None
        all_gather_into_tensor_235 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_752, 128, '0');  convert_element_type_752 = None
        wait_tensor_287 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_235);  all_gather_into_tensor_235 = None
        convert_element_type_2396 = torch.ops.prims.convert_element_type.default(wait_tensor_287, torch.float32);  wait_tensor_287 = None
        mul_1719 = torch.ops.aten.mul.Tensor(convert_element_type_2394, convert_element_type_2396);  convert_element_type_2396 = None
        convert_element_type_753 = torch.ops.prims.convert_element_type.default(getitem_1441, torch.float32);  getitem_1441 = None
        mul_650 = torch.ops.aten.mul.Tensor(convert_element_type_753, rsqrt_43);  convert_element_type_753 = None
        mul_1721 = torch.ops.aten.mul.Tensor(mul_650, mul_1719)
        sum_207 = torch.ops.aten.sum.dim_IntList(mul_1721, [2], True);  mul_1721 = None
        div_208 = torch.ops.aten.div.Tensor(mul_650, 512)
        mul_1722 = torch.ops.aten.mul.Tensor(div_208, sum_207);  div_208 = sum_207 = None
        sub_701 = torch.ops.aten.sub.Tensor(mul_1719, mul_1722);  mul_1719 = mul_1722 = None
        mul_1723 = torch.ops.aten.mul.Tensor(sub_701, rsqrt_43);  sub_701 = rsqrt_43 = None
        mul_1724 = torch.ops.aten.mul.Tensor(convert_element_type_2394, mul_650);  convert_element_type_2394 = mul_650 = None
        sum_208 = torch.ops.aten.sum.dim_IntList(mul_1724, [0, 1]);  mul_1724 = None
        convert_element_type_2397 = torch.ops.prims.convert_element_type.default(mul_1723, torch.bfloat16);  mul_1723 = None
        convert_element_type_default_44 = torch.ops.prims.convert_element_type.default(sum_208, torch.float32);  sum_208 = None
        reduce_scatter_tensor_180 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_44, 'avg', 128, '0');  convert_element_type_default_44 = None
        wait_tensor_765 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_180);  reduce_scatter_tensor_180 = None
        convert_element_type_2400 = torch.ops.prims.convert_element_type.default(sum_206, torch.float32);  sum_206 = None
        view_2020 = torch.ops.aten.view.default(convert_element_type_2400, [2, 4096, 1, 32, 2]);  convert_element_type_2400 = None
        view_as_complex_78 = torch.ops.aten.view_as_complex.default(view_2020);  view_2020 = None
        mul_1725 = torch.ops.aten.mul.Tensor(view_as_complex_78, clone_9);  view_as_complex_78 = None
        view_as_real_78 = torch.ops.aten.view_as_real.default(mul_1725);  mul_1725 = None
        view_2021 = torch.ops.aten.view.default(view_as_real_78, [2, 4096, 1, 64]);  view_as_real_78 = None
        convert_element_type_2401 = torch.ops.prims.convert_element_type.default(view_2021, torch.bfloat16);  view_2021 = None
        squeeze_38 = torch.ops.aten.squeeze.dim(convert_element_type_2401, 2);  convert_element_type_2401 = None
        cat_337 = torch.ops.aten.cat.default([convert_element_type_2397, squeeze_38], 2);  convert_element_type_2397 = squeeze_38 = None
        view_2022 = torch.ops.aten.view.default(cat_337, [8192, 576]);  cat_337 = None
        permute_1048 = torch.ops.aten.permute.default(view_2022, [1, 0])
        mm_422 = torch.ops.aten.mm.default(permute_1048, view_907);  permute_1048 = None
        convert_element_type_747 = torch.ops.prims.convert_element_type.default(primals_233, torch.bfloat16);  primals_233 = None
        all_gather_into_tensor_234 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_747, 128, '0');  convert_element_type_747 = None
        wait_tensor_286 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_234);  all_gather_into_tensor_234 = None
        slice_85 = torch.ops.aten.slice.Tensor(wait_tensor_286, 0, 0, 576);  wait_tensor_286 = None
        permute_207 = torch.ops.aten.permute.default(slice_85, [1, 0]);  slice_85 = None
        permute_1050 = torch.ops.aten.permute.default(permute_207, [1, 0]);  permute_207 = None
        mm_423 = torch.ops.aten.mm.default(view_2022, permute_1050);  view_2022 = permute_1050 = None
        view_2023 = torch.ops.aten.view.default(mm_423, [2, 4096, 2048]);  mm_423 = None
        convert_element_type_2406 = torch.ops.prims.convert_element_type.default(mm_422, torch.float32);  mm_422 = None
        split_844 = torch.ops.aten.split.Tensor(convert_element_type_2406, 5);  convert_element_type_2406 = None
        getitem_15753 = split_844[0]
        getitem_15754 = split_844[1]
        getitem_15755 = split_844[2]
        getitem_15756 = split_844[3]
        getitem_15757 = split_844[4]
        getitem_15758 = split_844[5]
        getitem_15759 = split_844[6]
        getitem_15760 = split_844[7]
        getitem_15761 = split_844[8]
        getitem_15762 = split_844[9]
        getitem_15763 = split_844[10]
        getitem_15764 = split_844[11]
        getitem_15765 = split_844[12]
        getitem_15766 = split_844[13]
        getitem_15767 = split_844[14]
        getitem_15768 = split_844[15]
        getitem_15769 = split_844[16]
        getitem_15770 = split_844[17]
        getitem_15771 = split_844[18]
        getitem_15772 = split_844[19]
        getitem_15773 = split_844[20]
        getitem_15774 = split_844[21]
        getitem_15775 = split_844[22]
        getitem_15776 = split_844[23]
        getitem_15777 = split_844[24]
        getitem_15778 = split_844[25]
        getitem_15779 = split_844[26]
        getitem_15780 = split_844[27]
        getitem_15781 = split_844[28]
        getitem_15782 = split_844[29]
        getitem_15783 = split_844[30]
        getitem_15784 = split_844[31]
        getitem_15785 = split_844[32]
        getitem_15786 = split_844[33]
        getitem_15787 = split_844[34]
        getitem_15788 = split_844[35]
        getitem_15789 = split_844[36]
        getitem_15790 = split_844[37]
        getitem_15791 = split_844[38]
        getitem_15792 = split_844[39]
        getitem_15793 = split_844[40]
        getitem_15794 = split_844[41]
        getitem_15795 = split_844[42]
        getitem_15796 = split_844[43]
        getitem_15797 = split_844[44]
        getitem_15798 = split_844[45]
        getitem_15799 = split_844[46]
        getitem_15800 = split_844[47]
        getitem_15801 = split_844[48]
        getitem_15802 = split_844[49]
        getitem_15803 = split_844[50]
        getitem_15804 = split_844[51]
        getitem_15805 = split_844[52]
        getitem_15806 = split_844[53]
        getitem_15807 = split_844[54]
        getitem_15808 = split_844[55]
        getitem_15809 = split_844[56]
        getitem_15810 = split_844[57]
        getitem_15811 = split_844[58]
        getitem_15812 = split_844[59]
        getitem_15813 = split_844[60]
        getitem_15814 = split_844[61]
        getitem_15815 = split_844[62]
        getitem_15816 = split_844[63]
        getitem_15817 = split_844[64]
        getitem_15818 = split_844[65]
        getitem_15819 = split_844[66]
        getitem_15820 = split_844[67]
        getitem_15821 = split_844[68]
        getitem_15822 = split_844[69]
        getitem_15823 = split_844[70]
        getitem_15824 = split_844[71]
        getitem_15825 = split_844[72]
        getitem_15826 = split_844[73]
        getitem_15827 = split_844[74]
        getitem_15828 = split_844[75]
        getitem_15829 = split_844[76]
        getitem_15830 = split_844[77]
        getitem_15831 = split_844[78]
        getitem_15832 = split_844[79]
        getitem_15833 = split_844[80]
        getitem_15834 = split_844[81]
        getitem_15835 = split_844[82]
        getitem_15836 = split_844[83]
        getitem_15837 = split_844[84]
        getitem_15838 = split_844[85]
        getitem_15839 = split_844[86]
        getitem_15840 = split_844[87]
        getitem_15841 = split_844[88]
        getitem_15842 = split_844[89]
        getitem_15843 = split_844[90]
        getitem_15844 = split_844[91]
        getitem_15845 = split_844[92]
        getitem_15846 = split_844[93]
        getitem_15847 = split_844[94]
        getitem_15848 = split_844[95]
        getitem_15849 = split_844[96]
        getitem_15850 = split_844[97]
        getitem_15851 = split_844[98]
        getitem_15852 = split_844[99]
        getitem_15853 = split_844[100]
        getitem_15854 = split_844[101]
        getitem_15855 = split_844[102]
        getitem_15856 = split_844[103]
        getitem_15857 = split_844[104]
        getitem_15858 = split_844[105]
        getitem_15859 = split_844[106]
        getitem_15860 = split_844[107]
        getitem_15861 = split_844[108]
        getitem_15862 = split_844[109]
        getitem_15863 = split_844[110]
        getitem_15864 = split_844[111]
        getitem_15865 = split_844[112]
        getitem_15866 = split_844[113]
        getitem_15867 = split_844[114]
        getitem_15868 = split_844[115];  split_844 = None
        constant_pad_nd_988 = torch.ops.aten.constant_pad_nd.default(getitem_15868, [0, 0, 0, 4], 0.0);  getitem_15868 = None
        cat_338 = torch.ops.aten.cat.default([getitem_15753, getitem_15754, getitem_15755, getitem_15756, getitem_15757, getitem_15758, getitem_15759, getitem_15760, getitem_15761, getitem_15762, getitem_15763, getitem_15764, getitem_15765, getitem_15766, getitem_15767, getitem_15768, getitem_15769, getitem_15770, getitem_15771, getitem_15772, getitem_15773, getitem_15774, getitem_15775, getitem_15776, getitem_15777, getitem_15778, getitem_15779, getitem_15780, getitem_15781, getitem_15782, getitem_15783, getitem_15784, getitem_15785, getitem_15786, getitem_15787, getitem_15788, getitem_15789, getitem_15790, getitem_15791, getitem_15792, getitem_15793, getitem_15794, getitem_15795, getitem_15796, getitem_15797, getitem_15798, getitem_15799, getitem_15800, getitem_15801, getitem_15802, getitem_15803, getitem_15804, getitem_15805, getitem_15806, getitem_15807, getitem_15808, getitem_15809, getitem_15810, getitem_15811, getitem_15812, getitem_15813, getitem_15814, getitem_15815, getitem_15816, getitem_15817, getitem_15818, getitem_15819, getitem_15820, getitem_15821, getitem_15822, getitem_15823, getitem_15824, getitem_15825, getitem_15826, getitem_15827, getitem_15828, getitem_15829, getitem_15830, getitem_15831, getitem_15832, getitem_15833, getitem_15834, getitem_15835, getitem_15836, getitem_15837, getitem_15838, getitem_15839, getitem_15840, getitem_15841, getitem_15842, getitem_15843, getitem_15844, getitem_15845, getitem_15846, getitem_15847, getitem_15848, getitem_15849, getitem_15850, getitem_15851, getitem_15852, getitem_15853, getitem_15854, getitem_15855, getitem_15856, getitem_15857, getitem_15858, getitem_15859, getitem_15860, getitem_15861, getitem_15862, getitem_15863, getitem_15864, getitem_15865, getitem_15866, getitem_15867, constant_pad_nd_988, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_15753 = getitem_15754 = getitem_15755 = getitem_15756 = getitem_15757 = getitem_15758 = getitem_15759 = getitem_15760 = getitem_15761 = getitem_15762 = getitem_15763 = getitem_15764 = getitem_15765 = getitem_15766 = getitem_15767 = getitem_15768 = getitem_15769 = getitem_15770 = getitem_15771 = getitem_15772 = getitem_15773 = getitem_15774 = getitem_15775 = getitem_15776 = getitem_15777 = getitem_15778 = getitem_15779 = getitem_15780 = getitem_15781 = getitem_15782 = getitem_15783 = getitem_15784 = getitem_15785 = getitem_15786 = getitem_15787 = getitem_15788 = getitem_15789 = getitem_15790 = getitem_15791 = getitem_15792 = getitem_15793 = getitem_15794 = getitem_15795 = getitem_15796 = getitem_15797 = getitem_15798 = getitem_15799 = getitem_15800 = getitem_15801 = getitem_15802 = getitem_15803 = getitem_15804 = getitem_15805 = getitem_15806 = getitem_15807 = getitem_15808 = getitem_15809 = getitem_15810 = getitem_15811 = getitem_15812 = getitem_15813 = getitem_15814 = getitem_15815 = getitem_15816 = getitem_15817 = getitem_15818 = getitem_15819 = getitem_15820 = getitem_15821 = getitem_15822 = getitem_15823 = getitem_15824 = getitem_15825 = getitem_15826 = getitem_15827 = getitem_15828 = getitem_15829 = getitem_15830 = getitem_15831 = getitem_15832 = getitem_15833 = getitem_15834 = getitem_15835 = getitem_15836 = getitem_15837 = getitem_15838 = getitem_15839 = getitem_15840 = getitem_15841 = getitem_15842 = getitem_15843 = getitem_15844 = getitem_15845 = getitem_15846 = getitem_15847 = getitem_15848 = getitem_15849 = getitem_15850 = getitem_15851 = getitem_15852 = getitem_15853 = getitem_15854 = getitem_15855 = getitem_15856 = getitem_15857 = getitem_15858 = getitem_15859 = getitem_15860 = getitem_15861 = getitem_15862 = getitem_15863 = getitem_15864 = getitem_15865 = getitem_15866 = getitem_15867 = constant_pad_nd_988 = None
        reduce_scatter_tensor_181 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_338, 'avg', 128, '0');  cat_338 = None
        wait_tensor_766 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_181);  reduce_scatter_tensor_181 = None
        slice_238 = torch.ops.aten.slice.Tensor(permute_1043, 3, 0, 128)
        slice_239 = torch.ops.aten.slice.Tensor(permute_1043, 3, 128, 192);  permute_1043 = None
        convert_element_type_2407 = torch.ops.prims.convert_element_type.default(slice_239, torch.float32);  slice_239 = None
        view_2024 = torch.ops.aten.view.default(convert_element_type_2407, [2, 4096, 16, 32, 2]);  convert_element_type_2407 = None
        view_as_complex_79 = torch.ops.aten.view_as_complex.default(view_2024);  view_2024 = None
        mul_1726 = torch.ops.aten.mul.Tensor(view_as_complex_79, clone_9);  view_as_complex_79 = None
        view_as_real_79 = torch.ops.aten.view_as_real.default(mul_1726);  mul_1726 = None
        view_2025 = torch.ops.aten.view.default(view_as_real_79, [2, 4096, 16, 64]);  view_as_real_79 = None
        convert_element_type_2408 = torch.ops.prims.convert_element_type.default(view_2025, torch.bfloat16);  view_2025 = None
        cat_339 = torch.ops.aten.cat.default([slice_238, convert_element_type_2408], 3);  slice_238 = convert_element_type_2408 = None
        view_2026 = torch.ops.aten.view.default(cat_339, [2, 4096, 3072]);  cat_339 = None
        view_2027 = torch.ops.aten.view.default(view_2026, [8192, 3072]);  view_2026 = None
        permute_1052 = torch.ops.aten.permute.default(view_2027, [1, 0])
        mm_424 = torch.ops.aten.mm.default(permute_1052, view_907);  permute_1052 = view_907 = None
        convert_element_type_742 = torch.ops.prims.convert_element_type.default(primals_232, torch.bfloat16);  primals_232 = None
        all_gather_into_tensor_233 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_742, 128, '0');  convert_element_type_742 = None
        wait_tensor_285 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_233);  all_gather_into_tensor_233 = None
        permute_206 = torch.ops.aten.permute.default(wait_tensor_285, [1, 0]);  wait_tensor_285 = None
        permute_1054 = torch.ops.aten.permute.default(permute_206, [1, 0]);  permute_206 = None
        mm_425 = torch.ops.aten.mm.default(view_2027, permute_1054);  view_2027 = permute_1054 = None
        view_2028 = torch.ops.aten.view.default(mm_425, [2, 4096, 2048]);  mm_425 = None
        add_1968 = torch.ops.aten.add.Tensor(view_2023, view_2028);  view_2023 = view_2028 = None
        convert_element_type_2413 = torch.ops.prims.convert_element_type.default(mm_424, torch.float32);  mm_424 = None
        reduce_scatter_tensor_182 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2413, 'avg', 128, '0');  convert_element_type_2413 = None
        wait_tensor_767 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_182);  reduce_scatter_tensor_182 = None
        convert_element_type_2414 = torch.ops.prims.convert_element_type.default(add_1968, torch.float32);  add_1968 = None
        convert_element_type_739 = torch.ops.prims.convert_element_type.default(primals_231, torch.bfloat16);  primals_231 = None
        all_gather_into_tensor_232 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_739, 128, '0');  convert_element_type_739 = None
        wait_tensor_284 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_232);  all_gather_into_tensor_232 = None
        convert_element_type_2416 = torch.ops.prims.convert_element_type.default(wait_tensor_284, torch.float32);  wait_tensor_284 = None
        mul_1727 = torch.ops.aten.mul.Tensor(convert_element_type_2414, convert_element_type_2416);  convert_element_type_2416 = None
        convert_element_type_740 = torch.ops.prims.convert_element_type.default(add_889, torch.float32);  add_889 = None
        mul_646 = torch.ops.aten.mul.Tensor(convert_element_type_740, rsqrt_42);  convert_element_type_740 = None
        mul_1729 = torch.ops.aten.mul.Tensor(mul_646, mul_1727)
        sum_209 = torch.ops.aten.sum.dim_IntList(mul_1729, [2], True);  mul_1729 = None
        div_209 = torch.ops.aten.div.Tensor(mul_646, 2048)
        mul_1730 = torch.ops.aten.mul.Tensor(div_209, sum_209);  div_209 = sum_209 = None
        sub_702 = torch.ops.aten.sub.Tensor(mul_1727, mul_1730);  mul_1727 = mul_1730 = None
        mul_1731 = torch.ops.aten.mul.Tensor(sub_702, rsqrt_42);  sub_702 = rsqrt_42 = None
        mul_1732 = torch.ops.aten.mul.Tensor(convert_element_type_2414, mul_646);  convert_element_type_2414 = mul_646 = None
        sum_210 = torch.ops.aten.sum.dim_IntList(mul_1732, [0, 1]);  mul_1732 = None
        convert_element_type_2417 = torch.ops.prims.convert_element_type.default(mul_1731, torch.bfloat16);  mul_1731 = None
        add_1969 = torch.ops.aten.add.Tensor(add_1967, convert_element_type_2417);  add_1967 = convert_element_type_2417 = None
        convert_element_type_default_43 = torch.ops.prims.convert_element_type.default(sum_210, torch.float32);  sum_210 = None
        reduce_scatter_tensor_183 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_43, 'avg', 128, '0');  convert_element_type_default_43 = None
        wait_tensor_768 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_183);  reduce_scatter_tensor_183 = None
        view_2029 = torch.ops.aten.view.default(add_1969, [8192, 2048])
        unsqueeze_66 = torch.ops.aten.unsqueeze.default(view_2029, 1)
        convert_element_type_2420 = torch.ops.prims.convert_element_type.default(unsqueeze_66, torch.float32);  unsqueeze_66 = None
        bmm_52 = torch.ops.aten.bmm.default(permute_1056, convert_element_type_2420);  permute_1056 = None
        bmm_53 = torch.ops.aten.bmm.default(convert_element_type_2420, permute_1057);  convert_element_type_2420 = permute_1057 = None
        convert_element_type_2421 = torch.ops.prims.convert_element_type.default(bmm_52, torch.bfloat16);  bmm_52 = None
        view_2030 = torch.ops.aten.view.default(bmm_53, [8192, 6]);  bmm_53 = None
        view_2031 = torch.ops.aten.view.default(convert_element_type_2421, [49152, 2048]);  convert_element_type_2421 = None
        index_78 = torch.ops.aten.index.Tensor(view_2031, [getitem_1341]);  view_2031 = getitem_1341 = None
        permute_1058 = torch.ops.aten.permute.default(view_2029, [1, 0])
        mm_426 = torch.ops.aten.mm.default(permute_1058, mul_643);  permute_1058 = mul_643 = None
        convert_element_type_734 = torch.ops.prims.convert_element_type.default(primals_230, torch.bfloat16);  primals_230 = None
        all_gather_into_tensor_231 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_734, 128, '0');  convert_element_type_734 = None
        wait_tensor_283 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_231);  all_gather_into_tensor_231 = None
        permute_205 = torch.ops.aten.permute.default(wait_tensor_283, [1, 0]);  wait_tensor_283 = None
        permute_1060 = torch.ops.aten.permute.default(permute_205, [1, 0]);  permute_205 = None
        mm_427 = torch.ops.aten.mm.default(view_2029, permute_1060);  view_2029 = permute_1060 = None
        convert_element_type_2426 = torch.ops.prims.convert_element_type.default(mm_426, torch.float32);  mm_426 = None
        reduce_scatter_tensor_184 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2426, 'avg', 128, '0');  convert_element_type_2426 = None
        wait_tensor_769 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_184);  reduce_scatter_tensor_184 = None
        convert_element_type_729 = torch.ops.prims.convert_element_type.default(mm_108, torch.float32);  mm_108 = None
        neg_26 = torch.ops.aten.neg.default(convert_element_type_729)
        exp_39 = torch.ops.aten.exp.default(neg_26);  neg_26 = None
        add_884 = torch.ops.aten.add.Tensor(exp_39, 1);  exp_39 = None
        div_65 = torch.ops.aten.div.Tensor(convert_element_type_729, add_884)
        convert_element_type_730 = torch.ops.prims.convert_element_type.default(div_65, torch.bfloat16);  div_65 = None
        mul_1733 = torch.ops.aten.mul.Tensor(mm_427, convert_element_type_730);  convert_element_type_730 = None
        mul_1734 = torch.ops.aten.mul.Tensor(mm_427, mm_109);  mm_427 = mm_109 = None
        permute_1062 = torch.ops.aten.permute.default(mul_1733, [1, 0])
        mm_428 = torch.ops.aten.mm.default(permute_1062, view_862);  permute_1062 = None
        convert_element_type_731 = torch.ops.prims.convert_element_type.default(primals_229, torch.bfloat16);  primals_229 = None
        all_gather_into_tensor_230 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_731, 128, '0');  convert_element_type_731 = None
        wait_tensor_282 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_230);  all_gather_into_tensor_230 = None
        permute_204 = torch.ops.aten.permute.default(wait_tensor_282, [1, 0]);  wait_tensor_282 = None
        permute_1064 = torch.ops.aten.permute.default(permute_204, [1, 0]);  permute_204 = None
        mm_429 = torch.ops.aten.mm.default(mul_1733, permute_1064);  mul_1733 = permute_1064 = None
        convert_element_type_2431 = torch.ops.prims.convert_element_type.default(mm_428, torch.float32);  mm_428 = None
        reduce_scatter_tensor_185 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2431, 'avg', 128, '0');  convert_element_type_2431 = None
        wait_tensor_770 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_185);  reduce_scatter_tensor_185 = None
        convert_element_type_2432 = torch.ops.prims.convert_element_type.default(mul_1734, torch.float32);  mul_1734 = None
        reciprocal_26 = torch.ops.aten.reciprocal.default(add_884);  add_884 = None
        mul_1735 = torch.ops.aten.mul.Tensor(reciprocal_26, 1);  reciprocal_26 = None
        mul_1736 = torch.ops.aten.mul.Tensor(convert_element_type_2432, mul_1735);  convert_element_type_2432 = None
        sub_703 = torch.ops.aten.sub.Tensor(1, mul_1735);  mul_1735 = None
        mul_1737 = torch.ops.aten.mul.Tensor(convert_element_type_729, sub_703);  convert_element_type_729 = sub_703 = None
        add_1971 = torch.ops.aten.add.Tensor(mul_1737, 1);  mul_1737 = None
        mul_1738 = torch.ops.aten.mul.Tensor(mul_1736, add_1971);  mul_1736 = add_1971 = None
        convert_element_type_2434 = torch.ops.prims.convert_element_type.default(mul_1738, torch.bfloat16);  mul_1738 = None
        permute_1066 = torch.ops.aten.permute.default(convert_element_type_2434, [1, 0])
        mm_430 = torch.ops.aten.mm.default(permute_1066, view_862);  permute_1066 = None
        convert_element_type_726 = torch.ops.prims.convert_element_type.default(primals_228, torch.bfloat16);  primals_228 = None
        all_gather_into_tensor_229 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_726, 128, '0');  convert_element_type_726 = None
        wait_tensor_281 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_229);  all_gather_into_tensor_229 = None
        permute_203 = torch.ops.aten.permute.default(wait_tensor_281, [1, 0]);  wait_tensor_281 = None
        permute_1068 = torch.ops.aten.permute.default(permute_203, [1, 0]);  permute_203 = None
        mm_431 = torch.ops.aten.mm.default(convert_element_type_2434, permute_1068);  convert_element_type_2434 = permute_1068 = None
        add_1972 = torch.ops.aten.add.Tensor(mm_429, mm_431);  mm_429 = mm_431 = None
        convert_element_type_2439 = torch.ops.prims.convert_element_type.default(mm_430, torch.float32);  mm_430 = None
        reduce_scatter_tensor_186 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2439, 'avg', 128, '0');  convert_element_type_2439 = None
        wait_tensor_771 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_186);  reduce_scatter_tensor_186 = None
        all_to_all_single_104 = torch.ops._c10d_functional.all_to_all_single.default(index_78, [_local_scalar_dense_200, _local_scalar_dense_201, _local_scalar_dense_202, _local_scalar_dense_203, _local_scalar_dense_204, _local_scalar_dense_205, _local_scalar_dense_206, _local_scalar_dense_207], [_local_scalar_dense_192, _local_scalar_dense_193, _local_scalar_dense_194, _local_scalar_dense_195, _local_scalar_dense_196, _local_scalar_dense_197, _local_scalar_dense_198, _local_scalar_dense_199], '1033');  index_78 = None
        wait_tensor_772 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_104);  all_to_all_single_104 = None
        full_426 = torch.ops.aten.full.default([sym_size_int_49, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_49 = None
        slice_scatter_13 = torch.ops.aten.slice_scatter.default(full_426, wait_tensor_772, 0, 0, -1);  wait_tensor_772 = None
        index_79 = torch.ops.aten.index.Tensor(slice_scatter_13, [getitem_1342]);  slice_scatter_13 = None
        permute_1070 = torch.ops.aten.permute.default(index_79, [1, 0])
        _grouped_mm_156 = torch.ops.aten._grouped_mm.default(permute_1070, mul_623, cumsum_38);  permute_1070 = mul_623 = None
        _grouped_mm_157 = torch.ops.aten._grouped_mm.default(index_79, permute_1072, cumsum_38);  index_79 = permute_1072 = None
        convert_element_type_724 = torch.ops.prims.convert_element_type.default(_grouped_mm_36, torch.float32);  _grouped_mm_36 = None
        neg_25 = torch.ops.aten.neg.default(convert_element_type_724)
        exp_38 = torch.ops.aten.exp.default(neg_25);  neg_25 = None
        add_848 = torch.ops.aten.add.Tensor(exp_38, 1);  exp_38 = None
        div_64 = torch.ops.aten.div.Tensor(convert_element_type_724, add_848)
        convert_element_type_725 = torch.ops.prims.convert_element_type.default(div_64, torch.bfloat16);  div_64 = None
        mul_1739 = torch.ops.aten.mul.Tensor(_grouped_mm_157, convert_element_type_725);  convert_element_type_725 = None
        mul_1740 = torch.ops.aten.mul.Tensor(_grouped_mm_157, _grouped_mm_37);  _grouped_mm_157 = _grouped_mm_37 = None
        permute_1074 = torch.ops.aten.permute.default(mul_1739, [1, 0])
        _grouped_mm_158 = torch.ops.aten._grouped_mm.default(permute_1074, index_25, cumsum_38);  permute_1074 = None
        _grouped_mm_159 = torch.ops.aten._grouped_mm.default(mul_1739, permute_1076, cumsum_38);  mul_1739 = permute_1076 = None
        convert_element_type_2440 = torch.ops.prims.convert_element_type.default(mul_1740, torch.float32);  mul_1740 = None
        reciprocal_27 = torch.ops.aten.reciprocal.default(add_848);  add_848 = None
        mul_1741 = torch.ops.aten.mul.Tensor(reciprocal_27, 1);  reciprocal_27 = None
        mul_1742 = torch.ops.aten.mul.Tensor(convert_element_type_2440, mul_1741);  convert_element_type_2440 = None
        sub_704 = torch.ops.aten.sub.Tensor(1, mul_1741);  mul_1741 = None
        mul_1743 = torch.ops.aten.mul.Tensor(convert_element_type_724, sub_704);  convert_element_type_724 = sub_704 = None
        add_1974 = torch.ops.aten.add.Tensor(mul_1743, 1);  mul_1743 = None
        mul_1744 = torch.ops.aten.mul.Tensor(mul_1742, add_1974);  mul_1742 = add_1974 = None
        convert_element_type_2442 = torch.ops.prims.convert_element_type.default(mul_1744, torch.bfloat16);  mul_1744 = None
        permute_1078 = torch.ops.aten.permute.default(convert_element_type_2442, [1, 0])
        _grouped_mm_160 = torch.ops.aten._grouped_mm.default(permute_1078, index_25, cumsum_38);  permute_1078 = index_25 = None
        _grouped_mm_161 = torch.ops.aten._grouped_mm.default(convert_element_type_2442, permute_1080, cumsum_38);  convert_element_type_2442 = permute_1080 = cumsum_38 = None
        add_1975 = torch.ops.aten.add.Tensor(_grouped_mm_159, _grouped_mm_161);  _grouped_mm_159 = _grouped_mm_161 = None
        convert_element_type_2443 = torch.ops.prims.convert_element_type.default(_grouped_mm_158, torch.float32);  _grouped_mm_158 = None
        div_210 = torch.ops.aten.div.Tensor(convert_element_type_2443, 128);  convert_element_type_2443 = None
        split_846 = torch.ops.aten.split.Tensor(div_210, 88, 1);  div_210 = None
        getitem_15885 = split_846[0]
        getitem_15902 = split_846[1]
        getitem_15919 = split_846[2]
        getitem_15936 = split_846[3]
        getitem_15953 = split_846[4]
        getitem_15970 = split_846[5]
        getitem_15987 = split_846[6]
        getitem_16004 = split_846[7]
        getitem_16021 = split_846[8]
        getitem_16038 = split_846[9]
        getitem_16055 = split_846[10]
        getitem_16072 = split_846[11]
        getitem_16089 = split_846[12]
        getitem_16106 = split_846[13]
        getitem_16123 = split_846[14]
        getitem_16140 = split_846[15];  split_846 = None
        cat_340 = torch.ops.aten.cat.default([getitem_15885, getitem_15902, getitem_15919, getitem_15936, getitem_15953, getitem_15970, getitem_15987, getitem_16004, getitem_16021, getitem_16038, getitem_16055, getitem_16072, getitem_16089, getitem_16106, getitem_16123, getitem_16140]);  getitem_15885 = getitem_15902 = getitem_15919 = getitem_15936 = getitem_15953 = getitem_15970 = getitem_15987 = getitem_16004 = getitem_16021 = getitem_16038 = getitem_16055 = getitem_16072 = getitem_16089 = getitem_16106 = getitem_16123 = getitem_16140 = None
        reduce_scatter_tensor_187 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_340, 'sum', 16, '1025');  cat_340 = None
        wait_tensor_773 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_187);  reduce_scatter_tensor_187 = None
        convert_element_type_2444 = torch.ops.prims.convert_element_type.default(_grouped_mm_156, torch.float32);  _grouped_mm_156 = None
        div_211 = torch.ops.aten.div.Tensor(convert_element_type_2444, 128);  convert_element_type_2444 = None
        split_863 = torch.ops.aten.split.Tensor(div_211, 128, 1);  div_211 = None
        getitem_16157 = split_863[0]
        getitem_16174 = split_863[1]
        getitem_16191 = split_863[2]
        getitem_16208 = split_863[3]
        getitem_16225 = split_863[4]
        getitem_16242 = split_863[5]
        getitem_16259 = split_863[6]
        getitem_16276 = split_863[7]
        getitem_16293 = split_863[8]
        getitem_16310 = split_863[9]
        getitem_16327 = split_863[10]
        getitem_16344 = split_863[11]
        getitem_16361 = split_863[12]
        getitem_16378 = split_863[13]
        getitem_16395 = split_863[14]
        getitem_16412 = split_863[15];  split_863 = None
        cat_341 = torch.ops.aten.cat.default([getitem_16157, getitem_16174, getitem_16191, getitem_16208, getitem_16225, getitem_16242, getitem_16259, getitem_16276, getitem_16293, getitem_16310, getitem_16327, getitem_16344, getitem_16361, getitem_16378, getitem_16395, getitem_16412]);  getitem_16157 = getitem_16174 = getitem_16191 = getitem_16208 = getitem_16225 = getitem_16242 = getitem_16259 = getitem_16276 = getitem_16293 = getitem_16310 = getitem_16327 = getitem_16344 = getitem_16361 = getitem_16378 = getitem_16395 = getitem_16412 = None
        reduce_scatter_tensor_188 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_341, 'sum', 16, '1025');  cat_341 = None
        wait_tensor_774 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_188);  reduce_scatter_tensor_188 = None
        convert_element_type_2445 = torch.ops.prims.convert_element_type.default(_grouped_mm_160, torch.float32);  _grouped_mm_160 = None
        div_212 = torch.ops.aten.div.Tensor(convert_element_type_2445, 128);  convert_element_type_2445 = None
        split_880 = torch.ops.aten.split.Tensor(div_212, 88, 1);  div_212 = None
        getitem_16429 = split_880[0]
        getitem_16446 = split_880[1]
        getitem_16463 = split_880[2]
        getitem_16480 = split_880[3]
        getitem_16497 = split_880[4]
        getitem_16514 = split_880[5]
        getitem_16531 = split_880[6]
        getitem_16548 = split_880[7]
        getitem_16565 = split_880[8]
        getitem_16582 = split_880[9]
        getitem_16599 = split_880[10]
        getitem_16616 = split_880[11]
        getitem_16633 = split_880[12]
        getitem_16650 = split_880[13]
        getitem_16667 = split_880[14]
        getitem_16684 = split_880[15];  split_880 = None
        cat_342 = torch.ops.aten.cat.default([getitem_16429, getitem_16446, getitem_16463, getitem_16480, getitem_16497, getitem_16514, getitem_16531, getitem_16548, getitem_16565, getitem_16582, getitem_16599, getitem_16616, getitem_16633, getitem_16650, getitem_16667, getitem_16684]);  getitem_16429 = getitem_16446 = getitem_16463 = getitem_16480 = getitem_16497 = getitem_16514 = getitem_16531 = getitem_16548 = getitem_16565 = getitem_16582 = getitem_16599 = getitem_16616 = getitem_16633 = getitem_16650 = getitem_16667 = getitem_16684 = None
        reduce_scatter_tensor_189 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_342, 'sum', 16, '1025');  cat_342 = None
        wait_tensor_775 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_189);  reduce_scatter_tensor_189 = None
        index_put_78 = torch.ops.aten.index_put.default(full_426, [getitem_1342], add_1975, True);  full_426 = getitem_1342 = add_1975 = None
        slice_240 = torch.ops.aten.slice.Tensor(index_put_78, 0, 0, add_1976);  index_put_78 = add_1976 = None
        all_to_all_single_105 = torch.ops._c10d_functional.all_to_all_single.default(slice_240, [_local_scalar_dense_192, _local_scalar_dense_193, _local_scalar_dense_194, _local_scalar_dense_195, _local_scalar_dense_196, _local_scalar_dense_197, _local_scalar_dense_198, _local_scalar_dense_199], [_local_scalar_dense_200, _local_scalar_dense_201, _local_scalar_dense_202, _local_scalar_dense_203, _local_scalar_dense_204, _local_scalar_dense_205, _local_scalar_dense_206, _local_scalar_dense_207], '1033');  slice_240 = _local_scalar_dense_192 = _local_scalar_dense_193 = _local_scalar_dense_194 = _local_scalar_dense_195 = _local_scalar_dense_196 = _local_scalar_dense_197 = _local_scalar_dense_198 = _local_scalar_dense_199 = _local_scalar_dense_200 = _local_scalar_dense_201 = _local_scalar_dense_202 = _local_scalar_dense_203 = _local_scalar_dense_204 = _local_scalar_dense_205 = _local_scalar_dense_206 = _local_scalar_dense_207 = None
        wait_tensor_776 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_105);  all_to_all_single_105 = None
        index_put_79 = torch.ops.aten.index_put.default(full_default_52, [div_62], wait_tensor_776, True);  div_62 = wait_tensor_776 = None
        add_1980 = torch.ops.aten.add.Tensor(add_1972, index_put_79);  add_1972 = index_put_79 = None
        mul_1745 = torch.ops.aten.mul.Tensor(view_2030, 1.0);  view_2030 = None
        scatter_add_13 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_1339, mul_1745);  getitem_1339 = mul_1745 = None
        convert_element_type_713 = torch.ops.prims.convert_element_type.default(mm_107, torch.float32);  mm_107 = None
        sub_288 = torch.ops.aten.sub.Tensor(convert_element_type_713, amax_12);  convert_element_type_713 = amax_12 = None
        exp_37 = torch.ops.aten.exp.default(sub_288);  sub_288 = None
        div_61 = torch.ops.aten.div.Tensor(exp_37, sum_49);  exp_37 = sum_49 = None
        mul_1746 = torch.ops.aten.mul.Tensor(scatter_add_13, div_61);  scatter_add_13 = None
        sum_211 = torch.ops.aten.sum.dim_IntList(mul_1746, [1], True)
        neg_94 = torch.ops.aten.neg.default(div_61);  div_61 = None
        fma_13 = torch.ops.prims.fma.default(neg_94, sum_211, mul_1746);  neg_94 = sum_211 = mul_1746 = None
        convert_element_type_2446 = torch.ops.prims.convert_element_type.default(fma_13, torch.bfloat16);  fma_13 = None
        permute_1082 = torch.ops.aten.permute.default(convert_element_type_2446, [1, 0])
        mm_432 = torch.ops.aten.mm.default(permute_1082, view_862);  permute_1082 = view_862 = None
        convert_element_type_710 = torch.ops.prims.convert_element_type.default(primals_223, torch.bfloat16);  primals_223 = None
        all_gather_into_tensor_222 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_710, 128, '0');  convert_element_type_710 = None
        wait_tensor_270 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_222);  all_gather_into_tensor_222 = None
        slice_81 = torch.ops.aten.slice.Tensor(wait_tensor_270, 0, 0, 64);  wait_tensor_270 = None
        permute_199 = torch.ops.aten.permute.default(slice_81, [1, 0]);  slice_81 = None
        permute_1084 = torch.ops.aten.permute.default(permute_199, [1, 0]);  permute_199 = None
        mm_433 = torch.ops.aten.mm.default(convert_element_type_2446, permute_1084);  convert_element_type_2446 = permute_1084 = None
        add_1981 = torch.ops.aten.add.Tensor(add_1980, mm_433);  add_1980 = mm_433 = None
        convert_element_type_2451 = torch.ops.prims.convert_element_type.default(mm_432, torch.float32);  mm_432 = None
        split_896 = torch.ops.aten.split.Tensor(convert_element_type_2451, 1);  convert_element_type_2451 = None
        getitem_16685 = split_896[0]
        getitem_16686 = split_896[1]
        getitem_16687 = split_896[2]
        getitem_16688 = split_896[3]
        getitem_16689 = split_896[4]
        getitem_16690 = split_896[5]
        getitem_16691 = split_896[6]
        getitem_16692 = split_896[7]
        getitem_16693 = split_896[8]
        getitem_16694 = split_896[9]
        getitem_16695 = split_896[10]
        getitem_16696 = split_896[11]
        getitem_16697 = split_896[12]
        getitem_16698 = split_896[13]
        getitem_16699 = split_896[14]
        getitem_16700 = split_896[15]
        getitem_16701 = split_896[16]
        getitem_16702 = split_896[17]
        getitem_16703 = split_896[18]
        getitem_16704 = split_896[19]
        getitem_16705 = split_896[20]
        getitem_16706 = split_896[21]
        getitem_16707 = split_896[22]
        getitem_16708 = split_896[23]
        getitem_16709 = split_896[24]
        getitem_16710 = split_896[25]
        getitem_16711 = split_896[26]
        getitem_16712 = split_896[27]
        getitem_16713 = split_896[28]
        getitem_16714 = split_896[29]
        getitem_16715 = split_896[30]
        getitem_16716 = split_896[31]
        getitem_16717 = split_896[32]
        getitem_16718 = split_896[33]
        getitem_16719 = split_896[34]
        getitem_16720 = split_896[35]
        getitem_16721 = split_896[36]
        getitem_16722 = split_896[37]
        getitem_16723 = split_896[38]
        getitem_16724 = split_896[39]
        getitem_16725 = split_896[40]
        getitem_16726 = split_896[41]
        getitem_16727 = split_896[42]
        getitem_16728 = split_896[43]
        getitem_16729 = split_896[44]
        getitem_16730 = split_896[45]
        getitem_16731 = split_896[46]
        getitem_16732 = split_896[47]
        getitem_16733 = split_896[48]
        getitem_16734 = split_896[49]
        getitem_16735 = split_896[50]
        getitem_16736 = split_896[51]
        getitem_16737 = split_896[52]
        getitem_16738 = split_896[53]
        getitem_16739 = split_896[54]
        getitem_16740 = split_896[55]
        getitem_16741 = split_896[56]
        getitem_16742 = split_896[57]
        getitem_16743 = split_896[58]
        getitem_16744 = split_896[59]
        getitem_16745 = split_896[60]
        getitem_16746 = split_896[61]
        getitem_16747 = split_896[62]
        getitem_16748 = split_896[63];  split_896 = None
        cat_343 = torch.ops.aten.cat.default([getitem_16685, getitem_16686, getitem_16687, getitem_16688, getitem_16689, getitem_16690, getitem_16691, getitem_16692, getitem_16693, getitem_16694, getitem_16695, getitem_16696, getitem_16697, getitem_16698, getitem_16699, getitem_16700, getitem_16701, getitem_16702, getitem_16703, getitem_16704, getitem_16705, getitem_16706, getitem_16707, getitem_16708, getitem_16709, getitem_16710, getitem_16711, getitem_16712, getitem_16713, getitem_16714, getitem_16715, getitem_16716, getitem_16717, getitem_16718, getitem_16719, getitem_16720, getitem_16721, getitem_16722, getitem_16723, getitem_16724, getitem_16725, getitem_16726, getitem_16727, getitem_16728, getitem_16729, getitem_16730, getitem_16731, getitem_16732, getitem_16733, getitem_16734, getitem_16735, getitem_16736, getitem_16737, getitem_16738, getitem_16739, getitem_16740, getitem_16741, getitem_16742, getitem_16743, getitem_16744, getitem_16745, getitem_16746, getitem_16747, getitem_16748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_16685 = getitem_16686 = getitem_16687 = getitem_16688 = getitem_16689 = getitem_16690 = getitem_16691 = getitem_16692 = getitem_16693 = getitem_16694 = getitem_16695 = getitem_16696 = getitem_16697 = getitem_16698 = getitem_16699 = getitem_16700 = getitem_16701 = getitem_16702 = getitem_16703 = getitem_16704 = getitem_16705 = getitem_16706 = getitem_16707 = getitem_16708 = getitem_16709 = getitem_16710 = getitem_16711 = getitem_16712 = getitem_16713 = getitem_16714 = getitem_16715 = getitem_16716 = getitem_16717 = getitem_16718 = getitem_16719 = getitem_16720 = getitem_16721 = getitem_16722 = getitem_16723 = getitem_16724 = getitem_16725 = getitem_16726 = getitem_16727 = getitem_16728 = getitem_16729 = getitem_16730 = getitem_16731 = getitem_16732 = getitem_16733 = getitem_16734 = getitem_16735 = getitem_16736 = getitem_16737 = getitem_16738 = getitem_16739 = getitem_16740 = getitem_16741 = getitem_16742 = getitem_16743 = getitem_16744 = getitem_16745 = getitem_16746 = getitem_16747 = getitem_16748 = None
        reduce_scatter_tensor_190 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_343, 'avg', 128, '0');  cat_343 = None
        wait_tensor_777 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_190);  reduce_scatter_tensor_190 = None
        view_2032 = torch.ops.aten.view.default(add_1981, [2, 4096, 2048]);  add_1981 = None
        convert_element_type_2452 = torch.ops.prims.convert_element_type.default(view_2032, torch.float32);  view_2032 = None
        convert_element_type_707 = torch.ops.prims.convert_element_type.default(primals_221, torch.bfloat16);  primals_221 = None
        all_gather_into_tensor_221 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_707, 128, '0');  convert_element_type_707 = None
        wait_tensor_269 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_221);  all_gather_into_tensor_221 = None
        convert_element_type_2454 = torch.ops.prims.convert_element_type.default(wait_tensor_269, torch.float32);  wait_tensor_269 = None
        mul_1747 = torch.ops.aten.mul.Tensor(convert_element_type_2452, convert_element_type_2454);  convert_element_type_2454 = None
        convert_element_type_708 = torch.ops.prims.convert_element_type.default(add_824, torch.float32);  add_824 = None
        mul_603 = torch.ops.aten.mul.Tensor(convert_element_type_708, rsqrt_41);  convert_element_type_708 = None
        mul_1749 = torch.ops.aten.mul.Tensor(mul_603, mul_1747)
        sum_212 = torch.ops.aten.sum.dim_IntList(mul_1749, [2], True);  mul_1749 = None
        div_213 = torch.ops.aten.div.Tensor(mul_603, 2048)
        mul_1750 = torch.ops.aten.mul.Tensor(div_213, sum_212);  div_213 = sum_212 = None
        sub_706 = torch.ops.aten.sub.Tensor(mul_1747, mul_1750);  mul_1747 = mul_1750 = None
        mul_1751 = torch.ops.aten.mul.Tensor(sub_706, rsqrt_41);  sub_706 = rsqrt_41 = None
        mul_1752 = torch.ops.aten.mul.Tensor(convert_element_type_2452, mul_603);  convert_element_type_2452 = mul_603 = None
        sum_213 = torch.ops.aten.sum.dim_IntList(mul_1752, [0, 1]);  mul_1752 = None
        convert_element_type_2455 = torch.ops.prims.convert_element_type.default(mul_1751, torch.bfloat16);  mul_1751 = None
        add_1982 = torch.ops.aten.add.Tensor(add_1969, convert_element_type_2455);  add_1969 = convert_element_type_2455 = None
        convert_element_type_default_42 = torch.ops.prims.convert_element_type.default(sum_213, torch.float32);  sum_213 = None
        reduce_scatter_tensor_191 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_42, 'avg', 128, '0');  convert_element_type_default_42 = None
        wait_tensor_778 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_191);  reduce_scatter_tensor_191 = None
        view_2033 = torch.ops.aten.view.default(add_1982, [8192, 2048])
        permute_1086 = torch.ops.aten.permute.default(view_2033, [1, 0])
        permute_197 = torch.ops.aten.permute.default(getitem_1335, [0, 2, 1, 3])
        view_857 = torch.ops.aten.view.default(permute_197, [2, 4096, -1]);  permute_197 = None
        view_859 = torch.ops.aten.view.default(view_857, [8192, 2048]);  view_857 = None
        mm_434 = torch.ops.aten.mm.default(permute_1086, view_859);  permute_1086 = view_859 = None
        convert_element_type_704 = torch.ops.prims.convert_element_type.default(primals_220, torch.bfloat16);  primals_220 = None
        all_gather_into_tensor_220 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_704, 128, '0');  convert_element_type_704 = None
        wait_tensor_268 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_220);  all_gather_into_tensor_220 = None
        permute_198 = torch.ops.aten.permute.default(wait_tensor_268, [1, 0]);  wait_tensor_268 = None
        permute_1088 = torch.ops.aten.permute.default(permute_198, [1, 0]);  permute_198 = None
        mm_435 = torch.ops.aten.mm.default(view_2033, permute_1088);  view_2033 = permute_1088 = None
        view_2034 = torch.ops.aten.view.default(mm_435, [2, 4096, 2048]);  mm_435 = None
        convert_element_type_2462 = torch.ops.prims.convert_element_type.default(mm_434, torch.float32);  mm_434 = None
        reduce_scatter_tensor_192 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2462, 'avg', 128, '0');  convert_element_type_2462 = None
        wait_tensor_779 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_192);  reduce_scatter_tensor_192 = None
        view_2035 = torch.ops.aten.view.default(view_2034, [2, 4096, 16, 128]);  view_2034 = None
        permute_1090 = torch.ops.aten.permute.default(view_2035, [0, 2, 1, 3]);  view_2035 = None
        fw_graph13 = self.fw_graph13
        joint_graph13 = self.joint_graph13
        mask_graph13 = self.mask_graph13
        flex_attention_backward_13 = torch.ops.higher_order.flex_attention_backward(permute_194, permute_195, permute_196, getitem_1335, getitem_1336, permute_1090, None, fw_graph13, joint_graph13, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph13), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_194 = permute_195 = permute_196 = getitem_1335 = getitem_1336 = permute_1090 = fw_graph13 = joint_graph13 = mask_graph13 = None
        getitem_16749 = flex_attention_backward_13[0]
        getitem_16750 = flex_attention_backward_13[1]
        getitem_16751 = flex_attention_backward_13[2];  flex_attention_backward_13 = None
        permute_1091 = torch.ops.aten.permute.default(getitem_16751, [0, 2, 1, 3]);  getitem_16751 = None
        permute_1092 = torch.ops.aten.permute.default(getitem_16750, [0, 2, 1, 3]);  getitem_16750 = None
        permute_1093 = torch.ops.aten.permute.default(getitem_16749, [0, 2, 1, 3]);  getitem_16749 = None
        slice_242 = torch.ops.aten.slice.Tensor(permute_1092, 3, 0, 128)
        slice_243 = torch.ops.aten.slice.Tensor(permute_1092, 3, 128, 192);  permute_1092 = None
        sum_214 = torch.ops.aten.sum.dim_IntList(slice_243, [2], True);  slice_243 = None
        cat_344 = torch.ops.aten.cat.default([slice_242, permute_1091], 3);  slice_242 = permute_1091 = None
        view_2036 = torch.ops.aten.view.default(cat_344, [2, 4096, 4096]);  cat_344 = None
        view_2037 = torch.ops.aten.view.default(view_2036, [8192, 4096]);  view_2036 = None
        permute_1094 = torch.ops.aten.permute.default(view_2037, [1, 0])
        mm_436 = torch.ops.aten.mm.default(permute_1094, view_854);  permute_1094 = view_854 = None
        convert_element_type_701 = torch.ops.prims.convert_element_type.default(primals_219, torch.bfloat16);  primals_219 = None
        all_gather_into_tensor_219 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_701, 128, '0');  convert_element_type_701 = None
        wait_tensor_267 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_219);  all_gather_into_tensor_219 = None
        permute_193 = torch.ops.aten.permute.default(wait_tensor_267, [1, 0]);  wait_tensor_267 = None
        permute_1096 = torch.ops.aten.permute.default(permute_193, [1, 0]);  permute_193 = None
        mm_437 = torch.ops.aten.mm.default(view_2037, permute_1096);  view_2037 = permute_1096 = None
        view_2038 = torch.ops.aten.view.default(mm_437, [2, 4096, 512]);  mm_437 = None
        convert_element_type_2467 = torch.ops.prims.convert_element_type.default(mm_436, torch.float32);  mm_436 = None
        reduce_scatter_tensor_193 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2467, 'avg', 128, '0');  convert_element_type_2467 = None
        wait_tensor_780 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_193);  reduce_scatter_tensor_193 = None
        convert_element_type_2468 = torch.ops.prims.convert_element_type.default(view_2038, torch.float32);  view_2038 = None
        convert_element_type_698 = torch.ops.prims.convert_element_type.default(primals_218, torch.bfloat16);  primals_218 = None
        all_gather_into_tensor_218 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_698, 128, '0');  convert_element_type_698 = None
        wait_tensor_266 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_218);  all_gather_into_tensor_218 = None
        convert_element_type_2470 = torch.ops.prims.convert_element_type.default(wait_tensor_266, torch.float32);  wait_tensor_266 = None
        mul_1753 = torch.ops.aten.mul.Tensor(convert_element_type_2468, convert_element_type_2470);  convert_element_type_2470 = None
        convert_element_type_699 = torch.ops.prims.convert_element_type.default(getitem_1331, torch.float32);  getitem_1331 = None
        mul_601 = torch.ops.aten.mul.Tensor(convert_element_type_699, rsqrt_40);  convert_element_type_699 = None
        mul_1755 = torch.ops.aten.mul.Tensor(mul_601, mul_1753)
        sum_215 = torch.ops.aten.sum.dim_IntList(mul_1755, [2], True);  mul_1755 = None
        div_214 = torch.ops.aten.div.Tensor(mul_601, 512)
        mul_1756 = torch.ops.aten.mul.Tensor(div_214, sum_215);  div_214 = sum_215 = None
        sub_707 = torch.ops.aten.sub.Tensor(mul_1753, mul_1756);  mul_1753 = mul_1756 = None
        mul_1757 = torch.ops.aten.mul.Tensor(sub_707, rsqrt_40);  sub_707 = rsqrt_40 = None
        mul_1758 = torch.ops.aten.mul.Tensor(convert_element_type_2468, mul_601);  convert_element_type_2468 = mul_601 = None
        sum_216 = torch.ops.aten.sum.dim_IntList(mul_1758, [0, 1]);  mul_1758 = None
        convert_element_type_2471 = torch.ops.prims.convert_element_type.default(mul_1757, torch.bfloat16);  mul_1757 = None
        convert_element_type_default_41 = torch.ops.prims.convert_element_type.default(sum_216, torch.float32);  sum_216 = None
        reduce_scatter_tensor_194 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_41, 'avg', 128, '0');  convert_element_type_default_41 = None
        wait_tensor_781 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_194);  reduce_scatter_tensor_194 = None
        convert_element_type_2474 = torch.ops.prims.convert_element_type.default(sum_214, torch.float32);  sum_214 = None
        view_2039 = torch.ops.aten.view.default(convert_element_type_2474, [2, 4096, 1, 32, 2]);  convert_element_type_2474 = None
        view_as_complex_80 = torch.ops.aten.view_as_complex.default(view_2039);  view_2039 = None
        mul_1759 = torch.ops.aten.mul.Tensor(view_as_complex_80, clone_9);  view_as_complex_80 = None
        view_as_real_80 = torch.ops.aten.view_as_real.default(mul_1759);  mul_1759 = None
        view_2040 = torch.ops.aten.view.default(view_as_real_80, [2, 4096, 1, 64]);  view_as_real_80 = None
        convert_element_type_2475 = torch.ops.prims.convert_element_type.default(view_2040, torch.bfloat16);  view_2040 = None
        squeeze_39 = torch.ops.aten.squeeze.dim(convert_element_type_2475, 2);  convert_element_type_2475 = None
        cat_345 = torch.ops.aten.cat.default([convert_element_type_2471, squeeze_39], 2);  convert_element_type_2471 = squeeze_39 = None
        view_2041 = torch.ops.aten.view.default(cat_345, [8192, 576]);  cat_345 = None
        permute_1098 = torch.ops.aten.permute.default(view_2041, [1, 0])
        mm_438 = torch.ops.aten.mm.default(permute_1098, view_840);  permute_1098 = None
        convert_element_type_693 = torch.ops.prims.convert_element_type.default(primals_217, torch.bfloat16);  primals_217 = None
        all_gather_into_tensor_217 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_693, 128, '0');  convert_element_type_693 = None
        wait_tensor_265 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_217);  all_gather_into_tensor_217 = None
        slice_79 = torch.ops.aten.slice.Tensor(wait_tensor_265, 0, 0, 576);  wait_tensor_265 = None
        permute_192 = torch.ops.aten.permute.default(slice_79, [1, 0]);  slice_79 = None
        permute_1100 = torch.ops.aten.permute.default(permute_192, [1, 0]);  permute_192 = None
        mm_439 = torch.ops.aten.mm.default(view_2041, permute_1100);  view_2041 = permute_1100 = None
        view_2042 = torch.ops.aten.view.default(mm_439, [2, 4096, 2048]);  mm_439 = None
        convert_element_type_2480 = torch.ops.prims.convert_element_type.default(mm_438, torch.float32);  mm_438 = None
        split_897 = torch.ops.aten.split.Tensor(convert_element_type_2480, 5);  convert_element_type_2480 = None
        getitem_16753 = split_897[0]
        getitem_16754 = split_897[1]
        getitem_16755 = split_897[2]
        getitem_16756 = split_897[3]
        getitem_16757 = split_897[4]
        getitem_16758 = split_897[5]
        getitem_16759 = split_897[6]
        getitem_16760 = split_897[7]
        getitem_16761 = split_897[8]
        getitem_16762 = split_897[9]
        getitem_16763 = split_897[10]
        getitem_16764 = split_897[11]
        getitem_16765 = split_897[12]
        getitem_16766 = split_897[13]
        getitem_16767 = split_897[14]
        getitem_16768 = split_897[15]
        getitem_16769 = split_897[16]
        getitem_16770 = split_897[17]
        getitem_16771 = split_897[18]
        getitem_16772 = split_897[19]
        getitem_16773 = split_897[20]
        getitem_16774 = split_897[21]
        getitem_16775 = split_897[22]
        getitem_16776 = split_897[23]
        getitem_16777 = split_897[24]
        getitem_16778 = split_897[25]
        getitem_16779 = split_897[26]
        getitem_16780 = split_897[27]
        getitem_16781 = split_897[28]
        getitem_16782 = split_897[29]
        getitem_16783 = split_897[30]
        getitem_16784 = split_897[31]
        getitem_16785 = split_897[32]
        getitem_16786 = split_897[33]
        getitem_16787 = split_897[34]
        getitem_16788 = split_897[35]
        getitem_16789 = split_897[36]
        getitem_16790 = split_897[37]
        getitem_16791 = split_897[38]
        getitem_16792 = split_897[39]
        getitem_16793 = split_897[40]
        getitem_16794 = split_897[41]
        getitem_16795 = split_897[42]
        getitem_16796 = split_897[43]
        getitem_16797 = split_897[44]
        getitem_16798 = split_897[45]
        getitem_16799 = split_897[46]
        getitem_16800 = split_897[47]
        getitem_16801 = split_897[48]
        getitem_16802 = split_897[49]
        getitem_16803 = split_897[50]
        getitem_16804 = split_897[51]
        getitem_16805 = split_897[52]
        getitem_16806 = split_897[53]
        getitem_16807 = split_897[54]
        getitem_16808 = split_897[55]
        getitem_16809 = split_897[56]
        getitem_16810 = split_897[57]
        getitem_16811 = split_897[58]
        getitem_16812 = split_897[59]
        getitem_16813 = split_897[60]
        getitem_16814 = split_897[61]
        getitem_16815 = split_897[62]
        getitem_16816 = split_897[63]
        getitem_16817 = split_897[64]
        getitem_16818 = split_897[65]
        getitem_16819 = split_897[66]
        getitem_16820 = split_897[67]
        getitem_16821 = split_897[68]
        getitem_16822 = split_897[69]
        getitem_16823 = split_897[70]
        getitem_16824 = split_897[71]
        getitem_16825 = split_897[72]
        getitem_16826 = split_897[73]
        getitem_16827 = split_897[74]
        getitem_16828 = split_897[75]
        getitem_16829 = split_897[76]
        getitem_16830 = split_897[77]
        getitem_16831 = split_897[78]
        getitem_16832 = split_897[79]
        getitem_16833 = split_897[80]
        getitem_16834 = split_897[81]
        getitem_16835 = split_897[82]
        getitem_16836 = split_897[83]
        getitem_16837 = split_897[84]
        getitem_16838 = split_897[85]
        getitem_16839 = split_897[86]
        getitem_16840 = split_897[87]
        getitem_16841 = split_897[88]
        getitem_16842 = split_897[89]
        getitem_16843 = split_897[90]
        getitem_16844 = split_897[91]
        getitem_16845 = split_897[92]
        getitem_16846 = split_897[93]
        getitem_16847 = split_897[94]
        getitem_16848 = split_897[95]
        getitem_16849 = split_897[96]
        getitem_16850 = split_897[97]
        getitem_16851 = split_897[98]
        getitem_16852 = split_897[99]
        getitem_16853 = split_897[100]
        getitem_16854 = split_897[101]
        getitem_16855 = split_897[102]
        getitem_16856 = split_897[103]
        getitem_16857 = split_897[104]
        getitem_16858 = split_897[105]
        getitem_16859 = split_897[106]
        getitem_16860 = split_897[107]
        getitem_16861 = split_897[108]
        getitem_16862 = split_897[109]
        getitem_16863 = split_897[110]
        getitem_16864 = split_897[111]
        getitem_16865 = split_897[112]
        getitem_16866 = split_897[113]
        getitem_16867 = split_897[114]
        getitem_16868 = split_897[115];  split_897 = None
        constant_pad_nd_1065 = torch.ops.aten.constant_pad_nd.default(getitem_16868, [0, 0, 0, 4], 0.0);  getitem_16868 = None
        cat_346 = torch.ops.aten.cat.default([getitem_16753, getitem_16754, getitem_16755, getitem_16756, getitem_16757, getitem_16758, getitem_16759, getitem_16760, getitem_16761, getitem_16762, getitem_16763, getitem_16764, getitem_16765, getitem_16766, getitem_16767, getitem_16768, getitem_16769, getitem_16770, getitem_16771, getitem_16772, getitem_16773, getitem_16774, getitem_16775, getitem_16776, getitem_16777, getitem_16778, getitem_16779, getitem_16780, getitem_16781, getitem_16782, getitem_16783, getitem_16784, getitem_16785, getitem_16786, getitem_16787, getitem_16788, getitem_16789, getitem_16790, getitem_16791, getitem_16792, getitem_16793, getitem_16794, getitem_16795, getitem_16796, getitem_16797, getitem_16798, getitem_16799, getitem_16800, getitem_16801, getitem_16802, getitem_16803, getitem_16804, getitem_16805, getitem_16806, getitem_16807, getitem_16808, getitem_16809, getitem_16810, getitem_16811, getitem_16812, getitem_16813, getitem_16814, getitem_16815, getitem_16816, getitem_16817, getitem_16818, getitem_16819, getitem_16820, getitem_16821, getitem_16822, getitem_16823, getitem_16824, getitem_16825, getitem_16826, getitem_16827, getitem_16828, getitem_16829, getitem_16830, getitem_16831, getitem_16832, getitem_16833, getitem_16834, getitem_16835, getitem_16836, getitem_16837, getitem_16838, getitem_16839, getitem_16840, getitem_16841, getitem_16842, getitem_16843, getitem_16844, getitem_16845, getitem_16846, getitem_16847, getitem_16848, getitem_16849, getitem_16850, getitem_16851, getitem_16852, getitem_16853, getitem_16854, getitem_16855, getitem_16856, getitem_16857, getitem_16858, getitem_16859, getitem_16860, getitem_16861, getitem_16862, getitem_16863, getitem_16864, getitem_16865, getitem_16866, getitem_16867, constant_pad_nd_1065, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_16753 = getitem_16754 = getitem_16755 = getitem_16756 = getitem_16757 = getitem_16758 = getitem_16759 = getitem_16760 = getitem_16761 = getitem_16762 = getitem_16763 = getitem_16764 = getitem_16765 = getitem_16766 = getitem_16767 = getitem_16768 = getitem_16769 = getitem_16770 = getitem_16771 = getitem_16772 = getitem_16773 = getitem_16774 = getitem_16775 = getitem_16776 = getitem_16777 = getitem_16778 = getitem_16779 = getitem_16780 = getitem_16781 = getitem_16782 = getitem_16783 = getitem_16784 = getitem_16785 = getitem_16786 = getitem_16787 = getitem_16788 = getitem_16789 = getitem_16790 = getitem_16791 = getitem_16792 = getitem_16793 = getitem_16794 = getitem_16795 = getitem_16796 = getitem_16797 = getitem_16798 = getitem_16799 = getitem_16800 = getitem_16801 = getitem_16802 = getitem_16803 = getitem_16804 = getitem_16805 = getitem_16806 = getitem_16807 = getitem_16808 = getitem_16809 = getitem_16810 = getitem_16811 = getitem_16812 = getitem_16813 = getitem_16814 = getitem_16815 = getitem_16816 = getitem_16817 = getitem_16818 = getitem_16819 = getitem_16820 = getitem_16821 = getitem_16822 = getitem_16823 = getitem_16824 = getitem_16825 = getitem_16826 = getitem_16827 = getitem_16828 = getitem_16829 = getitem_16830 = getitem_16831 = getitem_16832 = getitem_16833 = getitem_16834 = getitem_16835 = getitem_16836 = getitem_16837 = getitem_16838 = getitem_16839 = getitem_16840 = getitem_16841 = getitem_16842 = getitem_16843 = getitem_16844 = getitem_16845 = getitem_16846 = getitem_16847 = getitem_16848 = getitem_16849 = getitem_16850 = getitem_16851 = getitem_16852 = getitem_16853 = getitem_16854 = getitem_16855 = getitem_16856 = getitem_16857 = getitem_16858 = getitem_16859 = getitem_16860 = getitem_16861 = getitem_16862 = getitem_16863 = getitem_16864 = getitem_16865 = getitem_16866 = getitem_16867 = constant_pad_nd_1065 = None
        reduce_scatter_tensor_195 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_346, 'avg', 128, '0');  cat_346 = None
        wait_tensor_782 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_195);  reduce_scatter_tensor_195 = None
        slice_244 = torch.ops.aten.slice.Tensor(permute_1093, 3, 0, 128)
        slice_245 = torch.ops.aten.slice.Tensor(permute_1093, 3, 128, 192);  permute_1093 = None
        convert_element_type_2481 = torch.ops.prims.convert_element_type.default(slice_245, torch.float32);  slice_245 = None
        view_2043 = torch.ops.aten.view.default(convert_element_type_2481, [2, 4096, 16, 32, 2]);  convert_element_type_2481 = None
        view_as_complex_81 = torch.ops.aten.view_as_complex.default(view_2043);  view_2043 = None
        mul_1760 = torch.ops.aten.mul.Tensor(view_as_complex_81, clone_9);  view_as_complex_81 = None
        view_as_real_81 = torch.ops.aten.view_as_real.default(mul_1760);  mul_1760 = None
        view_2044 = torch.ops.aten.view.default(view_as_real_81, [2, 4096, 16, 64]);  view_as_real_81 = None
        convert_element_type_2482 = torch.ops.prims.convert_element_type.default(view_2044, torch.bfloat16);  view_2044 = None
        cat_347 = torch.ops.aten.cat.default([slice_244, convert_element_type_2482], 3);  slice_244 = convert_element_type_2482 = None
        view_2045 = torch.ops.aten.view.default(cat_347, [2, 4096, 3072]);  cat_347 = None
        view_2046 = torch.ops.aten.view.default(view_2045, [8192, 3072]);  view_2045 = None
        permute_1102 = torch.ops.aten.permute.default(view_2046, [1, 0])
        mm_440 = torch.ops.aten.mm.default(permute_1102, view_840);  permute_1102 = view_840 = None
        convert_element_type_688 = torch.ops.prims.convert_element_type.default(primals_216, torch.bfloat16);  primals_216 = None
        all_gather_into_tensor_216 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_688, 128, '0');  convert_element_type_688 = None
        wait_tensor_264 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_216);  all_gather_into_tensor_216 = None
        permute_191 = torch.ops.aten.permute.default(wait_tensor_264, [1, 0]);  wait_tensor_264 = None
        permute_1104 = torch.ops.aten.permute.default(permute_191, [1, 0]);  permute_191 = None
        mm_441 = torch.ops.aten.mm.default(view_2046, permute_1104);  view_2046 = permute_1104 = None
        view_2047 = torch.ops.aten.view.default(mm_441, [2, 4096, 2048]);  mm_441 = None
        add_1983 = torch.ops.aten.add.Tensor(view_2042, view_2047);  view_2042 = view_2047 = None
        convert_element_type_2487 = torch.ops.prims.convert_element_type.default(mm_440, torch.float32);  mm_440 = None
        reduce_scatter_tensor_196 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2487, 'avg', 128, '0');  convert_element_type_2487 = None
        wait_tensor_783 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_196);  reduce_scatter_tensor_196 = None
        convert_element_type_2488 = torch.ops.prims.convert_element_type.default(add_1983, torch.float32);  add_1983 = None
        convert_element_type_685 = torch.ops.prims.convert_element_type.default(primals_215, torch.bfloat16);  primals_215 = None
        all_gather_into_tensor_215 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_685, 128, '0');  convert_element_type_685 = None
        wait_tensor_263 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_215);  all_gather_into_tensor_215 = None
        convert_element_type_2490 = torch.ops.prims.convert_element_type.default(wait_tensor_263, torch.float32);  wait_tensor_263 = None
        mul_1761 = torch.ops.aten.mul.Tensor(convert_element_type_2488, convert_element_type_2490);  convert_element_type_2490 = None
        convert_element_type_686 = torch.ops.prims.convert_element_type.default(add_821, torch.float32);  add_821 = None
        mul_597 = torch.ops.aten.mul.Tensor(convert_element_type_686, rsqrt_39);  convert_element_type_686 = None
        mul_1763 = torch.ops.aten.mul.Tensor(mul_597, mul_1761)
        sum_217 = torch.ops.aten.sum.dim_IntList(mul_1763, [2], True);  mul_1763 = None
        div_215 = torch.ops.aten.div.Tensor(mul_597, 2048)
        mul_1764 = torch.ops.aten.mul.Tensor(div_215, sum_217);  div_215 = sum_217 = None
        sub_708 = torch.ops.aten.sub.Tensor(mul_1761, mul_1764);  mul_1761 = mul_1764 = None
        mul_1765 = torch.ops.aten.mul.Tensor(sub_708, rsqrt_39);  sub_708 = rsqrt_39 = None
        mul_1766 = torch.ops.aten.mul.Tensor(convert_element_type_2488, mul_597);  convert_element_type_2488 = mul_597 = None
        sum_218 = torch.ops.aten.sum.dim_IntList(mul_1766, [0, 1]);  mul_1766 = None
        convert_element_type_2491 = torch.ops.prims.convert_element_type.default(mul_1765, torch.bfloat16);  mul_1765 = None
        add_1984 = torch.ops.aten.add.Tensor(add_1982, convert_element_type_2491);  add_1982 = convert_element_type_2491 = None
        convert_element_type_default_40 = torch.ops.prims.convert_element_type.default(sum_218, torch.float32);  sum_218 = None
        reduce_scatter_tensor_197 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_40, 'avg', 128, '0');  convert_element_type_default_40 = None
        wait_tensor_784 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_197);  reduce_scatter_tensor_197 = None
        view_2048 = torch.ops.aten.view.default(add_1984, [8192, 2048])
        unsqueeze_67 = torch.ops.aten.unsqueeze.default(view_2048, 1)
        convert_element_type_2494 = torch.ops.prims.convert_element_type.default(unsqueeze_67, torch.float32);  unsqueeze_67 = None
        bmm_54 = torch.ops.aten.bmm.default(permute_1106, convert_element_type_2494);  permute_1106 = None
        bmm_55 = torch.ops.aten.bmm.default(convert_element_type_2494, permute_1107);  convert_element_type_2494 = permute_1107 = None
        convert_element_type_2495 = torch.ops.prims.convert_element_type.default(bmm_54, torch.bfloat16);  bmm_54 = None
        view_2049 = torch.ops.aten.view.default(bmm_55, [8192, 6]);  bmm_55 = None
        view_2050 = torch.ops.aten.view.default(convert_element_type_2495, [49152, 2048]);  convert_element_type_2495 = None
        index_80 = torch.ops.aten.index.Tensor(view_2050, [getitem_1231]);  view_2050 = getitem_1231 = None
        permute_1108 = torch.ops.aten.permute.default(view_2048, [1, 0])
        mm_442 = torch.ops.aten.mm.default(permute_1108, mul_594);  permute_1108 = mul_594 = None
        convert_element_type_680 = torch.ops.prims.convert_element_type.default(primals_214, torch.bfloat16);  primals_214 = None
        all_gather_into_tensor_214 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_680, 128, '0');  convert_element_type_680 = None
        wait_tensor_262 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_214);  all_gather_into_tensor_214 = None
        permute_190 = torch.ops.aten.permute.default(wait_tensor_262, [1, 0]);  wait_tensor_262 = None
        permute_1110 = torch.ops.aten.permute.default(permute_190, [1, 0]);  permute_190 = None
        mm_443 = torch.ops.aten.mm.default(view_2048, permute_1110);  view_2048 = permute_1110 = None
        convert_element_type_2500 = torch.ops.prims.convert_element_type.default(mm_442, torch.float32);  mm_442 = None
        reduce_scatter_tensor_198 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2500, 'avg', 128, '0');  convert_element_type_2500 = None
        wait_tensor_785 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_198);  reduce_scatter_tensor_198 = None
        convert_element_type_675 = torch.ops.prims.convert_element_type.default(mm_100, torch.float32);  mm_100 = None
        neg_24 = torch.ops.aten.neg.default(convert_element_type_675)
        exp_36 = torch.ops.aten.exp.default(neg_24);  neg_24 = None
        add_816 = torch.ops.aten.add.Tensor(exp_36, 1);  exp_36 = None
        div_60 = torch.ops.aten.div.Tensor(convert_element_type_675, add_816)
        convert_element_type_676 = torch.ops.prims.convert_element_type.default(div_60, torch.bfloat16);  div_60 = None
        mul_1767 = torch.ops.aten.mul.Tensor(mm_443, convert_element_type_676);  convert_element_type_676 = None
        mul_1768 = torch.ops.aten.mul.Tensor(mm_443, mm_101);  mm_443 = mm_101 = None
        permute_1112 = torch.ops.aten.permute.default(mul_1767, [1, 0])
        mm_444 = torch.ops.aten.mm.default(permute_1112, view_795);  permute_1112 = None
        convert_element_type_677 = torch.ops.prims.convert_element_type.default(primals_213, torch.bfloat16);  primals_213 = None
        all_gather_into_tensor_213 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_677, 128, '0');  convert_element_type_677 = None
        wait_tensor_261 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_213);  all_gather_into_tensor_213 = None
        permute_189 = torch.ops.aten.permute.default(wait_tensor_261, [1, 0]);  wait_tensor_261 = None
        permute_1114 = torch.ops.aten.permute.default(permute_189, [1, 0]);  permute_189 = None
        mm_445 = torch.ops.aten.mm.default(mul_1767, permute_1114);  mul_1767 = permute_1114 = None
        convert_element_type_2505 = torch.ops.prims.convert_element_type.default(mm_444, torch.float32);  mm_444 = None
        reduce_scatter_tensor_199 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2505, 'avg', 128, '0');  convert_element_type_2505 = None
        wait_tensor_786 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_199);  reduce_scatter_tensor_199 = None
        convert_element_type_2506 = torch.ops.prims.convert_element_type.default(mul_1768, torch.float32);  mul_1768 = None
        reciprocal_28 = torch.ops.aten.reciprocal.default(add_816);  add_816 = None
        mul_1769 = torch.ops.aten.mul.Tensor(reciprocal_28, 1);  reciprocal_28 = None
        mul_1770 = torch.ops.aten.mul.Tensor(convert_element_type_2506, mul_1769);  convert_element_type_2506 = None
        sub_709 = torch.ops.aten.sub.Tensor(1, mul_1769);  mul_1769 = None
        mul_1771 = torch.ops.aten.mul.Tensor(convert_element_type_675, sub_709);  convert_element_type_675 = sub_709 = None
        add_1986 = torch.ops.aten.add.Tensor(mul_1771, 1);  mul_1771 = None
        mul_1772 = torch.ops.aten.mul.Tensor(mul_1770, add_1986);  mul_1770 = add_1986 = None
        convert_element_type_2508 = torch.ops.prims.convert_element_type.default(mul_1772, torch.bfloat16);  mul_1772 = None
        permute_1116 = torch.ops.aten.permute.default(convert_element_type_2508, [1, 0])
        mm_446 = torch.ops.aten.mm.default(permute_1116, view_795);  permute_1116 = None
        convert_element_type_672 = torch.ops.prims.convert_element_type.default(primals_212, torch.bfloat16);  primals_212 = None
        all_gather_into_tensor_212 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_672, 128, '0');  convert_element_type_672 = None
        wait_tensor_260 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_212);  all_gather_into_tensor_212 = None
        permute_188 = torch.ops.aten.permute.default(wait_tensor_260, [1, 0]);  wait_tensor_260 = None
        permute_1118 = torch.ops.aten.permute.default(permute_188, [1, 0]);  permute_188 = None
        mm_447 = torch.ops.aten.mm.default(convert_element_type_2508, permute_1118);  convert_element_type_2508 = permute_1118 = None
        add_1987 = torch.ops.aten.add.Tensor(mm_445, mm_447);  mm_445 = mm_447 = None
        convert_element_type_2513 = torch.ops.prims.convert_element_type.default(mm_446, torch.float32);  mm_446 = None
        reduce_scatter_tensor_200 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2513, 'avg', 128, '0');  convert_element_type_2513 = None
        wait_tensor_787 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_200);  reduce_scatter_tensor_200 = None
        all_to_all_single_106 = torch.ops._c10d_functional.all_to_all_single.default(index_80, [_local_scalar_dense_184, _local_scalar_dense_185, _local_scalar_dense_186, _local_scalar_dense_187, _local_scalar_dense_188, _local_scalar_dense_189, _local_scalar_dense_190, _local_scalar_dense_191], [_local_scalar_dense_176, _local_scalar_dense_177, _local_scalar_dense_178, _local_scalar_dense_179, _local_scalar_dense_180, _local_scalar_dense_181, _local_scalar_dense_182, _local_scalar_dense_183], '1033');  index_80 = None
        wait_tensor_788 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_106);  all_to_all_single_106 = None
        full_432 = torch.ops.aten.full.default([sym_size_int_45, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_45 = None
        slice_scatter_14 = torch.ops.aten.slice_scatter.default(full_432, wait_tensor_788, 0, 0, -1);  wait_tensor_788 = None
        index_81 = torch.ops.aten.index.Tensor(slice_scatter_14, [getitem_1232]);  slice_scatter_14 = None
        permute_1120 = torch.ops.aten.permute.default(index_81, [1, 0])
        _grouped_mm_162 = torch.ops.aten._grouped_mm.default(permute_1120, mul_574, cumsum_35);  permute_1120 = mul_574 = None
        _grouped_mm_163 = torch.ops.aten._grouped_mm.default(index_81, permute_1122, cumsum_35);  index_81 = permute_1122 = None
        convert_element_type_670 = torch.ops.prims.convert_element_type.default(_grouped_mm_33, torch.float32);  _grouped_mm_33 = None
        neg_23 = torch.ops.aten.neg.default(convert_element_type_670)
        exp_35 = torch.ops.aten.exp.default(neg_23);  neg_23 = None
        add_780 = torch.ops.aten.add.Tensor(exp_35, 1);  exp_35 = None
        div_59 = torch.ops.aten.div.Tensor(convert_element_type_670, add_780)
        convert_element_type_671 = torch.ops.prims.convert_element_type.default(div_59, torch.bfloat16);  div_59 = None
        mul_1773 = torch.ops.aten.mul.Tensor(_grouped_mm_163, convert_element_type_671);  convert_element_type_671 = None
        mul_1774 = torch.ops.aten.mul.Tensor(_grouped_mm_163, _grouped_mm_34);  _grouped_mm_163 = _grouped_mm_34 = None
        permute_1124 = torch.ops.aten.permute.default(mul_1773, [1, 0])
        _grouped_mm_164 = torch.ops.aten._grouped_mm.default(permute_1124, index_23, cumsum_35);  permute_1124 = None
        _grouped_mm_165 = torch.ops.aten._grouped_mm.default(mul_1773, permute_1126, cumsum_35);  mul_1773 = permute_1126 = None
        convert_element_type_2514 = torch.ops.prims.convert_element_type.default(mul_1774, torch.float32);  mul_1774 = None
        reciprocal_29 = torch.ops.aten.reciprocal.default(add_780);  add_780 = None
        mul_1775 = torch.ops.aten.mul.Tensor(reciprocal_29, 1);  reciprocal_29 = None
        mul_1776 = torch.ops.aten.mul.Tensor(convert_element_type_2514, mul_1775);  convert_element_type_2514 = None
        sub_710 = torch.ops.aten.sub.Tensor(1, mul_1775);  mul_1775 = None
        mul_1777 = torch.ops.aten.mul.Tensor(convert_element_type_670, sub_710);  convert_element_type_670 = sub_710 = None
        add_1989 = torch.ops.aten.add.Tensor(mul_1777, 1);  mul_1777 = None
        mul_1778 = torch.ops.aten.mul.Tensor(mul_1776, add_1989);  mul_1776 = add_1989 = None
        convert_element_type_2516 = torch.ops.prims.convert_element_type.default(mul_1778, torch.bfloat16);  mul_1778 = None
        permute_1128 = torch.ops.aten.permute.default(convert_element_type_2516, [1, 0])
        _grouped_mm_166 = torch.ops.aten._grouped_mm.default(permute_1128, index_23, cumsum_35);  permute_1128 = index_23 = None
        _grouped_mm_167 = torch.ops.aten._grouped_mm.default(convert_element_type_2516, permute_1130, cumsum_35);  convert_element_type_2516 = permute_1130 = cumsum_35 = None
        add_1990 = torch.ops.aten.add.Tensor(_grouped_mm_165, _grouped_mm_167);  _grouped_mm_165 = _grouped_mm_167 = None
        convert_element_type_2517 = torch.ops.prims.convert_element_type.default(_grouped_mm_164, torch.float32);  _grouped_mm_164 = None
        div_216 = torch.ops.aten.div.Tensor(convert_element_type_2517, 128);  convert_element_type_2517 = None
        split_899 = torch.ops.aten.split.Tensor(div_216, 88, 1);  div_216 = None
        getitem_16885 = split_899[0]
        getitem_16902 = split_899[1]
        getitem_16919 = split_899[2]
        getitem_16936 = split_899[3]
        getitem_16953 = split_899[4]
        getitem_16970 = split_899[5]
        getitem_16987 = split_899[6]
        getitem_17004 = split_899[7]
        getitem_17021 = split_899[8]
        getitem_17038 = split_899[9]
        getitem_17055 = split_899[10]
        getitem_17072 = split_899[11]
        getitem_17089 = split_899[12]
        getitem_17106 = split_899[13]
        getitem_17123 = split_899[14]
        getitem_17140 = split_899[15];  split_899 = None
        cat_348 = torch.ops.aten.cat.default([getitem_16885, getitem_16902, getitem_16919, getitem_16936, getitem_16953, getitem_16970, getitem_16987, getitem_17004, getitem_17021, getitem_17038, getitem_17055, getitem_17072, getitem_17089, getitem_17106, getitem_17123, getitem_17140]);  getitem_16885 = getitem_16902 = getitem_16919 = getitem_16936 = getitem_16953 = getitem_16970 = getitem_16987 = getitem_17004 = getitem_17021 = getitem_17038 = getitem_17055 = getitem_17072 = getitem_17089 = getitem_17106 = getitem_17123 = getitem_17140 = None
        reduce_scatter_tensor_201 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_348, 'sum', 16, '1025');  cat_348 = None
        wait_tensor_789 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_201);  reduce_scatter_tensor_201 = None
        convert_element_type_2518 = torch.ops.prims.convert_element_type.default(_grouped_mm_162, torch.float32);  _grouped_mm_162 = None
        div_217 = torch.ops.aten.div.Tensor(convert_element_type_2518, 128);  convert_element_type_2518 = None
        split_916 = torch.ops.aten.split.Tensor(div_217, 128, 1);  div_217 = None
        getitem_17157 = split_916[0]
        getitem_17174 = split_916[1]
        getitem_17191 = split_916[2]
        getitem_17208 = split_916[3]
        getitem_17225 = split_916[4]
        getitem_17242 = split_916[5]
        getitem_17259 = split_916[6]
        getitem_17276 = split_916[7]
        getitem_17293 = split_916[8]
        getitem_17310 = split_916[9]
        getitem_17327 = split_916[10]
        getitem_17344 = split_916[11]
        getitem_17361 = split_916[12]
        getitem_17378 = split_916[13]
        getitem_17395 = split_916[14]
        getitem_17412 = split_916[15];  split_916 = None
        cat_349 = torch.ops.aten.cat.default([getitem_17157, getitem_17174, getitem_17191, getitem_17208, getitem_17225, getitem_17242, getitem_17259, getitem_17276, getitem_17293, getitem_17310, getitem_17327, getitem_17344, getitem_17361, getitem_17378, getitem_17395, getitem_17412]);  getitem_17157 = getitem_17174 = getitem_17191 = getitem_17208 = getitem_17225 = getitem_17242 = getitem_17259 = getitem_17276 = getitem_17293 = getitem_17310 = getitem_17327 = getitem_17344 = getitem_17361 = getitem_17378 = getitem_17395 = getitem_17412 = None
        reduce_scatter_tensor_202 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_349, 'sum', 16, '1025');  cat_349 = None
        wait_tensor_790 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_202);  reduce_scatter_tensor_202 = None
        convert_element_type_2519 = torch.ops.prims.convert_element_type.default(_grouped_mm_166, torch.float32);  _grouped_mm_166 = None
        div_218 = torch.ops.aten.div.Tensor(convert_element_type_2519, 128);  convert_element_type_2519 = None
        split_933 = torch.ops.aten.split.Tensor(div_218, 88, 1);  div_218 = None
        getitem_17429 = split_933[0]
        getitem_17446 = split_933[1]
        getitem_17463 = split_933[2]
        getitem_17480 = split_933[3]
        getitem_17497 = split_933[4]
        getitem_17514 = split_933[5]
        getitem_17531 = split_933[6]
        getitem_17548 = split_933[7]
        getitem_17565 = split_933[8]
        getitem_17582 = split_933[9]
        getitem_17599 = split_933[10]
        getitem_17616 = split_933[11]
        getitem_17633 = split_933[12]
        getitem_17650 = split_933[13]
        getitem_17667 = split_933[14]
        getitem_17684 = split_933[15];  split_933 = None
        cat_350 = torch.ops.aten.cat.default([getitem_17429, getitem_17446, getitem_17463, getitem_17480, getitem_17497, getitem_17514, getitem_17531, getitem_17548, getitem_17565, getitem_17582, getitem_17599, getitem_17616, getitem_17633, getitem_17650, getitem_17667, getitem_17684]);  getitem_17429 = getitem_17446 = getitem_17463 = getitem_17480 = getitem_17497 = getitem_17514 = getitem_17531 = getitem_17548 = getitem_17565 = getitem_17582 = getitem_17599 = getitem_17616 = getitem_17633 = getitem_17650 = getitem_17667 = getitem_17684 = None
        reduce_scatter_tensor_203 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_350, 'sum', 16, '1025');  cat_350 = None
        wait_tensor_791 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_203);  reduce_scatter_tensor_203 = None
        index_put_80 = torch.ops.aten.index_put.default(full_432, [getitem_1232], add_1990, True);  full_432 = getitem_1232 = add_1990 = None
        slice_246 = torch.ops.aten.slice.Tensor(index_put_80, 0, 0, add_1991);  index_put_80 = add_1991 = None
        all_to_all_single_107 = torch.ops._c10d_functional.all_to_all_single.default(slice_246, [_local_scalar_dense_176, _local_scalar_dense_177, _local_scalar_dense_178, _local_scalar_dense_179, _local_scalar_dense_180, _local_scalar_dense_181, _local_scalar_dense_182, _local_scalar_dense_183], [_local_scalar_dense_184, _local_scalar_dense_185, _local_scalar_dense_186, _local_scalar_dense_187, _local_scalar_dense_188, _local_scalar_dense_189, _local_scalar_dense_190, _local_scalar_dense_191], '1033');  slice_246 = _local_scalar_dense_176 = _local_scalar_dense_177 = _local_scalar_dense_178 = _local_scalar_dense_179 = _local_scalar_dense_180 = _local_scalar_dense_181 = _local_scalar_dense_182 = _local_scalar_dense_183 = _local_scalar_dense_184 = _local_scalar_dense_185 = _local_scalar_dense_186 = _local_scalar_dense_187 = _local_scalar_dense_188 = _local_scalar_dense_189 = _local_scalar_dense_190 = _local_scalar_dense_191 = None
        wait_tensor_792 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_107);  all_to_all_single_107 = None
        index_put_81 = torch.ops.aten.index_put.default(full_default_52, [div_57], wait_tensor_792, True);  div_57 = wait_tensor_792 = None
        add_1995 = torch.ops.aten.add.Tensor(add_1987, index_put_81);  add_1987 = index_put_81 = None
        mul_1779 = torch.ops.aten.mul.Tensor(view_2049, 1.0);  view_2049 = None
        scatter_add_14 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_1229, mul_1779);  getitem_1229 = mul_1779 = None
        convert_element_type_659 = torch.ops.prims.convert_element_type.default(mm_99, torch.float32);  mm_99 = None
        sub_264 = torch.ops.aten.sub.Tensor(convert_element_type_659, amax_11);  convert_element_type_659 = amax_11 = None
        exp_34 = torch.ops.aten.exp.default(sub_264);  sub_264 = None
        div_56 = torch.ops.aten.div.Tensor(exp_34, sum_45);  exp_34 = sum_45 = None
        mul_1780 = torch.ops.aten.mul.Tensor(scatter_add_14, div_56);  scatter_add_14 = None
        sum_219 = torch.ops.aten.sum.dim_IntList(mul_1780, [1], True)
        neg_97 = torch.ops.aten.neg.default(div_56);  div_56 = None
        fma_14 = torch.ops.prims.fma.default(neg_97, sum_219, mul_1780);  neg_97 = sum_219 = mul_1780 = None
        convert_element_type_2520 = torch.ops.prims.convert_element_type.default(fma_14, torch.bfloat16);  fma_14 = None
        permute_1132 = torch.ops.aten.permute.default(convert_element_type_2520, [1, 0])
        mm_448 = torch.ops.aten.mm.default(permute_1132, view_795);  permute_1132 = view_795 = None
        convert_element_type_656 = torch.ops.prims.convert_element_type.default(primals_207, torch.bfloat16);  primals_207 = None
        all_gather_into_tensor_205 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_656, 128, '0');  convert_element_type_656 = None
        wait_tensor_249 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_205);  all_gather_into_tensor_205 = None
        slice_75 = torch.ops.aten.slice.Tensor(wait_tensor_249, 0, 0, 64);  wait_tensor_249 = None
        permute_184 = torch.ops.aten.permute.default(slice_75, [1, 0]);  slice_75 = None
        permute_1134 = torch.ops.aten.permute.default(permute_184, [1, 0]);  permute_184 = None
        mm_449 = torch.ops.aten.mm.default(convert_element_type_2520, permute_1134);  convert_element_type_2520 = permute_1134 = None
        add_1996 = torch.ops.aten.add.Tensor(add_1995, mm_449);  add_1995 = mm_449 = None
        convert_element_type_2525 = torch.ops.prims.convert_element_type.default(mm_448, torch.float32);  mm_448 = None
        split_949 = torch.ops.aten.split.Tensor(convert_element_type_2525, 1);  convert_element_type_2525 = None
        getitem_17685 = split_949[0]
        getitem_17686 = split_949[1]
        getitem_17687 = split_949[2]
        getitem_17688 = split_949[3]
        getitem_17689 = split_949[4]
        getitem_17690 = split_949[5]
        getitem_17691 = split_949[6]
        getitem_17692 = split_949[7]
        getitem_17693 = split_949[8]
        getitem_17694 = split_949[9]
        getitem_17695 = split_949[10]
        getitem_17696 = split_949[11]
        getitem_17697 = split_949[12]
        getitem_17698 = split_949[13]
        getitem_17699 = split_949[14]
        getitem_17700 = split_949[15]
        getitem_17701 = split_949[16]
        getitem_17702 = split_949[17]
        getitem_17703 = split_949[18]
        getitem_17704 = split_949[19]
        getitem_17705 = split_949[20]
        getitem_17706 = split_949[21]
        getitem_17707 = split_949[22]
        getitem_17708 = split_949[23]
        getitem_17709 = split_949[24]
        getitem_17710 = split_949[25]
        getitem_17711 = split_949[26]
        getitem_17712 = split_949[27]
        getitem_17713 = split_949[28]
        getitem_17714 = split_949[29]
        getitem_17715 = split_949[30]
        getitem_17716 = split_949[31]
        getitem_17717 = split_949[32]
        getitem_17718 = split_949[33]
        getitem_17719 = split_949[34]
        getitem_17720 = split_949[35]
        getitem_17721 = split_949[36]
        getitem_17722 = split_949[37]
        getitem_17723 = split_949[38]
        getitem_17724 = split_949[39]
        getitem_17725 = split_949[40]
        getitem_17726 = split_949[41]
        getitem_17727 = split_949[42]
        getitem_17728 = split_949[43]
        getitem_17729 = split_949[44]
        getitem_17730 = split_949[45]
        getitem_17731 = split_949[46]
        getitem_17732 = split_949[47]
        getitem_17733 = split_949[48]
        getitem_17734 = split_949[49]
        getitem_17735 = split_949[50]
        getitem_17736 = split_949[51]
        getitem_17737 = split_949[52]
        getitem_17738 = split_949[53]
        getitem_17739 = split_949[54]
        getitem_17740 = split_949[55]
        getitem_17741 = split_949[56]
        getitem_17742 = split_949[57]
        getitem_17743 = split_949[58]
        getitem_17744 = split_949[59]
        getitem_17745 = split_949[60]
        getitem_17746 = split_949[61]
        getitem_17747 = split_949[62]
        getitem_17748 = split_949[63];  split_949 = None
        cat_351 = torch.ops.aten.cat.default([getitem_17685, getitem_17686, getitem_17687, getitem_17688, getitem_17689, getitem_17690, getitem_17691, getitem_17692, getitem_17693, getitem_17694, getitem_17695, getitem_17696, getitem_17697, getitem_17698, getitem_17699, getitem_17700, getitem_17701, getitem_17702, getitem_17703, getitem_17704, getitem_17705, getitem_17706, getitem_17707, getitem_17708, getitem_17709, getitem_17710, getitem_17711, getitem_17712, getitem_17713, getitem_17714, getitem_17715, getitem_17716, getitem_17717, getitem_17718, getitem_17719, getitem_17720, getitem_17721, getitem_17722, getitem_17723, getitem_17724, getitem_17725, getitem_17726, getitem_17727, getitem_17728, getitem_17729, getitem_17730, getitem_17731, getitem_17732, getitem_17733, getitem_17734, getitem_17735, getitem_17736, getitem_17737, getitem_17738, getitem_17739, getitem_17740, getitem_17741, getitem_17742, getitem_17743, getitem_17744, getitem_17745, getitem_17746, getitem_17747, getitem_17748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_17685 = getitem_17686 = getitem_17687 = getitem_17688 = getitem_17689 = getitem_17690 = getitem_17691 = getitem_17692 = getitem_17693 = getitem_17694 = getitem_17695 = getitem_17696 = getitem_17697 = getitem_17698 = getitem_17699 = getitem_17700 = getitem_17701 = getitem_17702 = getitem_17703 = getitem_17704 = getitem_17705 = getitem_17706 = getitem_17707 = getitem_17708 = getitem_17709 = getitem_17710 = getitem_17711 = getitem_17712 = getitem_17713 = getitem_17714 = getitem_17715 = getitem_17716 = getitem_17717 = getitem_17718 = getitem_17719 = getitem_17720 = getitem_17721 = getitem_17722 = getitem_17723 = getitem_17724 = getitem_17725 = getitem_17726 = getitem_17727 = getitem_17728 = getitem_17729 = getitem_17730 = getitem_17731 = getitem_17732 = getitem_17733 = getitem_17734 = getitem_17735 = getitem_17736 = getitem_17737 = getitem_17738 = getitem_17739 = getitem_17740 = getitem_17741 = getitem_17742 = getitem_17743 = getitem_17744 = getitem_17745 = getitem_17746 = getitem_17747 = getitem_17748 = None
        reduce_scatter_tensor_204 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_351, 'avg', 128, '0');  cat_351 = None
        wait_tensor_793 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_204);  reduce_scatter_tensor_204 = None
        view_2051 = torch.ops.aten.view.default(add_1996, [2, 4096, 2048]);  add_1996 = None
        convert_element_type_2526 = torch.ops.prims.convert_element_type.default(view_2051, torch.float32);  view_2051 = None
        convert_element_type_653 = torch.ops.prims.convert_element_type.default(primals_205, torch.bfloat16);  primals_205 = None
        all_gather_into_tensor_204 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_653, 128, '0');  convert_element_type_653 = None
        wait_tensor_248 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_204);  all_gather_into_tensor_204 = None
        convert_element_type_2528 = torch.ops.prims.convert_element_type.default(wait_tensor_248, torch.float32);  wait_tensor_248 = None
        mul_1781 = torch.ops.aten.mul.Tensor(convert_element_type_2526, convert_element_type_2528);  convert_element_type_2528 = None
        convert_element_type_654 = torch.ops.prims.convert_element_type.default(add_756, torch.float32);  add_756 = None
        mul_554 = torch.ops.aten.mul.Tensor(convert_element_type_654, rsqrt_38);  convert_element_type_654 = None
        mul_1783 = torch.ops.aten.mul.Tensor(mul_554, mul_1781)
        sum_220 = torch.ops.aten.sum.dim_IntList(mul_1783, [2], True);  mul_1783 = None
        div_219 = torch.ops.aten.div.Tensor(mul_554, 2048)
        mul_1784 = torch.ops.aten.mul.Tensor(div_219, sum_220);  div_219 = sum_220 = None
        sub_712 = torch.ops.aten.sub.Tensor(mul_1781, mul_1784);  mul_1781 = mul_1784 = None
        mul_1785 = torch.ops.aten.mul.Tensor(sub_712, rsqrt_38);  sub_712 = rsqrt_38 = None
        mul_1786 = torch.ops.aten.mul.Tensor(convert_element_type_2526, mul_554);  convert_element_type_2526 = mul_554 = None
        sum_221 = torch.ops.aten.sum.dim_IntList(mul_1786, [0, 1]);  mul_1786 = None
        convert_element_type_2529 = torch.ops.prims.convert_element_type.default(mul_1785, torch.bfloat16);  mul_1785 = None
        add_1997 = torch.ops.aten.add.Tensor(add_1984, convert_element_type_2529);  add_1984 = convert_element_type_2529 = None
        convert_element_type_default_39 = torch.ops.prims.convert_element_type.default(sum_221, torch.float32);  sum_221 = None
        reduce_scatter_tensor_205 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_39, 'avg', 128, '0');  convert_element_type_default_39 = None
        wait_tensor_794 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_205);  reduce_scatter_tensor_205 = None
        view_2052 = torch.ops.aten.view.default(add_1997, [8192, 2048])
        permute_1136 = torch.ops.aten.permute.default(view_2052, [1, 0])
        permute_182 = torch.ops.aten.permute.default(getitem_1225, [0, 2, 1, 3])
        view_790 = torch.ops.aten.view.default(permute_182, [2, 4096, -1]);  permute_182 = None
        view_792 = torch.ops.aten.view.default(view_790, [8192, 2048]);  view_790 = None
        mm_450 = torch.ops.aten.mm.default(permute_1136, view_792);  permute_1136 = view_792 = None
        convert_element_type_650 = torch.ops.prims.convert_element_type.default(primals_204, torch.bfloat16);  primals_204 = None
        all_gather_into_tensor_203 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_650, 128, '0');  convert_element_type_650 = None
        wait_tensor_247 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_203);  all_gather_into_tensor_203 = None
        permute_183 = torch.ops.aten.permute.default(wait_tensor_247, [1, 0]);  wait_tensor_247 = None
        permute_1138 = torch.ops.aten.permute.default(permute_183, [1, 0]);  permute_183 = None
        mm_451 = torch.ops.aten.mm.default(view_2052, permute_1138);  view_2052 = permute_1138 = None
        view_2053 = torch.ops.aten.view.default(mm_451, [2, 4096, 2048]);  mm_451 = None
        convert_element_type_2536 = torch.ops.prims.convert_element_type.default(mm_450, torch.float32);  mm_450 = None
        reduce_scatter_tensor_206 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2536, 'avg', 128, '0');  convert_element_type_2536 = None
        wait_tensor_795 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_206);  reduce_scatter_tensor_206 = None
        view_2054 = torch.ops.aten.view.default(view_2053, [2, 4096, 16, 128]);  view_2053 = None
        permute_1140 = torch.ops.aten.permute.default(view_2054, [0, 2, 1, 3]);  view_2054 = None
        fw_graph14 = self.fw_graph14
        joint_graph14 = self.joint_graph14
        mask_graph14 = self.mask_graph14
        flex_attention_backward_14 = torch.ops.higher_order.flex_attention_backward(permute_179, permute_180, permute_181, getitem_1225, getitem_1226, permute_1140, None, fw_graph14, joint_graph14, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph14), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_179 = permute_180 = permute_181 = getitem_1225 = getitem_1226 = permute_1140 = fw_graph14 = joint_graph14 = mask_graph14 = None
        getitem_17749 = flex_attention_backward_14[0]
        getitem_17750 = flex_attention_backward_14[1]
        getitem_17751 = flex_attention_backward_14[2];  flex_attention_backward_14 = None
        permute_1141 = torch.ops.aten.permute.default(getitem_17751, [0, 2, 1, 3]);  getitem_17751 = None
        permute_1142 = torch.ops.aten.permute.default(getitem_17750, [0, 2, 1, 3]);  getitem_17750 = None
        permute_1143 = torch.ops.aten.permute.default(getitem_17749, [0, 2, 1, 3]);  getitem_17749 = None
        slice_248 = torch.ops.aten.slice.Tensor(permute_1142, 3, 0, 128)
        slice_249 = torch.ops.aten.slice.Tensor(permute_1142, 3, 128, 192);  permute_1142 = None
        sum_222 = torch.ops.aten.sum.dim_IntList(slice_249, [2], True);  slice_249 = None
        cat_352 = torch.ops.aten.cat.default([slice_248, permute_1141], 3);  slice_248 = permute_1141 = None
        view_2055 = torch.ops.aten.view.default(cat_352, [2, 4096, 4096]);  cat_352 = None
        view_2056 = torch.ops.aten.view.default(view_2055, [8192, 4096]);  view_2055 = None
        permute_1144 = torch.ops.aten.permute.default(view_2056, [1, 0])
        mm_452 = torch.ops.aten.mm.default(permute_1144, view_787);  permute_1144 = view_787 = None
        convert_element_type_647 = torch.ops.prims.convert_element_type.default(primals_203, torch.bfloat16);  primals_203 = None
        all_gather_into_tensor_202 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_647, 128, '0');  convert_element_type_647 = None
        wait_tensor_246 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_202);  all_gather_into_tensor_202 = None
        permute_178 = torch.ops.aten.permute.default(wait_tensor_246, [1, 0]);  wait_tensor_246 = None
        permute_1146 = torch.ops.aten.permute.default(permute_178, [1, 0]);  permute_178 = None
        mm_453 = torch.ops.aten.mm.default(view_2056, permute_1146);  view_2056 = permute_1146 = None
        view_2057 = torch.ops.aten.view.default(mm_453, [2, 4096, 512]);  mm_453 = None
        convert_element_type_2541 = torch.ops.prims.convert_element_type.default(mm_452, torch.float32);  mm_452 = None
        reduce_scatter_tensor_207 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2541, 'avg', 128, '0');  convert_element_type_2541 = None
        wait_tensor_796 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_207);  reduce_scatter_tensor_207 = None
        convert_element_type_2542 = torch.ops.prims.convert_element_type.default(view_2057, torch.float32);  view_2057 = None
        convert_element_type_644 = torch.ops.prims.convert_element_type.default(primals_202, torch.bfloat16);  primals_202 = None
        all_gather_into_tensor_201 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_644, 128, '0');  convert_element_type_644 = None
        wait_tensor_245 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_201);  all_gather_into_tensor_201 = None
        convert_element_type_2544 = torch.ops.prims.convert_element_type.default(wait_tensor_245, torch.float32);  wait_tensor_245 = None
        mul_1787 = torch.ops.aten.mul.Tensor(convert_element_type_2542, convert_element_type_2544);  convert_element_type_2544 = None
        convert_element_type_645 = torch.ops.prims.convert_element_type.default(getitem_1221, torch.float32);  getitem_1221 = None
        mul_552 = torch.ops.aten.mul.Tensor(convert_element_type_645, rsqrt_37);  convert_element_type_645 = None
        mul_1789 = torch.ops.aten.mul.Tensor(mul_552, mul_1787)
        sum_223 = torch.ops.aten.sum.dim_IntList(mul_1789, [2], True);  mul_1789 = None
        div_220 = torch.ops.aten.div.Tensor(mul_552, 512)
        mul_1790 = torch.ops.aten.mul.Tensor(div_220, sum_223);  div_220 = sum_223 = None
        sub_713 = torch.ops.aten.sub.Tensor(mul_1787, mul_1790);  mul_1787 = mul_1790 = None
        mul_1791 = torch.ops.aten.mul.Tensor(sub_713, rsqrt_37);  sub_713 = rsqrt_37 = None
        mul_1792 = torch.ops.aten.mul.Tensor(convert_element_type_2542, mul_552);  convert_element_type_2542 = mul_552 = None
        sum_224 = torch.ops.aten.sum.dim_IntList(mul_1792, [0, 1]);  mul_1792 = None
        convert_element_type_2545 = torch.ops.prims.convert_element_type.default(mul_1791, torch.bfloat16);  mul_1791 = None
        convert_element_type_default_38 = torch.ops.prims.convert_element_type.default(sum_224, torch.float32);  sum_224 = None
        reduce_scatter_tensor_208 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_38, 'avg', 128, '0');  convert_element_type_default_38 = None
        wait_tensor_797 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_208);  reduce_scatter_tensor_208 = None
        convert_element_type_2548 = torch.ops.prims.convert_element_type.default(sum_222, torch.float32);  sum_222 = None
        view_2058 = torch.ops.aten.view.default(convert_element_type_2548, [2, 4096, 1, 32, 2]);  convert_element_type_2548 = None
        view_as_complex_82 = torch.ops.aten.view_as_complex.default(view_2058);  view_2058 = None
        mul_1793 = torch.ops.aten.mul.Tensor(view_as_complex_82, clone_9);  view_as_complex_82 = None
        view_as_real_82 = torch.ops.aten.view_as_real.default(mul_1793);  mul_1793 = None
        view_2059 = torch.ops.aten.view.default(view_as_real_82, [2, 4096, 1, 64]);  view_as_real_82 = None
        convert_element_type_2549 = torch.ops.prims.convert_element_type.default(view_2059, torch.bfloat16);  view_2059 = None
        squeeze_40 = torch.ops.aten.squeeze.dim(convert_element_type_2549, 2);  convert_element_type_2549 = None
        cat_353 = torch.ops.aten.cat.default([convert_element_type_2545, squeeze_40], 2);  convert_element_type_2545 = squeeze_40 = None
        view_2060 = torch.ops.aten.view.default(cat_353, [8192, 576]);  cat_353 = None
        permute_1148 = torch.ops.aten.permute.default(view_2060, [1, 0])
        mm_454 = torch.ops.aten.mm.default(permute_1148, view_773);  permute_1148 = None
        convert_element_type_639 = torch.ops.prims.convert_element_type.default(primals_201, torch.bfloat16);  primals_201 = None
        all_gather_into_tensor_200 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_639, 128, '0');  convert_element_type_639 = None
        wait_tensor_244 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_200);  all_gather_into_tensor_200 = None
        slice_73 = torch.ops.aten.slice.Tensor(wait_tensor_244, 0, 0, 576);  wait_tensor_244 = None
        permute_177 = torch.ops.aten.permute.default(slice_73, [1, 0]);  slice_73 = None
        permute_1150 = torch.ops.aten.permute.default(permute_177, [1, 0]);  permute_177 = None
        mm_455 = torch.ops.aten.mm.default(view_2060, permute_1150);  view_2060 = permute_1150 = None
        view_2061 = torch.ops.aten.view.default(mm_455, [2, 4096, 2048]);  mm_455 = None
        convert_element_type_2554 = torch.ops.prims.convert_element_type.default(mm_454, torch.float32);  mm_454 = None
        split_950 = torch.ops.aten.split.Tensor(convert_element_type_2554, 5);  convert_element_type_2554 = None
        getitem_17753 = split_950[0]
        getitem_17754 = split_950[1]
        getitem_17755 = split_950[2]
        getitem_17756 = split_950[3]
        getitem_17757 = split_950[4]
        getitem_17758 = split_950[5]
        getitem_17759 = split_950[6]
        getitem_17760 = split_950[7]
        getitem_17761 = split_950[8]
        getitem_17762 = split_950[9]
        getitem_17763 = split_950[10]
        getitem_17764 = split_950[11]
        getitem_17765 = split_950[12]
        getitem_17766 = split_950[13]
        getitem_17767 = split_950[14]
        getitem_17768 = split_950[15]
        getitem_17769 = split_950[16]
        getitem_17770 = split_950[17]
        getitem_17771 = split_950[18]
        getitem_17772 = split_950[19]
        getitem_17773 = split_950[20]
        getitem_17774 = split_950[21]
        getitem_17775 = split_950[22]
        getitem_17776 = split_950[23]
        getitem_17777 = split_950[24]
        getitem_17778 = split_950[25]
        getitem_17779 = split_950[26]
        getitem_17780 = split_950[27]
        getitem_17781 = split_950[28]
        getitem_17782 = split_950[29]
        getitem_17783 = split_950[30]
        getitem_17784 = split_950[31]
        getitem_17785 = split_950[32]
        getitem_17786 = split_950[33]
        getitem_17787 = split_950[34]
        getitem_17788 = split_950[35]
        getitem_17789 = split_950[36]
        getitem_17790 = split_950[37]
        getitem_17791 = split_950[38]
        getitem_17792 = split_950[39]
        getitem_17793 = split_950[40]
        getitem_17794 = split_950[41]
        getitem_17795 = split_950[42]
        getitem_17796 = split_950[43]
        getitem_17797 = split_950[44]
        getitem_17798 = split_950[45]
        getitem_17799 = split_950[46]
        getitem_17800 = split_950[47]
        getitem_17801 = split_950[48]
        getitem_17802 = split_950[49]
        getitem_17803 = split_950[50]
        getitem_17804 = split_950[51]
        getitem_17805 = split_950[52]
        getitem_17806 = split_950[53]
        getitem_17807 = split_950[54]
        getitem_17808 = split_950[55]
        getitem_17809 = split_950[56]
        getitem_17810 = split_950[57]
        getitem_17811 = split_950[58]
        getitem_17812 = split_950[59]
        getitem_17813 = split_950[60]
        getitem_17814 = split_950[61]
        getitem_17815 = split_950[62]
        getitem_17816 = split_950[63]
        getitem_17817 = split_950[64]
        getitem_17818 = split_950[65]
        getitem_17819 = split_950[66]
        getitem_17820 = split_950[67]
        getitem_17821 = split_950[68]
        getitem_17822 = split_950[69]
        getitem_17823 = split_950[70]
        getitem_17824 = split_950[71]
        getitem_17825 = split_950[72]
        getitem_17826 = split_950[73]
        getitem_17827 = split_950[74]
        getitem_17828 = split_950[75]
        getitem_17829 = split_950[76]
        getitem_17830 = split_950[77]
        getitem_17831 = split_950[78]
        getitem_17832 = split_950[79]
        getitem_17833 = split_950[80]
        getitem_17834 = split_950[81]
        getitem_17835 = split_950[82]
        getitem_17836 = split_950[83]
        getitem_17837 = split_950[84]
        getitem_17838 = split_950[85]
        getitem_17839 = split_950[86]
        getitem_17840 = split_950[87]
        getitem_17841 = split_950[88]
        getitem_17842 = split_950[89]
        getitem_17843 = split_950[90]
        getitem_17844 = split_950[91]
        getitem_17845 = split_950[92]
        getitem_17846 = split_950[93]
        getitem_17847 = split_950[94]
        getitem_17848 = split_950[95]
        getitem_17849 = split_950[96]
        getitem_17850 = split_950[97]
        getitem_17851 = split_950[98]
        getitem_17852 = split_950[99]
        getitem_17853 = split_950[100]
        getitem_17854 = split_950[101]
        getitem_17855 = split_950[102]
        getitem_17856 = split_950[103]
        getitem_17857 = split_950[104]
        getitem_17858 = split_950[105]
        getitem_17859 = split_950[106]
        getitem_17860 = split_950[107]
        getitem_17861 = split_950[108]
        getitem_17862 = split_950[109]
        getitem_17863 = split_950[110]
        getitem_17864 = split_950[111]
        getitem_17865 = split_950[112]
        getitem_17866 = split_950[113]
        getitem_17867 = split_950[114]
        getitem_17868 = split_950[115];  split_950 = None
        constant_pad_nd_1142 = torch.ops.aten.constant_pad_nd.default(getitem_17868, [0, 0, 0, 4], 0.0);  getitem_17868 = None
        cat_354 = torch.ops.aten.cat.default([getitem_17753, getitem_17754, getitem_17755, getitem_17756, getitem_17757, getitem_17758, getitem_17759, getitem_17760, getitem_17761, getitem_17762, getitem_17763, getitem_17764, getitem_17765, getitem_17766, getitem_17767, getitem_17768, getitem_17769, getitem_17770, getitem_17771, getitem_17772, getitem_17773, getitem_17774, getitem_17775, getitem_17776, getitem_17777, getitem_17778, getitem_17779, getitem_17780, getitem_17781, getitem_17782, getitem_17783, getitem_17784, getitem_17785, getitem_17786, getitem_17787, getitem_17788, getitem_17789, getitem_17790, getitem_17791, getitem_17792, getitem_17793, getitem_17794, getitem_17795, getitem_17796, getitem_17797, getitem_17798, getitem_17799, getitem_17800, getitem_17801, getitem_17802, getitem_17803, getitem_17804, getitem_17805, getitem_17806, getitem_17807, getitem_17808, getitem_17809, getitem_17810, getitem_17811, getitem_17812, getitem_17813, getitem_17814, getitem_17815, getitem_17816, getitem_17817, getitem_17818, getitem_17819, getitem_17820, getitem_17821, getitem_17822, getitem_17823, getitem_17824, getitem_17825, getitem_17826, getitem_17827, getitem_17828, getitem_17829, getitem_17830, getitem_17831, getitem_17832, getitem_17833, getitem_17834, getitem_17835, getitem_17836, getitem_17837, getitem_17838, getitem_17839, getitem_17840, getitem_17841, getitem_17842, getitem_17843, getitem_17844, getitem_17845, getitem_17846, getitem_17847, getitem_17848, getitem_17849, getitem_17850, getitem_17851, getitem_17852, getitem_17853, getitem_17854, getitem_17855, getitem_17856, getitem_17857, getitem_17858, getitem_17859, getitem_17860, getitem_17861, getitem_17862, getitem_17863, getitem_17864, getitem_17865, getitem_17866, getitem_17867, constant_pad_nd_1142, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_17753 = getitem_17754 = getitem_17755 = getitem_17756 = getitem_17757 = getitem_17758 = getitem_17759 = getitem_17760 = getitem_17761 = getitem_17762 = getitem_17763 = getitem_17764 = getitem_17765 = getitem_17766 = getitem_17767 = getitem_17768 = getitem_17769 = getitem_17770 = getitem_17771 = getitem_17772 = getitem_17773 = getitem_17774 = getitem_17775 = getitem_17776 = getitem_17777 = getitem_17778 = getitem_17779 = getitem_17780 = getitem_17781 = getitem_17782 = getitem_17783 = getitem_17784 = getitem_17785 = getitem_17786 = getitem_17787 = getitem_17788 = getitem_17789 = getitem_17790 = getitem_17791 = getitem_17792 = getitem_17793 = getitem_17794 = getitem_17795 = getitem_17796 = getitem_17797 = getitem_17798 = getitem_17799 = getitem_17800 = getitem_17801 = getitem_17802 = getitem_17803 = getitem_17804 = getitem_17805 = getitem_17806 = getitem_17807 = getitem_17808 = getitem_17809 = getitem_17810 = getitem_17811 = getitem_17812 = getitem_17813 = getitem_17814 = getitem_17815 = getitem_17816 = getitem_17817 = getitem_17818 = getitem_17819 = getitem_17820 = getitem_17821 = getitem_17822 = getitem_17823 = getitem_17824 = getitem_17825 = getitem_17826 = getitem_17827 = getitem_17828 = getitem_17829 = getitem_17830 = getitem_17831 = getitem_17832 = getitem_17833 = getitem_17834 = getitem_17835 = getitem_17836 = getitem_17837 = getitem_17838 = getitem_17839 = getitem_17840 = getitem_17841 = getitem_17842 = getitem_17843 = getitem_17844 = getitem_17845 = getitem_17846 = getitem_17847 = getitem_17848 = getitem_17849 = getitem_17850 = getitem_17851 = getitem_17852 = getitem_17853 = getitem_17854 = getitem_17855 = getitem_17856 = getitem_17857 = getitem_17858 = getitem_17859 = getitem_17860 = getitem_17861 = getitem_17862 = getitem_17863 = getitem_17864 = getitem_17865 = getitem_17866 = getitem_17867 = constant_pad_nd_1142 = None
        reduce_scatter_tensor_209 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_354, 'avg', 128, '0');  cat_354 = None
        wait_tensor_798 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_209);  reduce_scatter_tensor_209 = None
        slice_250 = torch.ops.aten.slice.Tensor(permute_1143, 3, 0, 128)
        slice_251 = torch.ops.aten.slice.Tensor(permute_1143, 3, 128, 192);  permute_1143 = None
        convert_element_type_2555 = torch.ops.prims.convert_element_type.default(slice_251, torch.float32);  slice_251 = None
        view_2062 = torch.ops.aten.view.default(convert_element_type_2555, [2, 4096, 16, 32, 2]);  convert_element_type_2555 = None
        view_as_complex_83 = torch.ops.aten.view_as_complex.default(view_2062);  view_2062 = None
        mul_1794 = torch.ops.aten.mul.Tensor(view_as_complex_83, clone_9);  view_as_complex_83 = None
        view_as_real_83 = torch.ops.aten.view_as_real.default(mul_1794);  mul_1794 = None
        view_2063 = torch.ops.aten.view.default(view_as_real_83, [2, 4096, 16, 64]);  view_as_real_83 = None
        convert_element_type_2556 = torch.ops.prims.convert_element_type.default(view_2063, torch.bfloat16);  view_2063 = None
        cat_355 = torch.ops.aten.cat.default([slice_250, convert_element_type_2556], 3);  slice_250 = convert_element_type_2556 = None
        view_2064 = torch.ops.aten.view.default(cat_355, [2, 4096, 3072]);  cat_355 = None
        view_2065 = torch.ops.aten.view.default(view_2064, [8192, 3072]);  view_2064 = None
        permute_1152 = torch.ops.aten.permute.default(view_2065, [1, 0])
        mm_456 = torch.ops.aten.mm.default(permute_1152, view_773);  permute_1152 = view_773 = None
        convert_element_type_634 = torch.ops.prims.convert_element_type.default(primals_200, torch.bfloat16);  primals_200 = None
        all_gather_into_tensor_199 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_634, 128, '0');  convert_element_type_634 = None
        wait_tensor_243 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_199);  all_gather_into_tensor_199 = None
        permute_176 = torch.ops.aten.permute.default(wait_tensor_243, [1, 0]);  wait_tensor_243 = None
        permute_1154 = torch.ops.aten.permute.default(permute_176, [1, 0]);  permute_176 = None
        mm_457 = torch.ops.aten.mm.default(view_2065, permute_1154);  view_2065 = permute_1154 = None
        view_2066 = torch.ops.aten.view.default(mm_457, [2, 4096, 2048]);  mm_457 = None
        add_1998 = torch.ops.aten.add.Tensor(view_2061, view_2066);  view_2061 = view_2066 = None
        convert_element_type_2561 = torch.ops.prims.convert_element_type.default(mm_456, torch.float32);  mm_456 = None
        reduce_scatter_tensor_210 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2561, 'avg', 128, '0');  convert_element_type_2561 = None
        wait_tensor_799 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_210);  reduce_scatter_tensor_210 = None
        convert_element_type_2562 = torch.ops.prims.convert_element_type.default(add_1998, torch.float32);  add_1998 = None
        convert_element_type_631 = torch.ops.prims.convert_element_type.default(primals_199, torch.bfloat16);  primals_199 = None
        all_gather_into_tensor_198 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_631, 128, '0');  convert_element_type_631 = None
        wait_tensor_242 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_198);  all_gather_into_tensor_198 = None
        convert_element_type_2564 = torch.ops.prims.convert_element_type.default(wait_tensor_242, torch.float32);  wait_tensor_242 = None
        mul_1795 = torch.ops.aten.mul.Tensor(convert_element_type_2562, convert_element_type_2564);  convert_element_type_2564 = None
        convert_element_type_632 = torch.ops.prims.convert_element_type.default(add_753, torch.float32);  add_753 = None
        mul_548 = torch.ops.aten.mul.Tensor(convert_element_type_632, rsqrt_36);  convert_element_type_632 = None
        mul_1797 = torch.ops.aten.mul.Tensor(mul_548, mul_1795)
        sum_225 = torch.ops.aten.sum.dim_IntList(mul_1797, [2], True);  mul_1797 = None
        div_221 = torch.ops.aten.div.Tensor(mul_548, 2048)
        mul_1798 = torch.ops.aten.mul.Tensor(div_221, sum_225);  div_221 = sum_225 = None
        sub_714 = torch.ops.aten.sub.Tensor(mul_1795, mul_1798);  mul_1795 = mul_1798 = None
        mul_1799 = torch.ops.aten.mul.Tensor(sub_714, rsqrt_36);  sub_714 = rsqrt_36 = None
        mul_1800 = torch.ops.aten.mul.Tensor(convert_element_type_2562, mul_548);  convert_element_type_2562 = mul_548 = None
        sum_226 = torch.ops.aten.sum.dim_IntList(mul_1800, [0, 1]);  mul_1800 = None
        convert_element_type_2565 = torch.ops.prims.convert_element_type.default(mul_1799, torch.bfloat16);  mul_1799 = None
        add_1999 = torch.ops.aten.add.Tensor(add_1997, convert_element_type_2565);  add_1997 = convert_element_type_2565 = None
        convert_element_type_default_37 = torch.ops.prims.convert_element_type.default(sum_226, torch.float32);  sum_226 = None
        reduce_scatter_tensor_211 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_37, 'avg', 128, '0');  convert_element_type_default_37 = None
        wait_tensor_800 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_211);  reduce_scatter_tensor_211 = None
        view_2067 = torch.ops.aten.view.default(add_1999, [8192, 2048])
        unsqueeze_68 = torch.ops.aten.unsqueeze.default(view_2067, 1)
        convert_element_type_2568 = torch.ops.prims.convert_element_type.default(unsqueeze_68, torch.float32);  unsqueeze_68 = None
        bmm_56 = torch.ops.aten.bmm.default(permute_1156, convert_element_type_2568);  permute_1156 = None
        bmm_57 = torch.ops.aten.bmm.default(convert_element_type_2568, permute_1157);  convert_element_type_2568 = permute_1157 = None
        convert_element_type_2569 = torch.ops.prims.convert_element_type.default(bmm_56, torch.bfloat16);  bmm_56 = None
        view_2068 = torch.ops.aten.view.default(bmm_57, [8192, 6]);  bmm_57 = None
        view_2069 = torch.ops.aten.view.default(convert_element_type_2569, [49152, 2048]);  convert_element_type_2569 = None
        index_82 = torch.ops.aten.index.Tensor(view_2069, [getitem_1121]);  view_2069 = getitem_1121 = None
        permute_1158 = torch.ops.aten.permute.default(view_2067, [1, 0])
        mm_458 = torch.ops.aten.mm.default(permute_1158, mul_545);  permute_1158 = mul_545 = None
        convert_element_type_626 = torch.ops.prims.convert_element_type.default(primals_198, torch.bfloat16);  primals_198 = None
        all_gather_into_tensor_197 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_626, 128, '0');  convert_element_type_626 = None
        wait_tensor_241 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_197);  all_gather_into_tensor_197 = None
        permute_175 = torch.ops.aten.permute.default(wait_tensor_241, [1, 0]);  wait_tensor_241 = None
        permute_1160 = torch.ops.aten.permute.default(permute_175, [1, 0]);  permute_175 = None
        mm_459 = torch.ops.aten.mm.default(view_2067, permute_1160);  view_2067 = permute_1160 = None
        convert_element_type_2574 = torch.ops.prims.convert_element_type.default(mm_458, torch.float32);  mm_458 = None
        reduce_scatter_tensor_212 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2574, 'avg', 128, '0');  convert_element_type_2574 = None
        wait_tensor_801 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_212);  reduce_scatter_tensor_212 = None
        convert_element_type_621 = torch.ops.prims.convert_element_type.default(mm_92, torch.float32);  mm_92 = None
        neg_22 = torch.ops.aten.neg.default(convert_element_type_621)
        exp_33 = torch.ops.aten.exp.default(neg_22);  neg_22 = None
        add_748 = torch.ops.aten.add.Tensor(exp_33, 1);  exp_33 = None
        div_55 = torch.ops.aten.div.Tensor(convert_element_type_621, add_748)
        convert_element_type_622 = torch.ops.prims.convert_element_type.default(div_55, torch.bfloat16);  div_55 = None
        mul_1801 = torch.ops.aten.mul.Tensor(mm_459, convert_element_type_622);  convert_element_type_622 = None
        mul_1802 = torch.ops.aten.mul.Tensor(mm_459, mm_93);  mm_459 = mm_93 = None
        permute_1162 = torch.ops.aten.permute.default(mul_1801, [1, 0])
        mm_460 = torch.ops.aten.mm.default(permute_1162, view_728);  permute_1162 = None
        convert_element_type_623 = torch.ops.prims.convert_element_type.default(primals_197, torch.bfloat16);  primals_197 = None
        all_gather_into_tensor_196 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_623, 128, '0');  convert_element_type_623 = None
        wait_tensor_240 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_196);  all_gather_into_tensor_196 = None
        permute_174 = torch.ops.aten.permute.default(wait_tensor_240, [1, 0]);  wait_tensor_240 = None
        permute_1164 = torch.ops.aten.permute.default(permute_174, [1, 0]);  permute_174 = None
        mm_461 = torch.ops.aten.mm.default(mul_1801, permute_1164);  mul_1801 = permute_1164 = None
        convert_element_type_2579 = torch.ops.prims.convert_element_type.default(mm_460, torch.float32);  mm_460 = None
        reduce_scatter_tensor_213 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2579, 'avg', 128, '0');  convert_element_type_2579 = None
        wait_tensor_802 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_213);  reduce_scatter_tensor_213 = None
        convert_element_type_2580 = torch.ops.prims.convert_element_type.default(mul_1802, torch.float32);  mul_1802 = None
        reciprocal_30 = torch.ops.aten.reciprocal.default(add_748);  add_748 = None
        mul_1803 = torch.ops.aten.mul.Tensor(reciprocal_30, 1);  reciprocal_30 = None
        mul_1804 = torch.ops.aten.mul.Tensor(convert_element_type_2580, mul_1803);  convert_element_type_2580 = None
        sub_715 = torch.ops.aten.sub.Tensor(1, mul_1803);  mul_1803 = None
        mul_1805 = torch.ops.aten.mul.Tensor(convert_element_type_621, sub_715);  convert_element_type_621 = sub_715 = None
        add_2001 = torch.ops.aten.add.Tensor(mul_1805, 1);  mul_1805 = None
        mul_1806 = torch.ops.aten.mul.Tensor(mul_1804, add_2001);  mul_1804 = add_2001 = None
        convert_element_type_2582 = torch.ops.prims.convert_element_type.default(mul_1806, torch.bfloat16);  mul_1806 = None
        permute_1166 = torch.ops.aten.permute.default(convert_element_type_2582, [1, 0])
        mm_462 = torch.ops.aten.mm.default(permute_1166, view_728);  permute_1166 = None
        convert_element_type_618 = torch.ops.prims.convert_element_type.default(primals_196, torch.bfloat16);  primals_196 = None
        all_gather_into_tensor_195 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_618, 128, '0');  convert_element_type_618 = None
        wait_tensor_239 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_195);  all_gather_into_tensor_195 = None
        permute_173 = torch.ops.aten.permute.default(wait_tensor_239, [1, 0]);  wait_tensor_239 = None
        permute_1168 = torch.ops.aten.permute.default(permute_173, [1, 0]);  permute_173 = None
        mm_463 = torch.ops.aten.mm.default(convert_element_type_2582, permute_1168);  convert_element_type_2582 = permute_1168 = None
        add_2002 = torch.ops.aten.add.Tensor(mm_461, mm_463);  mm_461 = mm_463 = None
        convert_element_type_2587 = torch.ops.prims.convert_element_type.default(mm_462, torch.float32);  mm_462 = None
        reduce_scatter_tensor_214 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2587, 'avg', 128, '0');  convert_element_type_2587 = None
        wait_tensor_803 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_214);  reduce_scatter_tensor_214 = None
        all_to_all_single_108 = torch.ops._c10d_functional.all_to_all_single.default(index_82, [_local_scalar_dense_168, _local_scalar_dense_169, _local_scalar_dense_170, _local_scalar_dense_171, _local_scalar_dense_172, _local_scalar_dense_173, _local_scalar_dense_174, _local_scalar_dense_175], [_local_scalar_dense_160, _local_scalar_dense_161, _local_scalar_dense_162, _local_scalar_dense_163, _local_scalar_dense_164, _local_scalar_dense_165, _local_scalar_dense_166, _local_scalar_dense_167], '1033');  index_82 = None
        wait_tensor_804 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_108);  all_to_all_single_108 = None
        full_438 = torch.ops.aten.full.default([sym_size_int_41, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_41 = None
        slice_scatter_15 = torch.ops.aten.slice_scatter.default(full_438, wait_tensor_804, 0, 0, -1);  wait_tensor_804 = None
        index_83 = torch.ops.aten.index.Tensor(slice_scatter_15, [getitem_1122]);  slice_scatter_15 = None
        permute_1170 = torch.ops.aten.permute.default(index_83, [1, 0])
        _grouped_mm_168 = torch.ops.aten._grouped_mm.default(permute_1170, mul_525, cumsum_32);  permute_1170 = mul_525 = None
        _grouped_mm_169 = torch.ops.aten._grouped_mm.default(index_83, permute_1172, cumsum_32);  index_83 = permute_1172 = None
        convert_element_type_616 = torch.ops.prims.convert_element_type.default(_grouped_mm_30, torch.float32);  _grouped_mm_30 = None
        neg_21 = torch.ops.aten.neg.default(convert_element_type_616)
        exp_32 = torch.ops.aten.exp.default(neg_21);  neg_21 = None
        add_712 = torch.ops.aten.add.Tensor(exp_32, 1);  exp_32 = None
        div_54 = torch.ops.aten.div.Tensor(convert_element_type_616, add_712)
        convert_element_type_617 = torch.ops.prims.convert_element_type.default(div_54, torch.bfloat16);  div_54 = None
        mul_1807 = torch.ops.aten.mul.Tensor(_grouped_mm_169, convert_element_type_617);  convert_element_type_617 = None
        mul_1808 = torch.ops.aten.mul.Tensor(_grouped_mm_169, _grouped_mm_31);  _grouped_mm_169 = _grouped_mm_31 = None
        permute_1174 = torch.ops.aten.permute.default(mul_1807, [1, 0])
        _grouped_mm_170 = torch.ops.aten._grouped_mm.default(permute_1174, index_21, cumsum_32);  permute_1174 = None
        _grouped_mm_171 = torch.ops.aten._grouped_mm.default(mul_1807, permute_1176, cumsum_32);  mul_1807 = permute_1176 = None
        convert_element_type_2588 = torch.ops.prims.convert_element_type.default(mul_1808, torch.float32);  mul_1808 = None
        reciprocal_31 = torch.ops.aten.reciprocal.default(add_712);  add_712 = None
        mul_1809 = torch.ops.aten.mul.Tensor(reciprocal_31, 1);  reciprocal_31 = None
        mul_1810 = torch.ops.aten.mul.Tensor(convert_element_type_2588, mul_1809);  convert_element_type_2588 = None
        sub_716 = torch.ops.aten.sub.Tensor(1, mul_1809);  mul_1809 = None
        mul_1811 = torch.ops.aten.mul.Tensor(convert_element_type_616, sub_716);  convert_element_type_616 = sub_716 = None
        add_2004 = torch.ops.aten.add.Tensor(mul_1811, 1);  mul_1811 = None
        mul_1812 = torch.ops.aten.mul.Tensor(mul_1810, add_2004);  mul_1810 = add_2004 = None
        convert_element_type_2590 = torch.ops.prims.convert_element_type.default(mul_1812, torch.bfloat16);  mul_1812 = None
        permute_1178 = torch.ops.aten.permute.default(convert_element_type_2590, [1, 0])
        _grouped_mm_172 = torch.ops.aten._grouped_mm.default(permute_1178, index_21, cumsum_32);  permute_1178 = index_21 = None
        _grouped_mm_173 = torch.ops.aten._grouped_mm.default(convert_element_type_2590, permute_1180, cumsum_32);  convert_element_type_2590 = permute_1180 = cumsum_32 = None
        add_2005 = torch.ops.aten.add.Tensor(_grouped_mm_171, _grouped_mm_173);  _grouped_mm_171 = _grouped_mm_173 = None
        convert_element_type_2591 = torch.ops.prims.convert_element_type.default(_grouped_mm_170, torch.float32);  _grouped_mm_170 = None
        div_222 = torch.ops.aten.div.Tensor(convert_element_type_2591, 128);  convert_element_type_2591 = None
        split_952 = torch.ops.aten.split.Tensor(div_222, 88, 1);  div_222 = None
        getitem_17885 = split_952[0]
        getitem_17902 = split_952[1]
        getitem_17919 = split_952[2]
        getitem_17936 = split_952[3]
        getitem_17953 = split_952[4]
        getitem_17970 = split_952[5]
        getitem_17987 = split_952[6]
        getitem_18004 = split_952[7]
        getitem_18021 = split_952[8]
        getitem_18038 = split_952[9]
        getitem_18055 = split_952[10]
        getitem_18072 = split_952[11]
        getitem_18089 = split_952[12]
        getitem_18106 = split_952[13]
        getitem_18123 = split_952[14]
        getitem_18140 = split_952[15];  split_952 = None
        cat_356 = torch.ops.aten.cat.default([getitem_17885, getitem_17902, getitem_17919, getitem_17936, getitem_17953, getitem_17970, getitem_17987, getitem_18004, getitem_18021, getitem_18038, getitem_18055, getitem_18072, getitem_18089, getitem_18106, getitem_18123, getitem_18140]);  getitem_17885 = getitem_17902 = getitem_17919 = getitem_17936 = getitem_17953 = getitem_17970 = getitem_17987 = getitem_18004 = getitem_18021 = getitem_18038 = getitem_18055 = getitem_18072 = getitem_18089 = getitem_18106 = getitem_18123 = getitem_18140 = None
        reduce_scatter_tensor_215 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_356, 'sum', 16, '1025');  cat_356 = None
        wait_tensor_805 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_215);  reduce_scatter_tensor_215 = None
        convert_element_type_2592 = torch.ops.prims.convert_element_type.default(_grouped_mm_168, torch.float32);  _grouped_mm_168 = None
        div_223 = torch.ops.aten.div.Tensor(convert_element_type_2592, 128);  convert_element_type_2592 = None
        split_969 = torch.ops.aten.split.Tensor(div_223, 128, 1);  div_223 = None
        getitem_18157 = split_969[0]
        getitem_18174 = split_969[1]
        getitem_18191 = split_969[2]
        getitem_18208 = split_969[3]
        getitem_18225 = split_969[4]
        getitem_18242 = split_969[5]
        getitem_18259 = split_969[6]
        getitem_18276 = split_969[7]
        getitem_18293 = split_969[8]
        getitem_18310 = split_969[9]
        getitem_18327 = split_969[10]
        getitem_18344 = split_969[11]
        getitem_18361 = split_969[12]
        getitem_18378 = split_969[13]
        getitem_18395 = split_969[14]
        getitem_18412 = split_969[15];  split_969 = None
        cat_357 = torch.ops.aten.cat.default([getitem_18157, getitem_18174, getitem_18191, getitem_18208, getitem_18225, getitem_18242, getitem_18259, getitem_18276, getitem_18293, getitem_18310, getitem_18327, getitem_18344, getitem_18361, getitem_18378, getitem_18395, getitem_18412]);  getitem_18157 = getitem_18174 = getitem_18191 = getitem_18208 = getitem_18225 = getitem_18242 = getitem_18259 = getitem_18276 = getitem_18293 = getitem_18310 = getitem_18327 = getitem_18344 = getitem_18361 = getitem_18378 = getitem_18395 = getitem_18412 = None
        reduce_scatter_tensor_216 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_357, 'sum', 16, '1025');  cat_357 = None
        wait_tensor_806 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_216);  reduce_scatter_tensor_216 = None
        convert_element_type_2593 = torch.ops.prims.convert_element_type.default(_grouped_mm_172, torch.float32);  _grouped_mm_172 = None
        div_224 = torch.ops.aten.div.Tensor(convert_element_type_2593, 128);  convert_element_type_2593 = None
        split_986 = torch.ops.aten.split.Tensor(div_224, 88, 1);  div_224 = None
        getitem_18429 = split_986[0]
        getitem_18446 = split_986[1]
        getitem_18463 = split_986[2]
        getitem_18480 = split_986[3]
        getitem_18497 = split_986[4]
        getitem_18514 = split_986[5]
        getitem_18531 = split_986[6]
        getitem_18548 = split_986[7]
        getitem_18565 = split_986[8]
        getitem_18582 = split_986[9]
        getitem_18599 = split_986[10]
        getitem_18616 = split_986[11]
        getitem_18633 = split_986[12]
        getitem_18650 = split_986[13]
        getitem_18667 = split_986[14]
        getitem_18684 = split_986[15];  split_986 = None
        cat_358 = torch.ops.aten.cat.default([getitem_18429, getitem_18446, getitem_18463, getitem_18480, getitem_18497, getitem_18514, getitem_18531, getitem_18548, getitem_18565, getitem_18582, getitem_18599, getitem_18616, getitem_18633, getitem_18650, getitem_18667, getitem_18684]);  getitem_18429 = getitem_18446 = getitem_18463 = getitem_18480 = getitem_18497 = getitem_18514 = getitem_18531 = getitem_18548 = getitem_18565 = getitem_18582 = getitem_18599 = getitem_18616 = getitem_18633 = getitem_18650 = getitem_18667 = getitem_18684 = None
        reduce_scatter_tensor_217 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_358, 'sum', 16, '1025');  cat_358 = None
        wait_tensor_807 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_217);  reduce_scatter_tensor_217 = None
        index_put_82 = torch.ops.aten.index_put.default(full_438, [getitem_1122], add_2005, True);  full_438 = getitem_1122 = add_2005 = None
        slice_252 = torch.ops.aten.slice.Tensor(index_put_82, 0, 0, add_2006);  index_put_82 = add_2006 = None
        all_to_all_single_109 = torch.ops._c10d_functional.all_to_all_single.default(slice_252, [_local_scalar_dense_160, _local_scalar_dense_161, _local_scalar_dense_162, _local_scalar_dense_163, _local_scalar_dense_164, _local_scalar_dense_165, _local_scalar_dense_166, _local_scalar_dense_167], [_local_scalar_dense_168, _local_scalar_dense_169, _local_scalar_dense_170, _local_scalar_dense_171, _local_scalar_dense_172, _local_scalar_dense_173, _local_scalar_dense_174, _local_scalar_dense_175], '1033');  slice_252 = _local_scalar_dense_160 = _local_scalar_dense_161 = _local_scalar_dense_162 = _local_scalar_dense_163 = _local_scalar_dense_164 = _local_scalar_dense_165 = _local_scalar_dense_166 = _local_scalar_dense_167 = _local_scalar_dense_168 = _local_scalar_dense_169 = _local_scalar_dense_170 = _local_scalar_dense_171 = _local_scalar_dense_172 = _local_scalar_dense_173 = _local_scalar_dense_174 = _local_scalar_dense_175 = None
        wait_tensor_808 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_109);  all_to_all_single_109 = None
        index_put_83 = torch.ops.aten.index_put.default(full_default_52, [div_52], wait_tensor_808, True);  div_52 = wait_tensor_808 = None
        add_2010 = torch.ops.aten.add.Tensor(add_2002, index_put_83);  add_2002 = index_put_83 = None
        mul_1813 = torch.ops.aten.mul.Tensor(view_2068, 1.0);  view_2068 = None
        scatter_add_15 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_1119, mul_1813);  getitem_1119 = mul_1813 = None
        convert_element_type_605 = torch.ops.prims.convert_element_type.default(mm_91, torch.float32);  mm_91 = None
        sub_240 = torch.ops.aten.sub.Tensor(convert_element_type_605, amax_10);  convert_element_type_605 = amax_10 = None
        exp_31 = torch.ops.aten.exp.default(sub_240);  sub_240 = None
        div_51 = torch.ops.aten.div.Tensor(exp_31, sum_41);  exp_31 = sum_41 = None
        mul_1814 = torch.ops.aten.mul.Tensor(scatter_add_15, div_51);  scatter_add_15 = None
        sum_227 = torch.ops.aten.sum.dim_IntList(mul_1814, [1], True)
        neg_100 = torch.ops.aten.neg.default(div_51);  div_51 = None
        fma_15 = torch.ops.prims.fma.default(neg_100, sum_227, mul_1814);  neg_100 = sum_227 = mul_1814 = None
        convert_element_type_2594 = torch.ops.prims.convert_element_type.default(fma_15, torch.bfloat16);  fma_15 = None
        permute_1182 = torch.ops.aten.permute.default(convert_element_type_2594, [1, 0])
        mm_464 = torch.ops.aten.mm.default(permute_1182, view_728);  permute_1182 = view_728 = None
        convert_element_type_602 = torch.ops.prims.convert_element_type.default(primals_191, torch.bfloat16);  primals_191 = None
        all_gather_into_tensor_188 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_602, 128, '0');  convert_element_type_602 = None
        wait_tensor_228 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_188);  all_gather_into_tensor_188 = None
        slice_69 = torch.ops.aten.slice.Tensor(wait_tensor_228, 0, 0, 64);  wait_tensor_228 = None
        permute_169 = torch.ops.aten.permute.default(slice_69, [1, 0]);  slice_69 = None
        permute_1184 = torch.ops.aten.permute.default(permute_169, [1, 0]);  permute_169 = None
        mm_465 = torch.ops.aten.mm.default(convert_element_type_2594, permute_1184);  convert_element_type_2594 = permute_1184 = None
        add_2011 = torch.ops.aten.add.Tensor(add_2010, mm_465);  add_2010 = mm_465 = None
        convert_element_type_2599 = torch.ops.prims.convert_element_type.default(mm_464, torch.float32);  mm_464 = None
        split_1002 = torch.ops.aten.split.Tensor(convert_element_type_2599, 1);  convert_element_type_2599 = None
        getitem_18685 = split_1002[0]
        getitem_18686 = split_1002[1]
        getitem_18687 = split_1002[2]
        getitem_18688 = split_1002[3]
        getitem_18689 = split_1002[4]
        getitem_18690 = split_1002[5]
        getitem_18691 = split_1002[6]
        getitem_18692 = split_1002[7]
        getitem_18693 = split_1002[8]
        getitem_18694 = split_1002[9]
        getitem_18695 = split_1002[10]
        getitem_18696 = split_1002[11]
        getitem_18697 = split_1002[12]
        getitem_18698 = split_1002[13]
        getitem_18699 = split_1002[14]
        getitem_18700 = split_1002[15]
        getitem_18701 = split_1002[16]
        getitem_18702 = split_1002[17]
        getitem_18703 = split_1002[18]
        getitem_18704 = split_1002[19]
        getitem_18705 = split_1002[20]
        getitem_18706 = split_1002[21]
        getitem_18707 = split_1002[22]
        getitem_18708 = split_1002[23]
        getitem_18709 = split_1002[24]
        getitem_18710 = split_1002[25]
        getitem_18711 = split_1002[26]
        getitem_18712 = split_1002[27]
        getitem_18713 = split_1002[28]
        getitem_18714 = split_1002[29]
        getitem_18715 = split_1002[30]
        getitem_18716 = split_1002[31]
        getitem_18717 = split_1002[32]
        getitem_18718 = split_1002[33]
        getitem_18719 = split_1002[34]
        getitem_18720 = split_1002[35]
        getitem_18721 = split_1002[36]
        getitem_18722 = split_1002[37]
        getitem_18723 = split_1002[38]
        getitem_18724 = split_1002[39]
        getitem_18725 = split_1002[40]
        getitem_18726 = split_1002[41]
        getitem_18727 = split_1002[42]
        getitem_18728 = split_1002[43]
        getitem_18729 = split_1002[44]
        getitem_18730 = split_1002[45]
        getitem_18731 = split_1002[46]
        getitem_18732 = split_1002[47]
        getitem_18733 = split_1002[48]
        getitem_18734 = split_1002[49]
        getitem_18735 = split_1002[50]
        getitem_18736 = split_1002[51]
        getitem_18737 = split_1002[52]
        getitem_18738 = split_1002[53]
        getitem_18739 = split_1002[54]
        getitem_18740 = split_1002[55]
        getitem_18741 = split_1002[56]
        getitem_18742 = split_1002[57]
        getitem_18743 = split_1002[58]
        getitem_18744 = split_1002[59]
        getitem_18745 = split_1002[60]
        getitem_18746 = split_1002[61]
        getitem_18747 = split_1002[62]
        getitem_18748 = split_1002[63];  split_1002 = None
        cat_359 = torch.ops.aten.cat.default([getitem_18685, getitem_18686, getitem_18687, getitem_18688, getitem_18689, getitem_18690, getitem_18691, getitem_18692, getitem_18693, getitem_18694, getitem_18695, getitem_18696, getitem_18697, getitem_18698, getitem_18699, getitem_18700, getitem_18701, getitem_18702, getitem_18703, getitem_18704, getitem_18705, getitem_18706, getitem_18707, getitem_18708, getitem_18709, getitem_18710, getitem_18711, getitem_18712, getitem_18713, getitem_18714, getitem_18715, getitem_18716, getitem_18717, getitem_18718, getitem_18719, getitem_18720, getitem_18721, getitem_18722, getitem_18723, getitem_18724, getitem_18725, getitem_18726, getitem_18727, getitem_18728, getitem_18729, getitem_18730, getitem_18731, getitem_18732, getitem_18733, getitem_18734, getitem_18735, getitem_18736, getitem_18737, getitem_18738, getitem_18739, getitem_18740, getitem_18741, getitem_18742, getitem_18743, getitem_18744, getitem_18745, getitem_18746, getitem_18747, getitem_18748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_18685 = getitem_18686 = getitem_18687 = getitem_18688 = getitem_18689 = getitem_18690 = getitem_18691 = getitem_18692 = getitem_18693 = getitem_18694 = getitem_18695 = getitem_18696 = getitem_18697 = getitem_18698 = getitem_18699 = getitem_18700 = getitem_18701 = getitem_18702 = getitem_18703 = getitem_18704 = getitem_18705 = getitem_18706 = getitem_18707 = getitem_18708 = getitem_18709 = getitem_18710 = getitem_18711 = getitem_18712 = getitem_18713 = getitem_18714 = getitem_18715 = getitem_18716 = getitem_18717 = getitem_18718 = getitem_18719 = getitem_18720 = getitem_18721 = getitem_18722 = getitem_18723 = getitem_18724 = getitem_18725 = getitem_18726 = getitem_18727 = getitem_18728 = getitem_18729 = getitem_18730 = getitem_18731 = getitem_18732 = getitem_18733 = getitem_18734 = getitem_18735 = getitem_18736 = getitem_18737 = getitem_18738 = getitem_18739 = getitem_18740 = getitem_18741 = getitem_18742 = getitem_18743 = getitem_18744 = getitem_18745 = getitem_18746 = getitem_18747 = getitem_18748 = None
        reduce_scatter_tensor_218 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_359, 'avg', 128, '0');  cat_359 = None
        wait_tensor_809 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_218);  reduce_scatter_tensor_218 = None
        view_2070 = torch.ops.aten.view.default(add_2011, [2, 4096, 2048]);  add_2011 = None
        convert_element_type_2600 = torch.ops.prims.convert_element_type.default(view_2070, torch.float32);  view_2070 = None
        convert_element_type_599 = torch.ops.prims.convert_element_type.default(primals_189, torch.bfloat16);  primals_189 = None
        all_gather_into_tensor_187 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_599, 128, '0');  convert_element_type_599 = None
        wait_tensor_227 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_187);  all_gather_into_tensor_187 = None
        convert_element_type_2602 = torch.ops.prims.convert_element_type.default(wait_tensor_227, torch.float32);  wait_tensor_227 = None
        mul_1815 = torch.ops.aten.mul.Tensor(convert_element_type_2600, convert_element_type_2602);  convert_element_type_2602 = None
        convert_element_type_600 = torch.ops.prims.convert_element_type.default(add_688, torch.float32);  add_688 = None
        mul_505 = torch.ops.aten.mul.Tensor(convert_element_type_600, rsqrt_35);  convert_element_type_600 = None
        mul_1817 = torch.ops.aten.mul.Tensor(mul_505, mul_1815)
        sum_228 = torch.ops.aten.sum.dim_IntList(mul_1817, [2], True);  mul_1817 = None
        div_225 = torch.ops.aten.div.Tensor(mul_505, 2048)
        mul_1818 = torch.ops.aten.mul.Tensor(div_225, sum_228);  div_225 = sum_228 = None
        sub_718 = torch.ops.aten.sub.Tensor(mul_1815, mul_1818);  mul_1815 = mul_1818 = None
        mul_1819 = torch.ops.aten.mul.Tensor(sub_718, rsqrt_35);  sub_718 = rsqrt_35 = None
        mul_1820 = torch.ops.aten.mul.Tensor(convert_element_type_2600, mul_505);  convert_element_type_2600 = mul_505 = None
        sum_229 = torch.ops.aten.sum.dim_IntList(mul_1820, [0, 1]);  mul_1820 = None
        convert_element_type_2603 = torch.ops.prims.convert_element_type.default(mul_1819, torch.bfloat16);  mul_1819 = None
        add_2012 = torch.ops.aten.add.Tensor(add_1999, convert_element_type_2603);  add_1999 = convert_element_type_2603 = None
        convert_element_type_default_36 = torch.ops.prims.convert_element_type.default(sum_229, torch.float32);  sum_229 = None
        reduce_scatter_tensor_219 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_36, 'avg', 128, '0');  convert_element_type_default_36 = None
        wait_tensor_810 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_219);  reduce_scatter_tensor_219 = None
        view_2071 = torch.ops.aten.view.default(add_2012, [8192, 2048])
        permute_1186 = torch.ops.aten.permute.default(view_2071, [1, 0])
        permute_167 = torch.ops.aten.permute.default(getitem_1115, [0, 2, 1, 3])
        view_723 = torch.ops.aten.view.default(permute_167, [2, 4096, -1]);  permute_167 = None
        view_725 = torch.ops.aten.view.default(view_723, [8192, 2048]);  view_723 = None
        mm_466 = torch.ops.aten.mm.default(permute_1186, view_725);  permute_1186 = view_725 = None
        convert_element_type_596 = torch.ops.prims.convert_element_type.default(primals_188, torch.bfloat16);  primals_188 = None
        all_gather_into_tensor_186 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_596, 128, '0');  convert_element_type_596 = None
        wait_tensor_226 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_186);  all_gather_into_tensor_186 = None
        permute_168 = torch.ops.aten.permute.default(wait_tensor_226, [1, 0]);  wait_tensor_226 = None
        permute_1188 = torch.ops.aten.permute.default(permute_168, [1, 0]);  permute_168 = None
        mm_467 = torch.ops.aten.mm.default(view_2071, permute_1188);  view_2071 = permute_1188 = None
        view_2072 = torch.ops.aten.view.default(mm_467, [2, 4096, 2048]);  mm_467 = None
        convert_element_type_2610 = torch.ops.prims.convert_element_type.default(mm_466, torch.float32);  mm_466 = None
        reduce_scatter_tensor_220 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2610, 'avg', 128, '0');  convert_element_type_2610 = None
        wait_tensor_811 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_220);  reduce_scatter_tensor_220 = None
        view_2073 = torch.ops.aten.view.default(view_2072, [2, 4096, 16, 128]);  view_2072 = None
        permute_1190 = torch.ops.aten.permute.default(view_2073, [0, 2, 1, 3]);  view_2073 = None
        fw_graph15 = self.fw_graph15
        joint_graph15 = self.joint_graph15
        mask_graph15 = self.mask_graph15
        flex_attention_backward_15 = torch.ops.higher_order.flex_attention_backward(permute_164, permute_165, permute_166, getitem_1115, getitem_1116, permute_1190, None, fw_graph15, joint_graph15, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph15), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_164 = permute_165 = permute_166 = getitem_1115 = getitem_1116 = permute_1190 = fw_graph15 = joint_graph15 = mask_graph15 = None
        getitem_18749 = flex_attention_backward_15[0]
        getitem_18750 = flex_attention_backward_15[1]
        getitem_18751 = flex_attention_backward_15[2];  flex_attention_backward_15 = None
        permute_1191 = torch.ops.aten.permute.default(getitem_18751, [0, 2, 1, 3]);  getitem_18751 = None
        permute_1192 = torch.ops.aten.permute.default(getitem_18750, [0, 2, 1, 3]);  getitem_18750 = None
        permute_1193 = torch.ops.aten.permute.default(getitem_18749, [0, 2, 1, 3]);  getitem_18749 = None
        slice_254 = torch.ops.aten.slice.Tensor(permute_1192, 3, 0, 128)
        slice_255 = torch.ops.aten.slice.Tensor(permute_1192, 3, 128, 192);  permute_1192 = None
        sum_230 = torch.ops.aten.sum.dim_IntList(slice_255, [2], True);  slice_255 = None
        cat_360 = torch.ops.aten.cat.default([slice_254, permute_1191], 3);  slice_254 = permute_1191 = None
        view_2074 = torch.ops.aten.view.default(cat_360, [2, 4096, 4096]);  cat_360 = None
        view_2075 = torch.ops.aten.view.default(view_2074, [8192, 4096]);  view_2074 = None
        permute_1194 = torch.ops.aten.permute.default(view_2075, [1, 0])
        mm_468 = torch.ops.aten.mm.default(permute_1194, view_720);  permute_1194 = view_720 = None
        convert_element_type_593 = torch.ops.prims.convert_element_type.default(primals_187, torch.bfloat16);  primals_187 = None
        all_gather_into_tensor_185 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_593, 128, '0');  convert_element_type_593 = None
        wait_tensor_225 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_185);  all_gather_into_tensor_185 = None
        permute_163 = torch.ops.aten.permute.default(wait_tensor_225, [1, 0]);  wait_tensor_225 = None
        permute_1196 = torch.ops.aten.permute.default(permute_163, [1, 0]);  permute_163 = None
        mm_469 = torch.ops.aten.mm.default(view_2075, permute_1196);  view_2075 = permute_1196 = None
        view_2076 = torch.ops.aten.view.default(mm_469, [2, 4096, 512]);  mm_469 = None
        convert_element_type_2615 = torch.ops.prims.convert_element_type.default(mm_468, torch.float32);  mm_468 = None
        reduce_scatter_tensor_221 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2615, 'avg', 128, '0');  convert_element_type_2615 = None
        wait_tensor_812 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_221);  reduce_scatter_tensor_221 = None
        convert_element_type_2616 = torch.ops.prims.convert_element_type.default(view_2076, torch.float32);  view_2076 = None
        convert_element_type_590 = torch.ops.prims.convert_element_type.default(primals_186, torch.bfloat16);  primals_186 = None
        all_gather_into_tensor_184 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_590, 128, '0');  convert_element_type_590 = None
        wait_tensor_224 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_184);  all_gather_into_tensor_184 = None
        convert_element_type_2618 = torch.ops.prims.convert_element_type.default(wait_tensor_224, torch.float32);  wait_tensor_224 = None
        mul_1821 = torch.ops.aten.mul.Tensor(convert_element_type_2616, convert_element_type_2618);  convert_element_type_2618 = None
        convert_element_type_591 = torch.ops.prims.convert_element_type.default(getitem_1111, torch.float32);  getitem_1111 = None
        mul_503 = torch.ops.aten.mul.Tensor(convert_element_type_591, rsqrt_34);  convert_element_type_591 = None
        mul_1823 = torch.ops.aten.mul.Tensor(mul_503, mul_1821)
        sum_231 = torch.ops.aten.sum.dim_IntList(mul_1823, [2], True);  mul_1823 = None
        div_226 = torch.ops.aten.div.Tensor(mul_503, 512)
        mul_1824 = torch.ops.aten.mul.Tensor(div_226, sum_231);  div_226 = sum_231 = None
        sub_719 = torch.ops.aten.sub.Tensor(mul_1821, mul_1824);  mul_1821 = mul_1824 = None
        mul_1825 = torch.ops.aten.mul.Tensor(sub_719, rsqrt_34);  sub_719 = rsqrt_34 = None
        mul_1826 = torch.ops.aten.mul.Tensor(convert_element_type_2616, mul_503);  convert_element_type_2616 = mul_503 = None
        sum_232 = torch.ops.aten.sum.dim_IntList(mul_1826, [0, 1]);  mul_1826 = None
        convert_element_type_2619 = torch.ops.prims.convert_element_type.default(mul_1825, torch.bfloat16);  mul_1825 = None
        convert_element_type_default_35 = torch.ops.prims.convert_element_type.default(sum_232, torch.float32);  sum_232 = None
        reduce_scatter_tensor_222 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_35, 'avg', 128, '0');  convert_element_type_default_35 = None
        wait_tensor_813 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_222);  reduce_scatter_tensor_222 = None
        convert_element_type_2622 = torch.ops.prims.convert_element_type.default(sum_230, torch.float32);  sum_230 = None
        view_2077 = torch.ops.aten.view.default(convert_element_type_2622, [2, 4096, 1, 32, 2]);  convert_element_type_2622 = None
        view_as_complex_84 = torch.ops.aten.view_as_complex.default(view_2077);  view_2077 = None
        mul_1827 = torch.ops.aten.mul.Tensor(view_as_complex_84, clone_9);  view_as_complex_84 = None
        view_as_real_84 = torch.ops.aten.view_as_real.default(mul_1827);  mul_1827 = None
        view_2078 = torch.ops.aten.view.default(view_as_real_84, [2, 4096, 1, 64]);  view_as_real_84 = None
        convert_element_type_2623 = torch.ops.prims.convert_element_type.default(view_2078, torch.bfloat16);  view_2078 = None
        squeeze_41 = torch.ops.aten.squeeze.dim(convert_element_type_2623, 2);  convert_element_type_2623 = None
        cat_361 = torch.ops.aten.cat.default([convert_element_type_2619, squeeze_41], 2);  convert_element_type_2619 = squeeze_41 = None
        view_2079 = torch.ops.aten.view.default(cat_361, [8192, 576]);  cat_361 = None
        permute_1198 = torch.ops.aten.permute.default(view_2079, [1, 0])
        mm_470 = torch.ops.aten.mm.default(permute_1198, view_706);  permute_1198 = None
        convert_element_type_585 = torch.ops.prims.convert_element_type.default(primals_185, torch.bfloat16);  primals_185 = None
        all_gather_into_tensor_183 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_585, 128, '0');  convert_element_type_585 = None
        wait_tensor_223 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_183);  all_gather_into_tensor_183 = None
        slice_67 = torch.ops.aten.slice.Tensor(wait_tensor_223, 0, 0, 576);  wait_tensor_223 = None
        permute_162 = torch.ops.aten.permute.default(slice_67, [1, 0]);  slice_67 = None
        permute_1200 = torch.ops.aten.permute.default(permute_162, [1, 0]);  permute_162 = None
        mm_471 = torch.ops.aten.mm.default(view_2079, permute_1200);  view_2079 = permute_1200 = None
        view_2080 = torch.ops.aten.view.default(mm_471, [2, 4096, 2048]);  mm_471 = None
        convert_element_type_2628 = torch.ops.prims.convert_element_type.default(mm_470, torch.float32);  mm_470 = None
        split_1003 = torch.ops.aten.split.Tensor(convert_element_type_2628, 5);  convert_element_type_2628 = None
        getitem_18753 = split_1003[0]
        getitem_18754 = split_1003[1]
        getitem_18755 = split_1003[2]
        getitem_18756 = split_1003[3]
        getitem_18757 = split_1003[4]
        getitem_18758 = split_1003[5]
        getitem_18759 = split_1003[6]
        getitem_18760 = split_1003[7]
        getitem_18761 = split_1003[8]
        getitem_18762 = split_1003[9]
        getitem_18763 = split_1003[10]
        getitem_18764 = split_1003[11]
        getitem_18765 = split_1003[12]
        getitem_18766 = split_1003[13]
        getitem_18767 = split_1003[14]
        getitem_18768 = split_1003[15]
        getitem_18769 = split_1003[16]
        getitem_18770 = split_1003[17]
        getitem_18771 = split_1003[18]
        getitem_18772 = split_1003[19]
        getitem_18773 = split_1003[20]
        getitem_18774 = split_1003[21]
        getitem_18775 = split_1003[22]
        getitem_18776 = split_1003[23]
        getitem_18777 = split_1003[24]
        getitem_18778 = split_1003[25]
        getitem_18779 = split_1003[26]
        getitem_18780 = split_1003[27]
        getitem_18781 = split_1003[28]
        getitem_18782 = split_1003[29]
        getitem_18783 = split_1003[30]
        getitem_18784 = split_1003[31]
        getitem_18785 = split_1003[32]
        getitem_18786 = split_1003[33]
        getitem_18787 = split_1003[34]
        getitem_18788 = split_1003[35]
        getitem_18789 = split_1003[36]
        getitem_18790 = split_1003[37]
        getitem_18791 = split_1003[38]
        getitem_18792 = split_1003[39]
        getitem_18793 = split_1003[40]
        getitem_18794 = split_1003[41]
        getitem_18795 = split_1003[42]
        getitem_18796 = split_1003[43]
        getitem_18797 = split_1003[44]
        getitem_18798 = split_1003[45]
        getitem_18799 = split_1003[46]
        getitem_18800 = split_1003[47]
        getitem_18801 = split_1003[48]
        getitem_18802 = split_1003[49]
        getitem_18803 = split_1003[50]
        getitem_18804 = split_1003[51]
        getitem_18805 = split_1003[52]
        getitem_18806 = split_1003[53]
        getitem_18807 = split_1003[54]
        getitem_18808 = split_1003[55]
        getitem_18809 = split_1003[56]
        getitem_18810 = split_1003[57]
        getitem_18811 = split_1003[58]
        getitem_18812 = split_1003[59]
        getitem_18813 = split_1003[60]
        getitem_18814 = split_1003[61]
        getitem_18815 = split_1003[62]
        getitem_18816 = split_1003[63]
        getitem_18817 = split_1003[64]
        getitem_18818 = split_1003[65]
        getitem_18819 = split_1003[66]
        getitem_18820 = split_1003[67]
        getitem_18821 = split_1003[68]
        getitem_18822 = split_1003[69]
        getitem_18823 = split_1003[70]
        getitem_18824 = split_1003[71]
        getitem_18825 = split_1003[72]
        getitem_18826 = split_1003[73]
        getitem_18827 = split_1003[74]
        getitem_18828 = split_1003[75]
        getitem_18829 = split_1003[76]
        getitem_18830 = split_1003[77]
        getitem_18831 = split_1003[78]
        getitem_18832 = split_1003[79]
        getitem_18833 = split_1003[80]
        getitem_18834 = split_1003[81]
        getitem_18835 = split_1003[82]
        getitem_18836 = split_1003[83]
        getitem_18837 = split_1003[84]
        getitem_18838 = split_1003[85]
        getitem_18839 = split_1003[86]
        getitem_18840 = split_1003[87]
        getitem_18841 = split_1003[88]
        getitem_18842 = split_1003[89]
        getitem_18843 = split_1003[90]
        getitem_18844 = split_1003[91]
        getitem_18845 = split_1003[92]
        getitem_18846 = split_1003[93]
        getitem_18847 = split_1003[94]
        getitem_18848 = split_1003[95]
        getitem_18849 = split_1003[96]
        getitem_18850 = split_1003[97]
        getitem_18851 = split_1003[98]
        getitem_18852 = split_1003[99]
        getitem_18853 = split_1003[100]
        getitem_18854 = split_1003[101]
        getitem_18855 = split_1003[102]
        getitem_18856 = split_1003[103]
        getitem_18857 = split_1003[104]
        getitem_18858 = split_1003[105]
        getitem_18859 = split_1003[106]
        getitem_18860 = split_1003[107]
        getitem_18861 = split_1003[108]
        getitem_18862 = split_1003[109]
        getitem_18863 = split_1003[110]
        getitem_18864 = split_1003[111]
        getitem_18865 = split_1003[112]
        getitem_18866 = split_1003[113]
        getitem_18867 = split_1003[114]
        getitem_18868 = split_1003[115];  split_1003 = None
        constant_pad_nd_1219 = torch.ops.aten.constant_pad_nd.default(getitem_18868, [0, 0, 0, 4], 0.0);  getitem_18868 = None
        cat_362 = torch.ops.aten.cat.default([getitem_18753, getitem_18754, getitem_18755, getitem_18756, getitem_18757, getitem_18758, getitem_18759, getitem_18760, getitem_18761, getitem_18762, getitem_18763, getitem_18764, getitem_18765, getitem_18766, getitem_18767, getitem_18768, getitem_18769, getitem_18770, getitem_18771, getitem_18772, getitem_18773, getitem_18774, getitem_18775, getitem_18776, getitem_18777, getitem_18778, getitem_18779, getitem_18780, getitem_18781, getitem_18782, getitem_18783, getitem_18784, getitem_18785, getitem_18786, getitem_18787, getitem_18788, getitem_18789, getitem_18790, getitem_18791, getitem_18792, getitem_18793, getitem_18794, getitem_18795, getitem_18796, getitem_18797, getitem_18798, getitem_18799, getitem_18800, getitem_18801, getitem_18802, getitem_18803, getitem_18804, getitem_18805, getitem_18806, getitem_18807, getitem_18808, getitem_18809, getitem_18810, getitem_18811, getitem_18812, getitem_18813, getitem_18814, getitem_18815, getitem_18816, getitem_18817, getitem_18818, getitem_18819, getitem_18820, getitem_18821, getitem_18822, getitem_18823, getitem_18824, getitem_18825, getitem_18826, getitem_18827, getitem_18828, getitem_18829, getitem_18830, getitem_18831, getitem_18832, getitem_18833, getitem_18834, getitem_18835, getitem_18836, getitem_18837, getitem_18838, getitem_18839, getitem_18840, getitem_18841, getitem_18842, getitem_18843, getitem_18844, getitem_18845, getitem_18846, getitem_18847, getitem_18848, getitem_18849, getitem_18850, getitem_18851, getitem_18852, getitem_18853, getitem_18854, getitem_18855, getitem_18856, getitem_18857, getitem_18858, getitem_18859, getitem_18860, getitem_18861, getitem_18862, getitem_18863, getitem_18864, getitem_18865, getitem_18866, getitem_18867, constant_pad_nd_1219, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_18753 = getitem_18754 = getitem_18755 = getitem_18756 = getitem_18757 = getitem_18758 = getitem_18759 = getitem_18760 = getitem_18761 = getitem_18762 = getitem_18763 = getitem_18764 = getitem_18765 = getitem_18766 = getitem_18767 = getitem_18768 = getitem_18769 = getitem_18770 = getitem_18771 = getitem_18772 = getitem_18773 = getitem_18774 = getitem_18775 = getitem_18776 = getitem_18777 = getitem_18778 = getitem_18779 = getitem_18780 = getitem_18781 = getitem_18782 = getitem_18783 = getitem_18784 = getitem_18785 = getitem_18786 = getitem_18787 = getitem_18788 = getitem_18789 = getitem_18790 = getitem_18791 = getitem_18792 = getitem_18793 = getitem_18794 = getitem_18795 = getitem_18796 = getitem_18797 = getitem_18798 = getitem_18799 = getitem_18800 = getitem_18801 = getitem_18802 = getitem_18803 = getitem_18804 = getitem_18805 = getitem_18806 = getitem_18807 = getitem_18808 = getitem_18809 = getitem_18810 = getitem_18811 = getitem_18812 = getitem_18813 = getitem_18814 = getitem_18815 = getitem_18816 = getitem_18817 = getitem_18818 = getitem_18819 = getitem_18820 = getitem_18821 = getitem_18822 = getitem_18823 = getitem_18824 = getitem_18825 = getitem_18826 = getitem_18827 = getitem_18828 = getitem_18829 = getitem_18830 = getitem_18831 = getitem_18832 = getitem_18833 = getitem_18834 = getitem_18835 = getitem_18836 = getitem_18837 = getitem_18838 = getitem_18839 = getitem_18840 = getitem_18841 = getitem_18842 = getitem_18843 = getitem_18844 = getitem_18845 = getitem_18846 = getitem_18847 = getitem_18848 = getitem_18849 = getitem_18850 = getitem_18851 = getitem_18852 = getitem_18853 = getitem_18854 = getitem_18855 = getitem_18856 = getitem_18857 = getitem_18858 = getitem_18859 = getitem_18860 = getitem_18861 = getitem_18862 = getitem_18863 = getitem_18864 = getitem_18865 = getitem_18866 = getitem_18867 = constant_pad_nd_1219 = None
        reduce_scatter_tensor_223 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_362, 'avg', 128, '0');  cat_362 = None
        wait_tensor_814 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_223);  reduce_scatter_tensor_223 = None
        slice_256 = torch.ops.aten.slice.Tensor(permute_1193, 3, 0, 128)
        slice_257 = torch.ops.aten.slice.Tensor(permute_1193, 3, 128, 192);  permute_1193 = None
        convert_element_type_2629 = torch.ops.prims.convert_element_type.default(slice_257, torch.float32);  slice_257 = None
        view_2081 = torch.ops.aten.view.default(convert_element_type_2629, [2, 4096, 16, 32, 2]);  convert_element_type_2629 = None
        view_as_complex_85 = torch.ops.aten.view_as_complex.default(view_2081);  view_2081 = None
        mul_1828 = torch.ops.aten.mul.Tensor(view_as_complex_85, clone_9);  view_as_complex_85 = None
        view_as_real_85 = torch.ops.aten.view_as_real.default(mul_1828);  mul_1828 = None
        view_2082 = torch.ops.aten.view.default(view_as_real_85, [2, 4096, 16, 64]);  view_as_real_85 = None
        convert_element_type_2630 = torch.ops.prims.convert_element_type.default(view_2082, torch.bfloat16);  view_2082 = None
        cat_363 = torch.ops.aten.cat.default([slice_256, convert_element_type_2630], 3);  slice_256 = convert_element_type_2630 = None
        view_2083 = torch.ops.aten.view.default(cat_363, [2, 4096, 3072]);  cat_363 = None
        view_2084 = torch.ops.aten.view.default(view_2083, [8192, 3072]);  view_2083 = None
        permute_1202 = torch.ops.aten.permute.default(view_2084, [1, 0])
        mm_472 = torch.ops.aten.mm.default(permute_1202, view_706);  permute_1202 = view_706 = None
        convert_element_type_580 = torch.ops.prims.convert_element_type.default(primals_184, torch.bfloat16);  primals_184 = None
        all_gather_into_tensor_182 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_580, 128, '0');  convert_element_type_580 = None
        wait_tensor_222 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_182);  all_gather_into_tensor_182 = None
        permute_161 = torch.ops.aten.permute.default(wait_tensor_222, [1, 0]);  wait_tensor_222 = None
        permute_1204 = torch.ops.aten.permute.default(permute_161, [1, 0]);  permute_161 = None
        mm_473 = torch.ops.aten.mm.default(view_2084, permute_1204);  view_2084 = permute_1204 = None
        view_2085 = torch.ops.aten.view.default(mm_473, [2, 4096, 2048]);  mm_473 = None
        add_2013 = torch.ops.aten.add.Tensor(view_2080, view_2085);  view_2080 = view_2085 = None
        convert_element_type_2635 = torch.ops.prims.convert_element_type.default(mm_472, torch.float32);  mm_472 = None
        reduce_scatter_tensor_224 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2635, 'avg', 128, '0');  convert_element_type_2635 = None
        wait_tensor_815 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_224);  reduce_scatter_tensor_224 = None
        convert_element_type_2636 = torch.ops.prims.convert_element_type.default(add_2013, torch.float32);  add_2013 = None
        convert_element_type_577 = torch.ops.prims.convert_element_type.default(primals_183, torch.bfloat16);  primals_183 = None
        all_gather_into_tensor_181 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_577, 128, '0');  convert_element_type_577 = None
        wait_tensor_221 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_181);  all_gather_into_tensor_181 = None
        convert_element_type_2638 = torch.ops.prims.convert_element_type.default(wait_tensor_221, torch.float32);  wait_tensor_221 = None
        mul_1829 = torch.ops.aten.mul.Tensor(convert_element_type_2636, convert_element_type_2638);  convert_element_type_2638 = None
        convert_element_type_578 = torch.ops.prims.convert_element_type.default(add_685, torch.float32);  add_685 = None
        mul_499 = torch.ops.aten.mul.Tensor(convert_element_type_578, rsqrt_33);  convert_element_type_578 = None
        mul_1831 = torch.ops.aten.mul.Tensor(mul_499, mul_1829)
        sum_233 = torch.ops.aten.sum.dim_IntList(mul_1831, [2], True);  mul_1831 = None
        div_227 = torch.ops.aten.div.Tensor(mul_499, 2048)
        mul_1832 = torch.ops.aten.mul.Tensor(div_227, sum_233);  div_227 = sum_233 = None
        sub_720 = torch.ops.aten.sub.Tensor(mul_1829, mul_1832);  mul_1829 = mul_1832 = None
        mul_1833 = torch.ops.aten.mul.Tensor(sub_720, rsqrt_33);  sub_720 = rsqrt_33 = None
        mul_1834 = torch.ops.aten.mul.Tensor(convert_element_type_2636, mul_499);  convert_element_type_2636 = mul_499 = None
        sum_234 = torch.ops.aten.sum.dim_IntList(mul_1834, [0, 1]);  mul_1834 = None
        convert_element_type_2639 = torch.ops.prims.convert_element_type.default(mul_1833, torch.bfloat16);  mul_1833 = None
        add_2014 = torch.ops.aten.add.Tensor(add_2012, convert_element_type_2639);  add_2012 = convert_element_type_2639 = None
        convert_element_type_default_34 = torch.ops.prims.convert_element_type.default(sum_234, torch.float32);  sum_234 = None
        reduce_scatter_tensor_225 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_34, 'avg', 128, '0');  convert_element_type_default_34 = None
        wait_tensor_816 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_225);  reduce_scatter_tensor_225 = None
        view_2086 = torch.ops.aten.view.default(add_2014, [8192, 2048])
        unsqueeze_69 = torch.ops.aten.unsqueeze.default(view_2086, 1)
        convert_element_type_2642 = torch.ops.prims.convert_element_type.default(unsqueeze_69, torch.float32);  unsqueeze_69 = None
        bmm_58 = torch.ops.aten.bmm.default(permute_1206, convert_element_type_2642);  permute_1206 = None
        bmm_59 = torch.ops.aten.bmm.default(convert_element_type_2642, permute_1207);  convert_element_type_2642 = permute_1207 = None
        convert_element_type_2643 = torch.ops.prims.convert_element_type.default(bmm_58, torch.bfloat16);  bmm_58 = None
        view_2087 = torch.ops.aten.view.default(bmm_59, [8192, 6]);  bmm_59 = None
        view_2088 = torch.ops.aten.view.default(convert_element_type_2643, [49152, 2048]);  convert_element_type_2643 = None
        index_84 = torch.ops.aten.index.Tensor(view_2088, [getitem_1011]);  view_2088 = getitem_1011 = None
        permute_1208 = torch.ops.aten.permute.default(view_2086, [1, 0])
        mm_474 = torch.ops.aten.mm.default(permute_1208, mul_496);  permute_1208 = mul_496 = None
        convert_element_type_572 = torch.ops.prims.convert_element_type.default(primals_182, torch.bfloat16);  primals_182 = None
        all_gather_into_tensor_180 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_572, 128, '0');  convert_element_type_572 = None
        wait_tensor_220 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_180);  all_gather_into_tensor_180 = None
        permute_160 = torch.ops.aten.permute.default(wait_tensor_220, [1, 0]);  wait_tensor_220 = None
        permute_1210 = torch.ops.aten.permute.default(permute_160, [1, 0]);  permute_160 = None
        mm_475 = torch.ops.aten.mm.default(view_2086, permute_1210);  view_2086 = permute_1210 = None
        convert_element_type_2648 = torch.ops.prims.convert_element_type.default(mm_474, torch.float32);  mm_474 = None
        reduce_scatter_tensor_226 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2648, 'avg', 128, '0');  convert_element_type_2648 = None
        wait_tensor_817 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_226);  reduce_scatter_tensor_226 = None
        convert_element_type_567 = torch.ops.prims.convert_element_type.default(mm_84, torch.float32);  mm_84 = None
        neg_20 = torch.ops.aten.neg.default(convert_element_type_567)
        exp_30 = torch.ops.aten.exp.default(neg_20);  neg_20 = None
        add_680 = torch.ops.aten.add.Tensor(exp_30, 1);  exp_30 = None
        div_50 = torch.ops.aten.div.Tensor(convert_element_type_567, add_680)
        convert_element_type_568 = torch.ops.prims.convert_element_type.default(div_50, torch.bfloat16);  div_50 = None
        mul_1835 = torch.ops.aten.mul.Tensor(mm_475, convert_element_type_568);  convert_element_type_568 = None
        mul_1836 = torch.ops.aten.mul.Tensor(mm_475, mm_85);  mm_475 = mm_85 = None
        permute_1212 = torch.ops.aten.permute.default(mul_1835, [1, 0])
        mm_476 = torch.ops.aten.mm.default(permute_1212, view_661);  permute_1212 = None
        convert_element_type_569 = torch.ops.prims.convert_element_type.default(primals_181, torch.bfloat16);  primals_181 = None
        all_gather_into_tensor_179 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_569, 128, '0');  convert_element_type_569 = None
        wait_tensor_219 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_179);  all_gather_into_tensor_179 = None
        permute_159 = torch.ops.aten.permute.default(wait_tensor_219, [1, 0]);  wait_tensor_219 = None
        permute_1214 = torch.ops.aten.permute.default(permute_159, [1, 0]);  permute_159 = None
        mm_477 = torch.ops.aten.mm.default(mul_1835, permute_1214);  mul_1835 = permute_1214 = None
        convert_element_type_2653 = torch.ops.prims.convert_element_type.default(mm_476, torch.float32);  mm_476 = None
        reduce_scatter_tensor_227 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2653, 'avg', 128, '0');  convert_element_type_2653 = None
        wait_tensor_818 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_227);  reduce_scatter_tensor_227 = None
        convert_element_type_2654 = torch.ops.prims.convert_element_type.default(mul_1836, torch.float32);  mul_1836 = None
        reciprocal_32 = torch.ops.aten.reciprocal.default(add_680);  add_680 = None
        mul_1837 = torch.ops.aten.mul.Tensor(reciprocal_32, 1);  reciprocal_32 = None
        mul_1838 = torch.ops.aten.mul.Tensor(convert_element_type_2654, mul_1837);  convert_element_type_2654 = None
        sub_721 = torch.ops.aten.sub.Tensor(1, mul_1837);  mul_1837 = None
        mul_1839 = torch.ops.aten.mul.Tensor(convert_element_type_567, sub_721);  convert_element_type_567 = sub_721 = None
        add_2016 = torch.ops.aten.add.Tensor(mul_1839, 1);  mul_1839 = None
        mul_1840 = torch.ops.aten.mul.Tensor(mul_1838, add_2016);  mul_1838 = add_2016 = None
        convert_element_type_2656 = torch.ops.prims.convert_element_type.default(mul_1840, torch.bfloat16);  mul_1840 = None
        permute_1216 = torch.ops.aten.permute.default(convert_element_type_2656, [1, 0])
        mm_478 = torch.ops.aten.mm.default(permute_1216, view_661);  permute_1216 = None
        convert_element_type_564 = torch.ops.prims.convert_element_type.default(primals_180, torch.bfloat16);  primals_180 = None
        all_gather_into_tensor_178 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_564, 128, '0');  convert_element_type_564 = None
        wait_tensor_218 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_178);  all_gather_into_tensor_178 = None
        permute_158 = torch.ops.aten.permute.default(wait_tensor_218, [1, 0]);  wait_tensor_218 = None
        permute_1218 = torch.ops.aten.permute.default(permute_158, [1, 0]);  permute_158 = None
        mm_479 = torch.ops.aten.mm.default(convert_element_type_2656, permute_1218);  convert_element_type_2656 = permute_1218 = None
        add_2017 = torch.ops.aten.add.Tensor(mm_477, mm_479);  mm_477 = mm_479 = None
        convert_element_type_2661 = torch.ops.prims.convert_element_type.default(mm_478, torch.float32);  mm_478 = None
        reduce_scatter_tensor_228 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2661, 'avg', 128, '0');  convert_element_type_2661 = None
        wait_tensor_819 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_228);  reduce_scatter_tensor_228 = None
        all_to_all_single_110 = torch.ops._c10d_functional.all_to_all_single.default(index_84, [_local_scalar_dense_152, _local_scalar_dense_153, _local_scalar_dense_154, _local_scalar_dense_155, _local_scalar_dense_156, _local_scalar_dense_157, _local_scalar_dense_158, _local_scalar_dense_159], [_local_scalar_dense_144, _local_scalar_dense_145, _local_scalar_dense_146, _local_scalar_dense_147, _local_scalar_dense_148, _local_scalar_dense_149, _local_scalar_dense_150, _local_scalar_dense_151], '1033');  index_84 = None
        wait_tensor_820 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_110);  all_to_all_single_110 = None
        full_444 = torch.ops.aten.full.default([sym_size_int_37, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_37 = None
        slice_scatter_16 = torch.ops.aten.slice_scatter.default(full_444, wait_tensor_820, 0, 0, -1);  wait_tensor_820 = None
        index_85 = torch.ops.aten.index.Tensor(slice_scatter_16, [getitem_1012]);  slice_scatter_16 = None
        permute_1220 = torch.ops.aten.permute.default(index_85, [1, 0])
        _grouped_mm_174 = torch.ops.aten._grouped_mm.default(permute_1220, mul_476, cumsum_29);  permute_1220 = mul_476 = None
        _grouped_mm_175 = torch.ops.aten._grouped_mm.default(index_85, permute_1222, cumsum_29);  index_85 = permute_1222 = None
        convert_element_type_562 = torch.ops.prims.convert_element_type.default(_grouped_mm_27, torch.float32);  _grouped_mm_27 = None
        neg_19 = torch.ops.aten.neg.default(convert_element_type_562)
        exp_29 = torch.ops.aten.exp.default(neg_19);  neg_19 = None
        add_644 = torch.ops.aten.add.Tensor(exp_29, 1);  exp_29 = None
        div_49 = torch.ops.aten.div.Tensor(convert_element_type_562, add_644)
        convert_element_type_563 = torch.ops.prims.convert_element_type.default(div_49, torch.bfloat16);  div_49 = None
        mul_1841 = torch.ops.aten.mul.Tensor(_grouped_mm_175, convert_element_type_563);  convert_element_type_563 = None
        mul_1842 = torch.ops.aten.mul.Tensor(_grouped_mm_175, _grouped_mm_28);  _grouped_mm_175 = _grouped_mm_28 = None
        permute_1224 = torch.ops.aten.permute.default(mul_1841, [1, 0])
        _grouped_mm_176 = torch.ops.aten._grouped_mm.default(permute_1224, index_19, cumsum_29);  permute_1224 = None
        _grouped_mm_177 = torch.ops.aten._grouped_mm.default(mul_1841, permute_1226, cumsum_29);  mul_1841 = permute_1226 = None
        convert_element_type_2662 = torch.ops.prims.convert_element_type.default(mul_1842, torch.float32);  mul_1842 = None
        reciprocal_33 = torch.ops.aten.reciprocal.default(add_644);  add_644 = None
        mul_1843 = torch.ops.aten.mul.Tensor(reciprocal_33, 1);  reciprocal_33 = None
        mul_1844 = torch.ops.aten.mul.Tensor(convert_element_type_2662, mul_1843);  convert_element_type_2662 = None
        sub_722 = torch.ops.aten.sub.Tensor(1, mul_1843);  mul_1843 = None
        mul_1845 = torch.ops.aten.mul.Tensor(convert_element_type_562, sub_722);  convert_element_type_562 = sub_722 = None
        add_2019 = torch.ops.aten.add.Tensor(mul_1845, 1);  mul_1845 = None
        mul_1846 = torch.ops.aten.mul.Tensor(mul_1844, add_2019);  mul_1844 = add_2019 = None
        convert_element_type_2664 = torch.ops.prims.convert_element_type.default(mul_1846, torch.bfloat16);  mul_1846 = None
        permute_1228 = torch.ops.aten.permute.default(convert_element_type_2664, [1, 0])
        _grouped_mm_178 = torch.ops.aten._grouped_mm.default(permute_1228, index_19, cumsum_29);  permute_1228 = index_19 = None
        _grouped_mm_179 = torch.ops.aten._grouped_mm.default(convert_element_type_2664, permute_1230, cumsum_29);  convert_element_type_2664 = permute_1230 = cumsum_29 = None
        add_2020 = torch.ops.aten.add.Tensor(_grouped_mm_177, _grouped_mm_179);  _grouped_mm_177 = _grouped_mm_179 = None
        convert_element_type_2665 = torch.ops.prims.convert_element_type.default(_grouped_mm_176, torch.float32);  _grouped_mm_176 = None
        div_228 = torch.ops.aten.div.Tensor(convert_element_type_2665, 128);  convert_element_type_2665 = None
        split_1005 = torch.ops.aten.split.Tensor(div_228, 88, 1);  div_228 = None
        getitem_18885 = split_1005[0]
        getitem_18902 = split_1005[1]
        getitem_18919 = split_1005[2]
        getitem_18936 = split_1005[3]
        getitem_18953 = split_1005[4]
        getitem_18970 = split_1005[5]
        getitem_18987 = split_1005[6]
        getitem_19004 = split_1005[7]
        getitem_19021 = split_1005[8]
        getitem_19038 = split_1005[9]
        getitem_19055 = split_1005[10]
        getitem_19072 = split_1005[11]
        getitem_19089 = split_1005[12]
        getitem_19106 = split_1005[13]
        getitem_19123 = split_1005[14]
        getitem_19140 = split_1005[15];  split_1005 = None
        cat_364 = torch.ops.aten.cat.default([getitem_18885, getitem_18902, getitem_18919, getitem_18936, getitem_18953, getitem_18970, getitem_18987, getitem_19004, getitem_19021, getitem_19038, getitem_19055, getitem_19072, getitem_19089, getitem_19106, getitem_19123, getitem_19140]);  getitem_18885 = getitem_18902 = getitem_18919 = getitem_18936 = getitem_18953 = getitem_18970 = getitem_18987 = getitem_19004 = getitem_19021 = getitem_19038 = getitem_19055 = getitem_19072 = getitem_19089 = getitem_19106 = getitem_19123 = getitem_19140 = None
        reduce_scatter_tensor_229 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_364, 'sum', 16, '1025');  cat_364 = None
        wait_tensor_821 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_229);  reduce_scatter_tensor_229 = None
        convert_element_type_2666 = torch.ops.prims.convert_element_type.default(_grouped_mm_174, torch.float32);  _grouped_mm_174 = None
        div_229 = torch.ops.aten.div.Tensor(convert_element_type_2666, 128);  convert_element_type_2666 = None
        split_1022 = torch.ops.aten.split.Tensor(div_229, 128, 1);  div_229 = None
        getitem_19157 = split_1022[0]
        getitem_19174 = split_1022[1]
        getitem_19191 = split_1022[2]
        getitem_19208 = split_1022[3]
        getitem_19225 = split_1022[4]
        getitem_19242 = split_1022[5]
        getitem_19259 = split_1022[6]
        getitem_19276 = split_1022[7]
        getitem_19293 = split_1022[8]
        getitem_19310 = split_1022[9]
        getitem_19327 = split_1022[10]
        getitem_19344 = split_1022[11]
        getitem_19361 = split_1022[12]
        getitem_19378 = split_1022[13]
        getitem_19395 = split_1022[14]
        getitem_19412 = split_1022[15];  split_1022 = None
        cat_365 = torch.ops.aten.cat.default([getitem_19157, getitem_19174, getitem_19191, getitem_19208, getitem_19225, getitem_19242, getitem_19259, getitem_19276, getitem_19293, getitem_19310, getitem_19327, getitem_19344, getitem_19361, getitem_19378, getitem_19395, getitem_19412]);  getitem_19157 = getitem_19174 = getitem_19191 = getitem_19208 = getitem_19225 = getitem_19242 = getitem_19259 = getitem_19276 = getitem_19293 = getitem_19310 = getitem_19327 = getitem_19344 = getitem_19361 = getitem_19378 = getitem_19395 = getitem_19412 = None
        reduce_scatter_tensor_230 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_365, 'sum', 16, '1025');  cat_365 = None
        wait_tensor_822 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_230);  reduce_scatter_tensor_230 = None
        convert_element_type_2667 = torch.ops.prims.convert_element_type.default(_grouped_mm_178, torch.float32);  _grouped_mm_178 = None
        div_230 = torch.ops.aten.div.Tensor(convert_element_type_2667, 128);  convert_element_type_2667 = None
        split_1039 = torch.ops.aten.split.Tensor(div_230, 88, 1);  div_230 = None
        getitem_19429 = split_1039[0]
        getitem_19446 = split_1039[1]
        getitem_19463 = split_1039[2]
        getitem_19480 = split_1039[3]
        getitem_19497 = split_1039[4]
        getitem_19514 = split_1039[5]
        getitem_19531 = split_1039[6]
        getitem_19548 = split_1039[7]
        getitem_19565 = split_1039[8]
        getitem_19582 = split_1039[9]
        getitem_19599 = split_1039[10]
        getitem_19616 = split_1039[11]
        getitem_19633 = split_1039[12]
        getitem_19650 = split_1039[13]
        getitem_19667 = split_1039[14]
        getitem_19684 = split_1039[15];  split_1039 = None
        cat_366 = torch.ops.aten.cat.default([getitem_19429, getitem_19446, getitem_19463, getitem_19480, getitem_19497, getitem_19514, getitem_19531, getitem_19548, getitem_19565, getitem_19582, getitem_19599, getitem_19616, getitem_19633, getitem_19650, getitem_19667, getitem_19684]);  getitem_19429 = getitem_19446 = getitem_19463 = getitem_19480 = getitem_19497 = getitem_19514 = getitem_19531 = getitem_19548 = getitem_19565 = getitem_19582 = getitem_19599 = getitem_19616 = getitem_19633 = getitem_19650 = getitem_19667 = getitem_19684 = None
        reduce_scatter_tensor_231 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_366, 'sum', 16, '1025');  cat_366 = None
        wait_tensor_823 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_231);  reduce_scatter_tensor_231 = None
        index_put_84 = torch.ops.aten.index_put.default(full_444, [getitem_1012], add_2020, True);  full_444 = getitem_1012 = add_2020 = None
        slice_258 = torch.ops.aten.slice.Tensor(index_put_84, 0, 0, add_2021);  index_put_84 = add_2021 = None
        all_to_all_single_111 = torch.ops._c10d_functional.all_to_all_single.default(slice_258, [_local_scalar_dense_144, _local_scalar_dense_145, _local_scalar_dense_146, _local_scalar_dense_147, _local_scalar_dense_148, _local_scalar_dense_149, _local_scalar_dense_150, _local_scalar_dense_151], [_local_scalar_dense_152, _local_scalar_dense_153, _local_scalar_dense_154, _local_scalar_dense_155, _local_scalar_dense_156, _local_scalar_dense_157, _local_scalar_dense_158, _local_scalar_dense_159], '1033');  slice_258 = _local_scalar_dense_144 = _local_scalar_dense_145 = _local_scalar_dense_146 = _local_scalar_dense_147 = _local_scalar_dense_148 = _local_scalar_dense_149 = _local_scalar_dense_150 = _local_scalar_dense_151 = _local_scalar_dense_152 = _local_scalar_dense_153 = _local_scalar_dense_154 = _local_scalar_dense_155 = _local_scalar_dense_156 = _local_scalar_dense_157 = _local_scalar_dense_158 = _local_scalar_dense_159 = None
        wait_tensor_824 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_111);  all_to_all_single_111 = None
        index_put_85 = torch.ops.aten.index_put.default(full_default_52, [div_47], wait_tensor_824, True);  div_47 = wait_tensor_824 = None
        add_2025 = torch.ops.aten.add.Tensor(add_2017, index_put_85);  add_2017 = index_put_85 = None
        mul_1847 = torch.ops.aten.mul.Tensor(view_2087, 1.0);  view_2087 = None
        scatter_add_16 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_1009, mul_1847);  getitem_1009 = mul_1847 = None
        convert_element_type_551 = torch.ops.prims.convert_element_type.default(mm_83, torch.float32);  mm_83 = None
        sub_216 = torch.ops.aten.sub.Tensor(convert_element_type_551, amax_9);  convert_element_type_551 = amax_9 = None
        exp_28 = torch.ops.aten.exp.default(sub_216);  sub_216 = None
        div_46 = torch.ops.aten.div.Tensor(exp_28, sum_37);  exp_28 = sum_37 = None
        mul_1848 = torch.ops.aten.mul.Tensor(scatter_add_16, div_46);  scatter_add_16 = None
        sum_235 = torch.ops.aten.sum.dim_IntList(mul_1848, [1], True)
        neg_103 = torch.ops.aten.neg.default(div_46);  div_46 = None
        fma_16 = torch.ops.prims.fma.default(neg_103, sum_235, mul_1848);  neg_103 = sum_235 = mul_1848 = None
        convert_element_type_2668 = torch.ops.prims.convert_element_type.default(fma_16, torch.bfloat16);  fma_16 = None
        permute_1232 = torch.ops.aten.permute.default(convert_element_type_2668, [1, 0])
        mm_480 = torch.ops.aten.mm.default(permute_1232, view_661);  permute_1232 = view_661 = None
        convert_element_type_548 = torch.ops.prims.convert_element_type.default(primals_175, torch.bfloat16);  primals_175 = None
        all_gather_into_tensor_171 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_548, 128, '0');  convert_element_type_548 = None
        wait_tensor_207 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_171);  all_gather_into_tensor_171 = None
        slice_63 = torch.ops.aten.slice.Tensor(wait_tensor_207, 0, 0, 64);  wait_tensor_207 = None
        permute_154 = torch.ops.aten.permute.default(slice_63, [1, 0]);  slice_63 = None
        permute_1234 = torch.ops.aten.permute.default(permute_154, [1, 0]);  permute_154 = None
        mm_481 = torch.ops.aten.mm.default(convert_element_type_2668, permute_1234);  convert_element_type_2668 = permute_1234 = None
        add_2026 = torch.ops.aten.add.Tensor(add_2025, mm_481);  add_2025 = mm_481 = None
        convert_element_type_2673 = torch.ops.prims.convert_element_type.default(mm_480, torch.float32);  mm_480 = None
        split_1055 = torch.ops.aten.split.Tensor(convert_element_type_2673, 1);  convert_element_type_2673 = None
        getitem_19685 = split_1055[0]
        getitem_19686 = split_1055[1]
        getitem_19687 = split_1055[2]
        getitem_19688 = split_1055[3]
        getitem_19689 = split_1055[4]
        getitem_19690 = split_1055[5]
        getitem_19691 = split_1055[6]
        getitem_19692 = split_1055[7]
        getitem_19693 = split_1055[8]
        getitem_19694 = split_1055[9]
        getitem_19695 = split_1055[10]
        getitem_19696 = split_1055[11]
        getitem_19697 = split_1055[12]
        getitem_19698 = split_1055[13]
        getitem_19699 = split_1055[14]
        getitem_19700 = split_1055[15]
        getitem_19701 = split_1055[16]
        getitem_19702 = split_1055[17]
        getitem_19703 = split_1055[18]
        getitem_19704 = split_1055[19]
        getitem_19705 = split_1055[20]
        getitem_19706 = split_1055[21]
        getitem_19707 = split_1055[22]
        getitem_19708 = split_1055[23]
        getitem_19709 = split_1055[24]
        getitem_19710 = split_1055[25]
        getitem_19711 = split_1055[26]
        getitem_19712 = split_1055[27]
        getitem_19713 = split_1055[28]
        getitem_19714 = split_1055[29]
        getitem_19715 = split_1055[30]
        getitem_19716 = split_1055[31]
        getitem_19717 = split_1055[32]
        getitem_19718 = split_1055[33]
        getitem_19719 = split_1055[34]
        getitem_19720 = split_1055[35]
        getitem_19721 = split_1055[36]
        getitem_19722 = split_1055[37]
        getitem_19723 = split_1055[38]
        getitem_19724 = split_1055[39]
        getitem_19725 = split_1055[40]
        getitem_19726 = split_1055[41]
        getitem_19727 = split_1055[42]
        getitem_19728 = split_1055[43]
        getitem_19729 = split_1055[44]
        getitem_19730 = split_1055[45]
        getitem_19731 = split_1055[46]
        getitem_19732 = split_1055[47]
        getitem_19733 = split_1055[48]
        getitem_19734 = split_1055[49]
        getitem_19735 = split_1055[50]
        getitem_19736 = split_1055[51]
        getitem_19737 = split_1055[52]
        getitem_19738 = split_1055[53]
        getitem_19739 = split_1055[54]
        getitem_19740 = split_1055[55]
        getitem_19741 = split_1055[56]
        getitem_19742 = split_1055[57]
        getitem_19743 = split_1055[58]
        getitem_19744 = split_1055[59]
        getitem_19745 = split_1055[60]
        getitem_19746 = split_1055[61]
        getitem_19747 = split_1055[62]
        getitem_19748 = split_1055[63];  split_1055 = None
        cat_367 = torch.ops.aten.cat.default([getitem_19685, getitem_19686, getitem_19687, getitem_19688, getitem_19689, getitem_19690, getitem_19691, getitem_19692, getitem_19693, getitem_19694, getitem_19695, getitem_19696, getitem_19697, getitem_19698, getitem_19699, getitem_19700, getitem_19701, getitem_19702, getitem_19703, getitem_19704, getitem_19705, getitem_19706, getitem_19707, getitem_19708, getitem_19709, getitem_19710, getitem_19711, getitem_19712, getitem_19713, getitem_19714, getitem_19715, getitem_19716, getitem_19717, getitem_19718, getitem_19719, getitem_19720, getitem_19721, getitem_19722, getitem_19723, getitem_19724, getitem_19725, getitem_19726, getitem_19727, getitem_19728, getitem_19729, getitem_19730, getitem_19731, getitem_19732, getitem_19733, getitem_19734, getitem_19735, getitem_19736, getitem_19737, getitem_19738, getitem_19739, getitem_19740, getitem_19741, getitem_19742, getitem_19743, getitem_19744, getitem_19745, getitem_19746, getitem_19747, getitem_19748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_19685 = getitem_19686 = getitem_19687 = getitem_19688 = getitem_19689 = getitem_19690 = getitem_19691 = getitem_19692 = getitem_19693 = getitem_19694 = getitem_19695 = getitem_19696 = getitem_19697 = getitem_19698 = getitem_19699 = getitem_19700 = getitem_19701 = getitem_19702 = getitem_19703 = getitem_19704 = getitem_19705 = getitem_19706 = getitem_19707 = getitem_19708 = getitem_19709 = getitem_19710 = getitem_19711 = getitem_19712 = getitem_19713 = getitem_19714 = getitem_19715 = getitem_19716 = getitem_19717 = getitem_19718 = getitem_19719 = getitem_19720 = getitem_19721 = getitem_19722 = getitem_19723 = getitem_19724 = getitem_19725 = getitem_19726 = getitem_19727 = getitem_19728 = getitem_19729 = getitem_19730 = getitem_19731 = getitem_19732 = getitem_19733 = getitem_19734 = getitem_19735 = getitem_19736 = getitem_19737 = getitem_19738 = getitem_19739 = getitem_19740 = getitem_19741 = getitem_19742 = getitem_19743 = getitem_19744 = getitem_19745 = getitem_19746 = getitem_19747 = getitem_19748 = None
        reduce_scatter_tensor_232 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_367, 'avg', 128, '0');  cat_367 = None
        wait_tensor_825 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_232);  reduce_scatter_tensor_232 = None
        view_2089 = torch.ops.aten.view.default(add_2026, [2, 4096, 2048]);  add_2026 = None
        convert_element_type_2674 = torch.ops.prims.convert_element_type.default(view_2089, torch.float32);  view_2089 = None
        convert_element_type_545 = torch.ops.prims.convert_element_type.default(primals_173, torch.bfloat16);  primals_173 = None
        all_gather_into_tensor_170 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_545, 128, '0');  convert_element_type_545 = None
        wait_tensor_206 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_170);  all_gather_into_tensor_170 = None
        convert_element_type_2676 = torch.ops.prims.convert_element_type.default(wait_tensor_206, torch.float32);  wait_tensor_206 = None
        mul_1849 = torch.ops.aten.mul.Tensor(convert_element_type_2674, convert_element_type_2676);  convert_element_type_2676 = None
        convert_element_type_546 = torch.ops.prims.convert_element_type.default(add_620, torch.float32);  add_620 = None
        mul_456 = torch.ops.aten.mul.Tensor(convert_element_type_546, rsqrt_32);  convert_element_type_546 = None
        mul_1851 = torch.ops.aten.mul.Tensor(mul_456, mul_1849)
        sum_236 = torch.ops.aten.sum.dim_IntList(mul_1851, [2], True);  mul_1851 = None
        div_231 = torch.ops.aten.div.Tensor(mul_456, 2048)
        mul_1852 = torch.ops.aten.mul.Tensor(div_231, sum_236);  div_231 = sum_236 = None
        sub_724 = torch.ops.aten.sub.Tensor(mul_1849, mul_1852);  mul_1849 = mul_1852 = None
        mul_1853 = torch.ops.aten.mul.Tensor(sub_724, rsqrt_32);  sub_724 = rsqrt_32 = None
        mul_1854 = torch.ops.aten.mul.Tensor(convert_element_type_2674, mul_456);  convert_element_type_2674 = mul_456 = None
        sum_237 = torch.ops.aten.sum.dim_IntList(mul_1854, [0, 1]);  mul_1854 = None
        convert_element_type_2677 = torch.ops.prims.convert_element_type.default(mul_1853, torch.bfloat16);  mul_1853 = None
        add_2027 = torch.ops.aten.add.Tensor(add_2014, convert_element_type_2677);  add_2014 = convert_element_type_2677 = None
        convert_element_type_default_33 = torch.ops.prims.convert_element_type.default(sum_237, torch.float32);  sum_237 = None
        reduce_scatter_tensor_233 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_33, 'avg', 128, '0');  convert_element_type_default_33 = None
        wait_tensor_826 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_233);  reduce_scatter_tensor_233 = None
        view_2090 = torch.ops.aten.view.default(add_2027, [8192, 2048])
        permute_1236 = torch.ops.aten.permute.default(view_2090, [1, 0])
        permute_152 = torch.ops.aten.permute.default(getitem_1005, [0, 2, 1, 3])
        view_656 = torch.ops.aten.view.default(permute_152, [2, 4096, -1]);  permute_152 = None
        view_658 = torch.ops.aten.view.default(view_656, [8192, 2048]);  view_656 = None
        mm_482 = torch.ops.aten.mm.default(permute_1236, view_658);  permute_1236 = view_658 = None
        convert_element_type_542 = torch.ops.prims.convert_element_type.default(primals_172, torch.bfloat16);  primals_172 = None
        all_gather_into_tensor_169 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_542, 128, '0');  convert_element_type_542 = None
        wait_tensor_205 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_169);  all_gather_into_tensor_169 = None
        permute_153 = torch.ops.aten.permute.default(wait_tensor_205, [1, 0]);  wait_tensor_205 = None
        permute_1238 = torch.ops.aten.permute.default(permute_153, [1, 0]);  permute_153 = None
        mm_483 = torch.ops.aten.mm.default(view_2090, permute_1238);  view_2090 = permute_1238 = None
        view_2091 = torch.ops.aten.view.default(mm_483, [2, 4096, 2048]);  mm_483 = None
        convert_element_type_2684 = torch.ops.prims.convert_element_type.default(mm_482, torch.float32);  mm_482 = None
        reduce_scatter_tensor_234 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2684, 'avg', 128, '0');  convert_element_type_2684 = None
        wait_tensor_827 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_234);  reduce_scatter_tensor_234 = None
        view_2092 = torch.ops.aten.view.default(view_2091, [2, 4096, 16, 128]);  view_2091 = None
        permute_1240 = torch.ops.aten.permute.default(view_2092, [0, 2, 1, 3]);  view_2092 = None
        fw_graph16 = self.fw_graph16
        joint_graph16 = self.joint_graph16
        mask_graph16 = self.mask_graph16
        flex_attention_backward_16 = torch.ops.higher_order.flex_attention_backward(permute_149, permute_150, permute_151, getitem_1005, getitem_1006, permute_1240, None, fw_graph16, joint_graph16, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph16), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_149 = permute_150 = permute_151 = getitem_1005 = getitem_1006 = permute_1240 = fw_graph16 = joint_graph16 = mask_graph16 = None
        getitem_19749 = flex_attention_backward_16[0]
        getitem_19750 = flex_attention_backward_16[1]
        getitem_19751 = flex_attention_backward_16[2];  flex_attention_backward_16 = None
        permute_1241 = torch.ops.aten.permute.default(getitem_19751, [0, 2, 1, 3]);  getitem_19751 = None
        permute_1242 = torch.ops.aten.permute.default(getitem_19750, [0, 2, 1, 3]);  getitem_19750 = None
        permute_1243 = torch.ops.aten.permute.default(getitem_19749, [0, 2, 1, 3]);  getitem_19749 = None
        slice_260 = torch.ops.aten.slice.Tensor(permute_1242, 3, 0, 128)
        slice_261 = torch.ops.aten.slice.Tensor(permute_1242, 3, 128, 192);  permute_1242 = None
        sum_238 = torch.ops.aten.sum.dim_IntList(slice_261, [2], True);  slice_261 = None
        cat_368 = torch.ops.aten.cat.default([slice_260, permute_1241], 3);  slice_260 = permute_1241 = None
        view_2093 = torch.ops.aten.view.default(cat_368, [2, 4096, 4096]);  cat_368 = None
        view_2094 = torch.ops.aten.view.default(view_2093, [8192, 4096]);  view_2093 = None
        permute_1244 = torch.ops.aten.permute.default(view_2094, [1, 0])
        mm_484 = torch.ops.aten.mm.default(permute_1244, view_653);  permute_1244 = view_653 = None
        convert_element_type_539 = torch.ops.prims.convert_element_type.default(primals_171, torch.bfloat16);  primals_171 = None
        all_gather_into_tensor_168 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_539, 128, '0');  convert_element_type_539 = None
        wait_tensor_204 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_168);  all_gather_into_tensor_168 = None
        permute_148 = torch.ops.aten.permute.default(wait_tensor_204, [1, 0]);  wait_tensor_204 = None
        permute_1246 = torch.ops.aten.permute.default(permute_148, [1, 0]);  permute_148 = None
        mm_485 = torch.ops.aten.mm.default(view_2094, permute_1246);  view_2094 = permute_1246 = None
        view_2095 = torch.ops.aten.view.default(mm_485, [2, 4096, 512]);  mm_485 = None
        convert_element_type_2689 = torch.ops.prims.convert_element_type.default(mm_484, torch.float32);  mm_484 = None
        reduce_scatter_tensor_235 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2689, 'avg', 128, '0');  convert_element_type_2689 = None
        wait_tensor_828 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_235);  reduce_scatter_tensor_235 = None
        convert_element_type_2690 = torch.ops.prims.convert_element_type.default(view_2095, torch.float32);  view_2095 = None
        convert_element_type_536 = torch.ops.prims.convert_element_type.default(primals_170, torch.bfloat16);  primals_170 = None
        all_gather_into_tensor_167 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_536, 128, '0');  convert_element_type_536 = None
        wait_tensor_203 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_167);  all_gather_into_tensor_167 = None
        convert_element_type_2692 = torch.ops.prims.convert_element_type.default(wait_tensor_203, torch.float32);  wait_tensor_203 = None
        mul_1855 = torch.ops.aten.mul.Tensor(convert_element_type_2690, convert_element_type_2692);  convert_element_type_2692 = None
        convert_element_type_537 = torch.ops.prims.convert_element_type.default(getitem_1001, torch.float32);  getitem_1001 = None
        mul_454 = torch.ops.aten.mul.Tensor(convert_element_type_537, rsqrt_31);  convert_element_type_537 = None
        mul_1857 = torch.ops.aten.mul.Tensor(mul_454, mul_1855)
        sum_239 = torch.ops.aten.sum.dim_IntList(mul_1857, [2], True);  mul_1857 = None
        div_232 = torch.ops.aten.div.Tensor(mul_454, 512)
        mul_1858 = torch.ops.aten.mul.Tensor(div_232, sum_239);  div_232 = sum_239 = None
        sub_725 = torch.ops.aten.sub.Tensor(mul_1855, mul_1858);  mul_1855 = mul_1858 = None
        mul_1859 = torch.ops.aten.mul.Tensor(sub_725, rsqrt_31);  sub_725 = rsqrt_31 = None
        mul_1860 = torch.ops.aten.mul.Tensor(convert_element_type_2690, mul_454);  convert_element_type_2690 = mul_454 = None
        sum_240 = torch.ops.aten.sum.dim_IntList(mul_1860, [0, 1]);  mul_1860 = None
        convert_element_type_2693 = torch.ops.prims.convert_element_type.default(mul_1859, torch.bfloat16);  mul_1859 = None
        convert_element_type_default_32 = torch.ops.prims.convert_element_type.default(sum_240, torch.float32);  sum_240 = None
        reduce_scatter_tensor_236 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_32, 'avg', 128, '0');  convert_element_type_default_32 = None
        wait_tensor_829 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_236);  reduce_scatter_tensor_236 = None
        convert_element_type_2696 = torch.ops.prims.convert_element_type.default(sum_238, torch.float32);  sum_238 = None
        view_2096 = torch.ops.aten.view.default(convert_element_type_2696, [2, 4096, 1, 32, 2]);  convert_element_type_2696 = None
        view_as_complex_86 = torch.ops.aten.view_as_complex.default(view_2096);  view_2096 = None
        mul_1861 = torch.ops.aten.mul.Tensor(view_as_complex_86, clone_9);  view_as_complex_86 = None
        view_as_real_86 = torch.ops.aten.view_as_real.default(mul_1861);  mul_1861 = None
        view_2097 = torch.ops.aten.view.default(view_as_real_86, [2, 4096, 1, 64]);  view_as_real_86 = None
        convert_element_type_2697 = torch.ops.prims.convert_element_type.default(view_2097, torch.bfloat16);  view_2097 = None
        squeeze_42 = torch.ops.aten.squeeze.dim(convert_element_type_2697, 2);  convert_element_type_2697 = None
        cat_369 = torch.ops.aten.cat.default([convert_element_type_2693, squeeze_42], 2);  convert_element_type_2693 = squeeze_42 = None
        view_2098 = torch.ops.aten.view.default(cat_369, [8192, 576]);  cat_369 = None
        permute_1248 = torch.ops.aten.permute.default(view_2098, [1, 0])
        mm_486 = torch.ops.aten.mm.default(permute_1248, view_639);  permute_1248 = None
        convert_element_type_531 = torch.ops.prims.convert_element_type.default(primals_169, torch.bfloat16);  primals_169 = None
        all_gather_into_tensor_166 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_531, 128, '0');  convert_element_type_531 = None
        wait_tensor_202 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_166);  all_gather_into_tensor_166 = None
        slice_61 = torch.ops.aten.slice.Tensor(wait_tensor_202, 0, 0, 576);  wait_tensor_202 = None
        permute_147 = torch.ops.aten.permute.default(slice_61, [1, 0]);  slice_61 = None
        permute_1250 = torch.ops.aten.permute.default(permute_147, [1, 0]);  permute_147 = None
        mm_487 = torch.ops.aten.mm.default(view_2098, permute_1250);  view_2098 = permute_1250 = None
        view_2099 = torch.ops.aten.view.default(mm_487, [2, 4096, 2048]);  mm_487 = None
        convert_element_type_2702 = torch.ops.prims.convert_element_type.default(mm_486, torch.float32);  mm_486 = None
        split_1056 = torch.ops.aten.split.Tensor(convert_element_type_2702, 5);  convert_element_type_2702 = None
        getitem_19753 = split_1056[0]
        getitem_19754 = split_1056[1]
        getitem_19755 = split_1056[2]
        getitem_19756 = split_1056[3]
        getitem_19757 = split_1056[4]
        getitem_19758 = split_1056[5]
        getitem_19759 = split_1056[6]
        getitem_19760 = split_1056[7]
        getitem_19761 = split_1056[8]
        getitem_19762 = split_1056[9]
        getitem_19763 = split_1056[10]
        getitem_19764 = split_1056[11]
        getitem_19765 = split_1056[12]
        getitem_19766 = split_1056[13]
        getitem_19767 = split_1056[14]
        getitem_19768 = split_1056[15]
        getitem_19769 = split_1056[16]
        getitem_19770 = split_1056[17]
        getitem_19771 = split_1056[18]
        getitem_19772 = split_1056[19]
        getitem_19773 = split_1056[20]
        getitem_19774 = split_1056[21]
        getitem_19775 = split_1056[22]
        getitem_19776 = split_1056[23]
        getitem_19777 = split_1056[24]
        getitem_19778 = split_1056[25]
        getitem_19779 = split_1056[26]
        getitem_19780 = split_1056[27]
        getitem_19781 = split_1056[28]
        getitem_19782 = split_1056[29]
        getitem_19783 = split_1056[30]
        getitem_19784 = split_1056[31]
        getitem_19785 = split_1056[32]
        getitem_19786 = split_1056[33]
        getitem_19787 = split_1056[34]
        getitem_19788 = split_1056[35]
        getitem_19789 = split_1056[36]
        getitem_19790 = split_1056[37]
        getitem_19791 = split_1056[38]
        getitem_19792 = split_1056[39]
        getitem_19793 = split_1056[40]
        getitem_19794 = split_1056[41]
        getitem_19795 = split_1056[42]
        getitem_19796 = split_1056[43]
        getitem_19797 = split_1056[44]
        getitem_19798 = split_1056[45]
        getitem_19799 = split_1056[46]
        getitem_19800 = split_1056[47]
        getitem_19801 = split_1056[48]
        getitem_19802 = split_1056[49]
        getitem_19803 = split_1056[50]
        getitem_19804 = split_1056[51]
        getitem_19805 = split_1056[52]
        getitem_19806 = split_1056[53]
        getitem_19807 = split_1056[54]
        getitem_19808 = split_1056[55]
        getitem_19809 = split_1056[56]
        getitem_19810 = split_1056[57]
        getitem_19811 = split_1056[58]
        getitem_19812 = split_1056[59]
        getitem_19813 = split_1056[60]
        getitem_19814 = split_1056[61]
        getitem_19815 = split_1056[62]
        getitem_19816 = split_1056[63]
        getitem_19817 = split_1056[64]
        getitem_19818 = split_1056[65]
        getitem_19819 = split_1056[66]
        getitem_19820 = split_1056[67]
        getitem_19821 = split_1056[68]
        getitem_19822 = split_1056[69]
        getitem_19823 = split_1056[70]
        getitem_19824 = split_1056[71]
        getitem_19825 = split_1056[72]
        getitem_19826 = split_1056[73]
        getitem_19827 = split_1056[74]
        getitem_19828 = split_1056[75]
        getitem_19829 = split_1056[76]
        getitem_19830 = split_1056[77]
        getitem_19831 = split_1056[78]
        getitem_19832 = split_1056[79]
        getitem_19833 = split_1056[80]
        getitem_19834 = split_1056[81]
        getitem_19835 = split_1056[82]
        getitem_19836 = split_1056[83]
        getitem_19837 = split_1056[84]
        getitem_19838 = split_1056[85]
        getitem_19839 = split_1056[86]
        getitem_19840 = split_1056[87]
        getitem_19841 = split_1056[88]
        getitem_19842 = split_1056[89]
        getitem_19843 = split_1056[90]
        getitem_19844 = split_1056[91]
        getitem_19845 = split_1056[92]
        getitem_19846 = split_1056[93]
        getitem_19847 = split_1056[94]
        getitem_19848 = split_1056[95]
        getitem_19849 = split_1056[96]
        getitem_19850 = split_1056[97]
        getitem_19851 = split_1056[98]
        getitem_19852 = split_1056[99]
        getitem_19853 = split_1056[100]
        getitem_19854 = split_1056[101]
        getitem_19855 = split_1056[102]
        getitem_19856 = split_1056[103]
        getitem_19857 = split_1056[104]
        getitem_19858 = split_1056[105]
        getitem_19859 = split_1056[106]
        getitem_19860 = split_1056[107]
        getitem_19861 = split_1056[108]
        getitem_19862 = split_1056[109]
        getitem_19863 = split_1056[110]
        getitem_19864 = split_1056[111]
        getitem_19865 = split_1056[112]
        getitem_19866 = split_1056[113]
        getitem_19867 = split_1056[114]
        getitem_19868 = split_1056[115];  split_1056 = None
        constant_pad_nd_1296 = torch.ops.aten.constant_pad_nd.default(getitem_19868, [0, 0, 0, 4], 0.0);  getitem_19868 = None
        cat_370 = torch.ops.aten.cat.default([getitem_19753, getitem_19754, getitem_19755, getitem_19756, getitem_19757, getitem_19758, getitem_19759, getitem_19760, getitem_19761, getitem_19762, getitem_19763, getitem_19764, getitem_19765, getitem_19766, getitem_19767, getitem_19768, getitem_19769, getitem_19770, getitem_19771, getitem_19772, getitem_19773, getitem_19774, getitem_19775, getitem_19776, getitem_19777, getitem_19778, getitem_19779, getitem_19780, getitem_19781, getitem_19782, getitem_19783, getitem_19784, getitem_19785, getitem_19786, getitem_19787, getitem_19788, getitem_19789, getitem_19790, getitem_19791, getitem_19792, getitem_19793, getitem_19794, getitem_19795, getitem_19796, getitem_19797, getitem_19798, getitem_19799, getitem_19800, getitem_19801, getitem_19802, getitem_19803, getitem_19804, getitem_19805, getitem_19806, getitem_19807, getitem_19808, getitem_19809, getitem_19810, getitem_19811, getitem_19812, getitem_19813, getitem_19814, getitem_19815, getitem_19816, getitem_19817, getitem_19818, getitem_19819, getitem_19820, getitem_19821, getitem_19822, getitem_19823, getitem_19824, getitem_19825, getitem_19826, getitem_19827, getitem_19828, getitem_19829, getitem_19830, getitem_19831, getitem_19832, getitem_19833, getitem_19834, getitem_19835, getitem_19836, getitem_19837, getitem_19838, getitem_19839, getitem_19840, getitem_19841, getitem_19842, getitem_19843, getitem_19844, getitem_19845, getitem_19846, getitem_19847, getitem_19848, getitem_19849, getitem_19850, getitem_19851, getitem_19852, getitem_19853, getitem_19854, getitem_19855, getitem_19856, getitem_19857, getitem_19858, getitem_19859, getitem_19860, getitem_19861, getitem_19862, getitem_19863, getitem_19864, getitem_19865, getitem_19866, getitem_19867, constant_pad_nd_1296, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_19753 = getitem_19754 = getitem_19755 = getitem_19756 = getitem_19757 = getitem_19758 = getitem_19759 = getitem_19760 = getitem_19761 = getitem_19762 = getitem_19763 = getitem_19764 = getitem_19765 = getitem_19766 = getitem_19767 = getitem_19768 = getitem_19769 = getitem_19770 = getitem_19771 = getitem_19772 = getitem_19773 = getitem_19774 = getitem_19775 = getitem_19776 = getitem_19777 = getitem_19778 = getitem_19779 = getitem_19780 = getitem_19781 = getitem_19782 = getitem_19783 = getitem_19784 = getitem_19785 = getitem_19786 = getitem_19787 = getitem_19788 = getitem_19789 = getitem_19790 = getitem_19791 = getitem_19792 = getitem_19793 = getitem_19794 = getitem_19795 = getitem_19796 = getitem_19797 = getitem_19798 = getitem_19799 = getitem_19800 = getitem_19801 = getitem_19802 = getitem_19803 = getitem_19804 = getitem_19805 = getitem_19806 = getitem_19807 = getitem_19808 = getitem_19809 = getitem_19810 = getitem_19811 = getitem_19812 = getitem_19813 = getitem_19814 = getitem_19815 = getitem_19816 = getitem_19817 = getitem_19818 = getitem_19819 = getitem_19820 = getitem_19821 = getitem_19822 = getitem_19823 = getitem_19824 = getitem_19825 = getitem_19826 = getitem_19827 = getitem_19828 = getitem_19829 = getitem_19830 = getitem_19831 = getitem_19832 = getitem_19833 = getitem_19834 = getitem_19835 = getitem_19836 = getitem_19837 = getitem_19838 = getitem_19839 = getitem_19840 = getitem_19841 = getitem_19842 = getitem_19843 = getitem_19844 = getitem_19845 = getitem_19846 = getitem_19847 = getitem_19848 = getitem_19849 = getitem_19850 = getitem_19851 = getitem_19852 = getitem_19853 = getitem_19854 = getitem_19855 = getitem_19856 = getitem_19857 = getitem_19858 = getitem_19859 = getitem_19860 = getitem_19861 = getitem_19862 = getitem_19863 = getitem_19864 = getitem_19865 = getitem_19866 = getitem_19867 = constant_pad_nd_1296 = None
        reduce_scatter_tensor_237 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_370, 'avg', 128, '0');  cat_370 = None
        wait_tensor_830 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_237);  reduce_scatter_tensor_237 = None
        slice_262 = torch.ops.aten.slice.Tensor(permute_1243, 3, 0, 128)
        slice_263 = torch.ops.aten.slice.Tensor(permute_1243, 3, 128, 192);  permute_1243 = None
        convert_element_type_2703 = torch.ops.prims.convert_element_type.default(slice_263, torch.float32);  slice_263 = None
        view_2100 = torch.ops.aten.view.default(convert_element_type_2703, [2, 4096, 16, 32, 2]);  convert_element_type_2703 = None
        view_as_complex_87 = torch.ops.aten.view_as_complex.default(view_2100);  view_2100 = None
        mul_1862 = torch.ops.aten.mul.Tensor(view_as_complex_87, clone_9);  view_as_complex_87 = None
        view_as_real_87 = torch.ops.aten.view_as_real.default(mul_1862);  mul_1862 = None
        view_2101 = torch.ops.aten.view.default(view_as_real_87, [2, 4096, 16, 64]);  view_as_real_87 = None
        convert_element_type_2704 = torch.ops.prims.convert_element_type.default(view_2101, torch.bfloat16);  view_2101 = None
        cat_371 = torch.ops.aten.cat.default([slice_262, convert_element_type_2704], 3);  slice_262 = convert_element_type_2704 = None
        view_2102 = torch.ops.aten.view.default(cat_371, [2, 4096, 3072]);  cat_371 = None
        view_2103 = torch.ops.aten.view.default(view_2102, [8192, 3072]);  view_2102 = None
        permute_1252 = torch.ops.aten.permute.default(view_2103, [1, 0])
        mm_488 = torch.ops.aten.mm.default(permute_1252, view_639);  permute_1252 = view_639 = None
        convert_element_type_526 = torch.ops.prims.convert_element_type.default(primals_168, torch.bfloat16);  primals_168 = None
        all_gather_into_tensor_165 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_526, 128, '0');  convert_element_type_526 = None
        wait_tensor_201 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_165);  all_gather_into_tensor_165 = None
        permute_146 = torch.ops.aten.permute.default(wait_tensor_201, [1, 0]);  wait_tensor_201 = None
        permute_1254 = torch.ops.aten.permute.default(permute_146, [1, 0]);  permute_146 = None
        mm_489 = torch.ops.aten.mm.default(view_2103, permute_1254);  view_2103 = permute_1254 = None
        view_2104 = torch.ops.aten.view.default(mm_489, [2, 4096, 2048]);  mm_489 = None
        add_2028 = torch.ops.aten.add.Tensor(view_2099, view_2104);  view_2099 = view_2104 = None
        convert_element_type_2709 = torch.ops.prims.convert_element_type.default(mm_488, torch.float32);  mm_488 = None
        reduce_scatter_tensor_238 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2709, 'avg', 128, '0');  convert_element_type_2709 = None
        wait_tensor_831 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_238);  reduce_scatter_tensor_238 = None
        convert_element_type_2710 = torch.ops.prims.convert_element_type.default(add_2028, torch.float32);  add_2028 = None
        convert_element_type_523 = torch.ops.prims.convert_element_type.default(primals_167, torch.bfloat16);  primals_167 = None
        all_gather_into_tensor_164 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_523, 128, '0');  convert_element_type_523 = None
        wait_tensor_200 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_164);  all_gather_into_tensor_164 = None
        convert_element_type_2712 = torch.ops.prims.convert_element_type.default(wait_tensor_200, torch.float32);  wait_tensor_200 = None
        mul_1863 = torch.ops.aten.mul.Tensor(convert_element_type_2710, convert_element_type_2712);  convert_element_type_2712 = None
        convert_element_type_524 = torch.ops.prims.convert_element_type.default(add_617, torch.float32);  add_617 = None
        mul_450 = torch.ops.aten.mul.Tensor(convert_element_type_524, rsqrt_30);  convert_element_type_524 = None
        mul_1865 = torch.ops.aten.mul.Tensor(mul_450, mul_1863)
        sum_241 = torch.ops.aten.sum.dim_IntList(mul_1865, [2], True);  mul_1865 = None
        div_233 = torch.ops.aten.div.Tensor(mul_450, 2048)
        mul_1866 = torch.ops.aten.mul.Tensor(div_233, sum_241);  div_233 = sum_241 = None
        sub_726 = torch.ops.aten.sub.Tensor(mul_1863, mul_1866);  mul_1863 = mul_1866 = None
        mul_1867 = torch.ops.aten.mul.Tensor(sub_726, rsqrt_30);  sub_726 = rsqrt_30 = None
        mul_1868 = torch.ops.aten.mul.Tensor(convert_element_type_2710, mul_450);  convert_element_type_2710 = mul_450 = None
        sum_242 = torch.ops.aten.sum.dim_IntList(mul_1868, [0, 1]);  mul_1868 = None
        convert_element_type_2713 = torch.ops.prims.convert_element_type.default(mul_1867, torch.bfloat16);  mul_1867 = None
        add_2029 = torch.ops.aten.add.Tensor(add_2027, convert_element_type_2713);  add_2027 = convert_element_type_2713 = None
        convert_element_type_default_31 = torch.ops.prims.convert_element_type.default(sum_242, torch.float32);  sum_242 = None
        reduce_scatter_tensor_239 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_31, 'avg', 128, '0');  convert_element_type_default_31 = None
        wait_tensor_832 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_239);  reduce_scatter_tensor_239 = None
        view_2105 = torch.ops.aten.view.default(add_2029, [8192, 2048])
        unsqueeze_70 = torch.ops.aten.unsqueeze.default(view_2105, 1)
        convert_element_type_2716 = torch.ops.prims.convert_element_type.default(unsqueeze_70, torch.float32);  unsqueeze_70 = None
        bmm_60 = torch.ops.aten.bmm.default(permute_1256, convert_element_type_2716);  permute_1256 = None
        bmm_61 = torch.ops.aten.bmm.default(convert_element_type_2716, permute_1257);  convert_element_type_2716 = permute_1257 = None
        convert_element_type_2717 = torch.ops.prims.convert_element_type.default(bmm_60, torch.bfloat16);  bmm_60 = None
        view_2106 = torch.ops.aten.view.default(bmm_61, [8192, 6]);  bmm_61 = None
        view_2107 = torch.ops.aten.view.default(convert_element_type_2717, [49152, 2048]);  convert_element_type_2717 = None
        index_86 = torch.ops.aten.index.Tensor(view_2107, [getitem_901]);  view_2107 = getitem_901 = None
        permute_1258 = torch.ops.aten.permute.default(view_2105, [1, 0])
        mm_490 = torch.ops.aten.mm.default(permute_1258, mul_447);  permute_1258 = mul_447 = None
        convert_element_type_518 = torch.ops.prims.convert_element_type.default(primals_166, torch.bfloat16);  primals_166 = None
        all_gather_into_tensor_163 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_518, 128, '0');  convert_element_type_518 = None
        wait_tensor_199 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_163);  all_gather_into_tensor_163 = None
        permute_145 = torch.ops.aten.permute.default(wait_tensor_199, [1, 0]);  wait_tensor_199 = None
        permute_1260 = torch.ops.aten.permute.default(permute_145, [1, 0]);  permute_145 = None
        mm_491 = torch.ops.aten.mm.default(view_2105, permute_1260);  view_2105 = permute_1260 = None
        convert_element_type_2722 = torch.ops.prims.convert_element_type.default(mm_490, torch.float32);  mm_490 = None
        reduce_scatter_tensor_240 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2722, 'avg', 128, '0');  convert_element_type_2722 = None
        wait_tensor_833 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_240);  reduce_scatter_tensor_240 = None
        convert_element_type_513 = torch.ops.prims.convert_element_type.default(mm_76, torch.float32);  mm_76 = None
        neg_18 = torch.ops.aten.neg.default(convert_element_type_513)
        exp_27 = torch.ops.aten.exp.default(neg_18);  neg_18 = None
        add_612 = torch.ops.aten.add.Tensor(exp_27, 1);  exp_27 = None
        div_45 = torch.ops.aten.div.Tensor(convert_element_type_513, add_612)
        convert_element_type_514 = torch.ops.prims.convert_element_type.default(div_45, torch.bfloat16);  div_45 = None
        mul_1869 = torch.ops.aten.mul.Tensor(mm_491, convert_element_type_514);  convert_element_type_514 = None
        mul_1870 = torch.ops.aten.mul.Tensor(mm_491, mm_77);  mm_491 = mm_77 = None
        permute_1262 = torch.ops.aten.permute.default(mul_1869, [1, 0])
        mm_492 = torch.ops.aten.mm.default(permute_1262, view_594);  permute_1262 = None
        convert_element_type_515 = torch.ops.prims.convert_element_type.default(primals_165, torch.bfloat16);  primals_165 = None
        all_gather_into_tensor_162 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_515, 128, '0');  convert_element_type_515 = None
        wait_tensor_198 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_162);  all_gather_into_tensor_162 = None
        permute_144 = torch.ops.aten.permute.default(wait_tensor_198, [1, 0]);  wait_tensor_198 = None
        permute_1264 = torch.ops.aten.permute.default(permute_144, [1, 0]);  permute_144 = None
        mm_493 = torch.ops.aten.mm.default(mul_1869, permute_1264);  mul_1869 = permute_1264 = None
        convert_element_type_2727 = torch.ops.prims.convert_element_type.default(mm_492, torch.float32);  mm_492 = None
        reduce_scatter_tensor_241 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2727, 'avg', 128, '0');  convert_element_type_2727 = None
        wait_tensor_834 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_241);  reduce_scatter_tensor_241 = None
        convert_element_type_2728 = torch.ops.prims.convert_element_type.default(mul_1870, torch.float32);  mul_1870 = None
        reciprocal_34 = torch.ops.aten.reciprocal.default(add_612);  add_612 = None
        mul_1871 = torch.ops.aten.mul.Tensor(reciprocal_34, 1);  reciprocal_34 = None
        mul_1872 = torch.ops.aten.mul.Tensor(convert_element_type_2728, mul_1871);  convert_element_type_2728 = None
        sub_727 = torch.ops.aten.sub.Tensor(1, mul_1871);  mul_1871 = None
        mul_1873 = torch.ops.aten.mul.Tensor(convert_element_type_513, sub_727);  convert_element_type_513 = sub_727 = None
        add_2031 = torch.ops.aten.add.Tensor(mul_1873, 1);  mul_1873 = None
        mul_1874 = torch.ops.aten.mul.Tensor(mul_1872, add_2031);  mul_1872 = add_2031 = None
        convert_element_type_2730 = torch.ops.prims.convert_element_type.default(mul_1874, torch.bfloat16);  mul_1874 = None
        permute_1266 = torch.ops.aten.permute.default(convert_element_type_2730, [1, 0])
        mm_494 = torch.ops.aten.mm.default(permute_1266, view_594);  permute_1266 = None
        convert_element_type_510 = torch.ops.prims.convert_element_type.default(primals_164, torch.bfloat16);  primals_164 = None
        all_gather_into_tensor_161 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_510, 128, '0');  convert_element_type_510 = None
        wait_tensor_197 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_161);  all_gather_into_tensor_161 = None
        permute_143 = torch.ops.aten.permute.default(wait_tensor_197, [1, 0]);  wait_tensor_197 = None
        permute_1268 = torch.ops.aten.permute.default(permute_143, [1, 0]);  permute_143 = None
        mm_495 = torch.ops.aten.mm.default(convert_element_type_2730, permute_1268);  convert_element_type_2730 = permute_1268 = None
        add_2032 = torch.ops.aten.add.Tensor(mm_493, mm_495);  mm_493 = mm_495 = None
        convert_element_type_2735 = torch.ops.prims.convert_element_type.default(mm_494, torch.float32);  mm_494 = None
        reduce_scatter_tensor_242 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2735, 'avg', 128, '0');  convert_element_type_2735 = None
        wait_tensor_835 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_242);  reduce_scatter_tensor_242 = None
        all_to_all_single_112 = torch.ops._c10d_functional.all_to_all_single.default(index_86, [_local_scalar_dense_136, _local_scalar_dense_137, _local_scalar_dense_138, _local_scalar_dense_139, _local_scalar_dense_140, _local_scalar_dense_141, _local_scalar_dense_142, _local_scalar_dense_143], [_local_scalar_dense_128, _local_scalar_dense_129, _local_scalar_dense_130, _local_scalar_dense_131, _local_scalar_dense_132, _local_scalar_dense_133, _local_scalar_dense_134, _local_scalar_dense_135], '1033');  index_86 = None
        wait_tensor_836 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_112);  all_to_all_single_112 = None
        full_450 = torch.ops.aten.full.default([sym_size_int_33, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_33 = None
        slice_scatter_17 = torch.ops.aten.slice_scatter.default(full_450, wait_tensor_836, 0, 0, -1);  wait_tensor_836 = None
        index_87 = torch.ops.aten.index.Tensor(slice_scatter_17, [getitem_902]);  slice_scatter_17 = None
        permute_1270 = torch.ops.aten.permute.default(index_87, [1, 0])
        _grouped_mm_180 = torch.ops.aten._grouped_mm.default(permute_1270, mul_427, cumsum_26);  permute_1270 = mul_427 = None
        _grouped_mm_181 = torch.ops.aten._grouped_mm.default(index_87, permute_1272, cumsum_26);  index_87 = permute_1272 = None
        convert_element_type_508 = torch.ops.prims.convert_element_type.default(_grouped_mm_24, torch.float32);  _grouped_mm_24 = None
        neg_17 = torch.ops.aten.neg.default(convert_element_type_508)
        exp_26 = torch.ops.aten.exp.default(neg_17);  neg_17 = None
        add_576 = torch.ops.aten.add.Tensor(exp_26, 1);  exp_26 = None
        div_44 = torch.ops.aten.div.Tensor(convert_element_type_508, add_576)
        convert_element_type_509 = torch.ops.prims.convert_element_type.default(div_44, torch.bfloat16);  div_44 = None
        mul_1875 = torch.ops.aten.mul.Tensor(_grouped_mm_181, convert_element_type_509);  convert_element_type_509 = None
        mul_1876 = torch.ops.aten.mul.Tensor(_grouped_mm_181, _grouped_mm_25);  _grouped_mm_181 = _grouped_mm_25 = None
        permute_1274 = torch.ops.aten.permute.default(mul_1875, [1, 0])
        _grouped_mm_182 = torch.ops.aten._grouped_mm.default(permute_1274, index_17, cumsum_26);  permute_1274 = None
        _grouped_mm_183 = torch.ops.aten._grouped_mm.default(mul_1875, permute_1276, cumsum_26);  mul_1875 = permute_1276 = None
        convert_element_type_2736 = torch.ops.prims.convert_element_type.default(mul_1876, torch.float32);  mul_1876 = None
        reciprocal_35 = torch.ops.aten.reciprocal.default(add_576);  add_576 = None
        mul_1877 = torch.ops.aten.mul.Tensor(reciprocal_35, 1);  reciprocal_35 = None
        mul_1878 = torch.ops.aten.mul.Tensor(convert_element_type_2736, mul_1877);  convert_element_type_2736 = None
        sub_728 = torch.ops.aten.sub.Tensor(1, mul_1877);  mul_1877 = None
        mul_1879 = torch.ops.aten.mul.Tensor(convert_element_type_508, sub_728);  convert_element_type_508 = sub_728 = None
        add_2034 = torch.ops.aten.add.Tensor(mul_1879, 1);  mul_1879 = None
        mul_1880 = torch.ops.aten.mul.Tensor(mul_1878, add_2034);  mul_1878 = add_2034 = None
        convert_element_type_2738 = torch.ops.prims.convert_element_type.default(mul_1880, torch.bfloat16);  mul_1880 = None
        permute_1278 = torch.ops.aten.permute.default(convert_element_type_2738, [1, 0])
        _grouped_mm_184 = torch.ops.aten._grouped_mm.default(permute_1278, index_17, cumsum_26);  permute_1278 = index_17 = None
        _grouped_mm_185 = torch.ops.aten._grouped_mm.default(convert_element_type_2738, permute_1280, cumsum_26);  convert_element_type_2738 = permute_1280 = cumsum_26 = None
        add_2035 = torch.ops.aten.add.Tensor(_grouped_mm_183, _grouped_mm_185);  _grouped_mm_183 = _grouped_mm_185 = None
        convert_element_type_2739 = torch.ops.prims.convert_element_type.default(_grouped_mm_182, torch.float32);  _grouped_mm_182 = None
        div_234 = torch.ops.aten.div.Tensor(convert_element_type_2739, 128);  convert_element_type_2739 = None
        split_1058 = torch.ops.aten.split.Tensor(div_234, 88, 1);  div_234 = None
        getitem_19885 = split_1058[0]
        getitem_19902 = split_1058[1]
        getitem_19919 = split_1058[2]
        getitem_19936 = split_1058[3]
        getitem_19953 = split_1058[4]
        getitem_19970 = split_1058[5]
        getitem_19987 = split_1058[6]
        getitem_20004 = split_1058[7]
        getitem_20021 = split_1058[8]
        getitem_20038 = split_1058[9]
        getitem_20055 = split_1058[10]
        getitem_20072 = split_1058[11]
        getitem_20089 = split_1058[12]
        getitem_20106 = split_1058[13]
        getitem_20123 = split_1058[14]
        getitem_20140 = split_1058[15];  split_1058 = None
        cat_372 = torch.ops.aten.cat.default([getitem_19885, getitem_19902, getitem_19919, getitem_19936, getitem_19953, getitem_19970, getitem_19987, getitem_20004, getitem_20021, getitem_20038, getitem_20055, getitem_20072, getitem_20089, getitem_20106, getitem_20123, getitem_20140]);  getitem_19885 = getitem_19902 = getitem_19919 = getitem_19936 = getitem_19953 = getitem_19970 = getitem_19987 = getitem_20004 = getitem_20021 = getitem_20038 = getitem_20055 = getitem_20072 = getitem_20089 = getitem_20106 = getitem_20123 = getitem_20140 = None
        reduce_scatter_tensor_243 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_372, 'sum', 16, '1025');  cat_372 = None
        wait_tensor_837 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_243);  reduce_scatter_tensor_243 = None
        convert_element_type_2740 = torch.ops.prims.convert_element_type.default(_grouped_mm_180, torch.float32);  _grouped_mm_180 = None
        div_235 = torch.ops.aten.div.Tensor(convert_element_type_2740, 128);  convert_element_type_2740 = None
        split_1075 = torch.ops.aten.split.Tensor(div_235, 128, 1);  div_235 = None
        getitem_20157 = split_1075[0]
        getitem_20174 = split_1075[1]
        getitem_20191 = split_1075[2]
        getitem_20208 = split_1075[3]
        getitem_20225 = split_1075[4]
        getitem_20242 = split_1075[5]
        getitem_20259 = split_1075[6]
        getitem_20276 = split_1075[7]
        getitem_20293 = split_1075[8]
        getitem_20310 = split_1075[9]
        getitem_20327 = split_1075[10]
        getitem_20344 = split_1075[11]
        getitem_20361 = split_1075[12]
        getitem_20378 = split_1075[13]
        getitem_20395 = split_1075[14]
        getitem_20412 = split_1075[15];  split_1075 = None
        cat_373 = torch.ops.aten.cat.default([getitem_20157, getitem_20174, getitem_20191, getitem_20208, getitem_20225, getitem_20242, getitem_20259, getitem_20276, getitem_20293, getitem_20310, getitem_20327, getitem_20344, getitem_20361, getitem_20378, getitem_20395, getitem_20412]);  getitem_20157 = getitem_20174 = getitem_20191 = getitem_20208 = getitem_20225 = getitem_20242 = getitem_20259 = getitem_20276 = getitem_20293 = getitem_20310 = getitem_20327 = getitem_20344 = getitem_20361 = getitem_20378 = getitem_20395 = getitem_20412 = None
        reduce_scatter_tensor_244 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_373, 'sum', 16, '1025');  cat_373 = None
        wait_tensor_838 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_244);  reduce_scatter_tensor_244 = None
        convert_element_type_2741 = torch.ops.prims.convert_element_type.default(_grouped_mm_184, torch.float32);  _grouped_mm_184 = None
        div_236 = torch.ops.aten.div.Tensor(convert_element_type_2741, 128);  convert_element_type_2741 = None
        split_1092 = torch.ops.aten.split.Tensor(div_236, 88, 1);  div_236 = None
        getitem_20429 = split_1092[0]
        getitem_20446 = split_1092[1]
        getitem_20463 = split_1092[2]
        getitem_20480 = split_1092[3]
        getitem_20497 = split_1092[4]
        getitem_20514 = split_1092[5]
        getitem_20531 = split_1092[6]
        getitem_20548 = split_1092[7]
        getitem_20565 = split_1092[8]
        getitem_20582 = split_1092[9]
        getitem_20599 = split_1092[10]
        getitem_20616 = split_1092[11]
        getitem_20633 = split_1092[12]
        getitem_20650 = split_1092[13]
        getitem_20667 = split_1092[14]
        getitem_20684 = split_1092[15];  split_1092 = None
        cat_374 = torch.ops.aten.cat.default([getitem_20429, getitem_20446, getitem_20463, getitem_20480, getitem_20497, getitem_20514, getitem_20531, getitem_20548, getitem_20565, getitem_20582, getitem_20599, getitem_20616, getitem_20633, getitem_20650, getitem_20667, getitem_20684]);  getitem_20429 = getitem_20446 = getitem_20463 = getitem_20480 = getitem_20497 = getitem_20514 = getitem_20531 = getitem_20548 = getitem_20565 = getitem_20582 = getitem_20599 = getitem_20616 = getitem_20633 = getitem_20650 = getitem_20667 = getitem_20684 = None
        reduce_scatter_tensor_245 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_374, 'sum', 16, '1025');  cat_374 = None
        wait_tensor_839 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_245);  reduce_scatter_tensor_245 = None
        index_put_86 = torch.ops.aten.index_put.default(full_450, [getitem_902], add_2035, True);  full_450 = getitem_902 = add_2035 = None
        slice_264 = torch.ops.aten.slice.Tensor(index_put_86, 0, 0, add_2036);  index_put_86 = add_2036 = None
        all_to_all_single_113 = torch.ops._c10d_functional.all_to_all_single.default(slice_264, [_local_scalar_dense_128, _local_scalar_dense_129, _local_scalar_dense_130, _local_scalar_dense_131, _local_scalar_dense_132, _local_scalar_dense_133, _local_scalar_dense_134, _local_scalar_dense_135], [_local_scalar_dense_136, _local_scalar_dense_137, _local_scalar_dense_138, _local_scalar_dense_139, _local_scalar_dense_140, _local_scalar_dense_141, _local_scalar_dense_142, _local_scalar_dense_143], '1033');  slice_264 = _local_scalar_dense_128 = _local_scalar_dense_129 = _local_scalar_dense_130 = _local_scalar_dense_131 = _local_scalar_dense_132 = _local_scalar_dense_133 = _local_scalar_dense_134 = _local_scalar_dense_135 = _local_scalar_dense_136 = _local_scalar_dense_137 = _local_scalar_dense_138 = _local_scalar_dense_139 = _local_scalar_dense_140 = _local_scalar_dense_141 = _local_scalar_dense_142 = _local_scalar_dense_143 = None
        wait_tensor_840 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_113);  all_to_all_single_113 = None
        index_put_87 = torch.ops.aten.index_put.default(full_default_52, [div_42], wait_tensor_840, True);  div_42 = wait_tensor_840 = None
        add_2040 = torch.ops.aten.add.Tensor(add_2032, index_put_87);  add_2032 = index_put_87 = None
        mul_1881 = torch.ops.aten.mul.Tensor(view_2106, 1.0);  view_2106 = None
        scatter_add_17 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_899, mul_1881);  getitem_899 = mul_1881 = None
        convert_element_type_497 = torch.ops.prims.convert_element_type.default(mm_75, torch.float32);  mm_75 = None
        sub_192 = torch.ops.aten.sub.Tensor(convert_element_type_497, amax_8);  convert_element_type_497 = amax_8 = None
        exp_25 = torch.ops.aten.exp.default(sub_192);  sub_192 = None
        div_41 = torch.ops.aten.div.Tensor(exp_25, sum_33);  exp_25 = sum_33 = None
        mul_1882 = torch.ops.aten.mul.Tensor(scatter_add_17, div_41);  scatter_add_17 = None
        sum_243 = torch.ops.aten.sum.dim_IntList(mul_1882, [1], True)
        neg_106 = torch.ops.aten.neg.default(div_41);  div_41 = None
        fma_17 = torch.ops.prims.fma.default(neg_106, sum_243, mul_1882);  neg_106 = sum_243 = mul_1882 = None
        convert_element_type_2742 = torch.ops.prims.convert_element_type.default(fma_17, torch.bfloat16);  fma_17 = None
        permute_1282 = torch.ops.aten.permute.default(convert_element_type_2742, [1, 0])
        mm_496 = torch.ops.aten.mm.default(permute_1282, view_594);  permute_1282 = view_594 = None
        convert_element_type_494 = torch.ops.prims.convert_element_type.default(primals_159, torch.bfloat16);  primals_159 = None
        all_gather_into_tensor_154 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_494, 128, '0');  convert_element_type_494 = None
        wait_tensor_186 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_154);  all_gather_into_tensor_154 = None
        slice_57 = torch.ops.aten.slice.Tensor(wait_tensor_186, 0, 0, 64);  wait_tensor_186 = None
        permute_139 = torch.ops.aten.permute.default(slice_57, [1, 0]);  slice_57 = None
        permute_1284 = torch.ops.aten.permute.default(permute_139, [1, 0]);  permute_139 = None
        mm_497 = torch.ops.aten.mm.default(convert_element_type_2742, permute_1284);  convert_element_type_2742 = permute_1284 = None
        add_2041 = torch.ops.aten.add.Tensor(add_2040, mm_497);  add_2040 = mm_497 = None
        convert_element_type_2747 = torch.ops.prims.convert_element_type.default(mm_496, torch.float32);  mm_496 = None
        split_1108 = torch.ops.aten.split.Tensor(convert_element_type_2747, 1);  convert_element_type_2747 = None
        getitem_20685 = split_1108[0]
        getitem_20686 = split_1108[1]
        getitem_20687 = split_1108[2]
        getitem_20688 = split_1108[3]
        getitem_20689 = split_1108[4]
        getitem_20690 = split_1108[5]
        getitem_20691 = split_1108[6]
        getitem_20692 = split_1108[7]
        getitem_20693 = split_1108[8]
        getitem_20694 = split_1108[9]
        getitem_20695 = split_1108[10]
        getitem_20696 = split_1108[11]
        getitem_20697 = split_1108[12]
        getitem_20698 = split_1108[13]
        getitem_20699 = split_1108[14]
        getitem_20700 = split_1108[15]
        getitem_20701 = split_1108[16]
        getitem_20702 = split_1108[17]
        getitem_20703 = split_1108[18]
        getitem_20704 = split_1108[19]
        getitem_20705 = split_1108[20]
        getitem_20706 = split_1108[21]
        getitem_20707 = split_1108[22]
        getitem_20708 = split_1108[23]
        getitem_20709 = split_1108[24]
        getitem_20710 = split_1108[25]
        getitem_20711 = split_1108[26]
        getitem_20712 = split_1108[27]
        getitem_20713 = split_1108[28]
        getitem_20714 = split_1108[29]
        getitem_20715 = split_1108[30]
        getitem_20716 = split_1108[31]
        getitem_20717 = split_1108[32]
        getitem_20718 = split_1108[33]
        getitem_20719 = split_1108[34]
        getitem_20720 = split_1108[35]
        getitem_20721 = split_1108[36]
        getitem_20722 = split_1108[37]
        getitem_20723 = split_1108[38]
        getitem_20724 = split_1108[39]
        getitem_20725 = split_1108[40]
        getitem_20726 = split_1108[41]
        getitem_20727 = split_1108[42]
        getitem_20728 = split_1108[43]
        getitem_20729 = split_1108[44]
        getitem_20730 = split_1108[45]
        getitem_20731 = split_1108[46]
        getitem_20732 = split_1108[47]
        getitem_20733 = split_1108[48]
        getitem_20734 = split_1108[49]
        getitem_20735 = split_1108[50]
        getitem_20736 = split_1108[51]
        getitem_20737 = split_1108[52]
        getitem_20738 = split_1108[53]
        getitem_20739 = split_1108[54]
        getitem_20740 = split_1108[55]
        getitem_20741 = split_1108[56]
        getitem_20742 = split_1108[57]
        getitem_20743 = split_1108[58]
        getitem_20744 = split_1108[59]
        getitem_20745 = split_1108[60]
        getitem_20746 = split_1108[61]
        getitem_20747 = split_1108[62]
        getitem_20748 = split_1108[63];  split_1108 = None
        cat_375 = torch.ops.aten.cat.default([getitem_20685, getitem_20686, getitem_20687, getitem_20688, getitem_20689, getitem_20690, getitem_20691, getitem_20692, getitem_20693, getitem_20694, getitem_20695, getitem_20696, getitem_20697, getitem_20698, getitem_20699, getitem_20700, getitem_20701, getitem_20702, getitem_20703, getitem_20704, getitem_20705, getitem_20706, getitem_20707, getitem_20708, getitem_20709, getitem_20710, getitem_20711, getitem_20712, getitem_20713, getitem_20714, getitem_20715, getitem_20716, getitem_20717, getitem_20718, getitem_20719, getitem_20720, getitem_20721, getitem_20722, getitem_20723, getitem_20724, getitem_20725, getitem_20726, getitem_20727, getitem_20728, getitem_20729, getitem_20730, getitem_20731, getitem_20732, getitem_20733, getitem_20734, getitem_20735, getitem_20736, getitem_20737, getitem_20738, getitem_20739, getitem_20740, getitem_20741, getitem_20742, getitem_20743, getitem_20744, getitem_20745, getitem_20746, getitem_20747, getitem_20748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_20685 = getitem_20686 = getitem_20687 = getitem_20688 = getitem_20689 = getitem_20690 = getitem_20691 = getitem_20692 = getitem_20693 = getitem_20694 = getitem_20695 = getitem_20696 = getitem_20697 = getitem_20698 = getitem_20699 = getitem_20700 = getitem_20701 = getitem_20702 = getitem_20703 = getitem_20704 = getitem_20705 = getitem_20706 = getitem_20707 = getitem_20708 = getitem_20709 = getitem_20710 = getitem_20711 = getitem_20712 = getitem_20713 = getitem_20714 = getitem_20715 = getitem_20716 = getitem_20717 = getitem_20718 = getitem_20719 = getitem_20720 = getitem_20721 = getitem_20722 = getitem_20723 = getitem_20724 = getitem_20725 = getitem_20726 = getitem_20727 = getitem_20728 = getitem_20729 = getitem_20730 = getitem_20731 = getitem_20732 = getitem_20733 = getitem_20734 = getitem_20735 = getitem_20736 = getitem_20737 = getitem_20738 = getitem_20739 = getitem_20740 = getitem_20741 = getitem_20742 = getitem_20743 = getitem_20744 = getitem_20745 = getitem_20746 = getitem_20747 = getitem_20748 = None
        reduce_scatter_tensor_246 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_375, 'avg', 128, '0');  cat_375 = None
        wait_tensor_841 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_246);  reduce_scatter_tensor_246 = None
        view_2108 = torch.ops.aten.view.default(add_2041, [2, 4096, 2048]);  add_2041 = None
        convert_element_type_2748 = torch.ops.prims.convert_element_type.default(view_2108, torch.float32);  view_2108 = None
        convert_element_type_491 = torch.ops.prims.convert_element_type.default(primals_157, torch.bfloat16);  primals_157 = None
        all_gather_into_tensor_153 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_491, 128, '0');  convert_element_type_491 = None
        wait_tensor_185 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_153);  all_gather_into_tensor_153 = None
        convert_element_type_2750 = torch.ops.prims.convert_element_type.default(wait_tensor_185, torch.float32);  wait_tensor_185 = None
        mul_1883 = torch.ops.aten.mul.Tensor(convert_element_type_2748, convert_element_type_2750);  convert_element_type_2750 = None
        convert_element_type_492 = torch.ops.prims.convert_element_type.default(add_552, torch.float32);  add_552 = None
        mul_407 = torch.ops.aten.mul.Tensor(convert_element_type_492, rsqrt_29);  convert_element_type_492 = None
        mul_1885 = torch.ops.aten.mul.Tensor(mul_407, mul_1883)
        sum_244 = torch.ops.aten.sum.dim_IntList(mul_1885, [2], True);  mul_1885 = None
        div_237 = torch.ops.aten.div.Tensor(mul_407, 2048)
        mul_1886 = torch.ops.aten.mul.Tensor(div_237, sum_244);  div_237 = sum_244 = None
        sub_730 = torch.ops.aten.sub.Tensor(mul_1883, mul_1886);  mul_1883 = mul_1886 = None
        mul_1887 = torch.ops.aten.mul.Tensor(sub_730, rsqrt_29);  sub_730 = rsqrt_29 = None
        mul_1888 = torch.ops.aten.mul.Tensor(convert_element_type_2748, mul_407);  convert_element_type_2748 = mul_407 = None
        sum_245 = torch.ops.aten.sum.dim_IntList(mul_1888, [0, 1]);  mul_1888 = None
        convert_element_type_2751 = torch.ops.prims.convert_element_type.default(mul_1887, torch.bfloat16);  mul_1887 = None
        add_2042 = torch.ops.aten.add.Tensor(add_2029, convert_element_type_2751);  add_2029 = convert_element_type_2751 = None
        convert_element_type_default_30 = torch.ops.prims.convert_element_type.default(sum_245, torch.float32);  sum_245 = None
        reduce_scatter_tensor_247 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_30, 'avg', 128, '0');  convert_element_type_default_30 = None
        wait_tensor_842 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_247);  reduce_scatter_tensor_247 = None
        view_2109 = torch.ops.aten.view.default(add_2042, [8192, 2048])
        permute_1286 = torch.ops.aten.permute.default(view_2109, [1, 0])
        permute_137 = torch.ops.aten.permute.default(getitem_895, [0, 2, 1, 3])
        view_589 = torch.ops.aten.view.default(permute_137, [2, 4096, -1]);  permute_137 = None
        view_591 = torch.ops.aten.view.default(view_589, [8192, 2048]);  view_589 = None
        mm_498 = torch.ops.aten.mm.default(permute_1286, view_591);  permute_1286 = view_591 = None
        convert_element_type_488 = torch.ops.prims.convert_element_type.default(primals_156, torch.bfloat16);  primals_156 = None
        all_gather_into_tensor_152 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_488, 128, '0');  convert_element_type_488 = None
        wait_tensor_184 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_152);  all_gather_into_tensor_152 = None
        permute_138 = torch.ops.aten.permute.default(wait_tensor_184, [1, 0]);  wait_tensor_184 = None
        permute_1288 = torch.ops.aten.permute.default(permute_138, [1, 0]);  permute_138 = None
        mm_499 = torch.ops.aten.mm.default(view_2109, permute_1288);  view_2109 = permute_1288 = None
        view_2110 = torch.ops.aten.view.default(mm_499, [2, 4096, 2048]);  mm_499 = None
        convert_element_type_2758 = torch.ops.prims.convert_element_type.default(mm_498, torch.float32);  mm_498 = None
        reduce_scatter_tensor_248 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2758, 'avg', 128, '0');  convert_element_type_2758 = None
        wait_tensor_843 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_248);  reduce_scatter_tensor_248 = None
        view_2111 = torch.ops.aten.view.default(view_2110, [2, 4096, 16, 128]);  view_2110 = None
        permute_1290 = torch.ops.aten.permute.default(view_2111, [0, 2, 1, 3]);  view_2111 = None
        fw_graph17 = self.fw_graph17
        joint_graph17 = self.joint_graph17
        mask_graph17 = self.mask_graph17
        flex_attention_backward_17 = torch.ops.higher_order.flex_attention_backward(permute_134, permute_135, permute_136, getitem_895, getitem_896, permute_1290, None, fw_graph17, joint_graph17, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph17), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_134 = permute_135 = permute_136 = getitem_895 = getitem_896 = permute_1290 = fw_graph17 = joint_graph17 = mask_graph17 = None
        getitem_20749 = flex_attention_backward_17[0]
        getitem_20750 = flex_attention_backward_17[1]
        getitem_20751 = flex_attention_backward_17[2];  flex_attention_backward_17 = None
        permute_1291 = torch.ops.aten.permute.default(getitem_20751, [0, 2, 1, 3]);  getitem_20751 = None
        permute_1292 = torch.ops.aten.permute.default(getitem_20750, [0, 2, 1, 3]);  getitem_20750 = None
        permute_1293 = torch.ops.aten.permute.default(getitem_20749, [0, 2, 1, 3]);  getitem_20749 = None
        slice_266 = torch.ops.aten.slice.Tensor(permute_1292, 3, 0, 128)
        slice_267 = torch.ops.aten.slice.Tensor(permute_1292, 3, 128, 192);  permute_1292 = None
        sum_246 = torch.ops.aten.sum.dim_IntList(slice_267, [2], True);  slice_267 = None
        cat_376 = torch.ops.aten.cat.default([slice_266, permute_1291], 3);  slice_266 = permute_1291 = None
        view_2112 = torch.ops.aten.view.default(cat_376, [2, 4096, 4096]);  cat_376 = None
        view_2113 = torch.ops.aten.view.default(view_2112, [8192, 4096]);  view_2112 = None
        permute_1294 = torch.ops.aten.permute.default(view_2113, [1, 0])
        mm_500 = torch.ops.aten.mm.default(permute_1294, view_586);  permute_1294 = view_586 = None
        convert_element_type_485 = torch.ops.prims.convert_element_type.default(primals_155, torch.bfloat16);  primals_155 = None
        all_gather_into_tensor_151 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_485, 128, '0');  convert_element_type_485 = None
        wait_tensor_183 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_151);  all_gather_into_tensor_151 = None
        permute_133 = torch.ops.aten.permute.default(wait_tensor_183, [1, 0]);  wait_tensor_183 = None
        permute_1296 = torch.ops.aten.permute.default(permute_133, [1, 0]);  permute_133 = None
        mm_501 = torch.ops.aten.mm.default(view_2113, permute_1296);  view_2113 = permute_1296 = None
        view_2114 = torch.ops.aten.view.default(mm_501, [2, 4096, 512]);  mm_501 = None
        convert_element_type_2763 = torch.ops.prims.convert_element_type.default(mm_500, torch.float32);  mm_500 = None
        reduce_scatter_tensor_249 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2763, 'avg', 128, '0');  convert_element_type_2763 = None
        wait_tensor_844 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_249);  reduce_scatter_tensor_249 = None
        convert_element_type_2764 = torch.ops.prims.convert_element_type.default(view_2114, torch.float32);  view_2114 = None
        convert_element_type_482 = torch.ops.prims.convert_element_type.default(primals_154, torch.bfloat16);  primals_154 = None
        all_gather_into_tensor_150 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_482, 128, '0');  convert_element_type_482 = None
        wait_tensor_182 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_150);  all_gather_into_tensor_150 = None
        convert_element_type_2766 = torch.ops.prims.convert_element_type.default(wait_tensor_182, torch.float32);  wait_tensor_182 = None
        mul_1889 = torch.ops.aten.mul.Tensor(convert_element_type_2764, convert_element_type_2766);  convert_element_type_2766 = None
        convert_element_type_483 = torch.ops.prims.convert_element_type.default(getitem_891, torch.float32);  getitem_891 = None
        mul_405 = torch.ops.aten.mul.Tensor(convert_element_type_483, rsqrt_28);  convert_element_type_483 = None
        mul_1891 = torch.ops.aten.mul.Tensor(mul_405, mul_1889)
        sum_247 = torch.ops.aten.sum.dim_IntList(mul_1891, [2], True);  mul_1891 = None
        div_238 = torch.ops.aten.div.Tensor(mul_405, 512)
        mul_1892 = torch.ops.aten.mul.Tensor(div_238, sum_247);  div_238 = sum_247 = None
        sub_731 = torch.ops.aten.sub.Tensor(mul_1889, mul_1892);  mul_1889 = mul_1892 = None
        mul_1893 = torch.ops.aten.mul.Tensor(sub_731, rsqrt_28);  sub_731 = rsqrt_28 = None
        mul_1894 = torch.ops.aten.mul.Tensor(convert_element_type_2764, mul_405);  convert_element_type_2764 = mul_405 = None
        sum_248 = torch.ops.aten.sum.dim_IntList(mul_1894, [0, 1]);  mul_1894 = None
        convert_element_type_2767 = torch.ops.prims.convert_element_type.default(mul_1893, torch.bfloat16);  mul_1893 = None
        convert_element_type_default_29 = torch.ops.prims.convert_element_type.default(sum_248, torch.float32);  sum_248 = None
        reduce_scatter_tensor_250 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_29, 'avg', 128, '0');  convert_element_type_default_29 = None
        wait_tensor_845 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_250);  reduce_scatter_tensor_250 = None
        convert_element_type_2770 = torch.ops.prims.convert_element_type.default(sum_246, torch.float32);  sum_246 = None
        view_2115 = torch.ops.aten.view.default(convert_element_type_2770, [2, 4096, 1, 32, 2]);  convert_element_type_2770 = None
        view_as_complex_88 = torch.ops.aten.view_as_complex.default(view_2115);  view_2115 = None
        mul_1895 = torch.ops.aten.mul.Tensor(view_as_complex_88, clone_9);  view_as_complex_88 = None
        view_as_real_88 = torch.ops.aten.view_as_real.default(mul_1895);  mul_1895 = None
        view_2116 = torch.ops.aten.view.default(view_as_real_88, [2, 4096, 1, 64]);  view_as_real_88 = None
        convert_element_type_2771 = torch.ops.prims.convert_element_type.default(view_2116, torch.bfloat16);  view_2116 = None
        squeeze_43 = torch.ops.aten.squeeze.dim(convert_element_type_2771, 2);  convert_element_type_2771 = None
        cat_377 = torch.ops.aten.cat.default([convert_element_type_2767, squeeze_43], 2);  convert_element_type_2767 = squeeze_43 = None
        view_2117 = torch.ops.aten.view.default(cat_377, [8192, 576]);  cat_377 = None
        permute_1298 = torch.ops.aten.permute.default(view_2117, [1, 0])
        mm_502 = torch.ops.aten.mm.default(permute_1298, view_572);  permute_1298 = None
        convert_element_type_477 = torch.ops.prims.convert_element_type.default(primals_153, torch.bfloat16);  primals_153 = None
        all_gather_into_tensor_149 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_477, 128, '0');  convert_element_type_477 = None
        wait_tensor_181 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_149);  all_gather_into_tensor_149 = None
        slice_55 = torch.ops.aten.slice.Tensor(wait_tensor_181, 0, 0, 576);  wait_tensor_181 = None
        permute_132 = torch.ops.aten.permute.default(slice_55, [1, 0]);  slice_55 = None
        permute_1300 = torch.ops.aten.permute.default(permute_132, [1, 0]);  permute_132 = None
        mm_503 = torch.ops.aten.mm.default(view_2117, permute_1300);  view_2117 = permute_1300 = None
        view_2118 = torch.ops.aten.view.default(mm_503, [2, 4096, 2048]);  mm_503 = None
        convert_element_type_2776 = torch.ops.prims.convert_element_type.default(mm_502, torch.float32);  mm_502 = None
        split_1109 = torch.ops.aten.split.Tensor(convert_element_type_2776, 5);  convert_element_type_2776 = None
        getitem_20753 = split_1109[0]
        getitem_20754 = split_1109[1]
        getitem_20755 = split_1109[2]
        getitem_20756 = split_1109[3]
        getitem_20757 = split_1109[4]
        getitem_20758 = split_1109[5]
        getitem_20759 = split_1109[6]
        getitem_20760 = split_1109[7]
        getitem_20761 = split_1109[8]
        getitem_20762 = split_1109[9]
        getitem_20763 = split_1109[10]
        getitem_20764 = split_1109[11]
        getitem_20765 = split_1109[12]
        getitem_20766 = split_1109[13]
        getitem_20767 = split_1109[14]
        getitem_20768 = split_1109[15]
        getitem_20769 = split_1109[16]
        getitem_20770 = split_1109[17]
        getitem_20771 = split_1109[18]
        getitem_20772 = split_1109[19]
        getitem_20773 = split_1109[20]
        getitem_20774 = split_1109[21]
        getitem_20775 = split_1109[22]
        getitem_20776 = split_1109[23]
        getitem_20777 = split_1109[24]
        getitem_20778 = split_1109[25]
        getitem_20779 = split_1109[26]
        getitem_20780 = split_1109[27]
        getitem_20781 = split_1109[28]
        getitem_20782 = split_1109[29]
        getitem_20783 = split_1109[30]
        getitem_20784 = split_1109[31]
        getitem_20785 = split_1109[32]
        getitem_20786 = split_1109[33]
        getitem_20787 = split_1109[34]
        getitem_20788 = split_1109[35]
        getitem_20789 = split_1109[36]
        getitem_20790 = split_1109[37]
        getitem_20791 = split_1109[38]
        getitem_20792 = split_1109[39]
        getitem_20793 = split_1109[40]
        getitem_20794 = split_1109[41]
        getitem_20795 = split_1109[42]
        getitem_20796 = split_1109[43]
        getitem_20797 = split_1109[44]
        getitem_20798 = split_1109[45]
        getitem_20799 = split_1109[46]
        getitem_20800 = split_1109[47]
        getitem_20801 = split_1109[48]
        getitem_20802 = split_1109[49]
        getitem_20803 = split_1109[50]
        getitem_20804 = split_1109[51]
        getitem_20805 = split_1109[52]
        getitem_20806 = split_1109[53]
        getitem_20807 = split_1109[54]
        getitem_20808 = split_1109[55]
        getitem_20809 = split_1109[56]
        getitem_20810 = split_1109[57]
        getitem_20811 = split_1109[58]
        getitem_20812 = split_1109[59]
        getitem_20813 = split_1109[60]
        getitem_20814 = split_1109[61]
        getitem_20815 = split_1109[62]
        getitem_20816 = split_1109[63]
        getitem_20817 = split_1109[64]
        getitem_20818 = split_1109[65]
        getitem_20819 = split_1109[66]
        getitem_20820 = split_1109[67]
        getitem_20821 = split_1109[68]
        getitem_20822 = split_1109[69]
        getitem_20823 = split_1109[70]
        getitem_20824 = split_1109[71]
        getitem_20825 = split_1109[72]
        getitem_20826 = split_1109[73]
        getitem_20827 = split_1109[74]
        getitem_20828 = split_1109[75]
        getitem_20829 = split_1109[76]
        getitem_20830 = split_1109[77]
        getitem_20831 = split_1109[78]
        getitem_20832 = split_1109[79]
        getitem_20833 = split_1109[80]
        getitem_20834 = split_1109[81]
        getitem_20835 = split_1109[82]
        getitem_20836 = split_1109[83]
        getitem_20837 = split_1109[84]
        getitem_20838 = split_1109[85]
        getitem_20839 = split_1109[86]
        getitem_20840 = split_1109[87]
        getitem_20841 = split_1109[88]
        getitem_20842 = split_1109[89]
        getitem_20843 = split_1109[90]
        getitem_20844 = split_1109[91]
        getitem_20845 = split_1109[92]
        getitem_20846 = split_1109[93]
        getitem_20847 = split_1109[94]
        getitem_20848 = split_1109[95]
        getitem_20849 = split_1109[96]
        getitem_20850 = split_1109[97]
        getitem_20851 = split_1109[98]
        getitem_20852 = split_1109[99]
        getitem_20853 = split_1109[100]
        getitem_20854 = split_1109[101]
        getitem_20855 = split_1109[102]
        getitem_20856 = split_1109[103]
        getitem_20857 = split_1109[104]
        getitem_20858 = split_1109[105]
        getitem_20859 = split_1109[106]
        getitem_20860 = split_1109[107]
        getitem_20861 = split_1109[108]
        getitem_20862 = split_1109[109]
        getitem_20863 = split_1109[110]
        getitem_20864 = split_1109[111]
        getitem_20865 = split_1109[112]
        getitem_20866 = split_1109[113]
        getitem_20867 = split_1109[114]
        getitem_20868 = split_1109[115];  split_1109 = None
        constant_pad_nd_1373 = torch.ops.aten.constant_pad_nd.default(getitem_20868, [0, 0, 0, 4], 0.0);  getitem_20868 = None
        cat_378 = torch.ops.aten.cat.default([getitem_20753, getitem_20754, getitem_20755, getitem_20756, getitem_20757, getitem_20758, getitem_20759, getitem_20760, getitem_20761, getitem_20762, getitem_20763, getitem_20764, getitem_20765, getitem_20766, getitem_20767, getitem_20768, getitem_20769, getitem_20770, getitem_20771, getitem_20772, getitem_20773, getitem_20774, getitem_20775, getitem_20776, getitem_20777, getitem_20778, getitem_20779, getitem_20780, getitem_20781, getitem_20782, getitem_20783, getitem_20784, getitem_20785, getitem_20786, getitem_20787, getitem_20788, getitem_20789, getitem_20790, getitem_20791, getitem_20792, getitem_20793, getitem_20794, getitem_20795, getitem_20796, getitem_20797, getitem_20798, getitem_20799, getitem_20800, getitem_20801, getitem_20802, getitem_20803, getitem_20804, getitem_20805, getitem_20806, getitem_20807, getitem_20808, getitem_20809, getitem_20810, getitem_20811, getitem_20812, getitem_20813, getitem_20814, getitem_20815, getitem_20816, getitem_20817, getitem_20818, getitem_20819, getitem_20820, getitem_20821, getitem_20822, getitem_20823, getitem_20824, getitem_20825, getitem_20826, getitem_20827, getitem_20828, getitem_20829, getitem_20830, getitem_20831, getitem_20832, getitem_20833, getitem_20834, getitem_20835, getitem_20836, getitem_20837, getitem_20838, getitem_20839, getitem_20840, getitem_20841, getitem_20842, getitem_20843, getitem_20844, getitem_20845, getitem_20846, getitem_20847, getitem_20848, getitem_20849, getitem_20850, getitem_20851, getitem_20852, getitem_20853, getitem_20854, getitem_20855, getitem_20856, getitem_20857, getitem_20858, getitem_20859, getitem_20860, getitem_20861, getitem_20862, getitem_20863, getitem_20864, getitem_20865, getitem_20866, getitem_20867, constant_pad_nd_1373, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_20753 = getitem_20754 = getitem_20755 = getitem_20756 = getitem_20757 = getitem_20758 = getitem_20759 = getitem_20760 = getitem_20761 = getitem_20762 = getitem_20763 = getitem_20764 = getitem_20765 = getitem_20766 = getitem_20767 = getitem_20768 = getitem_20769 = getitem_20770 = getitem_20771 = getitem_20772 = getitem_20773 = getitem_20774 = getitem_20775 = getitem_20776 = getitem_20777 = getitem_20778 = getitem_20779 = getitem_20780 = getitem_20781 = getitem_20782 = getitem_20783 = getitem_20784 = getitem_20785 = getitem_20786 = getitem_20787 = getitem_20788 = getitem_20789 = getitem_20790 = getitem_20791 = getitem_20792 = getitem_20793 = getitem_20794 = getitem_20795 = getitem_20796 = getitem_20797 = getitem_20798 = getitem_20799 = getitem_20800 = getitem_20801 = getitem_20802 = getitem_20803 = getitem_20804 = getitem_20805 = getitem_20806 = getitem_20807 = getitem_20808 = getitem_20809 = getitem_20810 = getitem_20811 = getitem_20812 = getitem_20813 = getitem_20814 = getitem_20815 = getitem_20816 = getitem_20817 = getitem_20818 = getitem_20819 = getitem_20820 = getitem_20821 = getitem_20822 = getitem_20823 = getitem_20824 = getitem_20825 = getitem_20826 = getitem_20827 = getitem_20828 = getitem_20829 = getitem_20830 = getitem_20831 = getitem_20832 = getitem_20833 = getitem_20834 = getitem_20835 = getitem_20836 = getitem_20837 = getitem_20838 = getitem_20839 = getitem_20840 = getitem_20841 = getitem_20842 = getitem_20843 = getitem_20844 = getitem_20845 = getitem_20846 = getitem_20847 = getitem_20848 = getitem_20849 = getitem_20850 = getitem_20851 = getitem_20852 = getitem_20853 = getitem_20854 = getitem_20855 = getitem_20856 = getitem_20857 = getitem_20858 = getitem_20859 = getitem_20860 = getitem_20861 = getitem_20862 = getitem_20863 = getitem_20864 = getitem_20865 = getitem_20866 = getitem_20867 = constant_pad_nd_1373 = None
        reduce_scatter_tensor_251 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_378, 'avg', 128, '0');  cat_378 = None
        wait_tensor_846 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_251);  reduce_scatter_tensor_251 = None
        slice_268 = torch.ops.aten.slice.Tensor(permute_1293, 3, 0, 128)
        slice_269 = torch.ops.aten.slice.Tensor(permute_1293, 3, 128, 192);  permute_1293 = None
        convert_element_type_2777 = torch.ops.prims.convert_element_type.default(slice_269, torch.float32);  slice_269 = None
        view_2119 = torch.ops.aten.view.default(convert_element_type_2777, [2, 4096, 16, 32, 2]);  convert_element_type_2777 = None
        view_as_complex_89 = torch.ops.aten.view_as_complex.default(view_2119);  view_2119 = None
        mul_1896 = torch.ops.aten.mul.Tensor(view_as_complex_89, clone_9);  view_as_complex_89 = None
        view_as_real_89 = torch.ops.aten.view_as_real.default(mul_1896);  mul_1896 = None
        view_2120 = torch.ops.aten.view.default(view_as_real_89, [2, 4096, 16, 64]);  view_as_real_89 = None
        convert_element_type_2778 = torch.ops.prims.convert_element_type.default(view_2120, torch.bfloat16);  view_2120 = None
        cat_379 = torch.ops.aten.cat.default([slice_268, convert_element_type_2778], 3);  slice_268 = convert_element_type_2778 = None
        view_2121 = torch.ops.aten.view.default(cat_379, [2, 4096, 3072]);  cat_379 = None
        view_2122 = torch.ops.aten.view.default(view_2121, [8192, 3072]);  view_2121 = None
        permute_1302 = torch.ops.aten.permute.default(view_2122, [1, 0])
        mm_504 = torch.ops.aten.mm.default(permute_1302, view_572);  permute_1302 = view_572 = None
        convert_element_type_472 = torch.ops.prims.convert_element_type.default(primals_152, torch.bfloat16);  primals_152 = None
        all_gather_into_tensor_148 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_472, 128, '0');  convert_element_type_472 = None
        wait_tensor_180 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_148);  all_gather_into_tensor_148 = None
        permute_131 = torch.ops.aten.permute.default(wait_tensor_180, [1, 0]);  wait_tensor_180 = None
        permute_1304 = torch.ops.aten.permute.default(permute_131, [1, 0]);  permute_131 = None
        mm_505 = torch.ops.aten.mm.default(view_2122, permute_1304);  view_2122 = permute_1304 = None
        view_2123 = torch.ops.aten.view.default(mm_505, [2, 4096, 2048]);  mm_505 = None
        add_2043 = torch.ops.aten.add.Tensor(view_2118, view_2123);  view_2118 = view_2123 = None
        convert_element_type_2783 = torch.ops.prims.convert_element_type.default(mm_504, torch.float32);  mm_504 = None
        reduce_scatter_tensor_252 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2783, 'avg', 128, '0');  convert_element_type_2783 = None
        wait_tensor_847 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_252);  reduce_scatter_tensor_252 = None
        convert_element_type_2784 = torch.ops.prims.convert_element_type.default(add_2043, torch.float32);  add_2043 = None
        convert_element_type_469 = torch.ops.prims.convert_element_type.default(primals_151, torch.bfloat16);  primals_151 = None
        all_gather_into_tensor_147 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_469, 128, '0');  convert_element_type_469 = None
        wait_tensor_179 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_147);  all_gather_into_tensor_147 = None
        convert_element_type_2786 = torch.ops.prims.convert_element_type.default(wait_tensor_179, torch.float32);  wait_tensor_179 = None
        mul_1897 = torch.ops.aten.mul.Tensor(convert_element_type_2784, convert_element_type_2786);  convert_element_type_2786 = None
        convert_element_type_470 = torch.ops.prims.convert_element_type.default(add_549, torch.float32);  add_549 = None
        mul_401 = torch.ops.aten.mul.Tensor(convert_element_type_470, rsqrt_27);  convert_element_type_470 = None
        mul_1899 = torch.ops.aten.mul.Tensor(mul_401, mul_1897)
        sum_249 = torch.ops.aten.sum.dim_IntList(mul_1899, [2], True);  mul_1899 = None
        div_239 = torch.ops.aten.div.Tensor(mul_401, 2048)
        mul_1900 = torch.ops.aten.mul.Tensor(div_239, sum_249);  div_239 = sum_249 = None
        sub_732 = torch.ops.aten.sub.Tensor(mul_1897, mul_1900);  mul_1897 = mul_1900 = None
        mul_1901 = torch.ops.aten.mul.Tensor(sub_732, rsqrt_27);  sub_732 = rsqrt_27 = None
        mul_1902 = torch.ops.aten.mul.Tensor(convert_element_type_2784, mul_401);  convert_element_type_2784 = mul_401 = None
        sum_250 = torch.ops.aten.sum.dim_IntList(mul_1902, [0, 1]);  mul_1902 = None
        convert_element_type_2787 = torch.ops.prims.convert_element_type.default(mul_1901, torch.bfloat16);  mul_1901 = None
        add_2044 = torch.ops.aten.add.Tensor(add_2042, convert_element_type_2787);  add_2042 = convert_element_type_2787 = None
        convert_element_type_default_28 = torch.ops.prims.convert_element_type.default(sum_250, torch.float32);  sum_250 = None
        reduce_scatter_tensor_253 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_28, 'avg', 128, '0');  convert_element_type_default_28 = None
        wait_tensor_848 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_253);  reduce_scatter_tensor_253 = None
        view_2124 = torch.ops.aten.view.default(add_2044, [8192, 2048])
        unsqueeze_71 = torch.ops.aten.unsqueeze.default(view_2124, 1)
        convert_element_type_2790 = torch.ops.prims.convert_element_type.default(unsqueeze_71, torch.float32);  unsqueeze_71 = None
        bmm_62 = torch.ops.aten.bmm.default(permute_1306, convert_element_type_2790);  permute_1306 = None
        bmm_63 = torch.ops.aten.bmm.default(convert_element_type_2790, permute_1307);  convert_element_type_2790 = permute_1307 = None
        convert_element_type_2791 = torch.ops.prims.convert_element_type.default(bmm_62, torch.bfloat16);  bmm_62 = None
        view_2125 = torch.ops.aten.view.default(bmm_63, [8192, 6]);  bmm_63 = None
        view_2126 = torch.ops.aten.view.default(convert_element_type_2791, [49152, 2048]);  convert_element_type_2791 = None
        index_88 = torch.ops.aten.index.Tensor(view_2126, [getitem_791]);  view_2126 = getitem_791 = None
        permute_1308 = torch.ops.aten.permute.default(view_2124, [1, 0])
        mm_506 = torch.ops.aten.mm.default(permute_1308, mul_398);  permute_1308 = mul_398 = None
        convert_element_type_464 = torch.ops.prims.convert_element_type.default(primals_150, torch.bfloat16);  primals_150 = None
        all_gather_into_tensor_146 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_464, 128, '0');  convert_element_type_464 = None
        wait_tensor_178 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_146);  all_gather_into_tensor_146 = None
        permute_130 = torch.ops.aten.permute.default(wait_tensor_178, [1, 0]);  wait_tensor_178 = None
        permute_1310 = torch.ops.aten.permute.default(permute_130, [1, 0]);  permute_130 = None
        mm_507 = torch.ops.aten.mm.default(view_2124, permute_1310);  view_2124 = permute_1310 = None
        convert_element_type_2796 = torch.ops.prims.convert_element_type.default(mm_506, torch.float32);  mm_506 = None
        reduce_scatter_tensor_254 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2796, 'avg', 128, '0');  convert_element_type_2796 = None
        wait_tensor_849 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_254);  reduce_scatter_tensor_254 = None
        convert_element_type_459 = torch.ops.prims.convert_element_type.default(mm_68, torch.float32);  mm_68 = None
        neg_16 = torch.ops.aten.neg.default(convert_element_type_459)
        exp_24 = torch.ops.aten.exp.default(neg_16);  neg_16 = None
        add_544 = torch.ops.aten.add.Tensor(exp_24, 1);  exp_24 = None
        div_40 = torch.ops.aten.div.Tensor(convert_element_type_459, add_544)
        convert_element_type_460 = torch.ops.prims.convert_element_type.default(div_40, torch.bfloat16);  div_40 = None
        mul_1903 = torch.ops.aten.mul.Tensor(mm_507, convert_element_type_460);  convert_element_type_460 = None
        mul_1904 = torch.ops.aten.mul.Tensor(mm_507, mm_69);  mm_507 = mm_69 = None
        permute_1312 = torch.ops.aten.permute.default(mul_1903, [1, 0])
        mm_508 = torch.ops.aten.mm.default(permute_1312, view_527);  permute_1312 = None
        convert_element_type_461 = torch.ops.prims.convert_element_type.default(primals_149, torch.bfloat16);  primals_149 = None
        all_gather_into_tensor_145 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_461, 128, '0');  convert_element_type_461 = None
        wait_tensor_177 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_145);  all_gather_into_tensor_145 = None
        permute_129 = torch.ops.aten.permute.default(wait_tensor_177, [1, 0]);  wait_tensor_177 = None
        permute_1314 = torch.ops.aten.permute.default(permute_129, [1, 0]);  permute_129 = None
        mm_509 = torch.ops.aten.mm.default(mul_1903, permute_1314);  mul_1903 = permute_1314 = None
        convert_element_type_2801 = torch.ops.prims.convert_element_type.default(mm_508, torch.float32);  mm_508 = None
        reduce_scatter_tensor_255 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2801, 'avg', 128, '0');  convert_element_type_2801 = None
        wait_tensor_850 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_255);  reduce_scatter_tensor_255 = None
        convert_element_type_2802 = torch.ops.prims.convert_element_type.default(mul_1904, torch.float32);  mul_1904 = None
        reciprocal_36 = torch.ops.aten.reciprocal.default(add_544);  add_544 = None
        mul_1905 = torch.ops.aten.mul.Tensor(reciprocal_36, 1);  reciprocal_36 = None
        mul_1906 = torch.ops.aten.mul.Tensor(convert_element_type_2802, mul_1905);  convert_element_type_2802 = None
        sub_733 = torch.ops.aten.sub.Tensor(1, mul_1905);  mul_1905 = None
        mul_1907 = torch.ops.aten.mul.Tensor(convert_element_type_459, sub_733);  convert_element_type_459 = sub_733 = None
        add_2046 = torch.ops.aten.add.Tensor(mul_1907, 1);  mul_1907 = None
        mul_1908 = torch.ops.aten.mul.Tensor(mul_1906, add_2046);  mul_1906 = add_2046 = None
        convert_element_type_2804 = torch.ops.prims.convert_element_type.default(mul_1908, torch.bfloat16);  mul_1908 = None
        permute_1316 = torch.ops.aten.permute.default(convert_element_type_2804, [1, 0])
        mm_510 = torch.ops.aten.mm.default(permute_1316, view_527);  permute_1316 = None
        convert_element_type_456 = torch.ops.prims.convert_element_type.default(primals_148, torch.bfloat16);  primals_148 = None
        all_gather_into_tensor_144 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_456, 128, '0');  convert_element_type_456 = None
        wait_tensor_176 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_144);  all_gather_into_tensor_144 = None
        permute_128 = torch.ops.aten.permute.default(wait_tensor_176, [1, 0]);  wait_tensor_176 = None
        permute_1318 = torch.ops.aten.permute.default(permute_128, [1, 0]);  permute_128 = None
        mm_511 = torch.ops.aten.mm.default(convert_element_type_2804, permute_1318);  convert_element_type_2804 = permute_1318 = None
        add_2047 = torch.ops.aten.add.Tensor(mm_509, mm_511);  mm_509 = mm_511 = None
        convert_element_type_2809 = torch.ops.prims.convert_element_type.default(mm_510, torch.float32);  mm_510 = None
        reduce_scatter_tensor_256 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2809, 'avg', 128, '0');  convert_element_type_2809 = None
        wait_tensor_851 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_256);  reduce_scatter_tensor_256 = None
        all_to_all_single_114 = torch.ops._c10d_functional.all_to_all_single.default(index_88, [_local_scalar_dense_120, _local_scalar_dense_121, _local_scalar_dense_122, _local_scalar_dense_123, _local_scalar_dense_124, _local_scalar_dense_125, _local_scalar_dense_126, _local_scalar_dense_127], [_local_scalar_dense_112, _local_scalar_dense_113, _local_scalar_dense_114, _local_scalar_dense_115, _local_scalar_dense_116, _local_scalar_dense_117, _local_scalar_dense_118, _local_scalar_dense_119], '1033');  index_88 = None
        wait_tensor_852 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_114);  all_to_all_single_114 = None
        full_456 = torch.ops.aten.full.default([sym_size_int_29, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_29 = None
        slice_scatter_18 = torch.ops.aten.slice_scatter.default(full_456, wait_tensor_852, 0, 0, -1);  wait_tensor_852 = None
        index_89 = torch.ops.aten.index.Tensor(slice_scatter_18, [getitem_792]);  slice_scatter_18 = None
        permute_1320 = torch.ops.aten.permute.default(index_89, [1, 0])
        _grouped_mm_186 = torch.ops.aten._grouped_mm.default(permute_1320, mul_378, cumsum_23);  permute_1320 = mul_378 = None
        _grouped_mm_187 = torch.ops.aten._grouped_mm.default(index_89, permute_1322, cumsum_23);  index_89 = permute_1322 = None
        convert_element_type_454 = torch.ops.prims.convert_element_type.default(_grouped_mm_21, torch.float32);  _grouped_mm_21 = None
        neg_15 = torch.ops.aten.neg.default(convert_element_type_454)
        exp_23 = torch.ops.aten.exp.default(neg_15);  neg_15 = None
        add_508 = torch.ops.aten.add.Tensor(exp_23, 1);  exp_23 = None
        div_39 = torch.ops.aten.div.Tensor(convert_element_type_454, add_508)
        convert_element_type_455 = torch.ops.prims.convert_element_type.default(div_39, torch.bfloat16);  div_39 = None
        mul_1909 = torch.ops.aten.mul.Tensor(_grouped_mm_187, convert_element_type_455);  convert_element_type_455 = None
        mul_1910 = torch.ops.aten.mul.Tensor(_grouped_mm_187, _grouped_mm_22);  _grouped_mm_187 = _grouped_mm_22 = None
        permute_1324 = torch.ops.aten.permute.default(mul_1909, [1, 0])
        _grouped_mm_188 = torch.ops.aten._grouped_mm.default(permute_1324, index_15, cumsum_23);  permute_1324 = None
        _grouped_mm_189 = torch.ops.aten._grouped_mm.default(mul_1909, permute_1326, cumsum_23);  mul_1909 = permute_1326 = None
        convert_element_type_2810 = torch.ops.prims.convert_element_type.default(mul_1910, torch.float32);  mul_1910 = None
        reciprocal_37 = torch.ops.aten.reciprocal.default(add_508);  add_508 = None
        mul_1911 = torch.ops.aten.mul.Tensor(reciprocal_37, 1);  reciprocal_37 = None
        mul_1912 = torch.ops.aten.mul.Tensor(convert_element_type_2810, mul_1911);  convert_element_type_2810 = None
        sub_734 = torch.ops.aten.sub.Tensor(1, mul_1911);  mul_1911 = None
        mul_1913 = torch.ops.aten.mul.Tensor(convert_element_type_454, sub_734);  convert_element_type_454 = sub_734 = None
        add_2049 = torch.ops.aten.add.Tensor(mul_1913, 1);  mul_1913 = None
        mul_1914 = torch.ops.aten.mul.Tensor(mul_1912, add_2049);  mul_1912 = add_2049 = None
        convert_element_type_2812 = torch.ops.prims.convert_element_type.default(mul_1914, torch.bfloat16);  mul_1914 = None
        permute_1328 = torch.ops.aten.permute.default(convert_element_type_2812, [1, 0])
        _grouped_mm_190 = torch.ops.aten._grouped_mm.default(permute_1328, index_15, cumsum_23);  permute_1328 = index_15 = None
        _grouped_mm_191 = torch.ops.aten._grouped_mm.default(convert_element_type_2812, permute_1330, cumsum_23);  convert_element_type_2812 = permute_1330 = cumsum_23 = None
        add_2050 = torch.ops.aten.add.Tensor(_grouped_mm_189, _grouped_mm_191);  _grouped_mm_189 = _grouped_mm_191 = None
        convert_element_type_2813 = torch.ops.prims.convert_element_type.default(_grouped_mm_188, torch.float32);  _grouped_mm_188 = None
        div_240 = torch.ops.aten.div.Tensor(convert_element_type_2813, 128);  convert_element_type_2813 = None
        split_1111 = torch.ops.aten.split.Tensor(div_240, 88, 1);  div_240 = None
        getitem_20885 = split_1111[0]
        getitem_20902 = split_1111[1]
        getitem_20919 = split_1111[2]
        getitem_20936 = split_1111[3]
        getitem_20953 = split_1111[4]
        getitem_20970 = split_1111[5]
        getitem_20987 = split_1111[6]
        getitem_21004 = split_1111[7]
        getitem_21021 = split_1111[8]
        getitem_21038 = split_1111[9]
        getitem_21055 = split_1111[10]
        getitem_21072 = split_1111[11]
        getitem_21089 = split_1111[12]
        getitem_21106 = split_1111[13]
        getitem_21123 = split_1111[14]
        getitem_21140 = split_1111[15];  split_1111 = None
        cat_380 = torch.ops.aten.cat.default([getitem_20885, getitem_20902, getitem_20919, getitem_20936, getitem_20953, getitem_20970, getitem_20987, getitem_21004, getitem_21021, getitem_21038, getitem_21055, getitem_21072, getitem_21089, getitem_21106, getitem_21123, getitem_21140]);  getitem_20885 = getitem_20902 = getitem_20919 = getitem_20936 = getitem_20953 = getitem_20970 = getitem_20987 = getitem_21004 = getitem_21021 = getitem_21038 = getitem_21055 = getitem_21072 = getitem_21089 = getitem_21106 = getitem_21123 = getitem_21140 = None
        reduce_scatter_tensor_257 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_380, 'sum', 16, '1025');  cat_380 = None
        wait_tensor_853 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_257);  reduce_scatter_tensor_257 = None
        convert_element_type_2814 = torch.ops.prims.convert_element_type.default(_grouped_mm_186, torch.float32);  _grouped_mm_186 = None
        div_241 = torch.ops.aten.div.Tensor(convert_element_type_2814, 128);  convert_element_type_2814 = None
        split_1128 = torch.ops.aten.split.Tensor(div_241, 128, 1);  div_241 = None
        getitem_21157 = split_1128[0]
        getitem_21174 = split_1128[1]
        getitem_21191 = split_1128[2]
        getitem_21208 = split_1128[3]
        getitem_21225 = split_1128[4]
        getitem_21242 = split_1128[5]
        getitem_21259 = split_1128[6]
        getitem_21276 = split_1128[7]
        getitem_21293 = split_1128[8]
        getitem_21310 = split_1128[9]
        getitem_21327 = split_1128[10]
        getitem_21344 = split_1128[11]
        getitem_21361 = split_1128[12]
        getitem_21378 = split_1128[13]
        getitem_21395 = split_1128[14]
        getitem_21412 = split_1128[15];  split_1128 = None
        cat_381 = torch.ops.aten.cat.default([getitem_21157, getitem_21174, getitem_21191, getitem_21208, getitem_21225, getitem_21242, getitem_21259, getitem_21276, getitem_21293, getitem_21310, getitem_21327, getitem_21344, getitem_21361, getitem_21378, getitem_21395, getitem_21412]);  getitem_21157 = getitem_21174 = getitem_21191 = getitem_21208 = getitem_21225 = getitem_21242 = getitem_21259 = getitem_21276 = getitem_21293 = getitem_21310 = getitem_21327 = getitem_21344 = getitem_21361 = getitem_21378 = getitem_21395 = getitem_21412 = None
        reduce_scatter_tensor_258 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_381, 'sum', 16, '1025');  cat_381 = None
        wait_tensor_854 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_258);  reduce_scatter_tensor_258 = None
        convert_element_type_2815 = torch.ops.prims.convert_element_type.default(_grouped_mm_190, torch.float32);  _grouped_mm_190 = None
        div_242 = torch.ops.aten.div.Tensor(convert_element_type_2815, 128);  convert_element_type_2815 = None
        split_1145 = torch.ops.aten.split.Tensor(div_242, 88, 1);  div_242 = None
        getitem_21429 = split_1145[0]
        getitem_21446 = split_1145[1]
        getitem_21463 = split_1145[2]
        getitem_21480 = split_1145[3]
        getitem_21497 = split_1145[4]
        getitem_21514 = split_1145[5]
        getitem_21531 = split_1145[6]
        getitem_21548 = split_1145[7]
        getitem_21565 = split_1145[8]
        getitem_21582 = split_1145[9]
        getitem_21599 = split_1145[10]
        getitem_21616 = split_1145[11]
        getitem_21633 = split_1145[12]
        getitem_21650 = split_1145[13]
        getitem_21667 = split_1145[14]
        getitem_21684 = split_1145[15];  split_1145 = None
        cat_382 = torch.ops.aten.cat.default([getitem_21429, getitem_21446, getitem_21463, getitem_21480, getitem_21497, getitem_21514, getitem_21531, getitem_21548, getitem_21565, getitem_21582, getitem_21599, getitem_21616, getitem_21633, getitem_21650, getitem_21667, getitem_21684]);  getitem_21429 = getitem_21446 = getitem_21463 = getitem_21480 = getitem_21497 = getitem_21514 = getitem_21531 = getitem_21548 = getitem_21565 = getitem_21582 = getitem_21599 = getitem_21616 = getitem_21633 = getitem_21650 = getitem_21667 = getitem_21684 = None
        reduce_scatter_tensor_259 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_382, 'sum', 16, '1025');  cat_382 = None
        wait_tensor_855 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_259);  reduce_scatter_tensor_259 = None
        index_put_88 = torch.ops.aten.index_put.default(full_456, [getitem_792], add_2050, True);  full_456 = getitem_792 = add_2050 = None
        slice_270 = torch.ops.aten.slice.Tensor(index_put_88, 0, 0, add_2051);  index_put_88 = add_2051 = None
        all_to_all_single_115 = torch.ops._c10d_functional.all_to_all_single.default(slice_270, [_local_scalar_dense_112, _local_scalar_dense_113, _local_scalar_dense_114, _local_scalar_dense_115, _local_scalar_dense_116, _local_scalar_dense_117, _local_scalar_dense_118, _local_scalar_dense_119], [_local_scalar_dense_120, _local_scalar_dense_121, _local_scalar_dense_122, _local_scalar_dense_123, _local_scalar_dense_124, _local_scalar_dense_125, _local_scalar_dense_126, _local_scalar_dense_127], '1033');  slice_270 = _local_scalar_dense_112 = _local_scalar_dense_113 = _local_scalar_dense_114 = _local_scalar_dense_115 = _local_scalar_dense_116 = _local_scalar_dense_117 = _local_scalar_dense_118 = _local_scalar_dense_119 = _local_scalar_dense_120 = _local_scalar_dense_121 = _local_scalar_dense_122 = _local_scalar_dense_123 = _local_scalar_dense_124 = _local_scalar_dense_125 = _local_scalar_dense_126 = _local_scalar_dense_127 = None
        wait_tensor_856 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_115);  all_to_all_single_115 = None
        index_put_89 = torch.ops.aten.index_put.default(full_default_52, [div_37], wait_tensor_856, True);  div_37 = wait_tensor_856 = None
        add_2055 = torch.ops.aten.add.Tensor(add_2047, index_put_89);  add_2047 = index_put_89 = None
        mul_1915 = torch.ops.aten.mul.Tensor(view_2125, 1.0);  view_2125 = None
        scatter_add_18 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_789, mul_1915);  getitem_789 = mul_1915 = None
        convert_element_type_443 = torch.ops.prims.convert_element_type.default(mm_67, torch.float32);  mm_67 = None
        sub_168 = torch.ops.aten.sub.Tensor(convert_element_type_443, amax_7);  convert_element_type_443 = amax_7 = None
        exp_22 = torch.ops.aten.exp.default(sub_168);  sub_168 = None
        div_36 = torch.ops.aten.div.Tensor(exp_22, sum_29);  exp_22 = sum_29 = None
        mul_1916 = torch.ops.aten.mul.Tensor(scatter_add_18, div_36);  scatter_add_18 = None
        sum_251 = torch.ops.aten.sum.dim_IntList(mul_1916, [1], True)
        neg_109 = torch.ops.aten.neg.default(div_36);  div_36 = None
        fma_18 = torch.ops.prims.fma.default(neg_109, sum_251, mul_1916);  neg_109 = sum_251 = mul_1916 = None
        convert_element_type_2816 = torch.ops.prims.convert_element_type.default(fma_18, torch.bfloat16);  fma_18 = None
        permute_1332 = torch.ops.aten.permute.default(convert_element_type_2816, [1, 0])
        mm_512 = torch.ops.aten.mm.default(permute_1332, view_527);  permute_1332 = view_527 = None
        convert_element_type_440 = torch.ops.prims.convert_element_type.default(primals_143, torch.bfloat16);  primals_143 = None
        all_gather_into_tensor_137 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_440, 128, '0');  convert_element_type_440 = None
        wait_tensor_165 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_137);  all_gather_into_tensor_137 = None
        slice_51 = torch.ops.aten.slice.Tensor(wait_tensor_165, 0, 0, 64);  wait_tensor_165 = None
        permute_124 = torch.ops.aten.permute.default(slice_51, [1, 0]);  slice_51 = None
        permute_1334 = torch.ops.aten.permute.default(permute_124, [1, 0]);  permute_124 = None
        mm_513 = torch.ops.aten.mm.default(convert_element_type_2816, permute_1334);  convert_element_type_2816 = permute_1334 = None
        add_2056 = torch.ops.aten.add.Tensor(add_2055, mm_513);  add_2055 = mm_513 = None
        convert_element_type_2821 = torch.ops.prims.convert_element_type.default(mm_512, torch.float32);  mm_512 = None
        split_1161 = torch.ops.aten.split.Tensor(convert_element_type_2821, 1);  convert_element_type_2821 = None
        getitem_21685 = split_1161[0]
        getitem_21686 = split_1161[1]
        getitem_21687 = split_1161[2]
        getitem_21688 = split_1161[3]
        getitem_21689 = split_1161[4]
        getitem_21690 = split_1161[5]
        getitem_21691 = split_1161[6]
        getitem_21692 = split_1161[7]
        getitem_21693 = split_1161[8]
        getitem_21694 = split_1161[9]
        getitem_21695 = split_1161[10]
        getitem_21696 = split_1161[11]
        getitem_21697 = split_1161[12]
        getitem_21698 = split_1161[13]
        getitem_21699 = split_1161[14]
        getitem_21700 = split_1161[15]
        getitem_21701 = split_1161[16]
        getitem_21702 = split_1161[17]
        getitem_21703 = split_1161[18]
        getitem_21704 = split_1161[19]
        getitem_21705 = split_1161[20]
        getitem_21706 = split_1161[21]
        getitem_21707 = split_1161[22]
        getitem_21708 = split_1161[23]
        getitem_21709 = split_1161[24]
        getitem_21710 = split_1161[25]
        getitem_21711 = split_1161[26]
        getitem_21712 = split_1161[27]
        getitem_21713 = split_1161[28]
        getitem_21714 = split_1161[29]
        getitem_21715 = split_1161[30]
        getitem_21716 = split_1161[31]
        getitem_21717 = split_1161[32]
        getitem_21718 = split_1161[33]
        getitem_21719 = split_1161[34]
        getitem_21720 = split_1161[35]
        getitem_21721 = split_1161[36]
        getitem_21722 = split_1161[37]
        getitem_21723 = split_1161[38]
        getitem_21724 = split_1161[39]
        getitem_21725 = split_1161[40]
        getitem_21726 = split_1161[41]
        getitem_21727 = split_1161[42]
        getitem_21728 = split_1161[43]
        getitem_21729 = split_1161[44]
        getitem_21730 = split_1161[45]
        getitem_21731 = split_1161[46]
        getitem_21732 = split_1161[47]
        getitem_21733 = split_1161[48]
        getitem_21734 = split_1161[49]
        getitem_21735 = split_1161[50]
        getitem_21736 = split_1161[51]
        getitem_21737 = split_1161[52]
        getitem_21738 = split_1161[53]
        getitem_21739 = split_1161[54]
        getitem_21740 = split_1161[55]
        getitem_21741 = split_1161[56]
        getitem_21742 = split_1161[57]
        getitem_21743 = split_1161[58]
        getitem_21744 = split_1161[59]
        getitem_21745 = split_1161[60]
        getitem_21746 = split_1161[61]
        getitem_21747 = split_1161[62]
        getitem_21748 = split_1161[63];  split_1161 = None
        cat_383 = torch.ops.aten.cat.default([getitem_21685, getitem_21686, getitem_21687, getitem_21688, getitem_21689, getitem_21690, getitem_21691, getitem_21692, getitem_21693, getitem_21694, getitem_21695, getitem_21696, getitem_21697, getitem_21698, getitem_21699, getitem_21700, getitem_21701, getitem_21702, getitem_21703, getitem_21704, getitem_21705, getitem_21706, getitem_21707, getitem_21708, getitem_21709, getitem_21710, getitem_21711, getitem_21712, getitem_21713, getitem_21714, getitem_21715, getitem_21716, getitem_21717, getitem_21718, getitem_21719, getitem_21720, getitem_21721, getitem_21722, getitem_21723, getitem_21724, getitem_21725, getitem_21726, getitem_21727, getitem_21728, getitem_21729, getitem_21730, getitem_21731, getitem_21732, getitem_21733, getitem_21734, getitem_21735, getitem_21736, getitem_21737, getitem_21738, getitem_21739, getitem_21740, getitem_21741, getitem_21742, getitem_21743, getitem_21744, getitem_21745, getitem_21746, getitem_21747, getitem_21748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_21685 = getitem_21686 = getitem_21687 = getitem_21688 = getitem_21689 = getitem_21690 = getitem_21691 = getitem_21692 = getitem_21693 = getitem_21694 = getitem_21695 = getitem_21696 = getitem_21697 = getitem_21698 = getitem_21699 = getitem_21700 = getitem_21701 = getitem_21702 = getitem_21703 = getitem_21704 = getitem_21705 = getitem_21706 = getitem_21707 = getitem_21708 = getitem_21709 = getitem_21710 = getitem_21711 = getitem_21712 = getitem_21713 = getitem_21714 = getitem_21715 = getitem_21716 = getitem_21717 = getitem_21718 = getitem_21719 = getitem_21720 = getitem_21721 = getitem_21722 = getitem_21723 = getitem_21724 = getitem_21725 = getitem_21726 = getitem_21727 = getitem_21728 = getitem_21729 = getitem_21730 = getitem_21731 = getitem_21732 = getitem_21733 = getitem_21734 = getitem_21735 = getitem_21736 = getitem_21737 = getitem_21738 = getitem_21739 = getitem_21740 = getitem_21741 = getitem_21742 = getitem_21743 = getitem_21744 = getitem_21745 = getitem_21746 = getitem_21747 = getitem_21748 = None
        reduce_scatter_tensor_260 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_383, 'avg', 128, '0');  cat_383 = None
        wait_tensor_857 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_260);  reduce_scatter_tensor_260 = None
        view_2127 = torch.ops.aten.view.default(add_2056, [2, 4096, 2048]);  add_2056 = None
        convert_element_type_2822 = torch.ops.prims.convert_element_type.default(view_2127, torch.float32);  view_2127 = None
        convert_element_type_437 = torch.ops.prims.convert_element_type.default(primals_141, torch.bfloat16);  primals_141 = None
        all_gather_into_tensor_136 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_437, 128, '0');  convert_element_type_437 = None
        wait_tensor_164 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_136);  all_gather_into_tensor_136 = None
        convert_element_type_2824 = torch.ops.prims.convert_element_type.default(wait_tensor_164, torch.float32);  wait_tensor_164 = None
        mul_1917 = torch.ops.aten.mul.Tensor(convert_element_type_2822, convert_element_type_2824);  convert_element_type_2824 = None
        convert_element_type_438 = torch.ops.prims.convert_element_type.default(add_484, torch.float32);  add_484 = None
        mul_358 = torch.ops.aten.mul.Tensor(convert_element_type_438, rsqrt_26);  convert_element_type_438 = None
        mul_1919 = torch.ops.aten.mul.Tensor(mul_358, mul_1917)
        sum_252 = torch.ops.aten.sum.dim_IntList(mul_1919, [2], True);  mul_1919 = None
        div_243 = torch.ops.aten.div.Tensor(mul_358, 2048)
        mul_1920 = torch.ops.aten.mul.Tensor(div_243, sum_252);  div_243 = sum_252 = None
        sub_736 = torch.ops.aten.sub.Tensor(mul_1917, mul_1920);  mul_1917 = mul_1920 = None
        mul_1921 = torch.ops.aten.mul.Tensor(sub_736, rsqrt_26);  sub_736 = rsqrt_26 = None
        mul_1922 = torch.ops.aten.mul.Tensor(convert_element_type_2822, mul_358);  convert_element_type_2822 = mul_358 = None
        sum_253 = torch.ops.aten.sum.dim_IntList(mul_1922, [0, 1]);  mul_1922 = None
        convert_element_type_2825 = torch.ops.prims.convert_element_type.default(mul_1921, torch.bfloat16);  mul_1921 = None
        add_2057 = torch.ops.aten.add.Tensor(add_2044, convert_element_type_2825);  add_2044 = convert_element_type_2825 = None
        convert_element_type_default_27 = torch.ops.prims.convert_element_type.default(sum_253, torch.float32);  sum_253 = None
        reduce_scatter_tensor_261 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_27, 'avg', 128, '0');  convert_element_type_default_27 = None
        wait_tensor_858 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_261);  reduce_scatter_tensor_261 = None
        view_2128 = torch.ops.aten.view.default(add_2057, [8192, 2048])
        permute_1336 = torch.ops.aten.permute.default(view_2128, [1, 0])
        permute_122 = torch.ops.aten.permute.default(getitem_785, [0, 2, 1, 3])
        view_522 = torch.ops.aten.view.default(permute_122, [2, 4096, -1]);  permute_122 = None
        view_524 = torch.ops.aten.view.default(view_522, [8192, 2048]);  view_522 = None
        mm_514 = torch.ops.aten.mm.default(permute_1336, view_524);  permute_1336 = view_524 = None
        convert_element_type_434 = torch.ops.prims.convert_element_type.default(primals_140, torch.bfloat16);  primals_140 = None
        all_gather_into_tensor_135 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_434, 128, '0');  convert_element_type_434 = None
        wait_tensor_163 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_135);  all_gather_into_tensor_135 = None
        permute_123 = torch.ops.aten.permute.default(wait_tensor_163, [1, 0]);  wait_tensor_163 = None
        permute_1338 = torch.ops.aten.permute.default(permute_123, [1, 0]);  permute_123 = None
        mm_515 = torch.ops.aten.mm.default(view_2128, permute_1338);  view_2128 = permute_1338 = None
        view_2129 = torch.ops.aten.view.default(mm_515, [2, 4096, 2048]);  mm_515 = None
        convert_element_type_2832 = torch.ops.prims.convert_element_type.default(mm_514, torch.float32);  mm_514 = None
        reduce_scatter_tensor_262 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2832, 'avg', 128, '0');  convert_element_type_2832 = None
        wait_tensor_859 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_262);  reduce_scatter_tensor_262 = None
        view_2130 = torch.ops.aten.view.default(view_2129, [2, 4096, 16, 128]);  view_2129 = None
        permute_1340 = torch.ops.aten.permute.default(view_2130, [0, 2, 1, 3]);  view_2130 = None
        fw_graph18 = self.fw_graph18
        joint_graph18 = self.joint_graph18
        mask_graph18 = self.mask_graph18
        flex_attention_backward_18 = torch.ops.higher_order.flex_attention_backward(permute_119, permute_120, permute_121, getitem_785, getitem_786, permute_1340, None, fw_graph18, joint_graph18, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph18), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_119 = permute_120 = permute_121 = getitem_785 = getitem_786 = permute_1340 = fw_graph18 = joint_graph18 = mask_graph18 = None
        getitem_21749 = flex_attention_backward_18[0]
        getitem_21750 = flex_attention_backward_18[1]
        getitem_21751 = flex_attention_backward_18[2];  flex_attention_backward_18 = None
        permute_1341 = torch.ops.aten.permute.default(getitem_21751, [0, 2, 1, 3]);  getitem_21751 = None
        permute_1342 = torch.ops.aten.permute.default(getitem_21750, [0, 2, 1, 3]);  getitem_21750 = None
        permute_1343 = torch.ops.aten.permute.default(getitem_21749, [0, 2, 1, 3]);  getitem_21749 = None
        slice_272 = torch.ops.aten.slice.Tensor(permute_1342, 3, 0, 128)
        slice_273 = torch.ops.aten.slice.Tensor(permute_1342, 3, 128, 192);  permute_1342 = None
        sum_254 = torch.ops.aten.sum.dim_IntList(slice_273, [2], True);  slice_273 = None
        cat_384 = torch.ops.aten.cat.default([slice_272, permute_1341], 3);  slice_272 = permute_1341 = None
        view_2131 = torch.ops.aten.view.default(cat_384, [2, 4096, 4096]);  cat_384 = None
        view_2132 = torch.ops.aten.view.default(view_2131, [8192, 4096]);  view_2131 = None
        permute_1344 = torch.ops.aten.permute.default(view_2132, [1, 0])
        mm_516 = torch.ops.aten.mm.default(permute_1344, view_519);  permute_1344 = view_519 = None
        convert_element_type_431 = torch.ops.prims.convert_element_type.default(primals_139, torch.bfloat16);  primals_139 = None
        all_gather_into_tensor_134 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_431, 128, '0');  convert_element_type_431 = None
        wait_tensor_162 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_134);  all_gather_into_tensor_134 = None
        permute_118 = torch.ops.aten.permute.default(wait_tensor_162, [1, 0]);  wait_tensor_162 = None
        permute_1346 = torch.ops.aten.permute.default(permute_118, [1, 0]);  permute_118 = None
        mm_517 = torch.ops.aten.mm.default(view_2132, permute_1346);  view_2132 = permute_1346 = None
        view_2133 = torch.ops.aten.view.default(mm_517, [2, 4096, 512]);  mm_517 = None
        convert_element_type_2837 = torch.ops.prims.convert_element_type.default(mm_516, torch.float32);  mm_516 = None
        reduce_scatter_tensor_263 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2837, 'avg', 128, '0');  convert_element_type_2837 = None
        wait_tensor_860 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_263);  reduce_scatter_tensor_263 = None
        convert_element_type_2838 = torch.ops.prims.convert_element_type.default(view_2133, torch.float32);  view_2133 = None
        convert_element_type_428 = torch.ops.prims.convert_element_type.default(primals_138, torch.bfloat16);  primals_138 = None
        all_gather_into_tensor_133 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_428, 128, '0');  convert_element_type_428 = None
        wait_tensor_161 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_133);  all_gather_into_tensor_133 = None
        convert_element_type_2840 = torch.ops.prims.convert_element_type.default(wait_tensor_161, torch.float32);  wait_tensor_161 = None
        mul_1923 = torch.ops.aten.mul.Tensor(convert_element_type_2838, convert_element_type_2840);  convert_element_type_2840 = None
        convert_element_type_429 = torch.ops.prims.convert_element_type.default(getitem_781, torch.float32);  getitem_781 = None
        mul_356 = torch.ops.aten.mul.Tensor(convert_element_type_429, rsqrt_25);  convert_element_type_429 = None
        mul_1925 = torch.ops.aten.mul.Tensor(mul_356, mul_1923)
        sum_255 = torch.ops.aten.sum.dim_IntList(mul_1925, [2], True);  mul_1925 = None
        div_244 = torch.ops.aten.div.Tensor(mul_356, 512)
        mul_1926 = torch.ops.aten.mul.Tensor(div_244, sum_255);  div_244 = sum_255 = None
        sub_737 = torch.ops.aten.sub.Tensor(mul_1923, mul_1926);  mul_1923 = mul_1926 = None
        mul_1927 = torch.ops.aten.mul.Tensor(sub_737, rsqrt_25);  sub_737 = rsqrt_25 = None
        mul_1928 = torch.ops.aten.mul.Tensor(convert_element_type_2838, mul_356);  convert_element_type_2838 = mul_356 = None
        sum_256 = torch.ops.aten.sum.dim_IntList(mul_1928, [0, 1]);  mul_1928 = None
        convert_element_type_2841 = torch.ops.prims.convert_element_type.default(mul_1927, torch.bfloat16);  mul_1927 = None
        convert_element_type_default_26 = torch.ops.prims.convert_element_type.default(sum_256, torch.float32);  sum_256 = None
        reduce_scatter_tensor_264 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_26, 'avg', 128, '0');  convert_element_type_default_26 = None
        wait_tensor_861 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_264);  reduce_scatter_tensor_264 = None
        convert_element_type_2844 = torch.ops.prims.convert_element_type.default(sum_254, torch.float32);  sum_254 = None
        view_2134 = torch.ops.aten.view.default(convert_element_type_2844, [2, 4096, 1, 32, 2]);  convert_element_type_2844 = None
        view_as_complex_90 = torch.ops.aten.view_as_complex.default(view_2134);  view_2134 = None
        mul_1929 = torch.ops.aten.mul.Tensor(view_as_complex_90, clone_9);  view_as_complex_90 = None
        view_as_real_90 = torch.ops.aten.view_as_real.default(mul_1929);  mul_1929 = None
        view_2135 = torch.ops.aten.view.default(view_as_real_90, [2, 4096, 1, 64]);  view_as_real_90 = None
        convert_element_type_2845 = torch.ops.prims.convert_element_type.default(view_2135, torch.bfloat16);  view_2135 = None
        squeeze_44 = torch.ops.aten.squeeze.dim(convert_element_type_2845, 2);  convert_element_type_2845 = None
        cat_385 = torch.ops.aten.cat.default([convert_element_type_2841, squeeze_44], 2);  convert_element_type_2841 = squeeze_44 = None
        view_2136 = torch.ops.aten.view.default(cat_385, [8192, 576]);  cat_385 = None
        permute_1348 = torch.ops.aten.permute.default(view_2136, [1, 0])
        mm_518 = torch.ops.aten.mm.default(permute_1348, view_505);  permute_1348 = None
        convert_element_type_423 = torch.ops.prims.convert_element_type.default(primals_137, torch.bfloat16);  primals_137 = None
        all_gather_into_tensor_132 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_423, 128, '0');  convert_element_type_423 = None
        wait_tensor_160 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_132);  all_gather_into_tensor_132 = None
        slice_49 = torch.ops.aten.slice.Tensor(wait_tensor_160, 0, 0, 576);  wait_tensor_160 = None
        permute_117 = torch.ops.aten.permute.default(slice_49, [1, 0]);  slice_49 = None
        permute_1350 = torch.ops.aten.permute.default(permute_117, [1, 0]);  permute_117 = None
        mm_519 = torch.ops.aten.mm.default(view_2136, permute_1350);  view_2136 = permute_1350 = None
        view_2137 = torch.ops.aten.view.default(mm_519, [2, 4096, 2048]);  mm_519 = None
        convert_element_type_2850 = torch.ops.prims.convert_element_type.default(mm_518, torch.float32);  mm_518 = None
        split_1162 = torch.ops.aten.split.Tensor(convert_element_type_2850, 5);  convert_element_type_2850 = None
        getitem_21753 = split_1162[0]
        getitem_21754 = split_1162[1]
        getitem_21755 = split_1162[2]
        getitem_21756 = split_1162[3]
        getitem_21757 = split_1162[4]
        getitem_21758 = split_1162[5]
        getitem_21759 = split_1162[6]
        getitem_21760 = split_1162[7]
        getitem_21761 = split_1162[8]
        getitem_21762 = split_1162[9]
        getitem_21763 = split_1162[10]
        getitem_21764 = split_1162[11]
        getitem_21765 = split_1162[12]
        getitem_21766 = split_1162[13]
        getitem_21767 = split_1162[14]
        getitem_21768 = split_1162[15]
        getitem_21769 = split_1162[16]
        getitem_21770 = split_1162[17]
        getitem_21771 = split_1162[18]
        getitem_21772 = split_1162[19]
        getitem_21773 = split_1162[20]
        getitem_21774 = split_1162[21]
        getitem_21775 = split_1162[22]
        getitem_21776 = split_1162[23]
        getitem_21777 = split_1162[24]
        getitem_21778 = split_1162[25]
        getitem_21779 = split_1162[26]
        getitem_21780 = split_1162[27]
        getitem_21781 = split_1162[28]
        getitem_21782 = split_1162[29]
        getitem_21783 = split_1162[30]
        getitem_21784 = split_1162[31]
        getitem_21785 = split_1162[32]
        getitem_21786 = split_1162[33]
        getitem_21787 = split_1162[34]
        getitem_21788 = split_1162[35]
        getitem_21789 = split_1162[36]
        getitem_21790 = split_1162[37]
        getitem_21791 = split_1162[38]
        getitem_21792 = split_1162[39]
        getitem_21793 = split_1162[40]
        getitem_21794 = split_1162[41]
        getitem_21795 = split_1162[42]
        getitem_21796 = split_1162[43]
        getitem_21797 = split_1162[44]
        getitem_21798 = split_1162[45]
        getitem_21799 = split_1162[46]
        getitem_21800 = split_1162[47]
        getitem_21801 = split_1162[48]
        getitem_21802 = split_1162[49]
        getitem_21803 = split_1162[50]
        getitem_21804 = split_1162[51]
        getitem_21805 = split_1162[52]
        getitem_21806 = split_1162[53]
        getitem_21807 = split_1162[54]
        getitem_21808 = split_1162[55]
        getitem_21809 = split_1162[56]
        getitem_21810 = split_1162[57]
        getitem_21811 = split_1162[58]
        getitem_21812 = split_1162[59]
        getitem_21813 = split_1162[60]
        getitem_21814 = split_1162[61]
        getitem_21815 = split_1162[62]
        getitem_21816 = split_1162[63]
        getitem_21817 = split_1162[64]
        getitem_21818 = split_1162[65]
        getitem_21819 = split_1162[66]
        getitem_21820 = split_1162[67]
        getitem_21821 = split_1162[68]
        getitem_21822 = split_1162[69]
        getitem_21823 = split_1162[70]
        getitem_21824 = split_1162[71]
        getitem_21825 = split_1162[72]
        getitem_21826 = split_1162[73]
        getitem_21827 = split_1162[74]
        getitem_21828 = split_1162[75]
        getitem_21829 = split_1162[76]
        getitem_21830 = split_1162[77]
        getitem_21831 = split_1162[78]
        getitem_21832 = split_1162[79]
        getitem_21833 = split_1162[80]
        getitem_21834 = split_1162[81]
        getitem_21835 = split_1162[82]
        getitem_21836 = split_1162[83]
        getitem_21837 = split_1162[84]
        getitem_21838 = split_1162[85]
        getitem_21839 = split_1162[86]
        getitem_21840 = split_1162[87]
        getitem_21841 = split_1162[88]
        getitem_21842 = split_1162[89]
        getitem_21843 = split_1162[90]
        getitem_21844 = split_1162[91]
        getitem_21845 = split_1162[92]
        getitem_21846 = split_1162[93]
        getitem_21847 = split_1162[94]
        getitem_21848 = split_1162[95]
        getitem_21849 = split_1162[96]
        getitem_21850 = split_1162[97]
        getitem_21851 = split_1162[98]
        getitem_21852 = split_1162[99]
        getitem_21853 = split_1162[100]
        getitem_21854 = split_1162[101]
        getitem_21855 = split_1162[102]
        getitem_21856 = split_1162[103]
        getitem_21857 = split_1162[104]
        getitem_21858 = split_1162[105]
        getitem_21859 = split_1162[106]
        getitem_21860 = split_1162[107]
        getitem_21861 = split_1162[108]
        getitem_21862 = split_1162[109]
        getitem_21863 = split_1162[110]
        getitem_21864 = split_1162[111]
        getitem_21865 = split_1162[112]
        getitem_21866 = split_1162[113]
        getitem_21867 = split_1162[114]
        getitem_21868 = split_1162[115];  split_1162 = None
        constant_pad_nd_1450 = torch.ops.aten.constant_pad_nd.default(getitem_21868, [0, 0, 0, 4], 0.0);  getitem_21868 = None
        cat_386 = torch.ops.aten.cat.default([getitem_21753, getitem_21754, getitem_21755, getitem_21756, getitem_21757, getitem_21758, getitem_21759, getitem_21760, getitem_21761, getitem_21762, getitem_21763, getitem_21764, getitem_21765, getitem_21766, getitem_21767, getitem_21768, getitem_21769, getitem_21770, getitem_21771, getitem_21772, getitem_21773, getitem_21774, getitem_21775, getitem_21776, getitem_21777, getitem_21778, getitem_21779, getitem_21780, getitem_21781, getitem_21782, getitem_21783, getitem_21784, getitem_21785, getitem_21786, getitem_21787, getitem_21788, getitem_21789, getitem_21790, getitem_21791, getitem_21792, getitem_21793, getitem_21794, getitem_21795, getitem_21796, getitem_21797, getitem_21798, getitem_21799, getitem_21800, getitem_21801, getitem_21802, getitem_21803, getitem_21804, getitem_21805, getitem_21806, getitem_21807, getitem_21808, getitem_21809, getitem_21810, getitem_21811, getitem_21812, getitem_21813, getitem_21814, getitem_21815, getitem_21816, getitem_21817, getitem_21818, getitem_21819, getitem_21820, getitem_21821, getitem_21822, getitem_21823, getitem_21824, getitem_21825, getitem_21826, getitem_21827, getitem_21828, getitem_21829, getitem_21830, getitem_21831, getitem_21832, getitem_21833, getitem_21834, getitem_21835, getitem_21836, getitem_21837, getitem_21838, getitem_21839, getitem_21840, getitem_21841, getitem_21842, getitem_21843, getitem_21844, getitem_21845, getitem_21846, getitem_21847, getitem_21848, getitem_21849, getitem_21850, getitem_21851, getitem_21852, getitem_21853, getitem_21854, getitem_21855, getitem_21856, getitem_21857, getitem_21858, getitem_21859, getitem_21860, getitem_21861, getitem_21862, getitem_21863, getitem_21864, getitem_21865, getitem_21866, getitem_21867, constant_pad_nd_1450, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_21753 = getitem_21754 = getitem_21755 = getitem_21756 = getitem_21757 = getitem_21758 = getitem_21759 = getitem_21760 = getitem_21761 = getitem_21762 = getitem_21763 = getitem_21764 = getitem_21765 = getitem_21766 = getitem_21767 = getitem_21768 = getitem_21769 = getitem_21770 = getitem_21771 = getitem_21772 = getitem_21773 = getitem_21774 = getitem_21775 = getitem_21776 = getitem_21777 = getitem_21778 = getitem_21779 = getitem_21780 = getitem_21781 = getitem_21782 = getitem_21783 = getitem_21784 = getitem_21785 = getitem_21786 = getitem_21787 = getitem_21788 = getitem_21789 = getitem_21790 = getitem_21791 = getitem_21792 = getitem_21793 = getitem_21794 = getitem_21795 = getitem_21796 = getitem_21797 = getitem_21798 = getitem_21799 = getitem_21800 = getitem_21801 = getitem_21802 = getitem_21803 = getitem_21804 = getitem_21805 = getitem_21806 = getitem_21807 = getitem_21808 = getitem_21809 = getitem_21810 = getitem_21811 = getitem_21812 = getitem_21813 = getitem_21814 = getitem_21815 = getitem_21816 = getitem_21817 = getitem_21818 = getitem_21819 = getitem_21820 = getitem_21821 = getitem_21822 = getitem_21823 = getitem_21824 = getitem_21825 = getitem_21826 = getitem_21827 = getitem_21828 = getitem_21829 = getitem_21830 = getitem_21831 = getitem_21832 = getitem_21833 = getitem_21834 = getitem_21835 = getitem_21836 = getitem_21837 = getitem_21838 = getitem_21839 = getitem_21840 = getitem_21841 = getitem_21842 = getitem_21843 = getitem_21844 = getitem_21845 = getitem_21846 = getitem_21847 = getitem_21848 = getitem_21849 = getitem_21850 = getitem_21851 = getitem_21852 = getitem_21853 = getitem_21854 = getitem_21855 = getitem_21856 = getitem_21857 = getitem_21858 = getitem_21859 = getitem_21860 = getitem_21861 = getitem_21862 = getitem_21863 = getitem_21864 = getitem_21865 = getitem_21866 = getitem_21867 = constant_pad_nd_1450 = None
        reduce_scatter_tensor_265 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_386, 'avg', 128, '0');  cat_386 = None
        wait_tensor_862 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_265);  reduce_scatter_tensor_265 = None
        slice_274 = torch.ops.aten.slice.Tensor(permute_1343, 3, 0, 128)
        slice_275 = torch.ops.aten.slice.Tensor(permute_1343, 3, 128, 192);  permute_1343 = None
        convert_element_type_2851 = torch.ops.prims.convert_element_type.default(slice_275, torch.float32);  slice_275 = None
        view_2138 = torch.ops.aten.view.default(convert_element_type_2851, [2, 4096, 16, 32, 2]);  convert_element_type_2851 = None
        view_as_complex_91 = torch.ops.aten.view_as_complex.default(view_2138);  view_2138 = None
        mul_1930 = torch.ops.aten.mul.Tensor(view_as_complex_91, clone_9);  view_as_complex_91 = None
        view_as_real_91 = torch.ops.aten.view_as_real.default(mul_1930);  mul_1930 = None
        view_2139 = torch.ops.aten.view.default(view_as_real_91, [2, 4096, 16, 64]);  view_as_real_91 = None
        convert_element_type_2852 = torch.ops.prims.convert_element_type.default(view_2139, torch.bfloat16);  view_2139 = None
        cat_387 = torch.ops.aten.cat.default([slice_274, convert_element_type_2852], 3);  slice_274 = convert_element_type_2852 = None
        view_2140 = torch.ops.aten.view.default(cat_387, [2, 4096, 3072]);  cat_387 = None
        view_2141 = torch.ops.aten.view.default(view_2140, [8192, 3072]);  view_2140 = None
        permute_1352 = torch.ops.aten.permute.default(view_2141, [1, 0])
        mm_520 = torch.ops.aten.mm.default(permute_1352, view_505);  permute_1352 = view_505 = None
        convert_element_type_418 = torch.ops.prims.convert_element_type.default(primals_136, torch.bfloat16);  primals_136 = None
        all_gather_into_tensor_131 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_418, 128, '0');  convert_element_type_418 = None
        wait_tensor_159 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_131);  all_gather_into_tensor_131 = None
        permute_116 = torch.ops.aten.permute.default(wait_tensor_159, [1, 0]);  wait_tensor_159 = None
        permute_1354 = torch.ops.aten.permute.default(permute_116, [1, 0]);  permute_116 = None
        mm_521 = torch.ops.aten.mm.default(view_2141, permute_1354);  view_2141 = permute_1354 = None
        view_2142 = torch.ops.aten.view.default(mm_521, [2, 4096, 2048]);  mm_521 = None
        add_2058 = torch.ops.aten.add.Tensor(view_2137, view_2142);  view_2137 = view_2142 = None
        convert_element_type_2857 = torch.ops.prims.convert_element_type.default(mm_520, torch.float32);  mm_520 = None
        reduce_scatter_tensor_266 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2857, 'avg', 128, '0');  convert_element_type_2857 = None
        wait_tensor_863 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_266);  reduce_scatter_tensor_266 = None
        convert_element_type_2858 = torch.ops.prims.convert_element_type.default(add_2058, torch.float32);  add_2058 = None
        convert_element_type_415 = torch.ops.prims.convert_element_type.default(primals_135, torch.bfloat16);  primals_135 = None
        all_gather_into_tensor_130 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_415, 128, '0');  convert_element_type_415 = None
        wait_tensor_158 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_130);  all_gather_into_tensor_130 = None
        convert_element_type_2860 = torch.ops.prims.convert_element_type.default(wait_tensor_158, torch.float32);  wait_tensor_158 = None
        mul_1931 = torch.ops.aten.mul.Tensor(convert_element_type_2858, convert_element_type_2860);  convert_element_type_2860 = None
        convert_element_type_416 = torch.ops.prims.convert_element_type.default(add_481, torch.float32);  add_481 = None
        mul_352 = torch.ops.aten.mul.Tensor(convert_element_type_416, rsqrt_24);  convert_element_type_416 = None
        mul_1933 = torch.ops.aten.mul.Tensor(mul_352, mul_1931)
        sum_257 = torch.ops.aten.sum.dim_IntList(mul_1933, [2], True);  mul_1933 = None
        div_245 = torch.ops.aten.div.Tensor(mul_352, 2048)
        mul_1934 = torch.ops.aten.mul.Tensor(div_245, sum_257);  div_245 = sum_257 = None
        sub_738 = torch.ops.aten.sub.Tensor(mul_1931, mul_1934);  mul_1931 = mul_1934 = None
        mul_1935 = torch.ops.aten.mul.Tensor(sub_738, rsqrt_24);  sub_738 = rsqrt_24 = None
        mul_1936 = torch.ops.aten.mul.Tensor(convert_element_type_2858, mul_352);  convert_element_type_2858 = mul_352 = None
        sum_258 = torch.ops.aten.sum.dim_IntList(mul_1936, [0, 1]);  mul_1936 = None
        convert_element_type_2861 = torch.ops.prims.convert_element_type.default(mul_1935, torch.bfloat16);  mul_1935 = None
        add_2059 = torch.ops.aten.add.Tensor(add_2057, convert_element_type_2861);  add_2057 = convert_element_type_2861 = None
        convert_element_type_default_25 = torch.ops.prims.convert_element_type.default(sum_258, torch.float32);  sum_258 = None
        reduce_scatter_tensor_267 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_25, 'avg', 128, '0');  convert_element_type_default_25 = None
        wait_tensor_864 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_267);  reduce_scatter_tensor_267 = None
        view_2143 = torch.ops.aten.view.default(add_2059, [8192, 2048])
        unsqueeze_72 = torch.ops.aten.unsqueeze.default(view_2143, 1)
        convert_element_type_2864 = torch.ops.prims.convert_element_type.default(unsqueeze_72, torch.float32);  unsqueeze_72 = None
        bmm_64 = torch.ops.aten.bmm.default(permute_1356, convert_element_type_2864);  permute_1356 = None
        bmm_65 = torch.ops.aten.bmm.default(convert_element_type_2864, permute_1357);  convert_element_type_2864 = permute_1357 = None
        convert_element_type_2865 = torch.ops.prims.convert_element_type.default(bmm_64, torch.bfloat16);  bmm_64 = None
        view_2144 = torch.ops.aten.view.default(bmm_65, [8192, 6]);  bmm_65 = None
        view_2145 = torch.ops.aten.view.default(convert_element_type_2865, [49152, 2048]);  convert_element_type_2865 = None
        index_90 = torch.ops.aten.index.Tensor(view_2145, [getitem_681]);  view_2145 = getitem_681 = None
        permute_1358 = torch.ops.aten.permute.default(view_2143, [1, 0])
        mm_522 = torch.ops.aten.mm.default(permute_1358, mul_349);  permute_1358 = mul_349 = None
        convert_element_type_410 = torch.ops.prims.convert_element_type.default(primals_134, torch.bfloat16);  primals_134 = None
        all_gather_into_tensor_129 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_410, 128, '0');  convert_element_type_410 = None
        wait_tensor_157 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_129);  all_gather_into_tensor_129 = None
        permute_115 = torch.ops.aten.permute.default(wait_tensor_157, [1, 0]);  wait_tensor_157 = None
        permute_1360 = torch.ops.aten.permute.default(permute_115, [1, 0]);  permute_115 = None
        mm_523 = torch.ops.aten.mm.default(view_2143, permute_1360);  view_2143 = permute_1360 = None
        convert_element_type_2870 = torch.ops.prims.convert_element_type.default(mm_522, torch.float32);  mm_522 = None
        reduce_scatter_tensor_268 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2870, 'avg', 128, '0');  convert_element_type_2870 = None
        wait_tensor_865 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_268);  reduce_scatter_tensor_268 = None
        convert_element_type_405 = torch.ops.prims.convert_element_type.default(mm_60, torch.float32);  mm_60 = None
        neg_14 = torch.ops.aten.neg.default(convert_element_type_405)
        exp_21 = torch.ops.aten.exp.default(neg_14);  neg_14 = None
        add_476 = torch.ops.aten.add.Tensor(exp_21, 1);  exp_21 = None
        div_35 = torch.ops.aten.div.Tensor(convert_element_type_405, add_476)
        convert_element_type_406 = torch.ops.prims.convert_element_type.default(div_35, torch.bfloat16);  div_35 = None
        mul_1937 = torch.ops.aten.mul.Tensor(mm_523, convert_element_type_406);  convert_element_type_406 = None
        mul_1938 = torch.ops.aten.mul.Tensor(mm_523, mm_61);  mm_523 = mm_61 = None
        permute_1362 = torch.ops.aten.permute.default(mul_1937, [1, 0])
        mm_524 = torch.ops.aten.mm.default(permute_1362, view_460);  permute_1362 = None
        convert_element_type_407 = torch.ops.prims.convert_element_type.default(primals_133, torch.bfloat16);  primals_133 = None
        all_gather_into_tensor_128 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_407, 128, '0');  convert_element_type_407 = None
        wait_tensor_156 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_128);  all_gather_into_tensor_128 = None
        permute_114 = torch.ops.aten.permute.default(wait_tensor_156, [1, 0]);  wait_tensor_156 = None
        permute_1364 = torch.ops.aten.permute.default(permute_114, [1, 0]);  permute_114 = None
        mm_525 = torch.ops.aten.mm.default(mul_1937, permute_1364);  mul_1937 = permute_1364 = None
        convert_element_type_2875 = torch.ops.prims.convert_element_type.default(mm_524, torch.float32);  mm_524 = None
        reduce_scatter_tensor_269 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2875, 'avg', 128, '0');  convert_element_type_2875 = None
        wait_tensor_866 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_269);  reduce_scatter_tensor_269 = None
        convert_element_type_2876 = torch.ops.prims.convert_element_type.default(mul_1938, torch.float32);  mul_1938 = None
        reciprocal_38 = torch.ops.aten.reciprocal.default(add_476);  add_476 = None
        mul_1939 = torch.ops.aten.mul.Tensor(reciprocal_38, 1);  reciprocal_38 = None
        mul_1940 = torch.ops.aten.mul.Tensor(convert_element_type_2876, mul_1939);  convert_element_type_2876 = None
        sub_739 = torch.ops.aten.sub.Tensor(1, mul_1939);  mul_1939 = None
        mul_1941 = torch.ops.aten.mul.Tensor(convert_element_type_405, sub_739);  convert_element_type_405 = sub_739 = None
        add_2061 = torch.ops.aten.add.Tensor(mul_1941, 1);  mul_1941 = None
        mul_1942 = torch.ops.aten.mul.Tensor(mul_1940, add_2061);  mul_1940 = add_2061 = None
        convert_element_type_2878 = torch.ops.prims.convert_element_type.default(mul_1942, torch.bfloat16);  mul_1942 = None
        permute_1366 = torch.ops.aten.permute.default(convert_element_type_2878, [1, 0])
        mm_526 = torch.ops.aten.mm.default(permute_1366, view_460);  permute_1366 = None
        convert_element_type_402 = torch.ops.prims.convert_element_type.default(primals_132, torch.bfloat16);  primals_132 = None
        all_gather_into_tensor_127 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_402, 128, '0');  convert_element_type_402 = None
        wait_tensor_155 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_127);  all_gather_into_tensor_127 = None
        permute_113 = torch.ops.aten.permute.default(wait_tensor_155, [1, 0]);  wait_tensor_155 = None
        permute_1368 = torch.ops.aten.permute.default(permute_113, [1, 0]);  permute_113 = None
        mm_527 = torch.ops.aten.mm.default(convert_element_type_2878, permute_1368);  convert_element_type_2878 = permute_1368 = None
        add_2062 = torch.ops.aten.add.Tensor(mm_525, mm_527);  mm_525 = mm_527 = None
        convert_element_type_2883 = torch.ops.prims.convert_element_type.default(mm_526, torch.float32);  mm_526 = None
        reduce_scatter_tensor_270 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2883, 'avg', 128, '0');  convert_element_type_2883 = None
        wait_tensor_867 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_270);  reduce_scatter_tensor_270 = None
        all_to_all_single_116 = torch.ops._c10d_functional.all_to_all_single.default(index_90, [_local_scalar_dense_104, _local_scalar_dense_105, _local_scalar_dense_106, _local_scalar_dense_107, _local_scalar_dense_108, _local_scalar_dense_109, _local_scalar_dense_110, _local_scalar_dense_111], [_local_scalar_dense_96, _local_scalar_dense_97, _local_scalar_dense_98, _local_scalar_dense_99, _local_scalar_dense_100, _local_scalar_dense_101, _local_scalar_dense_102, _local_scalar_dense_103], '1033');  index_90 = None
        wait_tensor_868 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_116);  all_to_all_single_116 = None
        full_462 = torch.ops.aten.full.default([sym_size_int_25, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_25 = None
        slice_scatter_19 = torch.ops.aten.slice_scatter.default(full_462, wait_tensor_868, 0, 0, -1);  wait_tensor_868 = None
        index_91 = torch.ops.aten.index.Tensor(slice_scatter_19, [getitem_682]);  slice_scatter_19 = None
        permute_1370 = torch.ops.aten.permute.default(index_91, [1, 0])
        _grouped_mm_192 = torch.ops.aten._grouped_mm.default(permute_1370, mul_329, cumsum_20);  permute_1370 = mul_329 = None
        _grouped_mm_193 = torch.ops.aten._grouped_mm.default(index_91, permute_1372, cumsum_20);  index_91 = permute_1372 = None
        convert_element_type_400 = torch.ops.prims.convert_element_type.default(_grouped_mm_18, torch.float32);  _grouped_mm_18 = None
        neg_13 = torch.ops.aten.neg.default(convert_element_type_400)
        exp_20 = torch.ops.aten.exp.default(neg_13);  neg_13 = None
        add_440 = torch.ops.aten.add.Tensor(exp_20, 1);  exp_20 = None
        div_34 = torch.ops.aten.div.Tensor(convert_element_type_400, add_440)
        convert_element_type_401 = torch.ops.prims.convert_element_type.default(div_34, torch.bfloat16);  div_34 = None
        mul_1943 = torch.ops.aten.mul.Tensor(_grouped_mm_193, convert_element_type_401);  convert_element_type_401 = None
        mul_1944 = torch.ops.aten.mul.Tensor(_grouped_mm_193, _grouped_mm_19);  _grouped_mm_193 = _grouped_mm_19 = None
        permute_1374 = torch.ops.aten.permute.default(mul_1943, [1, 0])
        _grouped_mm_194 = torch.ops.aten._grouped_mm.default(permute_1374, index_13, cumsum_20);  permute_1374 = None
        _grouped_mm_195 = torch.ops.aten._grouped_mm.default(mul_1943, permute_1376, cumsum_20);  mul_1943 = permute_1376 = None
        convert_element_type_2884 = torch.ops.prims.convert_element_type.default(mul_1944, torch.float32);  mul_1944 = None
        reciprocal_39 = torch.ops.aten.reciprocal.default(add_440);  add_440 = None
        mul_1945 = torch.ops.aten.mul.Tensor(reciprocal_39, 1);  reciprocal_39 = None
        mul_1946 = torch.ops.aten.mul.Tensor(convert_element_type_2884, mul_1945);  convert_element_type_2884 = None
        sub_740 = torch.ops.aten.sub.Tensor(1, mul_1945);  mul_1945 = None
        mul_1947 = torch.ops.aten.mul.Tensor(convert_element_type_400, sub_740);  convert_element_type_400 = sub_740 = None
        add_2064 = torch.ops.aten.add.Tensor(mul_1947, 1);  mul_1947 = None
        mul_1948 = torch.ops.aten.mul.Tensor(mul_1946, add_2064);  mul_1946 = add_2064 = None
        convert_element_type_2886 = torch.ops.prims.convert_element_type.default(mul_1948, torch.bfloat16);  mul_1948 = None
        permute_1378 = torch.ops.aten.permute.default(convert_element_type_2886, [1, 0])
        _grouped_mm_196 = torch.ops.aten._grouped_mm.default(permute_1378, index_13, cumsum_20);  permute_1378 = index_13 = None
        _grouped_mm_197 = torch.ops.aten._grouped_mm.default(convert_element_type_2886, permute_1380, cumsum_20);  convert_element_type_2886 = permute_1380 = cumsum_20 = None
        add_2065 = torch.ops.aten.add.Tensor(_grouped_mm_195, _grouped_mm_197);  _grouped_mm_195 = _grouped_mm_197 = None
        convert_element_type_2887 = torch.ops.prims.convert_element_type.default(_grouped_mm_194, torch.float32);  _grouped_mm_194 = None
        div_246 = torch.ops.aten.div.Tensor(convert_element_type_2887, 128);  convert_element_type_2887 = None
        split_1164 = torch.ops.aten.split.Tensor(div_246, 88, 1);  div_246 = None
        getitem_21885 = split_1164[0]
        getitem_21902 = split_1164[1]
        getitem_21919 = split_1164[2]
        getitem_21936 = split_1164[3]
        getitem_21953 = split_1164[4]
        getitem_21970 = split_1164[5]
        getitem_21987 = split_1164[6]
        getitem_22004 = split_1164[7]
        getitem_22021 = split_1164[8]
        getitem_22038 = split_1164[9]
        getitem_22055 = split_1164[10]
        getitem_22072 = split_1164[11]
        getitem_22089 = split_1164[12]
        getitem_22106 = split_1164[13]
        getitem_22123 = split_1164[14]
        getitem_22140 = split_1164[15];  split_1164 = None
        cat_388 = torch.ops.aten.cat.default([getitem_21885, getitem_21902, getitem_21919, getitem_21936, getitem_21953, getitem_21970, getitem_21987, getitem_22004, getitem_22021, getitem_22038, getitem_22055, getitem_22072, getitem_22089, getitem_22106, getitem_22123, getitem_22140]);  getitem_21885 = getitem_21902 = getitem_21919 = getitem_21936 = getitem_21953 = getitem_21970 = getitem_21987 = getitem_22004 = getitem_22021 = getitem_22038 = getitem_22055 = getitem_22072 = getitem_22089 = getitem_22106 = getitem_22123 = getitem_22140 = None
        reduce_scatter_tensor_271 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_388, 'sum', 16, '1025');  cat_388 = None
        wait_tensor_869 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_271);  reduce_scatter_tensor_271 = None
        convert_element_type_2888 = torch.ops.prims.convert_element_type.default(_grouped_mm_192, torch.float32);  _grouped_mm_192 = None
        div_247 = torch.ops.aten.div.Tensor(convert_element_type_2888, 128);  convert_element_type_2888 = None
        split_1181 = torch.ops.aten.split.Tensor(div_247, 128, 1);  div_247 = None
        getitem_22157 = split_1181[0]
        getitem_22174 = split_1181[1]
        getitem_22191 = split_1181[2]
        getitem_22208 = split_1181[3]
        getitem_22225 = split_1181[4]
        getitem_22242 = split_1181[5]
        getitem_22259 = split_1181[6]
        getitem_22276 = split_1181[7]
        getitem_22293 = split_1181[8]
        getitem_22310 = split_1181[9]
        getitem_22327 = split_1181[10]
        getitem_22344 = split_1181[11]
        getitem_22361 = split_1181[12]
        getitem_22378 = split_1181[13]
        getitem_22395 = split_1181[14]
        getitem_22412 = split_1181[15];  split_1181 = None
        cat_389 = torch.ops.aten.cat.default([getitem_22157, getitem_22174, getitem_22191, getitem_22208, getitem_22225, getitem_22242, getitem_22259, getitem_22276, getitem_22293, getitem_22310, getitem_22327, getitem_22344, getitem_22361, getitem_22378, getitem_22395, getitem_22412]);  getitem_22157 = getitem_22174 = getitem_22191 = getitem_22208 = getitem_22225 = getitem_22242 = getitem_22259 = getitem_22276 = getitem_22293 = getitem_22310 = getitem_22327 = getitem_22344 = getitem_22361 = getitem_22378 = getitem_22395 = getitem_22412 = None
        reduce_scatter_tensor_272 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_389, 'sum', 16, '1025');  cat_389 = None
        wait_tensor_870 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_272);  reduce_scatter_tensor_272 = None
        convert_element_type_2889 = torch.ops.prims.convert_element_type.default(_grouped_mm_196, torch.float32);  _grouped_mm_196 = None
        div_248 = torch.ops.aten.div.Tensor(convert_element_type_2889, 128);  convert_element_type_2889 = None
        split_1198 = torch.ops.aten.split.Tensor(div_248, 88, 1);  div_248 = None
        getitem_22429 = split_1198[0]
        getitem_22446 = split_1198[1]
        getitem_22463 = split_1198[2]
        getitem_22480 = split_1198[3]
        getitem_22497 = split_1198[4]
        getitem_22514 = split_1198[5]
        getitem_22531 = split_1198[6]
        getitem_22548 = split_1198[7]
        getitem_22565 = split_1198[8]
        getitem_22582 = split_1198[9]
        getitem_22599 = split_1198[10]
        getitem_22616 = split_1198[11]
        getitem_22633 = split_1198[12]
        getitem_22650 = split_1198[13]
        getitem_22667 = split_1198[14]
        getitem_22684 = split_1198[15];  split_1198 = None
        cat_390 = torch.ops.aten.cat.default([getitem_22429, getitem_22446, getitem_22463, getitem_22480, getitem_22497, getitem_22514, getitem_22531, getitem_22548, getitem_22565, getitem_22582, getitem_22599, getitem_22616, getitem_22633, getitem_22650, getitem_22667, getitem_22684]);  getitem_22429 = getitem_22446 = getitem_22463 = getitem_22480 = getitem_22497 = getitem_22514 = getitem_22531 = getitem_22548 = getitem_22565 = getitem_22582 = getitem_22599 = getitem_22616 = getitem_22633 = getitem_22650 = getitem_22667 = getitem_22684 = None
        reduce_scatter_tensor_273 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_390, 'sum', 16, '1025');  cat_390 = None
        wait_tensor_871 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_273);  reduce_scatter_tensor_273 = None
        index_put_90 = torch.ops.aten.index_put.default(full_462, [getitem_682], add_2065, True);  full_462 = getitem_682 = add_2065 = None
        slice_276 = torch.ops.aten.slice.Tensor(index_put_90, 0, 0, add_2066);  index_put_90 = add_2066 = None
        all_to_all_single_117 = torch.ops._c10d_functional.all_to_all_single.default(slice_276, [_local_scalar_dense_96, _local_scalar_dense_97, _local_scalar_dense_98, _local_scalar_dense_99, _local_scalar_dense_100, _local_scalar_dense_101, _local_scalar_dense_102, _local_scalar_dense_103], [_local_scalar_dense_104, _local_scalar_dense_105, _local_scalar_dense_106, _local_scalar_dense_107, _local_scalar_dense_108, _local_scalar_dense_109, _local_scalar_dense_110, _local_scalar_dense_111], '1033');  slice_276 = _local_scalar_dense_96 = _local_scalar_dense_97 = _local_scalar_dense_98 = _local_scalar_dense_99 = _local_scalar_dense_100 = _local_scalar_dense_101 = _local_scalar_dense_102 = _local_scalar_dense_103 = _local_scalar_dense_104 = _local_scalar_dense_105 = _local_scalar_dense_106 = _local_scalar_dense_107 = _local_scalar_dense_108 = _local_scalar_dense_109 = _local_scalar_dense_110 = _local_scalar_dense_111 = None
        wait_tensor_872 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_117);  all_to_all_single_117 = None
        index_put_91 = torch.ops.aten.index_put.default(full_default_52, [div_32], wait_tensor_872, True);  div_32 = wait_tensor_872 = None
        add_2070 = torch.ops.aten.add.Tensor(add_2062, index_put_91);  add_2062 = index_put_91 = None
        mul_1949 = torch.ops.aten.mul.Tensor(view_2144, 1.0);  view_2144 = None
        scatter_add_19 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_679, mul_1949);  getitem_679 = mul_1949 = None
        convert_element_type_389 = torch.ops.prims.convert_element_type.default(mm_59, torch.float32);  mm_59 = None
        sub_144 = torch.ops.aten.sub.Tensor(convert_element_type_389, amax_6);  convert_element_type_389 = amax_6 = None
        exp_19 = torch.ops.aten.exp.default(sub_144);  sub_144 = None
        div_31 = torch.ops.aten.div.Tensor(exp_19, sum_25);  exp_19 = sum_25 = None
        mul_1950 = torch.ops.aten.mul.Tensor(scatter_add_19, div_31);  scatter_add_19 = None
        sum_259 = torch.ops.aten.sum.dim_IntList(mul_1950, [1], True)
        neg_112 = torch.ops.aten.neg.default(div_31);  div_31 = None
        fma_19 = torch.ops.prims.fma.default(neg_112, sum_259, mul_1950);  neg_112 = sum_259 = mul_1950 = None
        convert_element_type_2890 = torch.ops.prims.convert_element_type.default(fma_19, torch.bfloat16);  fma_19 = None
        permute_1382 = torch.ops.aten.permute.default(convert_element_type_2890, [1, 0])
        mm_528 = torch.ops.aten.mm.default(permute_1382, view_460);  permute_1382 = view_460 = None
        convert_element_type_386 = torch.ops.prims.convert_element_type.default(primals_127, torch.bfloat16);  primals_127 = None
        all_gather_into_tensor_120 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_386, 128, '0');  convert_element_type_386 = None
        wait_tensor_144 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_120);  all_gather_into_tensor_120 = None
        slice_45 = torch.ops.aten.slice.Tensor(wait_tensor_144, 0, 0, 64);  wait_tensor_144 = None
        permute_109 = torch.ops.aten.permute.default(slice_45, [1, 0]);  slice_45 = None
        permute_1384 = torch.ops.aten.permute.default(permute_109, [1, 0]);  permute_109 = None
        mm_529 = torch.ops.aten.mm.default(convert_element_type_2890, permute_1384);  convert_element_type_2890 = permute_1384 = None
        add_2071 = torch.ops.aten.add.Tensor(add_2070, mm_529);  add_2070 = mm_529 = None
        convert_element_type_2895 = torch.ops.prims.convert_element_type.default(mm_528, torch.float32);  mm_528 = None
        split_1214 = torch.ops.aten.split.Tensor(convert_element_type_2895, 1);  convert_element_type_2895 = None
        getitem_22685 = split_1214[0]
        getitem_22686 = split_1214[1]
        getitem_22687 = split_1214[2]
        getitem_22688 = split_1214[3]
        getitem_22689 = split_1214[4]
        getitem_22690 = split_1214[5]
        getitem_22691 = split_1214[6]
        getitem_22692 = split_1214[7]
        getitem_22693 = split_1214[8]
        getitem_22694 = split_1214[9]
        getitem_22695 = split_1214[10]
        getitem_22696 = split_1214[11]
        getitem_22697 = split_1214[12]
        getitem_22698 = split_1214[13]
        getitem_22699 = split_1214[14]
        getitem_22700 = split_1214[15]
        getitem_22701 = split_1214[16]
        getitem_22702 = split_1214[17]
        getitem_22703 = split_1214[18]
        getitem_22704 = split_1214[19]
        getitem_22705 = split_1214[20]
        getitem_22706 = split_1214[21]
        getitem_22707 = split_1214[22]
        getitem_22708 = split_1214[23]
        getitem_22709 = split_1214[24]
        getitem_22710 = split_1214[25]
        getitem_22711 = split_1214[26]
        getitem_22712 = split_1214[27]
        getitem_22713 = split_1214[28]
        getitem_22714 = split_1214[29]
        getitem_22715 = split_1214[30]
        getitem_22716 = split_1214[31]
        getitem_22717 = split_1214[32]
        getitem_22718 = split_1214[33]
        getitem_22719 = split_1214[34]
        getitem_22720 = split_1214[35]
        getitem_22721 = split_1214[36]
        getitem_22722 = split_1214[37]
        getitem_22723 = split_1214[38]
        getitem_22724 = split_1214[39]
        getitem_22725 = split_1214[40]
        getitem_22726 = split_1214[41]
        getitem_22727 = split_1214[42]
        getitem_22728 = split_1214[43]
        getitem_22729 = split_1214[44]
        getitem_22730 = split_1214[45]
        getitem_22731 = split_1214[46]
        getitem_22732 = split_1214[47]
        getitem_22733 = split_1214[48]
        getitem_22734 = split_1214[49]
        getitem_22735 = split_1214[50]
        getitem_22736 = split_1214[51]
        getitem_22737 = split_1214[52]
        getitem_22738 = split_1214[53]
        getitem_22739 = split_1214[54]
        getitem_22740 = split_1214[55]
        getitem_22741 = split_1214[56]
        getitem_22742 = split_1214[57]
        getitem_22743 = split_1214[58]
        getitem_22744 = split_1214[59]
        getitem_22745 = split_1214[60]
        getitem_22746 = split_1214[61]
        getitem_22747 = split_1214[62]
        getitem_22748 = split_1214[63];  split_1214 = None
        cat_391 = torch.ops.aten.cat.default([getitem_22685, getitem_22686, getitem_22687, getitem_22688, getitem_22689, getitem_22690, getitem_22691, getitem_22692, getitem_22693, getitem_22694, getitem_22695, getitem_22696, getitem_22697, getitem_22698, getitem_22699, getitem_22700, getitem_22701, getitem_22702, getitem_22703, getitem_22704, getitem_22705, getitem_22706, getitem_22707, getitem_22708, getitem_22709, getitem_22710, getitem_22711, getitem_22712, getitem_22713, getitem_22714, getitem_22715, getitem_22716, getitem_22717, getitem_22718, getitem_22719, getitem_22720, getitem_22721, getitem_22722, getitem_22723, getitem_22724, getitem_22725, getitem_22726, getitem_22727, getitem_22728, getitem_22729, getitem_22730, getitem_22731, getitem_22732, getitem_22733, getitem_22734, getitem_22735, getitem_22736, getitem_22737, getitem_22738, getitem_22739, getitem_22740, getitem_22741, getitem_22742, getitem_22743, getitem_22744, getitem_22745, getitem_22746, getitem_22747, getitem_22748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_22685 = getitem_22686 = getitem_22687 = getitem_22688 = getitem_22689 = getitem_22690 = getitem_22691 = getitem_22692 = getitem_22693 = getitem_22694 = getitem_22695 = getitem_22696 = getitem_22697 = getitem_22698 = getitem_22699 = getitem_22700 = getitem_22701 = getitem_22702 = getitem_22703 = getitem_22704 = getitem_22705 = getitem_22706 = getitem_22707 = getitem_22708 = getitem_22709 = getitem_22710 = getitem_22711 = getitem_22712 = getitem_22713 = getitem_22714 = getitem_22715 = getitem_22716 = getitem_22717 = getitem_22718 = getitem_22719 = getitem_22720 = getitem_22721 = getitem_22722 = getitem_22723 = getitem_22724 = getitem_22725 = getitem_22726 = getitem_22727 = getitem_22728 = getitem_22729 = getitem_22730 = getitem_22731 = getitem_22732 = getitem_22733 = getitem_22734 = getitem_22735 = getitem_22736 = getitem_22737 = getitem_22738 = getitem_22739 = getitem_22740 = getitem_22741 = getitem_22742 = getitem_22743 = getitem_22744 = getitem_22745 = getitem_22746 = getitem_22747 = getitem_22748 = None
        reduce_scatter_tensor_274 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_391, 'avg', 128, '0');  cat_391 = None
        wait_tensor_873 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_274);  reduce_scatter_tensor_274 = None
        view_2146 = torch.ops.aten.view.default(add_2071, [2, 4096, 2048]);  add_2071 = None
        convert_element_type_2896 = torch.ops.prims.convert_element_type.default(view_2146, torch.float32);  view_2146 = None
        convert_element_type_383 = torch.ops.prims.convert_element_type.default(primals_125, torch.bfloat16);  primals_125 = None
        all_gather_into_tensor_119 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_383, 128, '0');  convert_element_type_383 = None
        wait_tensor_143 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_119);  all_gather_into_tensor_119 = None
        convert_element_type_2898 = torch.ops.prims.convert_element_type.default(wait_tensor_143, torch.float32);  wait_tensor_143 = None
        mul_1951 = torch.ops.aten.mul.Tensor(convert_element_type_2896, convert_element_type_2898);  convert_element_type_2898 = None
        convert_element_type_384 = torch.ops.prims.convert_element_type.default(add_416, torch.float32);  add_416 = None
        mul_309 = torch.ops.aten.mul.Tensor(convert_element_type_384, rsqrt_23);  convert_element_type_384 = None
        mul_1953 = torch.ops.aten.mul.Tensor(mul_309, mul_1951)
        sum_260 = torch.ops.aten.sum.dim_IntList(mul_1953, [2], True);  mul_1953 = None
        div_249 = torch.ops.aten.div.Tensor(mul_309, 2048)
        mul_1954 = torch.ops.aten.mul.Tensor(div_249, sum_260);  div_249 = sum_260 = None
        sub_742 = torch.ops.aten.sub.Tensor(mul_1951, mul_1954);  mul_1951 = mul_1954 = None
        mul_1955 = torch.ops.aten.mul.Tensor(sub_742, rsqrt_23);  sub_742 = rsqrt_23 = None
        mul_1956 = torch.ops.aten.mul.Tensor(convert_element_type_2896, mul_309);  convert_element_type_2896 = mul_309 = None
        sum_261 = torch.ops.aten.sum.dim_IntList(mul_1956, [0, 1]);  mul_1956 = None
        convert_element_type_2899 = torch.ops.prims.convert_element_type.default(mul_1955, torch.bfloat16);  mul_1955 = None
        add_2072 = torch.ops.aten.add.Tensor(add_2059, convert_element_type_2899);  add_2059 = convert_element_type_2899 = None
        convert_element_type_default_24 = torch.ops.prims.convert_element_type.default(sum_261, torch.float32);  sum_261 = None
        reduce_scatter_tensor_275 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_24, 'avg', 128, '0');  convert_element_type_default_24 = None
        wait_tensor_874 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_275);  reduce_scatter_tensor_275 = None
        view_2147 = torch.ops.aten.view.default(add_2072, [8192, 2048])
        permute_1386 = torch.ops.aten.permute.default(view_2147, [1, 0])
        permute_107 = torch.ops.aten.permute.default(getitem_675, [0, 2, 1, 3])
        view_455 = torch.ops.aten.view.default(permute_107, [2, 4096, -1]);  permute_107 = None
        view_457 = torch.ops.aten.view.default(view_455, [8192, 2048]);  view_455 = None
        mm_530 = torch.ops.aten.mm.default(permute_1386, view_457);  permute_1386 = view_457 = None
        convert_element_type_380 = torch.ops.prims.convert_element_type.default(primals_124, torch.bfloat16);  primals_124 = None
        all_gather_into_tensor_118 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_380, 128, '0');  convert_element_type_380 = None
        wait_tensor_142 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_118);  all_gather_into_tensor_118 = None
        permute_108 = torch.ops.aten.permute.default(wait_tensor_142, [1, 0]);  wait_tensor_142 = None
        permute_1388 = torch.ops.aten.permute.default(permute_108, [1, 0]);  permute_108 = None
        mm_531 = torch.ops.aten.mm.default(view_2147, permute_1388);  view_2147 = permute_1388 = None
        view_2148 = torch.ops.aten.view.default(mm_531, [2, 4096, 2048]);  mm_531 = None
        convert_element_type_2906 = torch.ops.prims.convert_element_type.default(mm_530, torch.float32);  mm_530 = None
        reduce_scatter_tensor_276 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2906, 'avg', 128, '0');  convert_element_type_2906 = None
        wait_tensor_875 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_276);  reduce_scatter_tensor_276 = None
        view_2149 = torch.ops.aten.view.default(view_2148, [2, 4096, 16, 128]);  view_2148 = None
        permute_1390 = torch.ops.aten.permute.default(view_2149, [0, 2, 1, 3]);  view_2149 = None
        fw_graph19 = self.fw_graph19
        joint_graph19 = self.joint_graph19
        mask_graph19 = self.mask_graph19
        flex_attention_backward_19 = torch.ops.higher_order.flex_attention_backward(permute_104, permute_105, permute_106, getitem_675, getitem_676, permute_1390, None, fw_graph19, joint_graph19, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph19), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_104 = permute_105 = permute_106 = getitem_675 = getitem_676 = permute_1390 = fw_graph19 = joint_graph19 = mask_graph19 = None
        getitem_22749 = flex_attention_backward_19[0]
        getitem_22750 = flex_attention_backward_19[1]
        getitem_22751 = flex_attention_backward_19[2];  flex_attention_backward_19 = None
        permute_1391 = torch.ops.aten.permute.default(getitem_22751, [0, 2, 1, 3]);  getitem_22751 = None
        permute_1392 = torch.ops.aten.permute.default(getitem_22750, [0, 2, 1, 3]);  getitem_22750 = None
        permute_1393 = torch.ops.aten.permute.default(getitem_22749, [0, 2, 1, 3]);  getitem_22749 = None
        slice_278 = torch.ops.aten.slice.Tensor(permute_1392, 3, 0, 128)
        slice_279 = torch.ops.aten.slice.Tensor(permute_1392, 3, 128, 192);  permute_1392 = None
        sum_262 = torch.ops.aten.sum.dim_IntList(slice_279, [2], True);  slice_279 = None
        cat_392 = torch.ops.aten.cat.default([slice_278, permute_1391], 3);  slice_278 = permute_1391 = None
        view_2150 = torch.ops.aten.view.default(cat_392, [2, 4096, 4096]);  cat_392 = None
        view_2151 = torch.ops.aten.view.default(view_2150, [8192, 4096]);  view_2150 = None
        permute_1394 = torch.ops.aten.permute.default(view_2151, [1, 0])
        mm_532 = torch.ops.aten.mm.default(permute_1394, view_452);  permute_1394 = view_452 = None
        convert_element_type_377 = torch.ops.prims.convert_element_type.default(primals_123, torch.bfloat16);  primals_123 = None
        all_gather_into_tensor_117 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_377, 128, '0');  convert_element_type_377 = None
        wait_tensor_141 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_117);  all_gather_into_tensor_117 = None
        permute_103 = torch.ops.aten.permute.default(wait_tensor_141, [1, 0]);  wait_tensor_141 = None
        permute_1396 = torch.ops.aten.permute.default(permute_103, [1, 0]);  permute_103 = None
        mm_533 = torch.ops.aten.mm.default(view_2151, permute_1396);  view_2151 = permute_1396 = None
        view_2152 = torch.ops.aten.view.default(mm_533, [2, 4096, 512]);  mm_533 = None
        convert_element_type_2911 = torch.ops.prims.convert_element_type.default(mm_532, torch.float32);  mm_532 = None
        reduce_scatter_tensor_277 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2911, 'avg', 128, '0');  convert_element_type_2911 = None
        wait_tensor_876 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_277);  reduce_scatter_tensor_277 = None
        convert_element_type_2912 = torch.ops.prims.convert_element_type.default(view_2152, torch.float32);  view_2152 = None
        convert_element_type_374 = torch.ops.prims.convert_element_type.default(primals_122, torch.bfloat16);  primals_122 = None
        all_gather_into_tensor_116 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_374, 128, '0');  convert_element_type_374 = None
        wait_tensor_140 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_116);  all_gather_into_tensor_116 = None
        convert_element_type_2914 = torch.ops.prims.convert_element_type.default(wait_tensor_140, torch.float32);  wait_tensor_140 = None
        mul_1957 = torch.ops.aten.mul.Tensor(convert_element_type_2912, convert_element_type_2914);  convert_element_type_2914 = None
        convert_element_type_375 = torch.ops.prims.convert_element_type.default(getitem_671, torch.float32);  getitem_671 = None
        mul_307 = torch.ops.aten.mul.Tensor(convert_element_type_375, rsqrt_22);  convert_element_type_375 = None
        mul_1959 = torch.ops.aten.mul.Tensor(mul_307, mul_1957)
        sum_263 = torch.ops.aten.sum.dim_IntList(mul_1959, [2], True);  mul_1959 = None
        div_250 = torch.ops.aten.div.Tensor(mul_307, 512)
        mul_1960 = torch.ops.aten.mul.Tensor(div_250, sum_263);  div_250 = sum_263 = None
        sub_743 = torch.ops.aten.sub.Tensor(mul_1957, mul_1960);  mul_1957 = mul_1960 = None
        mul_1961 = torch.ops.aten.mul.Tensor(sub_743, rsqrt_22);  sub_743 = rsqrt_22 = None
        mul_1962 = torch.ops.aten.mul.Tensor(convert_element_type_2912, mul_307);  convert_element_type_2912 = mul_307 = None
        sum_264 = torch.ops.aten.sum.dim_IntList(mul_1962, [0, 1]);  mul_1962 = None
        convert_element_type_2915 = torch.ops.prims.convert_element_type.default(mul_1961, torch.bfloat16);  mul_1961 = None
        convert_element_type_default_23 = torch.ops.prims.convert_element_type.default(sum_264, torch.float32);  sum_264 = None
        reduce_scatter_tensor_278 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_23, 'avg', 128, '0');  convert_element_type_default_23 = None
        wait_tensor_877 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_278);  reduce_scatter_tensor_278 = None
        convert_element_type_2918 = torch.ops.prims.convert_element_type.default(sum_262, torch.float32);  sum_262 = None
        view_2153 = torch.ops.aten.view.default(convert_element_type_2918, [2, 4096, 1, 32, 2]);  convert_element_type_2918 = None
        view_as_complex_92 = torch.ops.aten.view_as_complex.default(view_2153);  view_2153 = None
        mul_1963 = torch.ops.aten.mul.Tensor(view_as_complex_92, clone_9);  view_as_complex_92 = None
        view_as_real_92 = torch.ops.aten.view_as_real.default(mul_1963);  mul_1963 = None
        view_2154 = torch.ops.aten.view.default(view_as_real_92, [2, 4096, 1, 64]);  view_as_real_92 = None
        convert_element_type_2919 = torch.ops.prims.convert_element_type.default(view_2154, torch.bfloat16);  view_2154 = None
        squeeze_45 = torch.ops.aten.squeeze.dim(convert_element_type_2919, 2);  convert_element_type_2919 = None
        cat_393 = torch.ops.aten.cat.default([convert_element_type_2915, squeeze_45], 2);  convert_element_type_2915 = squeeze_45 = None
        view_2155 = torch.ops.aten.view.default(cat_393, [8192, 576]);  cat_393 = None
        permute_1398 = torch.ops.aten.permute.default(view_2155, [1, 0])
        mm_534 = torch.ops.aten.mm.default(permute_1398, view_438);  permute_1398 = None
        convert_element_type_369 = torch.ops.prims.convert_element_type.default(primals_121, torch.bfloat16);  primals_121 = None
        all_gather_into_tensor_115 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_369, 128, '0');  convert_element_type_369 = None
        wait_tensor_139 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_115);  all_gather_into_tensor_115 = None
        slice_43 = torch.ops.aten.slice.Tensor(wait_tensor_139, 0, 0, 576);  wait_tensor_139 = None
        permute_102 = torch.ops.aten.permute.default(slice_43, [1, 0]);  slice_43 = None
        permute_1400 = torch.ops.aten.permute.default(permute_102, [1, 0]);  permute_102 = None
        mm_535 = torch.ops.aten.mm.default(view_2155, permute_1400);  view_2155 = permute_1400 = None
        view_2156 = torch.ops.aten.view.default(mm_535, [2, 4096, 2048]);  mm_535 = None
        convert_element_type_2924 = torch.ops.prims.convert_element_type.default(mm_534, torch.float32);  mm_534 = None
        split_1215 = torch.ops.aten.split.Tensor(convert_element_type_2924, 5);  convert_element_type_2924 = None
        getitem_22753 = split_1215[0]
        getitem_22754 = split_1215[1]
        getitem_22755 = split_1215[2]
        getitem_22756 = split_1215[3]
        getitem_22757 = split_1215[4]
        getitem_22758 = split_1215[5]
        getitem_22759 = split_1215[6]
        getitem_22760 = split_1215[7]
        getitem_22761 = split_1215[8]
        getitem_22762 = split_1215[9]
        getitem_22763 = split_1215[10]
        getitem_22764 = split_1215[11]
        getitem_22765 = split_1215[12]
        getitem_22766 = split_1215[13]
        getitem_22767 = split_1215[14]
        getitem_22768 = split_1215[15]
        getitem_22769 = split_1215[16]
        getitem_22770 = split_1215[17]
        getitem_22771 = split_1215[18]
        getitem_22772 = split_1215[19]
        getitem_22773 = split_1215[20]
        getitem_22774 = split_1215[21]
        getitem_22775 = split_1215[22]
        getitem_22776 = split_1215[23]
        getitem_22777 = split_1215[24]
        getitem_22778 = split_1215[25]
        getitem_22779 = split_1215[26]
        getitem_22780 = split_1215[27]
        getitem_22781 = split_1215[28]
        getitem_22782 = split_1215[29]
        getitem_22783 = split_1215[30]
        getitem_22784 = split_1215[31]
        getitem_22785 = split_1215[32]
        getitem_22786 = split_1215[33]
        getitem_22787 = split_1215[34]
        getitem_22788 = split_1215[35]
        getitem_22789 = split_1215[36]
        getitem_22790 = split_1215[37]
        getitem_22791 = split_1215[38]
        getitem_22792 = split_1215[39]
        getitem_22793 = split_1215[40]
        getitem_22794 = split_1215[41]
        getitem_22795 = split_1215[42]
        getitem_22796 = split_1215[43]
        getitem_22797 = split_1215[44]
        getitem_22798 = split_1215[45]
        getitem_22799 = split_1215[46]
        getitem_22800 = split_1215[47]
        getitem_22801 = split_1215[48]
        getitem_22802 = split_1215[49]
        getitem_22803 = split_1215[50]
        getitem_22804 = split_1215[51]
        getitem_22805 = split_1215[52]
        getitem_22806 = split_1215[53]
        getitem_22807 = split_1215[54]
        getitem_22808 = split_1215[55]
        getitem_22809 = split_1215[56]
        getitem_22810 = split_1215[57]
        getitem_22811 = split_1215[58]
        getitem_22812 = split_1215[59]
        getitem_22813 = split_1215[60]
        getitem_22814 = split_1215[61]
        getitem_22815 = split_1215[62]
        getitem_22816 = split_1215[63]
        getitem_22817 = split_1215[64]
        getitem_22818 = split_1215[65]
        getitem_22819 = split_1215[66]
        getitem_22820 = split_1215[67]
        getitem_22821 = split_1215[68]
        getitem_22822 = split_1215[69]
        getitem_22823 = split_1215[70]
        getitem_22824 = split_1215[71]
        getitem_22825 = split_1215[72]
        getitem_22826 = split_1215[73]
        getitem_22827 = split_1215[74]
        getitem_22828 = split_1215[75]
        getitem_22829 = split_1215[76]
        getitem_22830 = split_1215[77]
        getitem_22831 = split_1215[78]
        getitem_22832 = split_1215[79]
        getitem_22833 = split_1215[80]
        getitem_22834 = split_1215[81]
        getitem_22835 = split_1215[82]
        getitem_22836 = split_1215[83]
        getitem_22837 = split_1215[84]
        getitem_22838 = split_1215[85]
        getitem_22839 = split_1215[86]
        getitem_22840 = split_1215[87]
        getitem_22841 = split_1215[88]
        getitem_22842 = split_1215[89]
        getitem_22843 = split_1215[90]
        getitem_22844 = split_1215[91]
        getitem_22845 = split_1215[92]
        getitem_22846 = split_1215[93]
        getitem_22847 = split_1215[94]
        getitem_22848 = split_1215[95]
        getitem_22849 = split_1215[96]
        getitem_22850 = split_1215[97]
        getitem_22851 = split_1215[98]
        getitem_22852 = split_1215[99]
        getitem_22853 = split_1215[100]
        getitem_22854 = split_1215[101]
        getitem_22855 = split_1215[102]
        getitem_22856 = split_1215[103]
        getitem_22857 = split_1215[104]
        getitem_22858 = split_1215[105]
        getitem_22859 = split_1215[106]
        getitem_22860 = split_1215[107]
        getitem_22861 = split_1215[108]
        getitem_22862 = split_1215[109]
        getitem_22863 = split_1215[110]
        getitem_22864 = split_1215[111]
        getitem_22865 = split_1215[112]
        getitem_22866 = split_1215[113]
        getitem_22867 = split_1215[114]
        getitem_22868 = split_1215[115];  split_1215 = None
        constant_pad_nd_1527 = torch.ops.aten.constant_pad_nd.default(getitem_22868, [0, 0, 0, 4], 0.0);  getitem_22868 = None
        cat_394 = torch.ops.aten.cat.default([getitem_22753, getitem_22754, getitem_22755, getitem_22756, getitem_22757, getitem_22758, getitem_22759, getitem_22760, getitem_22761, getitem_22762, getitem_22763, getitem_22764, getitem_22765, getitem_22766, getitem_22767, getitem_22768, getitem_22769, getitem_22770, getitem_22771, getitem_22772, getitem_22773, getitem_22774, getitem_22775, getitem_22776, getitem_22777, getitem_22778, getitem_22779, getitem_22780, getitem_22781, getitem_22782, getitem_22783, getitem_22784, getitem_22785, getitem_22786, getitem_22787, getitem_22788, getitem_22789, getitem_22790, getitem_22791, getitem_22792, getitem_22793, getitem_22794, getitem_22795, getitem_22796, getitem_22797, getitem_22798, getitem_22799, getitem_22800, getitem_22801, getitem_22802, getitem_22803, getitem_22804, getitem_22805, getitem_22806, getitem_22807, getitem_22808, getitem_22809, getitem_22810, getitem_22811, getitem_22812, getitem_22813, getitem_22814, getitem_22815, getitem_22816, getitem_22817, getitem_22818, getitem_22819, getitem_22820, getitem_22821, getitem_22822, getitem_22823, getitem_22824, getitem_22825, getitem_22826, getitem_22827, getitem_22828, getitem_22829, getitem_22830, getitem_22831, getitem_22832, getitem_22833, getitem_22834, getitem_22835, getitem_22836, getitem_22837, getitem_22838, getitem_22839, getitem_22840, getitem_22841, getitem_22842, getitem_22843, getitem_22844, getitem_22845, getitem_22846, getitem_22847, getitem_22848, getitem_22849, getitem_22850, getitem_22851, getitem_22852, getitem_22853, getitem_22854, getitem_22855, getitem_22856, getitem_22857, getitem_22858, getitem_22859, getitem_22860, getitem_22861, getitem_22862, getitem_22863, getitem_22864, getitem_22865, getitem_22866, getitem_22867, constant_pad_nd_1527, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_22753 = getitem_22754 = getitem_22755 = getitem_22756 = getitem_22757 = getitem_22758 = getitem_22759 = getitem_22760 = getitem_22761 = getitem_22762 = getitem_22763 = getitem_22764 = getitem_22765 = getitem_22766 = getitem_22767 = getitem_22768 = getitem_22769 = getitem_22770 = getitem_22771 = getitem_22772 = getitem_22773 = getitem_22774 = getitem_22775 = getitem_22776 = getitem_22777 = getitem_22778 = getitem_22779 = getitem_22780 = getitem_22781 = getitem_22782 = getitem_22783 = getitem_22784 = getitem_22785 = getitem_22786 = getitem_22787 = getitem_22788 = getitem_22789 = getitem_22790 = getitem_22791 = getitem_22792 = getitem_22793 = getitem_22794 = getitem_22795 = getitem_22796 = getitem_22797 = getitem_22798 = getitem_22799 = getitem_22800 = getitem_22801 = getitem_22802 = getitem_22803 = getitem_22804 = getitem_22805 = getitem_22806 = getitem_22807 = getitem_22808 = getitem_22809 = getitem_22810 = getitem_22811 = getitem_22812 = getitem_22813 = getitem_22814 = getitem_22815 = getitem_22816 = getitem_22817 = getitem_22818 = getitem_22819 = getitem_22820 = getitem_22821 = getitem_22822 = getitem_22823 = getitem_22824 = getitem_22825 = getitem_22826 = getitem_22827 = getitem_22828 = getitem_22829 = getitem_22830 = getitem_22831 = getitem_22832 = getitem_22833 = getitem_22834 = getitem_22835 = getitem_22836 = getitem_22837 = getitem_22838 = getitem_22839 = getitem_22840 = getitem_22841 = getitem_22842 = getitem_22843 = getitem_22844 = getitem_22845 = getitem_22846 = getitem_22847 = getitem_22848 = getitem_22849 = getitem_22850 = getitem_22851 = getitem_22852 = getitem_22853 = getitem_22854 = getitem_22855 = getitem_22856 = getitem_22857 = getitem_22858 = getitem_22859 = getitem_22860 = getitem_22861 = getitem_22862 = getitem_22863 = getitem_22864 = getitem_22865 = getitem_22866 = getitem_22867 = constant_pad_nd_1527 = None
        reduce_scatter_tensor_279 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_394, 'avg', 128, '0');  cat_394 = None
        wait_tensor_878 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_279);  reduce_scatter_tensor_279 = None
        slice_280 = torch.ops.aten.slice.Tensor(permute_1393, 3, 0, 128)
        slice_281 = torch.ops.aten.slice.Tensor(permute_1393, 3, 128, 192);  permute_1393 = None
        convert_element_type_2925 = torch.ops.prims.convert_element_type.default(slice_281, torch.float32);  slice_281 = None
        view_2157 = torch.ops.aten.view.default(convert_element_type_2925, [2, 4096, 16, 32, 2]);  convert_element_type_2925 = None
        view_as_complex_93 = torch.ops.aten.view_as_complex.default(view_2157);  view_2157 = None
        mul_1964 = torch.ops.aten.mul.Tensor(view_as_complex_93, clone_9);  view_as_complex_93 = None
        view_as_real_93 = torch.ops.aten.view_as_real.default(mul_1964);  mul_1964 = None
        view_2158 = torch.ops.aten.view.default(view_as_real_93, [2, 4096, 16, 64]);  view_as_real_93 = None
        convert_element_type_2926 = torch.ops.prims.convert_element_type.default(view_2158, torch.bfloat16);  view_2158 = None
        cat_395 = torch.ops.aten.cat.default([slice_280, convert_element_type_2926], 3);  slice_280 = convert_element_type_2926 = None
        view_2159 = torch.ops.aten.view.default(cat_395, [2, 4096, 3072]);  cat_395 = None
        view_2160 = torch.ops.aten.view.default(view_2159, [8192, 3072]);  view_2159 = None
        permute_1402 = torch.ops.aten.permute.default(view_2160, [1, 0])
        mm_536 = torch.ops.aten.mm.default(permute_1402, view_438);  permute_1402 = view_438 = None
        convert_element_type_364 = torch.ops.prims.convert_element_type.default(primals_120, torch.bfloat16);  primals_120 = None
        all_gather_into_tensor_114 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_364, 128, '0');  convert_element_type_364 = None
        wait_tensor_138 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_114);  all_gather_into_tensor_114 = None
        permute_101 = torch.ops.aten.permute.default(wait_tensor_138, [1, 0]);  wait_tensor_138 = None
        permute_1404 = torch.ops.aten.permute.default(permute_101, [1, 0]);  permute_101 = None
        mm_537 = torch.ops.aten.mm.default(view_2160, permute_1404);  view_2160 = permute_1404 = None
        view_2161 = torch.ops.aten.view.default(mm_537, [2, 4096, 2048]);  mm_537 = None
        add_2073 = torch.ops.aten.add.Tensor(view_2156, view_2161);  view_2156 = view_2161 = None
        convert_element_type_2931 = torch.ops.prims.convert_element_type.default(mm_536, torch.float32);  mm_536 = None
        reduce_scatter_tensor_280 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2931, 'avg', 128, '0');  convert_element_type_2931 = None
        wait_tensor_879 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_280);  reduce_scatter_tensor_280 = None
        convert_element_type_2932 = torch.ops.prims.convert_element_type.default(add_2073, torch.float32);  add_2073 = None
        convert_element_type_361 = torch.ops.prims.convert_element_type.default(primals_119, torch.bfloat16);  primals_119 = None
        all_gather_into_tensor_113 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_361, 128, '0');  convert_element_type_361 = None
        wait_tensor_137 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_113);  all_gather_into_tensor_113 = None
        convert_element_type_2934 = torch.ops.prims.convert_element_type.default(wait_tensor_137, torch.float32);  wait_tensor_137 = None
        mul_1965 = torch.ops.aten.mul.Tensor(convert_element_type_2932, convert_element_type_2934);  convert_element_type_2934 = None
        convert_element_type_362 = torch.ops.prims.convert_element_type.default(add_413, torch.float32);  add_413 = None
        mul_303 = torch.ops.aten.mul.Tensor(convert_element_type_362, rsqrt_21);  convert_element_type_362 = None
        mul_1967 = torch.ops.aten.mul.Tensor(mul_303, mul_1965)
        sum_265 = torch.ops.aten.sum.dim_IntList(mul_1967, [2], True);  mul_1967 = None
        div_251 = torch.ops.aten.div.Tensor(mul_303, 2048)
        mul_1968 = torch.ops.aten.mul.Tensor(div_251, sum_265);  div_251 = sum_265 = None
        sub_744 = torch.ops.aten.sub.Tensor(mul_1965, mul_1968);  mul_1965 = mul_1968 = None
        mul_1969 = torch.ops.aten.mul.Tensor(sub_744, rsqrt_21);  sub_744 = rsqrt_21 = None
        mul_1970 = torch.ops.aten.mul.Tensor(convert_element_type_2932, mul_303);  convert_element_type_2932 = mul_303 = None
        sum_266 = torch.ops.aten.sum.dim_IntList(mul_1970, [0, 1]);  mul_1970 = None
        convert_element_type_2935 = torch.ops.prims.convert_element_type.default(mul_1969, torch.bfloat16);  mul_1969 = None
        add_2074 = torch.ops.aten.add.Tensor(add_2072, convert_element_type_2935);  add_2072 = convert_element_type_2935 = None
        convert_element_type_default_22 = torch.ops.prims.convert_element_type.default(sum_266, torch.float32);  sum_266 = None
        reduce_scatter_tensor_281 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_22, 'avg', 128, '0');  convert_element_type_default_22 = None
        wait_tensor_880 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_281);  reduce_scatter_tensor_281 = None
        view_2162 = torch.ops.aten.view.default(add_2074, [8192, 2048])
        unsqueeze_73 = torch.ops.aten.unsqueeze.default(view_2162, 1)
        convert_element_type_2938 = torch.ops.prims.convert_element_type.default(unsqueeze_73, torch.float32);  unsqueeze_73 = None
        bmm_66 = torch.ops.aten.bmm.default(permute_1406, convert_element_type_2938);  permute_1406 = None
        bmm_67 = torch.ops.aten.bmm.default(convert_element_type_2938, permute_1407);  convert_element_type_2938 = permute_1407 = None
        convert_element_type_2939 = torch.ops.prims.convert_element_type.default(bmm_66, torch.bfloat16);  bmm_66 = None
        view_2163 = torch.ops.aten.view.default(bmm_67, [8192, 6]);  bmm_67 = None
        view_2164 = torch.ops.aten.view.default(convert_element_type_2939, [49152, 2048]);  convert_element_type_2939 = None
        index_92 = torch.ops.aten.index.Tensor(view_2164, [getitem_571]);  view_2164 = getitem_571 = None
        permute_1408 = torch.ops.aten.permute.default(view_2162, [1, 0])
        mm_538 = torch.ops.aten.mm.default(permute_1408, mul_300);  permute_1408 = mul_300 = None
        convert_element_type_356 = torch.ops.prims.convert_element_type.default(primals_118, torch.bfloat16);  primals_118 = None
        all_gather_into_tensor_112 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_356, 128, '0');  convert_element_type_356 = None
        wait_tensor_136 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_112);  all_gather_into_tensor_112 = None
        permute_100 = torch.ops.aten.permute.default(wait_tensor_136, [1, 0]);  wait_tensor_136 = None
        permute_1410 = torch.ops.aten.permute.default(permute_100, [1, 0]);  permute_100 = None
        mm_539 = torch.ops.aten.mm.default(view_2162, permute_1410);  view_2162 = permute_1410 = None
        convert_element_type_2944 = torch.ops.prims.convert_element_type.default(mm_538, torch.float32);  mm_538 = None
        reduce_scatter_tensor_282 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2944, 'avg', 128, '0');  convert_element_type_2944 = None
        wait_tensor_881 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_282);  reduce_scatter_tensor_282 = None
        convert_element_type_351 = torch.ops.prims.convert_element_type.default(mm_52, torch.float32);  mm_52 = None
        neg_12 = torch.ops.aten.neg.default(convert_element_type_351)
        exp_18 = torch.ops.aten.exp.default(neg_12);  neg_12 = None
        add_408 = torch.ops.aten.add.Tensor(exp_18, 1);  exp_18 = None
        div_30 = torch.ops.aten.div.Tensor(convert_element_type_351, add_408)
        convert_element_type_352 = torch.ops.prims.convert_element_type.default(div_30, torch.bfloat16);  div_30 = None
        mul_1971 = torch.ops.aten.mul.Tensor(mm_539, convert_element_type_352);  convert_element_type_352 = None
        mul_1972 = torch.ops.aten.mul.Tensor(mm_539, mm_53);  mm_539 = mm_53 = None
        permute_1412 = torch.ops.aten.permute.default(mul_1971, [1, 0])
        mm_540 = torch.ops.aten.mm.default(permute_1412, view_393);  permute_1412 = None
        convert_element_type_353 = torch.ops.prims.convert_element_type.default(primals_117, torch.bfloat16);  primals_117 = None
        all_gather_into_tensor_111 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_353, 128, '0');  convert_element_type_353 = None
        wait_tensor_135 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_111);  all_gather_into_tensor_111 = None
        permute_99 = torch.ops.aten.permute.default(wait_tensor_135, [1, 0]);  wait_tensor_135 = None
        permute_1414 = torch.ops.aten.permute.default(permute_99, [1, 0]);  permute_99 = None
        mm_541 = torch.ops.aten.mm.default(mul_1971, permute_1414);  mul_1971 = permute_1414 = None
        convert_element_type_2949 = torch.ops.prims.convert_element_type.default(mm_540, torch.float32);  mm_540 = None
        reduce_scatter_tensor_283 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2949, 'avg', 128, '0');  convert_element_type_2949 = None
        wait_tensor_882 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_283);  reduce_scatter_tensor_283 = None
        convert_element_type_2950 = torch.ops.prims.convert_element_type.default(mul_1972, torch.float32);  mul_1972 = None
        reciprocal_40 = torch.ops.aten.reciprocal.default(add_408);  add_408 = None
        mul_1973 = torch.ops.aten.mul.Tensor(reciprocal_40, 1);  reciprocal_40 = None
        mul_1974 = torch.ops.aten.mul.Tensor(convert_element_type_2950, mul_1973);  convert_element_type_2950 = None
        sub_745 = torch.ops.aten.sub.Tensor(1, mul_1973);  mul_1973 = None
        mul_1975 = torch.ops.aten.mul.Tensor(convert_element_type_351, sub_745);  convert_element_type_351 = sub_745 = None
        add_2076 = torch.ops.aten.add.Tensor(mul_1975, 1);  mul_1975 = None
        mul_1976 = torch.ops.aten.mul.Tensor(mul_1974, add_2076);  mul_1974 = add_2076 = None
        convert_element_type_2952 = torch.ops.prims.convert_element_type.default(mul_1976, torch.bfloat16);  mul_1976 = None
        permute_1416 = torch.ops.aten.permute.default(convert_element_type_2952, [1, 0])
        mm_542 = torch.ops.aten.mm.default(permute_1416, view_393);  permute_1416 = None
        convert_element_type_348 = torch.ops.prims.convert_element_type.default(primals_116, torch.bfloat16);  primals_116 = None
        all_gather_into_tensor_110 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_348, 128, '0');  convert_element_type_348 = None
        wait_tensor_134 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_110);  all_gather_into_tensor_110 = None
        permute_98 = torch.ops.aten.permute.default(wait_tensor_134, [1, 0]);  wait_tensor_134 = None
        permute_1418 = torch.ops.aten.permute.default(permute_98, [1, 0]);  permute_98 = None
        mm_543 = torch.ops.aten.mm.default(convert_element_type_2952, permute_1418);  convert_element_type_2952 = permute_1418 = None
        add_2077 = torch.ops.aten.add.Tensor(mm_541, mm_543);  mm_541 = mm_543 = None
        convert_element_type_2957 = torch.ops.prims.convert_element_type.default(mm_542, torch.float32);  mm_542 = None
        reduce_scatter_tensor_284 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2957, 'avg', 128, '0');  convert_element_type_2957 = None
        wait_tensor_883 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_284);  reduce_scatter_tensor_284 = None
        all_to_all_single_118 = torch.ops._c10d_functional.all_to_all_single.default(index_92, [_local_scalar_dense_88, _local_scalar_dense_89, _local_scalar_dense_90, _local_scalar_dense_91, _local_scalar_dense_92, _local_scalar_dense_93, _local_scalar_dense_94, _local_scalar_dense_95], [_local_scalar_dense_80, _local_scalar_dense_81, _local_scalar_dense_82, _local_scalar_dense_83, _local_scalar_dense_84, _local_scalar_dense_85, _local_scalar_dense_86, _local_scalar_dense_87], '1033');  index_92 = None
        wait_tensor_884 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_118);  all_to_all_single_118 = None
        full_468 = torch.ops.aten.full.default([sym_size_int_21, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_21 = None
        slice_scatter_20 = torch.ops.aten.slice_scatter.default(full_468, wait_tensor_884, 0, 0, -1);  wait_tensor_884 = None
        index_93 = torch.ops.aten.index.Tensor(slice_scatter_20, [getitem_572]);  slice_scatter_20 = None
        permute_1420 = torch.ops.aten.permute.default(index_93, [1, 0])
        _grouped_mm_198 = torch.ops.aten._grouped_mm.default(permute_1420, mul_280, cumsum_17);  permute_1420 = mul_280 = None
        _grouped_mm_199 = torch.ops.aten._grouped_mm.default(index_93, permute_1422, cumsum_17);  index_93 = permute_1422 = None
        convert_element_type_346 = torch.ops.prims.convert_element_type.default(_grouped_mm_15, torch.float32);  _grouped_mm_15 = None
        neg_11 = torch.ops.aten.neg.default(convert_element_type_346)
        exp_17 = torch.ops.aten.exp.default(neg_11);  neg_11 = None
        add_372 = torch.ops.aten.add.Tensor(exp_17, 1);  exp_17 = None
        div_29 = torch.ops.aten.div.Tensor(convert_element_type_346, add_372)
        convert_element_type_347 = torch.ops.prims.convert_element_type.default(div_29, torch.bfloat16);  div_29 = None
        mul_1977 = torch.ops.aten.mul.Tensor(_grouped_mm_199, convert_element_type_347);  convert_element_type_347 = None
        mul_1978 = torch.ops.aten.mul.Tensor(_grouped_mm_199, _grouped_mm_16);  _grouped_mm_199 = _grouped_mm_16 = None
        permute_1424 = torch.ops.aten.permute.default(mul_1977, [1, 0])
        _grouped_mm_200 = torch.ops.aten._grouped_mm.default(permute_1424, index_11, cumsum_17);  permute_1424 = None
        _grouped_mm_201 = torch.ops.aten._grouped_mm.default(mul_1977, permute_1426, cumsum_17);  mul_1977 = permute_1426 = None
        convert_element_type_2958 = torch.ops.prims.convert_element_type.default(mul_1978, torch.float32);  mul_1978 = None
        reciprocal_41 = torch.ops.aten.reciprocal.default(add_372);  add_372 = None
        mul_1979 = torch.ops.aten.mul.Tensor(reciprocal_41, 1);  reciprocal_41 = None
        mul_1980 = torch.ops.aten.mul.Tensor(convert_element_type_2958, mul_1979);  convert_element_type_2958 = None
        sub_746 = torch.ops.aten.sub.Tensor(1, mul_1979);  mul_1979 = None
        mul_1981 = torch.ops.aten.mul.Tensor(convert_element_type_346, sub_746);  convert_element_type_346 = sub_746 = None
        add_2079 = torch.ops.aten.add.Tensor(mul_1981, 1);  mul_1981 = None
        mul_1982 = torch.ops.aten.mul.Tensor(mul_1980, add_2079);  mul_1980 = add_2079 = None
        convert_element_type_2960 = torch.ops.prims.convert_element_type.default(mul_1982, torch.bfloat16);  mul_1982 = None
        permute_1428 = torch.ops.aten.permute.default(convert_element_type_2960, [1, 0])
        _grouped_mm_202 = torch.ops.aten._grouped_mm.default(permute_1428, index_11, cumsum_17);  permute_1428 = index_11 = None
        _grouped_mm_203 = torch.ops.aten._grouped_mm.default(convert_element_type_2960, permute_1430, cumsum_17);  convert_element_type_2960 = permute_1430 = cumsum_17 = None
        add_2080 = torch.ops.aten.add.Tensor(_grouped_mm_201, _grouped_mm_203);  _grouped_mm_201 = _grouped_mm_203 = None
        convert_element_type_2961 = torch.ops.prims.convert_element_type.default(_grouped_mm_200, torch.float32);  _grouped_mm_200 = None
        div_252 = torch.ops.aten.div.Tensor(convert_element_type_2961, 128);  convert_element_type_2961 = None
        split_1217 = torch.ops.aten.split.Tensor(div_252, 88, 1);  div_252 = None
        getitem_22885 = split_1217[0]
        getitem_22902 = split_1217[1]
        getitem_22919 = split_1217[2]
        getitem_22936 = split_1217[3]
        getitem_22953 = split_1217[4]
        getitem_22970 = split_1217[5]
        getitem_22987 = split_1217[6]
        getitem_23004 = split_1217[7]
        getitem_23021 = split_1217[8]
        getitem_23038 = split_1217[9]
        getitem_23055 = split_1217[10]
        getitem_23072 = split_1217[11]
        getitem_23089 = split_1217[12]
        getitem_23106 = split_1217[13]
        getitem_23123 = split_1217[14]
        getitem_23140 = split_1217[15];  split_1217 = None
        cat_396 = torch.ops.aten.cat.default([getitem_22885, getitem_22902, getitem_22919, getitem_22936, getitem_22953, getitem_22970, getitem_22987, getitem_23004, getitem_23021, getitem_23038, getitem_23055, getitem_23072, getitem_23089, getitem_23106, getitem_23123, getitem_23140]);  getitem_22885 = getitem_22902 = getitem_22919 = getitem_22936 = getitem_22953 = getitem_22970 = getitem_22987 = getitem_23004 = getitem_23021 = getitem_23038 = getitem_23055 = getitem_23072 = getitem_23089 = getitem_23106 = getitem_23123 = getitem_23140 = None
        reduce_scatter_tensor_285 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_396, 'sum', 16, '1025');  cat_396 = None
        wait_tensor_885 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_285);  reduce_scatter_tensor_285 = None
        convert_element_type_2962 = torch.ops.prims.convert_element_type.default(_grouped_mm_198, torch.float32);  _grouped_mm_198 = None
        div_253 = torch.ops.aten.div.Tensor(convert_element_type_2962, 128);  convert_element_type_2962 = None
        split_1234 = torch.ops.aten.split.Tensor(div_253, 128, 1);  div_253 = None
        getitem_23157 = split_1234[0]
        getitem_23174 = split_1234[1]
        getitem_23191 = split_1234[2]
        getitem_23208 = split_1234[3]
        getitem_23225 = split_1234[4]
        getitem_23242 = split_1234[5]
        getitem_23259 = split_1234[6]
        getitem_23276 = split_1234[7]
        getitem_23293 = split_1234[8]
        getitem_23310 = split_1234[9]
        getitem_23327 = split_1234[10]
        getitem_23344 = split_1234[11]
        getitem_23361 = split_1234[12]
        getitem_23378 = split_1234[13]
        getitem_23395 = split_1234[14]
        getitem_23412 = split_1234[15];  split_1234 = None
        cat_397 = torch.ops.aten.cat.default([getitem_23157, getitem_23174, getitem_23191, getitem_23208, getitem_23225, getitem_23242, getitem_23259, getitem_23276, getitem_23293, getitem_23310, getitem_23327, getitem_23344, getitem_23361, getitem_23378, getitem_23395, getitem_23412]);  getitem_23157 = getitem_23174 = getitem_23191 = getitem_23208 = getitem_23225 = getitem_23242 = getitem_23259 = getitem_23276 = getitem_23293 = getitem_23310 = getitem_23327 = getitem_23344 = getitem_23361 = getitem_23378 = getitem_23395 = getitem_23412 = None
        reduce_scatter_tensor_286 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_397, 'sum', 16, '1025');  cat_397 = None
        wait_tensor_886 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_286);  reduce_scatter_tensor_286 = None
        convert_element_type_2963 = torch.ops.prims.convert_element_type.default(_grouped_mm_202, torch.float32);  _grouped_mm_202 = None
        div_254 = torch.ops.aten.div.Tensor(convert_element_type_2963, 128);  convert_element_type_2963 = None
        split_1251 = torch.ops.aten.split.Tensor(div_254, 88, 1);  div_254 = None
        getitem_23429 = split_1251[0]
        getitem_23446 = split_1251[1]
        getitem_23463 = split_1251[2]
        getitem_23480 = split_1251[3]
        getitem_23497 = split_1251[4]
        getitem_23514 = split_1251[5]
        getitem_23531 = split_1251[6]
        getitem_23548 = split_1251[7]
        getitem_23565 = split_1251[8]
        getitem_23582 = split_1251[9]
        getitem_23599 = split_1251[10]
        getitem_23616 = split_1251[11]
        getitem_23633 = split_1251[12]
        getitem_23650 = split_1251[13]
        getitem_23667 = split_1251[14]
        getitem_23684 = split_1251[15];  split_1251 = None
        cat_398 = torch.ops.aten.cat.default([getitem_23429, getitem_23446, getitem_23463, getitem_23480, getitem_23497, getitem_23514, getitem_23531, getitem_23548, getitem_23565, getitem_23582, getitem_23599, getitem_23616, getitem_23633, getitem_23650, getitem_23667, getitem_23684]);  getitem_23429 = getitem_23446 = getitem_23463 = getitem_23480 = getitem_23497 = getitem_23514 = getitem_23531 = getitem_23548 = getitem_23565 = getitem_23582 = getitem_23599 = getitem_23616 = getitem_23633 = getitem_23650 = getitem_23667 = getitem_23684 = None
        reduce_scatter_tensor_287 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_398, 'sum', 16, '1025');  cat_398 = None
        wait_tensor_887 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_287);  reduce_scatter_tensor_287 = None
        index_put_92 = torch.ops.aten.index_put.default(full_468, [getitem_572], add_2080, True);  full_468 = getitem_572 = add_2080 = None
        slice_282 = torch.ops.aten.slice.Tensor(index_put_92, 0, 0, add_2081);  index_put_92 = add_2081 = None
        all_to_all_single_119 = torch.ops._c10d_functional.all_to_all_single.default(slice_282, [_local_scalar_dense_80, _local_scalar_dense_81, _local_scalar_dense_82, _local_scalar_dense_83, _local_scalar_dense_84, _local_scalar_dense_85, _local_scalar_dense_86, _local_scalar_dense_87], [_local_scalar_dense_88, _local_scalar_dense_89, _local_scalar_dense_90, _local_scalar_dense_91, _local_scalar_dense_92, _local_scalar_dense_93, _local_scalar_dense_94, _local_scalar_dense_95], '1033');  slice_282 = _local_scalar_dense_80 = _local_scalar_dense_81 = _local_scalar_dense_82 = _local_scalar_dense_83 = _local_scalar_dense_84 = _local_scalar_dense_85 = _local_scalar_dense_86 = _local_scalar_dense_87 = _local_scalar_dense_88 = _local_scalar_dense_89 = _local_scalar_dense_90 = _local_scalar_dense_91 = _local_scalar_dense_92 = _local_scalar_dense_93 = _local_scalar_dense_94 = _local_scalar_dense_95 = None
        wait_tensor_888 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_119);  all_to_all_single_119 = None
        index_put_93 = torch.ops.aten.index_put.default(full_default_52, [div_27], wait_tensor_888, True);  div_27 = wait_tensor_888 = None
        add_2085 = torch.ops.aten.add.Tensor(add_2077, index_put_93);  add_2077 = index_put_93 = None
        mul_1983 = torch.ops.aten.mul.Tensor(view_2163, 1.0);  view_2163 = None
        scatter_add_20 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_569, mul_1983);  getitem_569 = mul_1983 = None
        convert_element_type_335 = torch.ops.prims.convert_element_type.default(mm_51, torch.float32);  mm_51 = None
        sub_120 = torch.ops.aten.sub.Tensor(convert_element_type_335, amax_5);  convert_element_type_335 = amax_5 = None
        exp_16 = torch.ops.aten.exp.default(sub_120);  sub_120 = None
        div_26 = torch.ops.aten.div.Tensor(exp_16, sum_21);  exp_16 = sum_21 = None
        mul_1984 = torch.ops.aten.mul.Tensor(scatter_add_20, div_26);  scatter_add_20 = None
        sum_267 = torch.ops.aten.sum.dim_IntList(mul_1984, [1], True)
        neg_115 = torch.ops.aten.neg.default(div_26);  div_26 = None
        fma_20 = torch.ops.prims.fma.default(neg_115, sum_267, mul_1984);  neg_115 = sum_267 = mul_1984 = None
        convert_element_type_2964 = torch.ops.prims.convert_element_type.default(fma_20, torch.bfloat16);  fma_20 = None
        permute_1432 = torch.ops.aten.permute.default(convert_element_type_2964, [1, 0])
        mm_544 = torch.ops.aten.mm.default(permute_1432, view_393);  permute_1432 = view_393 = None
        convert_element_type_332 = torch.ops.prims.convert_element_type.default(primals_111, torch.bfloat16);  primals_111 = None
        all_gather_into_tensor_103 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_332, 128, '0');  convert_element_type_332 = None
        wait_tensor_123 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_103);  all_gather_into_tensor_103 = None
        slice_39 = torch.ops.aten.slice.Tensor(wait_tensor_123, 0, 0, 64);  wait_tensor_123 = None
        permute_94 = torch.ops.aten.permute.default(slice_39, [1, 0]);  slice_39 = None
        permute_1434 = torch.ops.aten.permute.default(permute_94, [1, 0]);  permute_94 = None
        mm_545 = torch.ops.aten.mm.default(convert_element_type_2964, permute_1434);  convert_element_type_2964 = permute_1434 = None
        add_2086 = torch.ops.aten.add.Tensor(add_2085, mm_545);  add_2085 = mm_545 = None
        convert_element_type_2969 = torch.ops.prims.convert_element_type.default(mm_544, torch.float32);  mm_544 = None
        split_1267 = torch.ops.aten.split.Tensor(convert_element_type_2969, 1);  convert_element_type_2969 = None
        getitem_23685 = split_1267[0]
        getitem_23686 = split_1267[1]
        getitem_23687 = split_1267[2]
        getitem_23688 = split_1267[3]
        getitem_23689 = split_1267[4]
        getitem_23690 = split_1267[5]
        getitem_23691 = split_1267[6]
        getitem_23692 = split_1267[7]
        getitem_23693 = split_1267[8]
        getitem_23694 = split_1267[9]
        getitem_23695 = split_1267[10]
        getitem_23696 = split_1267[11]
        getitem_23697 = split_1267[12]
        getitem_23698 = split_1267[13]
        getitem_23699 = split_1267[14]
        getitem_23700 = split_1267[15]
        getitem_23701 = split_1267[16]
        getitem_23702 = split_1267[17]
        getitem_23703 = split_1267[18]
        getitem_23704 = split_1267[19]
        getitem_23705 = split_1267[20]
        getitem_23706 = split_1267[21]
        getitem_23707 = split_1267[22]
        getitem_23708 = split_1267[23]
        getitem_23709 = split_1267[24]
        getitem_23710 = split_1267[25]
        getitem_23711 = split_1267[26]
        getitem_23712 = split_1267[27]
        getitem_23713 = split_1267[28]
        getitem_23714 = split_1267[29]
        getitem_23715 = split_1267[30]
        getitem_23716 = split_1267[31]
        getitem_23717 = split_1267[32]
        getitem_23718 = split_1267[33]
        getitem_23719 = split_1267[34]
        getitem_23720 = split_1267[35]
        getitem_23721 = split_1267[36]
        getitem_23722 = split_1267[37]
        getitem_23723 = split_1267[38]
        getitem_23724 = split_1267[39]
        getitem_23725 = split_1267[40]
        getitem_23726 = split_1267[41]
        getitem_23727 = split_1267[42]
        getitem_23728 = split_1267[43]
        getitem_23729 = split_1267[44]
        getitem_23730 = split_1267[45]
        getitem_23731 = split_1267[46]
        getitem_23732 = split_1267[47]
        getitem_23733 = split_1267[48]
        getitem_23734 = split_1267[49]
        getitem_23735 = split_1267[50]
        getitem_23736 = split_1267[51]
        getitem_23737 = split_1267[52]
        getitem_23738 = split_1267[53]
        getitem_23739 = split_1267[54]
        getitem_23740 = split_1267[55]
        getitem_23741 = split_1267[56]
        getitem_23742 = split_1267[57]
        getitem_23743 = split_1267[58]
        getitem_23744 = split_1267[59]
        getitem_23745 = split_1267[60]
        getitem_23746 = split_1267[61]
        getitem_23747 = split_1267[62]
        getitem_23748 = split_1267[63];  split_1267 = None
        cat_399 = torch.ops.aten.cat.default([getitem_23685, getitem_23686, getitem_23687, getitem_23688, getitem_23689, getitem_23690, getitem_23691, getitem_23692, getitem_23693, getitem_23694, getitem_23695, getitem_23696, getitem_23697, getitem_23698, getitem_23699, getitem_23700, getitem_23701, getitem_23702, getitem_23703, getitem_23704, getitem_23705, getitem_23706, getitem_23707, getitem_23708, getitem_23709, getitem_23710, getitem_23711, getitem_23712, getitem_23713, getitem_23714, getitem_23715, getitem_23716, getitem_23717, getitem_23718, getitem_23719, getitem_23720, getitem_23721, getitem_23722, getitem_23723, getitem_23724, getitem_23725, getitem_23726, getitem_23727, getitem_23728, getitem_23729, getitem_23730, getitem_23731, getitem_23732, getitem_23733, getitem_23734, getitem_23735, getitem_23736, getitem_23737, getitem_23738, getitem_23739, getitem_23740, getitem_23741, getitem_23742, getitem_23743, getitem_23744, getitem_23745, getitem_23746, getitem_23747, getitem_23748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_23685 = getitem_23686 = getitem_23687 = getitem_23688 = getitem_23689 = getitem_23690 = getitem_23691 = getitem_23692 = getitem_23693 = getitem_23694 = getitem_23695 = getitem_23696 = getitem_23697 = getitem_23698 = getitem_23699 = getitem_23700 = getitem_23701 = getitem_23702 = getitem_23703 = getitem_23704 = getitem_23705 = getitem_23706 = getitem_23707 = getitem_23708 = getitem_23709 = getitem_23710 = getitem_23711 = getitem_23712 = getitem_23713 = getitem_23714 = getitem_23715 = getitem_23716 = getitem_23717 = getitem_23718 = getitem_23719 = getitem_23720 = getitem_23721 = getitem_23722 = getitem_23723 = getitem_23724 = getitem_23725 = getitem_23726 = getitem_23727 = getitem_23728 = getitem_23729 = getitem_23730 = getitem_23731 = getitem_23732 = getitem_23733 = getitem_23734 = getitem_23735 = getitem_23736 = getitem_23737 = getitem_23738 = getitem_23739 = getitem_23740 = getitem_23741 = getitem_23742 = getitem_23743 = getitem_23744 = getitem_23745 = getitem_23746 = getitem_23747 = getitem_23748 = None
        reduce_scatter_tensor_288 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_399, 'avg', 128, '0');  cat_399 = None
        wait_tensor_889 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_288);  reduce_scatter_tensor_288 = None
        view_2165 = torch.ops.aten.view.default(add_2086, [2, 4096, 2048]);  add_2086 = None
        convert_element_type_2970 = torch.ops.prims.convert_element_type.default(view_2165, torch.float32);  view_2165 = None
        convert_element_type_329 = torch.ops.prims.convert_element_type.default(primals_109, torch.bfloat16);  primals_109 = None
        all_gather_into_tensor_102 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_329, 128, '0');  convert_element_type_329 = None
        wait_tensor_122 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_102);  all_gather_into_tensor_102 = None
        convert_element_type_2972 = torch.ops.prims.convert_element_type.default(wait_tensor_122, torch.float32);  wait_tensor_122 = None
        mul_1985 = torch.ops.aten.mul.Tensor(convert_element_type_2970, convert_element_type_2972);  convert_element_type_2972 = None
        convert_element_type_330 = torch.ops.prims.convert_element_type.default(add_348, torch.float32);  add_348 = None
        mul_260 = torch.ops.aten.mul.Tensor(convert_element_type_330, rsqrt_20);  convert_element_type_330 = None
        mul_1987 = torch.ops.aten.mul.Tensor(mul_260, mul_1985)
        sum_268 = torch.ops.aten.sum.dim_IntList(mul_1987, [2], True);  mul_1987 = None
        div_255 = torch.ops.aten.div.Tensor(mul_260, 2048)
        mul_1988 = torch.ops.aten.mul.Tensor(div_255, sum_268);  div_255 = sum_268 = None
        sub_748 = torch.ops.aten.sub.Tensor(mul_1985, mul_1988);  mul_1985 = mul_1988 = None
        mul_1989 = torch.ops.aten.mul.Tensor(sub_748, rsqrt_20);  sub_748 = rsqrt_20 = None
        mul_1990 = torch.ops.aten.mul.Tensor(convert_element_type_2970, mul_260);  convert_element_type_2970 = mul_260 = None
        sum_269 = torch.ops.aten.sum.dim_IntList(mul_1990, [0, 1]);  mul_1990 = None
        convert_element_type_2973 = torch.ops.prims.convert_element_type.default(mul_1989, torch.bfloat16);  mul_1989 = None
        add_2087 = torch.ops.aten.add.Tensor(add_2074, convert_element_type_2973);  add_2074 = convert_element_type_2973 = None
        convert_element_type_default_21 = torch.ops.prims.convert_element_type.default(sum_269, torch.float32);  sum_269 = None
        reduce_scatter_tensor_289 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_21, 'avg', 128, '0');  convert_element_type_default_21 = None
        wait_tensor_890 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_289);  reduce_scatter_tensor_289 = None
        view_2166 = torch.ops.aten.view.default(add_2087, [8192, 2048])
        permute_1436 = torch.ops.aten.permute.default(view_2166, [1, 0])
        permute_92 = torch.ops.aten.permute.default(getitem_565, [0, 2, 1, 3])
        view_388 = torch.ops.aten.view.default(permute_92, [2, 4096, -1]);  permute_92 = None
        view_390 = torch.ops.aten.view.default(view_388, [8192, 2048]);  view_388 = None
        mm_546 = torch.ops.aten.mm.default(permute_1436, view_390);  permute_1436 = view_390 = None
        convert_element_type_326 = torch.ops.prims.convert_element_type.default(primals_108, torch.bfloat16);  primals_108 = None
        all_gather_into_tensor_101 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_326, 128, '0');  convert_element_type_326 = None
        wait_tensor_121 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_101);  all_gather_into_tensor_101 = None
        permute_93 = torch.ops.aten.permute.default(wait_tensor_121, [1, 0]);  wait_tensor_121 = None
        permute_1438 = torch.ops.aten.permute.default(permute_93, [1, 0]);  permute_93 = None
        mm_547 = torch.ops.aten.mm.default(view_2166, permute_1438);  view_2166 = permute_1438 = None
        view_2167 = torch.ops.aten.view.default(mm_547, [2, 4096, 2048]);  mm_547 = None
        convert_element_type_2980 = torch.ops.prims.convert_element_type.default(mm_546, torch.float32);  mm_546 = None
        reduce_scatter_tensor_290 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2980, 'avg', 128, '0');  convert_element_type_2980 = None
        wait_tensor_891 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_290);  reduce_scatter_tensor_290 = None
        view_2168 = torch.ops.aten.view.default(view_2167, [2, 4096, 16, 128]);  view_2167 = None
        permute_1440 = torch.ops.aten.permute.default(view_2168, [0, 2, 1, 3]);  view_2168 = None
        fw_graph20 = self.fw_graph20
        joint_graph20 = self.joint_graph20
        mask_graph20 = self.mask_graph20
        flex_attention_backward_20 = torch.ops.higher_order.flex_attention_backward(permute_89, permute_90, permute_91, getitem_565, getitem_566, permute_1440, None, fw_graph20, joint_graph20, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph20), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_89 = permute_90 = permute_91 = getitem_565 = getitem_566 = permute_1440 = fw_graph20 = joint_graph20 = mask_graph20 = None
        getitem_23749 = flex_attention_backward_20[0]
        getitem_23750 = flex_attention_backward_20[1]
        getitem_23751 = flex_attention_backward_20[2];  flex_attention_backward_20 = None
        permute_1441 = torch.ops.aten.permute.default(getitem_23751, [0, 2, 1, 3]);  getitem_23751 = None
        permute_1442 = torch.ops.aten.permute.default(getitem_23750, [0, 2, 1, 3]);  getitem_23750 = None
        permute_1443 = torch.ops.aten.permute.default(getitem_23749, [0, 2, 1, 3]);  getitem_23749 = None
        slice_284 = torch.ops.aten.slice.Tensor(permute_1442, 3, 0, 128)
        slice_285 = torch.ops.aten.slice.Tensor(permute_1442, 3, 128, 192);  permute_1442 = None
        sum_270 = torch.ops.aten.sum.dim_IntList(slice_285, [2], True);  slice_285 = None
        cat_400 = torch.ops.aten.cat.default([slice_284, permute_1441], 3);  slice_284 = permute_1441 = None
        view_2169 = torch.ops.aten.view.default(cat_400, [2, 4096, 4096]);  cat_400 = None
        view_2170 = torch.ops.aten.view.default(view_2169, [8192, 4096]);  view_2169 = None
        permute_1444 = torch.ops.aten.permute.default(view_2170, [1, 0])
        mm_548 = torch.ops.aten.mm.default(permute_1444, view_385);  permute_1444 = view_385 = None
        convert_element_type_323 = torch.ops.prims.convert_element_type.default(primals_107, torch.bfloat16);  primals_107 = None
        all_gather_into_tensor_100 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_323, 128, '0');  convert_element_type_323 = None
        wait_tensor_120 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_100);  all_gather_into_tensor_100 = None
        permute_88 = torch.ops.aten.permute.default(wait_tensor_120, [1, 0]);  wait_tensor_120 = None
        permute_1446 = torch.ops.aten.permute.default(permute_88, [1, 0]);  permute_88 = None
        mm_549 = torch.ops.aten.mm.default(view_2170, permute_1446);  view_2170 = permute_1446 = None
        view_2171 = torch.ops.aten.view.default(mm_549, [2, 4096, 512]);  mm_549 = None
        convert_element_type_2985 = torch.ops.prims.convert_element_type.default(mm_548, torch.float32);  mm_548 = None
        reduce_scatter_tensor_291 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_2985, 'avg', 128, '0');  convert_element_type_2985 = None
        wait_tensor_892 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_291);  reduce_scatter_tensor_291 = None
        convert_element_type_2986 = torch.ops.prims.convert_element_type.default(view_2171, torch.float32);  view_2171 = None
        convert_element_type_320 = torch.ops.prims.convert_element_type.default(primals_106, torch.bfloat16);  primals_106 = None
        all_gather_into_tensor_99 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_320, 128, '0');  convert_element_type_320 = None
        wait_tensor_119 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_99);  all_gather_into_tensor_99 = None
        convert_element_type_2988 = torch.ops.prims.convert_element_type.default(wait_tensor_119, torch.float32);  wait_tensor_119 = None
        mul_1991 = torch.ops.aten.mul.Tensor(convert_element_type_2986, convert_element_type_2988);  convert_element_type_2988 = None
        convert_element_type_321 = torch.ops.prims.convert_element_type.default(getitem_561, torch.float32);  getitem_561 = None
        mul_258 = torch.ops.aten.mul.Tensor(convert_element_type_321, rsqrt_19);  convert_element_type_321 = None
        mul_1993 = torch.ops.aten.mul.Tensor(mul_258, mul_1991)
        sum_271 = torch.ops.aten.sum.dim_IntList(mul_1993, [2], True);  mul_1993 = None
        div_256 = torch.ops.aten.div.Tensor(mul_258, 512)
        mul_1994 = torch.ops.aten.mul.Tensor(div_256, sum_271);  div_256 = sum_271 = None
        sub_749 = torch.ops.aten.sub.Tensor(mul_1991, mul_1994);  mul_1991 = mul_1994 = None
        mul_1995 = torch.ops.aten.mul.Tensor(sub_749, rsqrt_19);  sub_749 = rsqrt_19 = None
        mul_1996 = torch.ops.aten.mul.Tensor(convert_element_type_2986, mul_258);  convert_element_type_2986 = mul_258 = None
        sum_272 = torch.ops.aten.sum.dim_IntList(mul_1996, [0, 1]);  mul_1996 = None
        convert_element_type_2989 = torch.ops.prims.convert_element_type.default(mul_1995, torch.bfloat16);  mul_1995 = None
        convert_element_type_default_20 = torch.ops.prims.convert_element_type.default(sum_272, torch.float32);  sum_272 = None
        reduce_scatter_tensor_292 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_20, 'avg', 128, '0');  convert_element_type_default_20 = None
        wait_tensor_893 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_292);  reduce_scatter_tensor_292 = None
        convert_element_type_2992 = torch.ops.prims.convert_element_type.default(sum_270, torch.float32);  sum_270 = None
        view_2172 = torch.ops.aten.view.default(convert_element_type_2992, [2, 4096, 1, 32, 2]);  convert_element_type_2992 = None
        view_as_complex_94 = torch.ops.aten.view_as_complex.default(view_2172);  view_2172 = None
        mul_1997 = torch.ops.aten.mul.Tensor(view_as_complex_94, clone_9);  view_as_complex_94 = None
        view_as_real_94 = torch.ops.aten.view_as_real.default(mul_1997);  mul_1997 = None
        view_2173 = torch.ops.aten.view.default(view_as_real_94, [2, 4096, 1, 64]);  view_as_real_94 = None
        convert_element_type_2993 = torch.ops.prims.convert_element_type.default(view_2173, torch.bfloat16);  view_2173 = None
        squeeze_46 = torch.ops.aten.squeeze.dim(convert_element_type_2993, 2);  convert_element_type_2993 = None
        cat_401 = torch.ops.aten.cat.default([convert_element_type_2989, squeeze_46], 2);  convert_element_type_2989 = squeeze_46 = None
        view_2174 = torch.ops.aten.view.default(cat_401, [8192, 576]);  cat_401 = None
        permute_1448 = torch.ops.aten.permute.default(view_2174, [1, 0])
        mm_550 = torch.ops.aten.mm.default(permute_1448, view_371);  permute_1448 = None
        convert_element_type_315 = torch.ops.prims.convert_element_type.default(primals_105, torch.bfloat16);  primals_105 = None
        all_gather_into_tensor_98 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_315, 128, '0');  convert_element_type_315 = None
        wait_tensor_118 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_98);  all_gather_into_tensor_98 = None
        slice_37 = torch.ops.aten.slice.Tensor(wait_tensor_118, 0, 0, 576);  wait_tensor_118 = None
        permute_87 = torch.ops.aten.permute.default(slice_37, [1, 0]);  slice_37 = None
        permute_1450 = torch.ops.aten.permute.default(permute_87, [1, 0]);  permute_87 = None
        mm_551 = torch.ops.aten.mm.default(view_2174, permute_1450);  view_2174 = permute_1450 = None
        view_2175 = torch.ops.aten.view.default(mm_551, [2, 4096, 2048]);  mm_551 = None
        convert_element_type_2998 = torch.ops.prims.convert_element_type.default(mm_550, torch.float32);  mm_550 = None
        split_1268 = torch.ops.aten.split.Tensor(convert_element_type_2998, 5);  convert_element_type_2998 = None
        getitem_23753 = split_1268[0]
        getitem_23754 = split_1268[1]
        getitem_23755 = split_1268[2]
        getitem_23756 = split_1268[3]
        getitem_23757 = split_1268[4]
        getitem_23758 = split_1268[5]
        getitem_23759 = split_1268[6]
        getitem_23760 = split_1268[7]
        getitem_23761 = split_1268[8]
        getitem_23762 = split_1268[9]
        getitem_23763 = split_1268[10]
        getitem_23764 = split_1268[11]
        getitem_23765 = split_1268[12]
        getitem_23766 = split_1268[13]
        getitem_23767 = split_1268[14]
        getitem_23768 = split_1268[15]
        getitem_23769 = split_1268[16]
        getitem_23770 = split_1268[17]
        getitem_23771 = split_1268[18]
        getitem_23772 = split_1268[19]
        getitem_23773 = split_1268[20]
        getitem_23774 = split_1268[21]
        getitem_23775 = split_1268[22]
        getitem_23776 = split_1268[23]
        getitem_23777 = split_1268[24]
        getitem_23778 = split_1268[25]
        getitem_23779 = split_1268[26]
        getitem_23780 = split_1268[27]
        getitem_23781 = split_1268[28]
        getitem_23782 = split_1268[29]
        getitem_23783 = split_1268[30]
        getitem_23784 = split_1268[31]
        getitem_23785 = split_1268[32]
        getitem_23786 = split_1268[33]
        getitem_23787 = split_1268[34]
        getitem_23788 = split_1268[35]
        getitem_23789 = split_1268[36]
        getitem_23790 = split_1268[37]
        getitem_23791 = split_1268[38]
        getitem_23792 = split_1268[39]
        getitem_23793 = split_1268[40]
        getitem_23794 = split_1268[41]
        getitem_23795 = split_1268[42]
        getitem_23796 = split_1268[43]
        getitem_23797 = split_1268[44]
        getitem_23798 = split_1268[45]
        getitem_23799 = split_1268[46]
        getitem_23800 = split_1268[47]
        getitem_23801 = split_1268[48]
        getitem_23802 = split_1268[49]
        getitem_23803 = split_1268[50]
        getitem_23804 = split_1268[51]
        getitem_23805 = split_1268[52]
        getitem_23806 = split_1268[53]
        getitem_23807 = split_1268[54]
        getitem_23808 = split_1268[55]
        getitem_23809 = split_1268[56]
        getitem_23810 = split_1268[57]
        getitem_23811 = split_1268[58]
        getitem_23812 = split_1268[59]
        getitem_23813 = split_1268[60]
        getitem_23814 = split_1268[61]
        getitem_23815 = split_1268[62]
        getitem_23816 = split_1268[63]
        getitem_23817 = split_1268[64]
        getitem_23818 = split_1268[65]
        getitem_23819 = split_1268[66]
        getitem_23820 = split_1268[67]
        getitem_23821 = split_1268[68]
        getitem_23822 = split_1268[69]
        getitem_23823 = split_1268[70]
        getitem_23824 = split_1268[71]
        getitem_23825 = split_1268[72]
        getitem_23826 = split_1268[73]
        getitem_23827 = split_1268[74]
        getitem_23828 = split_1268[75]
        getitem_23829 = split_1268[76]
        getitem_23830 = split_1268[77]
        getitem_23831 = split_1268[78]
        getitem_23832 = split_1268[79]
        getitem_23833 = split_1268[80]
        getitem_23834 = split_1268[81]
        getitem_23835 = split_1268[82]
        getitem_23836 = split_1268[83]
        getitem_23837 = split_1268[84]
        getitem_23838 = split_1268[85]
        getitem_23839 = split_1268[86]
        getitem_23840 = split_1268[87]
        getitem_23841 = split_1268[88]
        getitem_23842 = split_1268[89]
        getitem_23843 = split_1268[90]
        getitem_23844 = split_1268[91]
        getitem_23845 = split_1268[92]
        getitem_23846 = split_1268[93]
        getitem_23847 = split_1268[94]
        getitem_23848 = split_1268[95]
        getitem_23849 = split_1268[96]
        getitem_23850 = split_1268[97]
        getitem_23851 = split_1268[98]
        getitem_23852 = split_1268[99]
        getitem_23853 = split_1268[100]
        getitem_23854 = split_1268[101]
        getitem_23855 = split_1268[102]
        getitem_23856 = split_1268[103]
        getitem_23857 = split_1268[104]
        getitem_23858 = split_1268[105]
        getitem_23859 = split_1268[106]
        getitem_23860 = split_1268[107]
        getitem_23861 = split_1268[108]
        getitem_23862 = split_1268[109]
        getitem_23863 = split_1268[110]
        getitem_23864 = split_1268[111]
        getitem_23865 = split_1268[112]
        getitem_23866 = split_1268[113]
        getitem_23867 = split_1268[114]
        getitem_23868 = split_1268[115];  split_1268 = None
        constant_pad_nd_1604 = torch.ops.aten.constant_pad_nd.default(getitem_23868, [0, 0, 0, 4], 0.0);  getitem_23868 = None
        cat_402 = torch.ops.aten.cat.default([getitem_23753, getitem_23754, getitem_23755, getitem_23756, getitem_23757, getitem_23758, getitem_23759, getitem_23760, getitem_23761, getitem_23762, getitem_23763, getitem_23764, getitem_23765, getitem_23766, getitem_23767, getitem_23768, getitem_23769, getitem_23770, getitem_23771, getitem_23772, getitem_23773, getitem_23774, getitem_23775, getitem_23776, getitem_23777, getitem_23778, getitem_23779, getitem_23780, getitem_23781, getitem_23782, getitem_23783, getitem_23784, getitem_23785, getitem_23786, getitem_23787, getitem_23788, getitem_23789, getitem_23790, getitem_23791, getitem_23792, getitem_23793, getitem_23794, getitem_23795, getitem_23796, getitem_23797, getitem_23798, getitem_23799, getitem_23800, getitem_23801, getitem_23802, getitem_23803, getitem_23804, getitem_23805, getitem_23806, getitem_23807, getitem_23808, getitem_23809, getitem_23810, getitem_23811, getitem_23812, getitem_23813, getitem_23814, getitem_23815, getitem_23816, getitem_23817, getitem_23818, getitem_23819, getitem_23820, getitem_23821, getitem_23822, getitem_23823, getitem_23824, getitem_23825, getitem_23826, getitem_23827, getitem_23828, getitem_23829, getitem_23830, getitem_23831, getitem_23832, getitem_23833, getitem_23834, getitem_23835, getitem_23836, getitem_23837, getitem_23838, getitem_23839, getitem_23840, getitem_23841, getitem_23842, getitem_23843, getitem_23844, getitem_23845, getitem_23846, getitem_23847, getitem_23848, getitem_23849, getitem_23850, getitem_23851, getitem_23852, getitem_23853, getitem_23854, getitem_23855, getitem_23856, getitem_23857, getitem_23858, getitem_23859, getitem_23860, getitem_23861, getitem_23862, getitem_23863, getitem_23864, getitem_23865, getitem_23866, getitem_23867, constant_pad_nd_1604, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_23753 = getitem_23754 = getitem_23755 = getitem_23756 = getitem_23757 = getitem_23758 = getitem_23759 = getitem_23760 = getitem_23761 = getitem_23762 = getitem_23763 = getitem_23764 = getitem_23765 = getitem_23766 = getitem_23767 = getitem_23768 = getitem_23769 = getitem_23770 = getitem_23771 = getitem_23772 = getitem_23773 = getitem_23774 = getitem_23775 = getitem_23776 = getitem_23777 = getitem_23778 = getitem_23779 = getitem_23780 = getitem_23781 = getitem_23782 = getitem_23783 = getitem_23784 = getitem_23785 = getitem_23786 = getitem_23787 = getitem_23788 = getitem_23789 = getitem_23790 = getitem_23791 = getitem_23792 = getitem_23793 = getitem_23794 = getitem_23795 = getitem_23796 = getitem_23797 = getitem_23798 = getitem_23799 = getitem_23800 = getitem_23801 = getitem_23802 = getitem_23803 = getitem_23804 = getitem_23805 = getitem_23806 = getitem_23807 = getitem_23808 = getitem_23809 = getitem_23810 = getitem_23811 = getitem_23812 = getitem_23813 = getitem_23814 = getitem_23815 = getitem_23816 = getitem_23817 = getitem_23818 = getitem_23819 = getitem_23820 = getitem_23821 = getitem_23822 = getitem_23823 = getitem_23824 = getitem_23825 = getitem_23826 = getitem_23827 = getitem_23828 = getitem_23829 = getitem_23830 = getitem_23831 = getitem_23832 = getitem_23833 = getitem_23834 = getitem_23835 = getitem_23836 = getitem_23837 = getitem_23838 = getitem_23839 = getitem_23840 = getitem_23841 = getitem_23842 = getitem_23843 = getitem_23844 = getitem_23845 = getitem_23846 = getitem_23847 = getitem_23848 = getitem_23849 = getitem_23850 = getitem_23851 = getitem_23852 = getitem_23853 = getitem_23854 = getitem_23855 = getitem_23856 = getitem_23857 = getitem_23858 = getitem_23859 = getitem_23860 = getitem_23861 = getitem_23862 = getitem_23863 = getitem_23864 = getitem_23865 = getitem_23866 = getitem_23867 = constant_pad_nd_1604 = None
        reduce_scatter_tensor_293 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_402, 'avg', 128, '0');  cat_402 = None
        wait_tensor_894 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_293);  reduce_scatter_tensor_293 = None
        slice_286 = torch.ops.aten.slice.Tensor(permute_1443, 3, 0, 128)
        slice_287 = torch.ops.aten.slice.Tensor(permute_1443, 3, 128, 192);  permute_1443 = None
        convert_element_type_2999 = torch.ops.prims.convert_element_type.default(slice_287, torch.float32);  slice_287 = None
        view_2176 = torch.ops.aten.view.default(convert_element_type_2999, [2, 4096, 16, 32, 2]);  convert_element_type_2999 = None
        view_as_complex_95 = torch.ops.aten.view_as_complex.default(view_2176);  view_2176 = None
        mul_1998 = torch.ops.aten.mul.Tensor(view_as_complex_95, clone_9);  view_as_complex_95 = None
        view_as_real_95 = torch.ops.aten.view_as_real.default(mul_1998);  mul_1998 = None
        view_2177 = torch.ops.aten.view.default(view_as_real_95, [2, 4096, 16, 64]);  view_as_real_95 = None
        convert_element_type_3000 = torch.ops.prims.convert_element_type.default(view_2177, torch.bfloat16);  view_2177 = None
        cat_403 = torch.ops.aten.cat.default([slice_286, convert_element_type_3000], 3);  slice_286 = convert_element_type_3000 = None
        view_2178 = torch.ops.aten.view.default(cat_403, [2, 4096, 3072]);  cat_403 = None
        view_2179 = torch.ops.aten.view.default(view_2178, [8192, 3072]);  view_2178 = None
        permute_1452 = torch.ops.aten.permute.default(view_2179, [1, 0])
        mm_552 = torch.ops.aten.mm.default(permute_1452, view_371);  permute_1452 = view_371 = None
        convert_element_type_310 = torch.ops.prims.convert_element_type.default(primals_104, torch.bfloat16);  primals_104 = None
        all_gather_into_tensor_97 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_310, 128, '0');  convert_element_type_310 = None
        wait_tensor_117 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_97);  all_gather_into_tensor_97 = None
        permute_86 = torch.ops.aten.permute.default(wait_tensor_117, [1, 0]);  wait_tensor_117 = None
        permute_1454 = torch.ops.aten.permute.default(permute_86, [1, 0]);  permute_86 = None
        mm_553 = torch.ops.aten.mm.default(view_2179, permute_1454);  view_2179 = permute_1454 = None
        view_2180 = torch.ops.aten.view.default(mm_553, [2, 4096, 2048]);  mm_553 = None
        add_2088 = torch.ops.aten.add.Tensor(view_2175, view_2180);  view_2175 = view_2180 = None
        convert_element_type_3005 = torch.ops.prims.convert_element_type.default(mm_552, torch.float32);  mm_552 = None
        reduce_scatter_tensor_294 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3005, 'avg', 128, '0');  convert_element_type_3005 = None
        wait_tensor_895 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_294);  reduce_scatter_tensor_294 = None
        convert_element_type_3006 = torch.ops.prims.convert_element_type.default(add_2088, torch.float32);  add_2088 = None
        convert_element_type_307 = torch.ops.prims.convert_element_type.default(primals_103, torch.bfloat16);  primals_103 = None
        all_gather_into_tensor_96 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_307, 128, '0');  convert_element_type_307 = None
        wait_tensor_116 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_96);  all_gather_into_tensor_96 = None
        convert_element_type_3008 = torch.ops.prims.convert_element_type.default(wait_tensor_116, torch.float32);  wait_tensor_116 = None
        mul_1999 = torch.ops.aten.mul.Tensor(convert_element_type_3006, convert_element_type_3008);  convert_element_type_3008 = None
        convert_element_type_308 = torch.ops.prims.convert_element_type.default(add_345, torch.float32);  add_345 = None
        mul_254 = torch.ops.aten.mul.Tensor(convert_element_type_308, rsqrt_18);  convert_element_type_308 = None
        mul_2001 = torch.ops.aten.mul.Tensor(mul_254, mul_1999)
        sum_273 = torch.ops.aten.sum.dim_IntList(mul_2001, [2], True);  mul_2001 = None
        div_257 = torch.ops.aten.div.Tensor(mul_254, 2048)
        mul_2002 = torch.ops.aten.mul.Tensor(div_257, sum_273);  div_257 = sum_273 = None
        sub_750 = torch.ops.aten.sub.Tensor(mul_1999, mul_2002);  mul_1999 = mul_2002 = None
        mul_2003 = torch.ops.aten.mul.Tensor(sub_750, rsqrt_18);  sub_750 = rsqrt_18 = None
        mul_2004 = torch.ops.aten.mul.Tensor(convert_element_type_3006, mul_254);  convert_element_type_3006 = mul_254 = None
        sum_274 = torch.ops.aten.sum.dim_IntList(mul_2004, [0, 1]);  mul_2004 = None
        convert_element_type_3009 = torch.ops.prims.convert_element_type.default(mul_2003, torch.bfloat16);  mul_2003 = None
        add_2089 = torch.ops.aten.add.Tensor(add_2087, convert_element_type_3009);  add_2087 = convert_element_type_3009 = None
        convert_element_type_default_19 = torch.ops.prims.convert_element_type.default(sum_274, torch.float32);  sum_274 = None
        reduce_scatter_tensor_295 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_19, 'avg', 128, '0');  convert_element_type_default_19 = None
        wait_tensor_896 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_295);  reduce_scatter_tensor_295 = None
        view_2181 = torch.ops.aten.view.default(add_2089, [8192, 2048])
        unsqueeze_74 = torch.ops.aten.unsqueeze.default(view_2181, 1)
        convert_element_type_3012 = torch.ops.prims.convert_element_type.default(unsqueeze_74, torch.float32);  unsqueeze_74 = None
        bmm_68 = torch.ops.aten.bmm.default(permute_1456, convert_element_type_3012);  permute_1456 = None
        bmm_69 = torch.ops.aten.bmm.default(convert_element_type_3012, permute_1457);  convert_element_type_3012 = permute_1457 = None
        convert_element_type_3013 = torch.ops.prims.convert_element_type.default(bmm_68, torch.bfloat16);  bmm_68 = None
        view_2182 = torch.ops.aten.view.default(bmm_69, [8192, 6]);  bmm_69 = None
        view_2183 = torch.ops.aten.view.default(convert_element_type_3013, [49152, 2048]);  convert_element_type_3013 = None
        index_94 = torch.ops.aten.index.Tensor(view_2183, [getitem_461]);  view_2183 = getitem_461 = None
        permute_1458 = torch.ops.aten.permute.default(view_2181, [1, 0])
        mm_554 = torch.ops.aten.mm.default(permute_1458, mul_251);  permute_1458 = mul_251 = None
        convert_element_type_302 = torch.ops.prims.convert_element_type.default(primals_102, torch.bfloat16);  primals_102 = None
        all_gather_into_tensor_95 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_302, 128, '0');  convert_element_type_302 = None
        wait_tensor_115 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_95);  all_gather_into_tensor_95 = None
        permute_85 = torch.ops.aten.permute.default(wait_tensor_115, [1, 0]);  wait_tensor_115 = None
        permute_1460 = torch.ops.aten.permute.default(permute_85, [1, 0]);  permute_85 = None
        mm_555 = torch.ops.aten.mm.default(view_2181, permute_1460);  view_2181 = permute_1460 = None
        convert_element_type_3018 = torch.ops.prims.convert_element_type.default(mm_554, torch.float32);  mm_554 = None
        reduce_scatter_tensor_296 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3018, 'avg', 128, '0');  convert_element_type_3018 = None
        wait_tensor_897 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_296);  reduce_scatter_tensor_296 = None
        convert_element_type_297 = torch.ops.prims.convert_element_type.default(mm_44, torch.float32);  mm_44 = None
        neg_10 = torch.ops.aten.neg.default(convert_element_type_297)
        exp_15 = torch.ops.aten.exp.default(neg_10);  neg_10 = None
        add_340 = torch.ops.aten.add.Tensor(exp_15, 1);  exp_15 = None
        div_25 = torch.ops.aten.div.Tensor(convert_element_type_297, add_340)
        convert_element_type_298 = torch.ops.prims.convert_element_type.default(div_25, torch.bfloat16);  div_25 = None
        mul_2005 = torch.ops.aten.mul.Tensor(mm_555, convert_element_type_298);  convert_element_type_298 = None
        mul_2006 = torch.ops.aten.mul.Tensor(mm_555, mm_45);  mm_555 = mm_45 = None
        permute_1462 = torch.ops.aten.permute.default(mul_2005, [1, 0])
        mm_556 = torch.ops.aten.mm.default(permute_1462, view_326);  permute_1462 = None
        convert_element_type_299 = torch.ops.prims.convert_element_type.default(primals_101, torch.bfloat16);  primals_101 = None
        all_gather_into_tensor_94 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_299, 128, '0');  convert_element_type_299 = None
        wait_tensor_114 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_94);  all_gather_into_tensor_94 = None
        permute_84 = torch.ops.aten.permute.default(wait_tensor_114, [1, 0]);  wait_tensor_114 = None
        permute_1464 = torch.ops.aten.permute.default(permute_84, [1, 0]);  permute_84 = None
        mm_557 = torch.ops.aten.mm.default(mul_2005, permute_1464);  mul_2005 = permute_1464 = None
        convert_element_type_3023 = torch.ops.prims.convert_element_type.default(mm_556, torch.float32);  mm_556 = None
        reduce_scatter_tensor_297 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3023, 'avg', 128, '0');  convert_element_type_3023 = None
        wait_tensor_898 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_297);  reduce_scatter_tensor_297 = None
        convert_element_type_3024 = torch.ops.prims.convert_element_type.default(mul_2006, torch.float32);  mul_2006 = None
        reciprocal_42 = torch.ops.aten.reciprocal.default(add_340);  add_340 = None
        mul_2007 = torch.ops.aten.mul.Tensor(reciprocal_42, 1);  reciprocal_42 = None
        mul_2008 = torch.ops.aten.mul.Tensor(convert_element_type_3024, mul_2007);  convert_element_type_3024 = None
        sub_751 = torch.ops.aten.sub.Tensor(1, mul_2007);  mul_2007 = None
        mul_2009 = torch.ops.aten.mul.Tensor(convert_element_type_297, sub_751);  convert_element_type_297 = sub_751 = None
        add_2091 = torch.ops.aten.add.Tensor(mul_2009, 1);  mul_2009 = None
        mul_2010 = torch.ops.aten.mul.Tensor(mul_2008, add_2091);  mul_2008 = add_2091 = None
        convert_element_type_3026 = torch.ops.prims.convert_element_type.default(mul_2010, torch.bfloat16);  mul_2010 = None
        permute_1466 = torch.ops.aten.permute.default(convert_element_type_3026, [1, 0])
        mm_558 = torch.ops.aten.mm.default(permute_1466, view_326);  permute_1466 = None
        convert_element_type_294 = torch.ops.prims.convert_element_type.default(primals_100, torch.bfloat16);  primals_100 = None
        all_gather_into_tensor_93 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_294, 128, '0');  convert_element_type_294 = None
        wait_tensor_113 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_93);  all_gather_into_tensor_93 = None
        permute_83 = torch.ops.aten.permute.default(wait_tensor_113, [1, 0]);  wait_tensor_113 = None
        permute_1468 = torch.ops.aten.permute.default(permute_83, [1, 0]);  permute_83 = None
        mm_559 = torch.ops.aten.mm.default(convert_element_type_3026, permute_1468);  convert_element_type_3026 = permute_1468 = None
        add_2092 = torch.ops.aten.add.Tensor(mm_557, mm_559);  mm_557 = mm_559 = None
        convert_element_type_3031 = torch.ops.prims.convert_element_type.default(mm_558, torch.float32);  mm_558 = None
        reduce_scatter_tensor_298 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3031, 'avg', 128, '0');  convert_element_type_3031 = None
        wait_tensor_899 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_298);  reduce_scatter_tensor_298 = None
        all_to_all_single_120 = torch.ops._c10d_functional.all_to_all_single.default(index_94, [_local_scalar_dense_72, _local_scalar_dense_73, _local_scalar_dense_74, _local_scalar_dense_75, _local_scalar_dense_76, _local_scalar_dense_77, _local_scalar_dense_78, _local_scalar_dense_79], [_local_scalar_dense_64, _local_scalar_dense_65, _local_scalar_dense_66, _local_scalar_dense_67, _local_scalar_dense_68, _local_scalar_dense_69, _local_scalar_dense_70, _local_scalar_dense_71], '1033');  index_94 = None
        wait_tensor_900 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_120);  all_to_all_single_120 = None
        full_474 = torch.ops.aten.full.default([sym_size_int_17, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_17 = None
        slice_scatter_21 = torch.ops.aten.slice_scatter.default(full_474, wait_tensor_900, 0, 0, -1);  wait_tensor_900 = None
        index_95 = torch.ops.aten.index.Tensor(slice_scatter_21, [getitem_462]);  slice_scatter_21 = None
        permute_1470 = torch.ops.aten.permute.default(index_95, [1, 0])
        _grouped_mm_204 = torch.ops.aten._grouped_mm.default(permute_1470, mul_231, cumsum_14);  permute_1470 = mul_231 = None
        _grouped_mm_205 = torch.ops.aten._grouped_mm.default(index_95, permute_1472, cumsum_14);  index_95 = permute_1472 = None
        convert_element_type_292 = torch.ops.prims.convert_element_type.default(_grouped_mm_12, torch.float32);  _grouped_mm_12 = None
        neg_9 = torch.ops.aten.neg.default(convert_element_type_292)
        exp_14 = torch.ops.aten.exp.default(neg_9);  neg_9 = None
        add_304 = torch.ops.aten.add.Tensor(exp_14, 1);  exp_14 = None
        div_24 = torch.ops.aten.div.Tensor(convert_element_type_292, add_304)
        convert_element_type_293 = torch.ops.prims.convert_element_type.default(div_24, torch.bfloat16);  div_24 = None
        mul_2011 = torch.ops.aten.mul.Tensor(_grouped_mm_205, convert_element_type_293);  convert_element_type_293 = None
        mul_2012 = torch.ops.aten.mul.Tensor(_grouped_mm_205, _grouped_mm_13);  _grouped_mm_205 = _grouped_mm_13 = None
        permute_1474 = torch.ops.aten.permute.default(mul_2011, [1, 0])
        _grouped_mm_206 = torch.ops.aten._grouped_mm.default(permute_1474, index_9, cumsum_14);  permute_1474 = None
        _grouped_mm_207 = torch.ops.aten._grouped_mm.default(mul_2011, permute_1476, cumsum_14);  mul_2011 = permute_1476 = None
        convert_element_type_3032 = torch.ops.prims.convert_element_type.default(mul_2012, torch.float32);  mul_2012 = None
        reciprocal_43 = torch.ops.aten.reciprocal.default(add_304);  add_304 = None
        mul_2013 = torch.ops.aten.mul.Tensor(reciprocal_43, 1);  reciprocal_43 = None
        mul_2014 = torch.ops.aten.mul.Tensor(convert_element_type_3032, mul_2013);  convert_element_type_3032 = None
        sub_752 = torch.ops.aten.sub.Tensor(1, mul_2013);  mul_2013 = None
        mul_2015 = torch.ops.aten.mul.Tensor(convert_element_type_292, sub_752);  convert_element_type_292 = sub_752 = None
        add_2094 = torch.ops.aten.add.Tensor(mul_2015, 1);  mul_2015 = None
        mul_2016 = torch.ops.aten.mul.Tensor(mul_2014, add_2094);  mul_2014 = add_2094 = None
        convert_element_type_3034 = torch.ops.prims.convert_element_type.default(mul_2016, torch.bfloat16);  mul_2016 = None
        permute_1478 = torch.ops.aten.permute.default(convert_element_type_3034, [1, 0])
        _grouped_mm_208 = torch.ops.aten._grouped_mm.default(permute_1478, index_9, cumsum_14);  permute_1478 = index_9 = None
        _grouped_mm_209 = torch.ops.aten._grouped_mm.default(convert_element_type_3034, permute_1480, cumsum_14);  convert_element_type_3034 = permute_1480 = cumsum_14 = None
        add_2095 = torch.ops.aten.add.Tensor(_grouped_mm_207, _grouped_mm_209);  _grouped_mm_207 = _grouped_mm_209 = None
        convert_element_type_3035 = torch.ops.prims.convert_element_type.default(_grouped_mm_206, torch.float32);  _grouped_mm_206 = None
        div_258 = torch.ops.aten.div.Tensor(convert_element_type_3035, 128);  convert_element_type_3035 = None
        split_1270 = torch.ops.aten.split.Tensor(div_258, 88, 1);  div_258 = None
        getitem_23885 = split_1270[0]
        getitem_23902 = split_1270[1]
        getitem_23919 = split_1270[2]
        getitem_23936 = split_1270[3]
        getitem_23953 = split_1270[4]
        getitem_23970 = split_1270[5]
        getitem_23987 = split_1270[6]
        getitem_24004 = split_1270[7]
        getitem_24021 = split_1270[8]
        getitem_24038 = split_1270[9]
        getitem_24055 = split_1270[10]
        getitem_24072 = split_1270[11]
        getitem_24089 = split_1270[12]
        getitem_24106 = split_1270[13]
        getitem_24123 = split_1270[14]
        getitem_24140 = split_1270[15];  split_1270 = None
        cat_404 = torch.ops.aten.cat.default([getitem_23885, getitem_23902, getitem_23919, getitem_23936, getitem_23953, getitem_23970, getitem_23987, getitem_24004, getitem_24021, getitem_24038, getitem_24055, getitem_24072, getitem_24089, getitem_24106, getitem_24123, getitem_24140]);  getitem_23885 = getitem_23902 = getitem_23919 = getitem_23936 = getitem_23953 = getitem_23970 = getitem_23987 = getitem_24004 = getitem_24021 = getitem_24038 = getitem_24055 = getitem_24072 = getitem_24089 = getitem_24106 = getitem_24123 = getitem_24140 = None
        reduce_scatter_tensor_299 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_404, 'sum', 16, '1025');  cat_404 = None
        wait_tensor_901 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_299);  reduce_scatter_tensor_299 = None
        convert_element_type_3036 = torch.ops.prims.convert_element_type.default(_grouped_mm_204, torch.float32);  _grouped_mm_204 = None
        div_259 = torch.ops.aten.div.Tensor(convert_element_type_3036, 128);  convert_element_type_3036 = None
        split_1287 = torch.ops.aten.split.Tensor(div_259, 128, 1);  div_259 = None
        getitem_24157 = split_1287[0]
        getitem_24174 = split_1287[1]
        getitem_24191 = split_1287[2]
        getitem_24208 = split_1287[3]
        getitem_24225 = split_1287[4]
        getitem_24242 = split_1287[5]
        getitem_24259 = split_1287[6]
        getitem_24276 = split_1287[7]
        getitem_24293 = split_1287[8]
        getitem_24310 = split_1287[9]
        getitem_24327 = split_1287[10]
        getitem_24344 = split_1287[11]
        getitem_24361 = split_1287[12]
        getitem_24378 = split_1287[13]
        getitem_24395 = split_1287[14]
        getitem_24412 = split_1287[15];  split_1287 = None
        cat_405 = torch.ops.aten.cat.default([getitem_24157, getitem_24174, getitem_24191, getitem_24208, getitem_24225, getitem_24242, getitem_24259, getitem_24276, getitem_24293, getitem_24310, getitem_24327, getitem_24344, getitem_24361, getitem_24378, getitem_24395, getitem_24412]);  getitem_24157 = getitem_24174 = getitem_24191 = getitem_24208 = getitem_24225 = getitem_24242 = getitem_24259 = getitem_24276 = getitem_24293 = getitem_24310 = getitem_24327 = getitem_24344 = getitem_24361 = getitem_24378 = getitem_24395 = getitem_24412 = None
        reduce_scatter_tensor_300 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_405, 'sum', 16, '1025');  cat_405 = None
        wait_tensor_902 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_300);  reduce_scatter_tensor_300 = None
        convert_element_type_3037 = torch.ops.prims.convert_element_type.default(_grouped_mm_208, torch.float32);  _grouped_mm_208 = None
        div_260 = torch.ops.aten.div.Tensor(convert_element_type_3037, 128);  convert_element_type_3037 = None
        split_1304 = torch.ops.aten.split.Tensor(div_260, 88, 1);  div_260 = None
        getitem_24429 = split_1304[0]
        getitem_24446 = split_1304[1]
        getitem_24463 = split_1304[2]
        getitem_24480 = split_1304[3]
        getitem_24497 = split_1304[4]
        getitem_24514 = split_1304[5]
        getitem_24531 = split_1304[6]
        getitem_24548 = split_1304[7]
        getitem_24565 = split_1304[8]
        getitem_24582 = split_1304[9]
        getitem_24599 = split_1304[10]
        getitem_24616 = split_1304[11]
        getitem_24633 = split_1304[12]
        getitem_24650 = split_1304[13]
        getitem_24667 = split_1304[14]
        getitem_24684 = split_1304[15];  split_1304 = None
        cat_406 = torch.ops.aten.cat.default([getitem_24429, getitem_24446, getitem_24463, getitem_24480, getitem_24497, getitem_24514, getitem_24531, getitem_24548, getitem_24565, getitem_24582, getitem_24599, getitem_24616, getitem_24633, getitem_24650, getitem_24667, getitem_24684]);  getitem_24429 = getitem_24446 = getitem_24463 = getitem_24480 = getitem_24497 = getitem_24514 = getitem_24531 = getitem_24548 = getitem_24565 = getitem_24582 = getitem_24599 = getitem_24616 = getitem_24633 = getitem_24650 = getitem_24667 = getitem_24684 = None
        reduce_scatter_tensor_301 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_406, 'sum', 16, '1025');  cat_406 = None
        wait_tensor_903 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_301);  reduce_scatter_tensor_301 = None
        index_put_94 = torch.ops.aten.index_put.default(full_474, [getitem_462], add_2095, True);  full_474 = getitem_462 = add_2095 = None
        slice_288 = torch.ops.aten.slice.Tensor(index_put_94, 0, 0, add_2096);  index_put_94 = add_2096 = None
        all_to_all_single_121 = torch.ops._c10d_functional.all_to_all_single.default(slice_288, [_local_scalar_dense_64, _local_scalar_dense_65, _local_scalar_dense_66, _local_scalar_dense_67, _local_scalar_dense_68, _local_scalar_dense_69, _local_scalar_dense_70, _local_scalar_dense_71], [_local_scalar_dense_72, _local_scalar_dense_73, _local_scalar_dense_74, _local_scalar_dense_75, _local_scalar_dense_76, _local_scalar_dense_77, _local_scalar_dense_78, _local_scalar_dense_79], '1033');  slice_288 = _local_scalar_dense_64 = _local_scalar_dense_65 = _local_scalar_dense_66 = _local_scalar_dense_67 = _local_scalar_dense_68 = _local_scalar_dense_69 = _local_scalar_dense_70 = _local_scalar_dense_71 = _local_scalar_dense_72 = _local_scalar_dense_73 = _local_scalar_dense_74 = _local_scalar_dense_75 = _local_scalar_dense_76 = _local_scalar_dense_77 = _local_scalar_dense_78 = _local_scalar_dense_79 = None
        wait_tensor_904 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_121);  all_to_all_single_121 = None
        index_put_95 = torch.ops.aten.index_put.default(full_default_52, [div_22], wait_tensor_904, True);  div_22 = wait_tensor_904 = None
        add_2100 = torch.ops.aten.add.Tensor(add_2092, index_put_95);  add_2092 = index_put_95 = None
        mul_2017 = torch.ops.aten.mul.Tensor(view_2182, 1.0);  view_2182 = None
        scatter_add_21 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_459, mul_2017);  getitem_459 = mul_2017 = None
        convert_element_type_281 = torch.ops.prims.convert_element_type.default(mm_43, torch.float32);  mm_43 = None
        sub_96 = torch.ops.aten.sub.Tensor(convert_element_type_281, amax_4);  convert_element_type_281 = amax_4 = None
        exp_13 = torch.ops.aten.exp.default(sub_96);  sub_96 = None
        div_21 = torch.ops.aten.div.Tensor(exp_13, sum_17);  exp_13 = sum_17 = None
        mul_2018 = torch.ops.aten.mul.Tensor(scatter_add_21, div_21);  scatter_add_21 = None
        sum_275 = torch.ops.aten.sum.dim_IntList(mul_2018, [1], True)
        neg_118 = torch.ops.aten.neg.default(div_21);  div_21 = None
        fma_21 = torch.ops.prims.fma.default(neg_118, sum_275, mul_2018);  neg_118 = sum_275 = mul_2018 = None
        convert_element_type_3038 = torch.ops.prims.convert_element_type.default(fma_21, torch.bfloat16);  fma_21 = None
        permute_1482 = torch.ops.aten.permute.default(convert_element_type_3038, [1, 0])
        mm_560 = torch.ops.aten.mm.default(permute_1482, view_326);  permute_1482 = view_326 = None
        convert_element_type_278 = torch.ops.prims.convert_element_type.default(primals_95, torch.bfloat16);  primals_95 = None
        all_gather_into_tensor_86 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_278, 128, '0');  convert_element_type_278 = None
        wait_tensor_102 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_86);  all_gather_into_tensor_86 = None
        slice_33 = torch.ops.aten.slice.Tensor(wait_tensor_102, 0, 0, 64);  wait_tensor_102 = None
        permute_79 = torch.ops.aten.permute.default(slice_33, [1, 0]);  slice_33 = None
        permute_1484 = torch.ops.aten.permute.default(permute_79, [1, 0]);  permute_79 = None
        mm_561 = torch.ops.aten.mm.default(convert_element_type_3038, permute_1484);  convert_element_type_3038 = permute_1484 = None
        add_2101 = torch.ops.aten.add.Tensor(add_2100, mm_561);  add_2100 = mm_561 = None
        convert_element_type_3043 = torch.ops.prims.convert_element_type.default(mm_560, torch.float32);  mm_560 = None
        split_1320 = torch.ops.aten.split.Tensor(convert_element_type_3043, 1);  convert_element_type_3043 = None
        getitem_24685 = split_1320[0]
        getitem_24686 = split_1320[1]
        getitem_24687 = split_1320[2]
        getitem_24688 = split_1320[3]
        getitem_24689 = split_1320[4]
        getitem_24690 = split_1320[5]
        getitem_24691 = split_1320[6]
        getitem_24692 = split_1320[7]
        getitem_24693 = split_1320[8]
        getitem_24694 = split_1320[9]
        getitem_24695 = split_1320[10]
        getitem_24696 = split_1320[11]
        getitem_24697 = split_1320[12]
        getitem_24698 = split_1320[13]
        getitem_24699 = split_1320[14]
        getitem_24700 = split_1320[15]
        getitem_24701 = split_1320[16]
        getitem_24702 = split_1320[17]
        getitem_24703 = split_1320[18]
        getitem_24704 = split_1320[19]
        getitem_24705 = split_1320[20]
        getitem_24706 = split_1320[21]
        getitem_24707 = split_1320[22]
        getitem_24708 = split_1320[23]
        getitem_24709 = split_1320[24]
        getitem_24710 = split_1320[25]
        getitem_24711 = split_1320[26]
        getitem_24712 = split_1320[27]
        getitem_24713 = split_1320[28]
        getitem_24714 = split_1320[29]
        getitem_24715 = split_1320[30]
        getitem_24716 = split_1320[31]
        getitem_24717 = split_1320[32]
        getitem_24718 = split_1320[33]
        getitem_24719 = split_1320[34]
        getitem_24720 = split_1320[35]
        getitem_24721 = split_1320[36]
        getitem_24722 = split_1320[37]
        getitem_24723 = split_1320[38]
        getitem_24724 = split_1320[39]
        getitem_24725 = split_1320[40]
        getitem_24726 = split_1320[41]
        getitem_24727 = split_1320[42]
        getitem_24728 = split_1320[43]
        getitem_24729 = split_1320[44]
        getitem_24730 = split_1320[45]
        getitem_24731 = split_1320[46]
        getitem_24732 = split_1320[47]
        getitem_24733 = split_1320[48]
        getitem_24734 = split_1320[49]
        getitem_24735 = split_1320[50]
        getitem_24736 = split_1320[51]
        getitem_24737 = split_1320[52]
        getitem_24738 = split_1320[53]
        getitem_24739 = split_1320[54]
        getitem_24740 = split_1320[55]
        getitem_24741 = split_1320[56]
        getitem_24742 = split_1320[57]
        getitem_24743 = split_1320[58]
        getitem_24744 = split_1320[59]
        getitem_24745 = split_1320[60]
        getitem_24746 = split_1320[61]
        getitem_24747 = split_1320[62]
        getitem_24748 = split_1320[63];  split_1320 = None
        cat_407 = torch.ops.aten.cat.default([getitem_24685, getitem_24686, getitem_24687, getitem_24688, getitem_24689, getitem_24690, getitem_24691, getitem_24692, getitem_24693, getitem_24694, getitem_24695, getitem_24696, getitem_24697, getitem_24698, getitem_24699, getitem_24700, getitem_24701, getitem_24702, getitem_24703, getitem_24704, getitem_24705, getitem_24706, getitem_24707, getitem_24708, getitem_24709, getitem_24710, getitem_24711, getitem_24712, getitem_24713, getitem_24714, getitem_24715, getitem_24716, getitem_24717, getitem_24718, getitem_24719, getitem_24720, getitem_24721, getitem_24722, getitem_24723, getitem_24724, getitem_24725, getitem_24726, getitem_24727, getitem_24728, getitem_24729, getitem_24730, getitem_24731, getitem_24732, getitem_24733, getitem_24734, getitem_24735, getitem_24736, getitem_24737, getitem_24738, getitem_24739, getitem_24740, getitem_24741, getitem_24742, getitem_24743, getitem_24744, getitem_24745, getitem_24746, getitem_24747, getitem_24748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_24685 = getitem_24686 = getitem_24687 = getitem_24688 = getitem_24689 = getitem_24690 = getitem_24691 = getitem_24692 = getitem_24693 = getitem_24694 = getitem_24695 = getitem_24696 = getitem_24697 = getitem_24698 = getitem_24699 = getitem_24700 = getitem_24701 = getitem_24702 = getitem_24703 = getitem_24704 = getitem_24705 = getitem_24706 = getitem_24707 = getitem_24708 = getitem_24709 = getitem_24710 = getitem_24711 = getitem_24712 = getitem_24713 = getitem_24714 = getitem_24715 = getitem_24716 = getitem_24717 = getitem_24718 = getitem_24719 = getitem_24720 = getitem_24721 = getitem_24722 = getitem_24723 = getitem_24724 = getitem_24725 = getitem_24726 = getitem_24727 = getitem_24728 = getitem_24729 = getitem_24730 = getitem_24731 = getitem_24732 = getitem_24733 = getitem_24734 = getitem_24735 = getitem_24736 = getitem_24737 = getitem_24738 = getitem_24739 = getitem_24740 = getitem_24741 = getitem_24742 = getitem_24743 = getitem_24744 = getitem_24745 = getitem_24746 = getitem_24747 = getitem_24748 = None
        reduce_scatter_tensor_302 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_407, 'avg', 128, '0');  cat_407 = None
        wait_tensor_905 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_302);  reduce_scatter_tensor_302 = None
        view_2184 = torch.ops.aten.view.default(add_2101, [2, 4096, 2048]);  add_2101 = None
        convert_element_type_3044 = torch.ops.prims.convert_element_type.default(view_2184, torch.float32);  view_2184 = None
        convert_element_type_275 = torch.ops.prims.convert_element_type.default(primals_93, torch.bfloat16);  primals_93 = None
        all_gather_into_tensor_85 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_275, 128, '0');  convert_element_type_275 = None
        wait_tensor_101 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_85);  all_gather_into_tensor_85 = None
        convert_element_type_3046 = torch.ops.prims.convert_element_type.default(wait_tensor_101, torch.float32);  wait_tensor_101 = None
        mul_2019 = torch.ops.aten.mul.Tensor(convert_element_type_3044, convert_element_type_3046);  convert_element_type_3046 = None
        convert_element_type_276 = torch.ops.prims.convert_element_type.default(add_280, torch.float32);  add_280 = None
        mul_211 = torch.ops.aten.mul.Tensor(convert_element_type_276, rsqrt_17);  convert_element_type_276 = None
        mul_2021 = torch.ops.aten.mul.Tensor(mul_211, mul_2019)
        sum_276 = torch.ops.aten.sum.dim_IntList(mul_2021, [2], True);  mul_2021 = None
        div_261 = torch.ops.aten.div.Tensor(mul_211, 2048)
        mul_2022 = torch.ops.aten.mul.Tensor(div_261, sum_276);  div_261 = sum_276 = None
        sub_754 = torch.ops.aten.sub.Tensor(mul_2019, mul_2022);  mul_2019 = mul_2022 = None
        mul_2023 = torch.ops.aten.mul.Tensor(sub_754, rsqrt_17);  sub_754 = rsqrt_17 = None
        mul_2024 = torch.ops.aten.mul.Tensor(convert_element_type_3044, mul_211);  convert_element_type_3044 = mul_211 = None
        sum_277 = torch.ops.aten.sum.dim_IntList(mul_2024, [0, 1]);  mul_2024 = None
        convert_element_type_3047 = torch.ops.prims.convert_element_type.default(mul_2023, torch.bfloat16);  mul_2023 = None
        add_2102 = torch.ops.aten.add.Tensor(add_2089, convert_element_type_3047);  add_2089 = convert_element_type_3047 = None
        convert_element_type_default_18 = torch.ops.prims.convert_element_type.default(sum_277, torch.float32);  sum_277 = None
        reduce_scatter_tensor_303 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_18, 'avg', 128, '0');  convert_element_type_default_18 = None
        wait_tensor_906 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_303);  reduce_scatter_tensor_303 = None
        view_2185 = torch.ops.aten.view.default(add_2102, [8192, 2048])
        permute_1486 = torch.ops.aten.permute.default(view_2185, [1, 0])
        permute_77 = torch.ops.aten.permute.default(getitem_455, [0, 2, 1, 3])
        view_321 = torch.ops.aten.view.default(permute_77, [2, 4096, -1]);  permute_77 = None
        view_323 = torch.ops.aten.view.default(view_321, [8192, 2048]);  view_321 = None
        mm_562 = torch.ops.aten.mm.default(permute_1486, view_323);  permute_1486 = view_323 = None
        convert_element_type_272 = torch.ops.prims.convert_element_type.default(primals_92, torch.bfloat16);  primals_92 = None
        all_gather_into_tensor_84 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_272, 128, '0');  convert_element_type_272 = None
        wait_tensor_100 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_84);  all_gather_into_tensor_84 = None
        permute_78 = torch.ops.aten.permute.default(wait_tensor_100, [1, 0]);  wait_tensor_100 = None
        permute_1488 = torch.ops.aten.permute.default(permute_78, [1, 0]);  permute_78 = None
        mm_563 = torch.ops.aten.mm.default(view_2185, permute_1488);  view_2185 = permute_1488 = None
        view_2186 = torch.ops.aten.view.default(mm_563, [2, 4096, 2048]);  mm_563 = None
        convert_element_type_3054 = torch.ops.prims.convert_element_type.default(mm_562, torch.float32);  mm_562 = None
        reduce_scatter_tensor_304 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3054, 'avg', 128, '0');  convert_element_type_3054 = None
        wait_tensor_907 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_304);  reduce_scatter_tensor_304 = None
        view_2187 = torch.ops.aten.view.default(view_2186, [2, 4096, 16, 128]);  view_2186 = None
        permute_1490 = torch.ops.aten.permute.default(view_2187, [0, 2, 1, 3]);  view_2187 = None
        fw_graph21 = self.fw_graph21
        joint_graph21 = self.joint_graph21
        mask_graph21 = self.mask_graph21
        flex_attention_backward_21 = torch.ops.higher_order.flex_attention_backward(permute_74, permute_75, permute_76, getitem_455, getitem_456, permute_1490, None, fw_graph21, joint_graph21, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph21), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_74 = permute_75 = permute_76 = getitem_455 = getitem_456 = permute_1490 = fw_graph21 = joint_graph21 = mask_graph21 = None
        getitem_24749 = flex_attention_backward_21[0]
        getitem_24750 = flex_attention_backward_21[1]
        getitem_24751 = flex_attention_backward_21[2];  flex_attention_backward_21 = None
        permute_1491 = torch.ops.aten.permute.default(getitem_24751, [0, 2, 1, 3]);  getitem_24751 = None
        permute_1492 = torch.ops.aten.permute.default(getitem_24750, [0, 2, 1, 3]);  getitem_24750 = None
        permute_1493 = torch.ops.aten.permute.default(getitem_24749, [0, 2, 1, 3]);  getitem_24749 = None
        slice_290 = torch.ops.aten.slice.Tensor(permute_1492, 3, 0, 128)
        slice_291 = torch.ops.aten.slice.Tensor(permute_1492, 3, 128, 192);  permute_1492 = None
        sum_278 = torch.ops.aten.sum.dim_IntList(slice_291, [2], True);  slice_291 = None
        cat_408 = torch.ops.aten.cat.default([slice_290, permute_1491], 3);  slice_290 = permute_1491 = None
        view_2188 = torch.ops.aten.view.default(cat_408, [2, 4096, 4096]);  cat_408 = None
        view_2189 = torch.ops.aten.view.default(view_2188, [8192, 4096]);  view_2188 = None
        permute_1494 = torch.ops.aten.permute.default(view_2189, [1, 0])
        mm_564 = torch.ops.aten.mm.default(permute_1494, view_318);  permute_1494 = view_318 = None
        convert_element_type_269 = torch.ops.prims.convert_element_type.default(primals_91, torch.bfloat16);  primals_91 = None
        all_gather_into_tensor_83 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_269, 128, '0');  convert_element_type_269 = None
        wait_tensor_99 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_83);  all_gather_into_tensor_83 = None
        permute_73 = torch.ops.aten.permute.default(wait_tensor_99, [1, 0]);  wait_tensor_99 = None
        permute_1496 = torch.ops.aten.permute.default(permute_73, [1, 0]);  permute_73 = None
        mm_565 = torch.ops.aten.mm.default(view_2189, permute_1496);  view_2189 = permute_1496 = None
        view_2190 = torch.ops.aten.view.default(mm_565, [2, 4096, 512]);  mm_565 = None
        convert_element_type_3059 = torch.ops.prims.convert_element_type.default(mm_564, torch.float32);  mm_564 = None
        reduce_scatter_tensor_305 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3059, 'avg', 128, '0');  convert_element_type_3059 = None
        wait_tensor_908 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_305);  reduce_scatter_tensor_305 = None
        convert_element_type_3060 = torch.ops.prims.convert_element_type.default(view_2190, torch.float32);  view_2190 = None
        convert_element_type_266 = torch.ops.prims.convert_element_type.default(primals_90, torch.bfloat16);  primals_90 = None
        all_gather_into_tensor_82 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_266, 128, '0');  convert_element_type_266 = None
        wait_tensor_98 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_82);  all_gather_into_tensor_82 = None
        convert_element_type_3062 = torch.ops.prims.convert_element_type.default(wait_tensor_98, torch.float32);  wait_tensor_98 = None
        mul_2025 = torch.ops.aten.mul.Tensor(convert_element_type_3060, convert_element_type_3062);  convert_element_type_3062 = None
        convert_element_type_267 = torch.ops.prims.convert_element_type.default(getitem_451, torch.float32);  getitem_451 = None
        mul_209 = torch.ops.aten.mul.Tensor(convert_element_type_267, rsqrt_16);  convert_element_type_267 = None
        mul_2027 = torch.ops.aten.mul.Tensor(mul_209, mul_2025)
        sum_279 = torch.ops.aten.sum.dim_IntList(mul_2027, [2], True);  mul_2027 = None
        div_262 = torch.ops.aten.div.Tensor(mul_209, 512)
        mul_2028 = torch.ops.aten.mul.Tensor(div_262, sum_279);  div_262 = sum_279 = None
        sub_755 = torch.ops.aten.sub.Tensor(mul_2025, mul_2028);  mul_2025 = mul_2028 = None
        mul_2029 = torch.ops.aten.mul.Tensor(sub_755, rsqrt_16);  sub_755 = rsqrt_16 = None
        mul_2030 = torch.ops.aten.mul.Tensor(convert_element_type_3060, mul_209);  convert_element_type_3060 = mul_209 = None
        sum_280 = torch.ops.aten.sum.dim_IntList(mul_2030, [0, 1]);  mul_2030 = None
        convert_element_type_3063 = torch.ops.prims.convert_element_type.default(mul_2029, torch.bfloat16);  mul_2029 = None
        convert_element_type_default_17 = torch.ops.prims.convert_element_type.default(sum_280, torch.float32);  sum_280 = None
        reduce_scatter_tensor_306 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_17, 'avg', 128, '0');  convert_element_type_default_17 = None
        wait_tensor_909 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_306);  reduce_scatter_tensor_306 = None
        convert_element_type_3066 = torch.ops.prims.convert_element_type.default(sum_278, torch.float32);  sum_278 = None
        view_2191 = torch.ops.aten.view.default(convert_element_type_3066, [2, 4096, 1, 32, 2]);  convert_element_type_3066 = None
        view_as_complex_96 = torch.ops.aten.view_as_complex.default(view_2191);  view_2191 = None
        mul_2031 = torch.ops.aten.mul.Tensor(view_as_complex_96, clone_9);  view_as_complex_96 = None
        view_as_real_96 = torch.ops.aten.view_as_real.default(mul_2031);  mul_2031 = None
        view_2192 = torch.ops.aten.view.default(view_as_real_96, [2, 4096, 1, 64]);  view_as_real_96 = None
        convert_element_type_3067 = torch.ops.prims.convert_element_type.default(view_2192, torch.bfloat16);  view_2192 = None
        squeeze_47 = torch.ops.aten.squeeze.dim(convert_element_type_3067, 2);  convert_element_type_3067 = None
        cat_409 = torch.ops.aten.cat.default([convert_element_type_3063, squeeze_47], 2);  convert_element_type_3063 = squeeze_47 = None
        view_2193 = torch.ops.aten.view.default(cat_409, [8192, 576]);  cat_409 = None
        permute_1498 = torch.ops.aten.permute.default(view_2193, [1, 0])
        mm_566 = torch.ops.aten.mm.default(permute_1498, view_304);  permute_1498 = None
        convert_element_type_261 = torch.ops.prims.convert_element_type.default(primals_89, torch.bfloat16);  primals_89 = None
        all_gather_into_tensor_81 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_261, 128, '0');  convert_element_type_261 = None
        wait_tensor_97 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_81);  all_gather_into_tensor_81 = None
        slice_31 = torch.ops.aten.slice.Tensor(wait_tensor_97, 0, 0, 576);  wait_tensor_97 = None
        permute_72 = torch.ops.aten.permute.default(slice_31, [1, 0]);  slice_31 = None
        permute_1500 = torch.ops.aten.permute.default(permute_72, [1, 0]);  permute_72 = None
        mm_567 = torch.ops.aten.mm.default(view_2193, permute_1500);  view_2193 = permute_1500 = None
        view_2194 = torch.ops.aten.view.default(mm_567, [2, 4096, 2048]);  mm_567 = None
        convert_element_type_3072 = torch.ops.prims.convert_element_type.default(mm_566, torch.float32);  mm_566 = None
        split_1321 = torch.ops.aten.split.Tensor(convert_element_type_3072, 5);  convert_element_type_3072 = None
        getitem_24753 = split_1321[0]
        getitem_24754 = split_1321[1]
        getitem_24755 = split_1321[2]
        getitem_24756 = split_1321[3]
        getitem_24757 = split_1321[4]
        getitem_24758 = split_1321[5]
        getitem_24759 = split_1321[6]
        getitem_24760 = split_1321[7]
        getitem_24761 = split_1321[8]
        getitem_24762 = split_1321[9]
        getitem_24763 = split_1321[10]
        getitem_24764 = split_1321[11]
        getitem_24765 = split_1321[12]
        getitem_24766 = split_1321[13]
        getitem_24767 = split_1321[14]
        getitem_24768 = split_1321[15]
        getitem_24769 = split_1321[16]
        getitem_24770 = split_1321[17]
        getitem_24771 = split_1321[18]
        getitem_24772 = split_1321[19]
        getitem_24773 = split_1321[20]
        getitem_24774 = split_1321[21]
        getitem_24775 = split_1321[22]
        getitem_24776 = split_1321[23]
        getitem_24777 = split_1321[24]
        getitem_24778 = split_1321[25]
        getitem_24779 = split_1321[26]
        getitem_24780 = split_1321[27]
        getitem_24781 = split_1321[28]
        getitem_24782 = split_1321[29]
        getitem_24783 = split_1321[30]
        getitem_24784 = split_1321[31]
        getitem_24785 = split_1321[32]
        getitem_24786 = split_1321[33]
        getitem_24787 = split_1321[34]
        getitem_24788 = split_1321[35]
        getitem_24789 = split_1321[36]
        getitem_24790 = split_1321[37]
        getitem_24791 = split_1321[38]
        getitem_24792 = split_1321[39]
        getitem_24793 = split_1321[40]
        getitem_24794 = split_1321[41]
        getitem_24795 = split_1321[42]
        getitem_24796 = split_1321[43]
        getitem_24797 = split_1321[44]
        getitem_24798 = split_1321[45]
        getitem_24799 = split_1321[46]
        getitem_24800 = split_1321[47]
        getitem_24801 = split_1321[48]
        getitem_24802 = split_1321[49]
        getitem_24803 = split_1321[50]
        getitem_24804 = split_1321[51]
        getitem_24805 = split_1321[52]
        getitem_24806 = split_1321[53]
        getitem_24807 = split_1321[54]
        getitem_24808 = split_1321[55]
        getitem_24809 = split_1321[56]
        getitem_24810 = split_1321[57]
        getitem_24811 = split_1321[58]
        getitem_24812 = split_1321[59]
        getitem_24813 = split_1321[60]
        getitem_24814 = split_1321[61]
        getitem_24815 = split_1321[62]
        getitem_24816 = split_1321[63]
        getitem_24817 = split_1321[64]
        getitem_24818 = split_1321[65]
        getitem_24819 = split_1321[66]
        getitem_24820 = split_1321[67]
        getitem_24821 = split_1321[68]
        getitem_24822 = split_1321[69]
        getitem_24823 = split_1321[70]
        getitem_24824 = split_1321[71]
        getitem_24825 = split_1321[72]
        getitem_24826 = split_1321[73]
        getitem_24827 = split_1321[74]
        getitem_24828 = split_1321[75]
        getitem_24829 = split_1321[76]
        getitem_24830 = split_1321[77]
        getitem_24831 = split_1321[78]
        getitem_24832 = split_1321[79]
        getitem_24833 = split_1321[80]
        getitem_24834 = split_1321[81]
        getitem_24835 = split_1321[82]
        getitem_24836 = split_1321[83]
        getitem_24837 = split_1321[84]
        getitem_24838 = split_1321[85]
        getitem_24839 = split_1321[86]
        getitem_24840 = split_1321[87]
        getitem_24841 = split_1321[88]
        getitem_24842 = split_1321[89]
        getitem_24843 = split_1321[90]
        getitem_24844 = split_1321[91]
        getitem_24845 = split_1321[92]
        getitem_24846 = split_1321[93]
        getitem_24847 = split_1321[94]
        getitem_24848 = split_1321[95]
        getitem_24849 = split_1321[96]
        getitem_24850 = split_1321[97]
        getitem_24851 = split_1321[98]
        getitem_24852 = split_1321[99]
        getitem_24853 = split_1321[100]
        getitem_24854 = split_1321[101]
        getitem_24855 = split_1321[102]
        getitem_24856 = split_1321[103]
        getitem_24857 = split_1321[104]
        getitem_24858 = split_1321[105]
        getitem_24859 = split_1321[106]
        getitem_24860 = split_1321[107]
        getitem_24861 = split_1321[108]
        getitem_24862 = split_1321[109]
        getitem_24863 = split_1321[110]
        getitem_24864 = split_1321[111]
        getitem_24865 = split_1321[112]
        getitem_24866 = split_1321[113]
        getitem_24867 = split_1321[114]
        getitem_24868 = split_1321[115];  split_1321 = None
        constant_pad_nd_1681 = torch.ops.aten.constant_pad_nd.default(getitem_24868, [0, 0, 0, 4], 0.0);  getitem_24868 = None
        cat_410 = torch.ops.aten.cat.default([getitem_24753, getitem_24754, getitem_24755, getitem_24756, getitem_24757, getitem_24758, getitem_24759, getitem_24760, getitem_24761, getitem_24762, getitem_24763, getitem_24764, getitem_24765, getitem_24766, getitem_24767, getitem_24768, getitem_24769, getitem_24770, getitem_24771, getitem_24772, getitem_24773, getitem_24774, getitem_24775, getitem_24776, getitem_24777, getitem_24778, getitem_24779, getitem_24780, getitem_24781, getitem_24782, getitem_24783, getitem_24784, getitem_24785, getitem_24786, getitem_24787, getitem_24788, getitem_24789, getitem_24790, getitem_24791, getitem_24792, getitem_24793, getitem_24794, getitem_24795, getitem_24796, getitem_24797, getitem_24798, getitem_24799, getitem_24800, getitem_24801, getitem_24802, getitem_24803, getitem_24804, getitem_24805, getitem_24806, getitem_24807, getitem_24808, getitem_24809, getitem_24810, getitem_24811, getitem_24812, getitem_24813, getitem_24814, getitem_24815, getitem_24816, getitem_24817, getitem_24818, getitem_24819, getitem_24820, getitem_24821, getitem_24822, getitem_24823, getitem_24824, getitem_24825, getitem_24826, getitem_24827, getitem_24828, getitem_24829, getitem_24830, getitem_24831, getitem_24832, getitem_24833, getitem_24834, getitem_24835, getitem_24836, getitem_24837, getitem_24838, getitem_24839, getitem_24840, getitem_24841, getitem_24842, getitem_24843, getitem_24844, getitem_24845, getitem_24846, getitem_24847, getitem_24848, getitem_24849, getitem_24850, getitem_24851, getitem_24852, getitem_24853, getitem_24854, getitem_24855, getitem_24856, getitem_24857, getitem_24858, getitem_24859, getitem_24860, getitem_24861, getitem_24862, getitem_24863, getitem_24864, getitem_24865, getitem_24866, getitem_24867, constant_pad_nd_1681, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_24753 = getitem_24754 = getitem_24755 = getitem_24756 = getitem_24757 = getitem_24758 = getitem_24759 = getitem_24760 = getitem_24761 = getitem_24762 = getitem_24763 = getitem_24764 = getitem_24765 = getitem_24766 = getitem_24767 = getitem_24768 = getitem_24769 = getitem_24770 = getitem_24771 = getitem_24772 = getitem_24773 = getitem_24774 = getitem_24775 = getitem_24776 = getitem_24777 = getitem_24778 = getitem_24779 = getitem_24780 = getitem_24781 = getitem_24782 = getitem_24783 = getitem_24784 = getitem_24785 = getitem_24786 = getitem_24787 = getitem_24788 = getitem_24789 = getitem_24790 = getitem_24791 = getitem_24792 = getitem_24793 = getitem_24794 = getitem_24795 = getitem_24796 = getitem_24797 = getitem_24798 = getitem_24799 = getitem_24800 = getitem_24801 = getitem_24802 = getitem_24803 = getitem_24804 = getitem_24805 = getitem_24806 = getitem_24807 = getitem_24808 = getitem_24809 = getitem_24810 = getitem_24811 = getitem_24812 = getitem_24813 = getitem_24814 = getitem_24815 = getitem_24816 = getitem_24817 = getitem_24818 = getitem_24819 = getitem_24820 = getitem_24821 = getitem_24822 = getitem_24823 = getitem_24824 = getitem_24825 = getitem_24826 = getitem_24827 = getitem_24828 = getitem_24829 = getitem_24830 = getitem_24831 = getitem_24832 = getitem_24833 = getitem_24834 = getitem_24835 = getitem_24836 = getitem_24837 = getitem_24838 = getitem_24839 = getitem_24840 = getitem_24841 = getitem_24842 = getitem_24843 = getitem_24844 = getitem_24845 = getitem_24846 = getitem_24847 = getitem_24848 = getitem_24849 = getitem_24850 = getitem_24851 = getitem_24852 = getitem_24853 = getitem_24854 = getitem_24855 = getitem_24856 = getitem_24857 = getitem_24858 = getitem_24859 = getitem_24860 = getitem_24861 = getitem_24862 = getitem_24863 = getitem_24864 = getitem_24865 = getitem_24866 = getitem_24867 = constant_pad_nd_1681 = None
        reduce_scatter_tensor_307 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_410, 'avg', 128, '0');  cat_410 = None
        wait_tensor_910 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_307);  reduce_scatter_tensor_307 = None
        slice_292 = torch.ops.aten.slice.Tensor(permute_1493, 3, 0, 128)
        slice_293 = torch.ops.aten.slice.Tensor(permute_1493, 3, 128, 192);  permute_1493 = None
        convert_element_type_3073 = torch.ops.prims.convert_element_type.default(slice_293, torch.float32);  slice_293 = None
        view_2195 = torch.ops.aten.view.default(convert_element_type_3073, [2, 4096, 16, 32, 2]);  convert_element_type_3073 = None
        view_as_complex_97 = torch.ops.aten.view_as_complex.default(view_2195);  view_2195 = None
        mul_2032 = torch.ops.aten.mul.Tensor(view_as_complex_97, clone_9);  view_as_complex_97 = None
        view_as_real_97 = torch.ops.aten.view_as_real.default(mul_2032);  mul_2032 = None
        view_2196 = torch.ops.aten.view.default(view_as_real_97, [2, 4096, 16, 64]);  view_as_real_97 = None
        convert_element_type_3074 = torch.ops.prims.convert_element_type.default(view_2196, torch.bfloat16);  view_2196 = None
        cat_411 = torch.ops.aten.cat.default([slice_292, convert_element_type_3074], 3);  slice_292 = convert_element_type_3074 = None
        view_2197 = torch.ops.aten.view.default(cat_411, [2, 4096, 3072]);  cat_411 = None
        view_2198 = torch.ops.aten.view.default(view_2197, [8192, 3072]);  view_2197 = None
        permute_1502 = torch.ops.aten.permute.default(view_2198, [1, 0])
        mm_568 = torch.ops.aten.mm.default(permute_1502, view_304);  permute_1502 = view_304 = None
        convert_element_type_256 = torch.ops.prims.convert_element_type.default(primals_88, torch.bfloat16);  primals_88 = None
        all_gather_into_tensor_80 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_256, 128, '0');  convert_element_type_256 = None
        wait_tensor_96 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_80);  all_gather_into_tensor_80 = None
        permute_71 = torch.ops.aten.permute.default(wait_tensor_96, [1, 0]);  wait_tensor_96 = None
        permute_1504 = torch.ops.aten.permute.default(permute_71, [1, 0]);  permute_71 = None
        mm_569 = torch.ops.aten.mm.default(view_2198, permute_1504);  view_2198 = permute_1504 = None
        view_2199 = torch.ops.aten.view.default(mm_569, [2, 4096, 2048]);  mm_569 = None
        add_2103 = torch.ops.aten.add.Tensor(view_2194, view_2199);  view_2194 = view_2199 = None
        convert_element_type_3079 = torch.ops.prims.convert_element_type.default(mm_568, torch.float32);  mm_568 = None
        reduce_scatter_tensor_308 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3079, 'avg', 128, '0');  convert_element_type_3079 = None
        wait_tensor_911 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_308);  reduce_scatter_tensor_308 = None
        convert_element_type_3080 = torch.ops.prims.convert_element_type.default(add_2103, torch.float32);  add_2103 = None
        convert_element_type_253 = torch.ops.prims.convert_element_type.default(primals_87, torch.bfloat16);  primals_87 = None
        all_gather_into_tensor_79 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_253, 128, '0');  convert_element_type_253 = None
        wait_tensor_95 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_79);  all_gather_into_tensor_79 = None
        convert_element_type_3082 = torch.ops.prims.convert_element_type.default(wait_tensor_95, torch.float32);  wait_tensor_95 = None
        mul_2033 = torch.ops.aten.mul.Tensor(convert_element_type_3080, convert_element_type_3082);  convert_element_type_3082 = None
        convert_element_type_254 = torch.ops.prims.convert_element_type.default(add_277, torch.float32);  add_277 = None
        mul_205 = torch.ops.aten.mul.Tensor(convert_element_type_254, rsqrt_15);  convert_element_type_254 = None
        mul_2035 = torch.ops.aten.mul.Tensor(mul_205, mul_2033)
        sum_281 = torch.ops.aten.sum.dim_IntList(mul_2035, [2], True);  mul_2035 = None
        div_263 = torch.ops.aten.div.Tensor(mul_205, 2048)
        mul_2036 = torch.ops.aten.mul.Tensor(div_263, sum_281);  div_263 = sum_281 = None
        sub_756 = torch.ops.aten.sub.Tensor(mul_2033, mul_2036);  mul_2033 = mul_2036 = None
        mul_2037 = torch.ops.aten.mul.Tensor(sub_756, rsqrt_15);  sub_756 = rsqrt_15 = None
        mul_2038 = torch.ops.aten.mul.Tensor(convert_element_type_3080, mul_205);  convert_element_type_3080 = mul_205 = None
        sum_282 = torch.ops.aten.sum.dim_IntList(mul_2038, [0, 1]);  mul_2038 = None
        convert_element_type_3083 = torch.ops.prims.convert_element_type.default(mul_2037, torch.bfloat16);  mul_2037 = None
        add_2104 = torch.ops.aten.add.Tensor(add_2102, convert_element_type_3083);  add_2102 = convert_element_type_3083 = None
        convert_element_type_default_16 = torch.ops.prims.convert_element_type.default(sum_282, torch.float32);  sum_282 = None
        reduce_scatter_tensor_309 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_16, 'avg', 128, '0');  convert_element_type_default_16 = None
        wait_tensor_912 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_309);  reduce_scatter_tensor_309 = None
        view_2200 = torch.ops.aten.view.default(add_2104, [8192, 2048])
        unsqueeze_75 = torch.ops.aten.unsqueeze.default(view_2200, 1)
        convert_element_type_3086 = torch.ops.prims.convert_element_type.default(unsqueeze_75, torch.float32);  unsqueeze_75 = None
        bmm_70 = torch.ops.aten.bmm.default(permute_1506, convert_element_type_3086);  permute_1506 = None
        bmm_71 = torch.ops.aten.bmm.default(convert_element_type_3086, permute_1507);  convert_element_type_3086 = permute_1507 = None
        convert_element_type_3087 = torch.ops.prims.convert_element_type.default(bmm_70, torch.bfloat16);  bmm_70 = None
        view_2201 = torch.ops.aten.view.default(bmm_71, [8192, 6]);  bmm_71 = None
        view_2202 = torch.ops.aten.view.default(convert_element_type_3087, [49152, 2048]);  convert_element_type_3087 = None
        index_96 = torch.ops.aten.index.Tensor(view_2202, [getitem_351]);  view_2202 = getitem_351 = None
        permute_1508 = torch.ops.aten.permute.default(view_2200, [1, 0])
        mm_570 = torch.ops.aten.mm.default(permute_1508, mul_202);  permute_1508 = mul_202 = None
        convert_element_type_248 = torch.ops.prims.convert_element_type.default(primals_86, torch.bfloat16);  primals_86 = None
        all_gather_into_tensor_78 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_248, 128, '0');  convert_element_type_248 = None
        wait_tensor_94 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_78);  all_gather_into_tensor_78 = None
        permute_70 = torch.ops.aten.permute.default(wait_tensor_94, [1, 0]);  wait_tensor_94 = None
        permute_1510 = torch.ops.aten.permute.default(permute_70, [1, 0]);  permute_70 = None
        mm_571 = torch.ops.aten.mm.default(view_2200, permute_1510);  view_2200 = permute_1510 = None
        convert_element_type_3092 = torch.ops.prims.convert_element_type.default(mm_570, torch.float32);  mm_570 = None
        reduce_scatter_tensor_310 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3092, 'avg', 128, '0');  convert_element_type_3092 = None
        wait_tensor_913 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_310);  reduce_scatter_tensor_310 = None
        convert_element_type_243 = torch.ops.prims.convert_element_type.default(mm_36, torch.float32);  mm_36 = None
        neg_8 = torch.ops.aten.neg.default(convert_element_type_243)
        exp_12 = torch.ops.aten.exp.default(neg_8);  neg_8 = None
        add_272 = torch.ops.aten.add.Tensor(exp_12, 1);  exp_12 = None
        div_20 = torch.ops.aten.div.Tensor(convert_element_type_243, add_272)
        convert_element_type_244 = torch.ops.prims.convert_element_type.default(div_20, torch.bfloat16);  div_20 = None
        mul_2039 = torch.ops.aten.mul.Tensor(mm_571, convert_element_type_244);  convert_element_type_244 = None
        mul_2040 = torch.ops.aten.mul.Tensor(mm_571, mm_37);  mm_571 = mm_37 = None
        permute_1512 = torch.ops.aten.permute.default(mul_2039, [1, 0])
        mm_572 = torch.ops.aten.mm.default(permute_1512, view_259);  permute_1512 = None
        convert_element_type_245 = torch.ops.prims.convert_element_type.default(primals_85, torch.bfloat16);  primals_85 = None
        all_gather_into_tensor_77 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_245, 128, '0');  convert_element_type_245 = None
        wait_tensor_93 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_77);  all_gather_into_tensor_77 = None
        permute_69 = torch.ops.aten.permute.default(wait_tensor_93, [1, 0]);  wait_tensor_93 = None
        permute_1514 = torch.ops.aten.permute.default(permute_69, [1, 0]);  permute_69 = None
        mm_573 = torch.ops.aten.mm.default(mul_2039, permute_1514);  mul_2039 = permute_1514 = None
        convert_element_type_3097 = torch.ops.prims.convert_element_type.default(mm_572, torch.float32);  mm_572 = None
        reduce_scatter_tensor_311 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3097, 'avg', 128, '0');  convert_element_type_3097 = None
        wait_tensor_914 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_311);  reduce_scatter_tensor_311 = None
        convert_element_type_3098 = torch.ops.prims.convert_element_type.default(mul_2040, torch.float32);  mul_2040 = None
        reciprocal_44 = torch.ops.aten.reciprocal.default(add_272);  add_272 = None
        mul_2041 = torch.ops.aten.mul.Tensor(reciprocal_44, 1);  reciprocal_44 = None
        mul_2042 = torch.ops.aten.mul.Tensor(convert_element_type_3098, mul_2041);  convert_element_type_3098 = None
        sub_757 = torch.ops.aten.sub.Tensor(1, mul_2041);  mul_2041 = None
        mul_2043 = torch.ops.aten.mul.Tensor(convert_element_type_243, sub_757);  convert_element_type_243 = sub_757 = None
        add_2106 = torch.ops.aten.add.Tensor(mul_2043, 1);  mul_2043 = None
        mul_2044 = torch.ops.aten.mul.Tensor(mul_2042, add_2106);  mul_2042 = add_2106 = None
        convert_element_type_3100 = torch.ops.prims.convert_element_type.default(mul_2044, torch.bfloat16);  mul_2044 = None
        permute_1516 = torch.ops.aten.permute.default(convert_element_type_3100, [1, 0])
        mm_574 = torch.ops.aten.mm.default(permute_1516, view_259);  permute_1516 = None
        convert_element_type_240 = torch.ops.prims.convert_element_type.default(primals_84, torch.bfloat16);  primals_84 = None
        all_gather_into_tensor_76 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_240, 128, '0');  convert_element_type_240 = None
        wait_tensor_92 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_76);  all_gather_into_tensor_76 = None
        permute_68 = torch.ops.aten.permute.default(wait_tensor_92, [1, 0]);  wait_tensor_92 = None
        permute_1518 = torch.ops.aten.permute.default(permute_68, [1, 0]);  permute_68 = None
        mm_575 = torch.ops.aten.mm.default(convert_element_type_3100, permute_1518);  convert_element_type_3100 = permute_1518 = None
        add_2107 = torch.ops.aten.add.Tensor(mm_573, mm_575);  mm_573 = mm_575 = None
        convert_element_type_3105 = torch.ops.prims.convert_element_type.default(mm_574, torch.float32);  mm_574 = None
        reduce_scatter_tensor_312 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3105, 'avg', 128, '0');  convert_element_type_3105 = None
        wait_tensor_915 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_312);  reduce_scatter_tensor_312 = None
        all_to_all_single_122 = torch.ops._c10d_functional.all_to_all_single.default(index_96, [_local_scalar_dense_56, _local_scalar_dense_57, _local_scalar_dense_58, _local_scalar_dense_59, _local_scalar_dense_60, _local_scalar_dense_61, _local_scalar_dense_62, _local_scalar_dense_63], [_local_scalar_dense_48, _local_scalar_dense_49, _local_scalar_dense_50, _local_scalar_dense_51, _local_scalar_dense_52, _local_scalar_dense_53, _local_scalar_dense_54, _local_scalar_dense_55], '1033');  index_96 = None
        wait_tensor_916 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_122);  all_to_all_single_122 = None
        full_480 = torch.ops.aten.full.default([sym_size_int_13, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_13 = None
        slice_scatter_22 = torch.ops.aten.slice_scatter.default(full_480, wait_tensor_916, 0, 0, -1);  wait_tensor_916 = None
        index_97 = torch.ops.aten.index.Tensor(slice_scatter_22, [getitem_352]);  slice_scatter_22 = None
        permute_1520 = torch.ops.aten.permute.default(index_97, [1, 0])
        _grouped_mm_210 = torch.ops.aten._grouped_mm.default(permute_1520, mul_182, cumsum_11);  permute_1520 = mul_182 = None
        _grouped_mm_211 = torch.ops.aten._grouped_mm.default(index_97, permute_1522, cumsum_11);  index_97 = permute_1522 = None
        convert_element_type_238 = torch.ops.prims.convert_element_type.default(_grouped_mm_9, torch.float32);  _grouped_mm_9 = None
        neg_7 = torch.ops.aten.neg.default(convert_element_type_238)
        exp_11 = torch.ops.aten.exp.default(neg_7);  neg_7 = None
        add_236 = torch.ops.aten.add.Tensor(exp_11, 1);  exp_11 = None
        div_19 = torch.ops.aten.div.Tensor(convert_element_type_238, add_236)
        convert_element_type_239 = torch.ops.prims.convert_element_type.default(div_19, torch.bfloat16);  div_19 = None
        mul_2045 = torch.ops.aten.mul.Tensor(_grouped_mm_211, convert_element_type_239);  convert_element_type_239 = None
        mul_2046 = torch.ops.aten.mul.Tensor(_grouped_mm_211, _grouped_mm_10);  _grouped_mm_211 = _grouped_mm_10 = None
        permute_1524 = torch.ops.aten.permute.default(mul_2045, [1, 0])
        _grouped_mm_212 = torch.ops.aten._grouped_mm.default(permute_1524, index_7, cumsum_11);  permute_1524 = None
        _grouped_mm_213 = torch.ops.aten._grouped_mm.default(mul_2045, permute_1526, cumsum_11);  mul_2045 = permute_1526 = None
        convert_element_type_3106 = torch.ops.prims.convert_element_type.default(mul_2046, torch.float32);  mul_2046 = None
        reciprocal_45 = torch.ops.aten.reciprocal.default(add_236);  add_236 = None
        mul_2047 = torch.ops.aten.mul.Tensor(reciprocal_45, 1);  reciprocal_45 = None
        mul_2048 = torch.ops.aten.mul.Tensor(convert_element_type_3106, mul_2047);  convert_element_type_3106 = None
        sub_758 = torch.ops.aten.sub.Tensor(1, mul_2047);  mul_2047 = None
        mul_2049 = torch.ops.aten.mul.Tensor(convert_element_type_238, sub_758);  convert_element_type_238 = sub_758 = None
        add_2109 = torch.ops.aten.add.Tensor(mul_2049, 1);  mul_2049 = None
        mul_2050 = torch.ops.aten.mul.Tensor(mul_2048, add_2109);  mul_2048 = add_2109 = None
        convert_element_type_3108 = torch.ops.prims.convert_element_type.default(mul_2050, torch.bfloat16);  mul_2050 = None
        permute_1528 = torch.ops.aten.permute.default(convert_element_type_3108, [1, 0])
        _grouped_mm_214 = torch.ops.aten._grouped_mm.default(permute_1528, index_7, cumsum_11);  permute_1528 = index_7 = None
        _grouped_mm_215 = torch.ops.aten._grouped_mm.default(convert_element_type_3108, permute_1530, cumsum_11);  convert_element_type_3108 = permute_1530 = cumsum_11 = None
        add_2110 = torch.ops.aten.add.Tensor(_grouped_mm_213, _grouped_mm_215);  _grouped_mm_213 = _grouped_mm_215 = None
        convert_element_type_3109 = torch.ops.prims.convert_element_type.default(_grouped_mm_212, torch.float32);  _grouped_mm_212 = None
        div_264 = torch.ops.aten.div.Tensor(convert_element_type_3109, 128);  convert_element_type_3109 = None
        split_1323 = torch.ops.aten.split.Tensor(div_264, 88, 1);  div_264 = None
        getitem_24885 = split_1323[0]
        getitem_24902 = split_1323[1]
        getitem_24919 = split_1323[2]
        getitem_24936 = split_1323[3]
        getitem_24953 = split_1323[4]
        getitem_24970 = split_1323[5]
        getitem_24987 = split_1323[6]
        getitem_25004 = split_1323[7]
        getitem_25021 = split_1323[8]
        getitem_25038 = split_1323[9]
        getitem_25055 = split_1323[10]
        getitem_25072 = split_1323[11]
        getitem_25089 = split_1323[12]
        getitem_25106 = split_1323[13]
        getitem_25123 = split_1323[14]
        getitem_25140 = split_1323[15];  split_1323 = None
        cat_412 = torch.ops.aten.cat.default([getitem_24885, getitem_24902, getitem_24919, getitem_24936, getitem_24953, getitem_24970, getitem_24987, getitem_25004, getitem_25021, getitem_25038, getitem_25055, getitem_25072, getitem_25089, getitem_25106, getitem_25123, getitem_25140]);  getitem_24885 = getitem_24902 = getitem_24919 = getitem_24936 = getitem_24953 = getitem_24970 = getitem_24987 = getitem_25004 = getitem_25021 = getitem_25038 = getitem_25055 = getitem_25072 = getitem_25089 = getitem_25106 = getitem_25123 = getitem_25140 = None
        reduce_scatter_tensor_313 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_412, 'sum', 16, '1025');  cat_412 = None
        wait_tensor_917 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_313);  reduce_scatter_tensor_313 = None
        convert_element_type_3110 = torch.ops.prims.convert_element_type.default(_grouped_mm_210, torch.float32);  _grouped_mm_210 = None
        div_265 = torch.ops.aten.div.Tensor(convert_element_type_3110, 128);  convert_element_type_3110 = None
        split_1340 = torch.ops.aten.split.Tensor(div_265, 128, 1);  div_265 = None
        getitem_25157 = split_1340[0]
        getitem_25174 = split_1340[1]
        getitem_25191 = split_1340[2]
        getitem_25208 = split_1340[3]
        getitem_25225 = split_1340[4]
        getitem_25242 = split_1340[5]
        getitem_25259 = split_1340[6]
        getitem_25276 = split_1340[7]
        getitem_25293 = split_1340[8]
        getitem_25310 = split_1340[9]
        getitem_25327 = split_1340[10]
        getitem_25344 = split_1340[11]
        getitem_25361 = split_1340[12]
        getitem_25378 = split_1340[13]
        getitem_25395 = split_1340[14]
        getitem_25412 = split_1340[15];  split_1340 = None
        cat_413 = torch.ops.aten.cat.default([getitem_25157, getitem_25174, getitem_25191, getitem_25208, getitem_25225, getitem_25242, getitem_25259, getitem_25276, getitem_25293, getitem_25310, getitem_25327, getitem_25344, getitem_25361, getitem_25378, getitem_25395, getitem_25412]);  getitem_25157 = getitem_25174 = getitem_25191 = getitem_25208 = getitem_25225 = getitem_25242 = getitem_25259 = getitem_25276 = getitem_25293 = getitem_25310 = getitem_25327 = getitem_25344 = getitem_25361 = getitem_25378 = getitem_25395 = getitem_25412 = None
        reduce_scatter_tensor_314 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_413, 'sum', 16, '1025');  cat_413 = None
        wait_tensor_918 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_314);  reduce_scatter_tensor_314 = None
        convert_element_type_3111 = torch.ops.prims.convert_element_type.default(_grouped_mm_214, torch.float32);  _grouped_mm_214 = None
        div_266 = torch.ops.aten.div.Tensor(convert_element_type_3111, 128);  convert_element_type_3111 = None
        split_1357 = torch.ops.aten.split.Tensor(div_266, 88, 1);  div_266 = None
        getitem_25429 = split_1357[0]
        getitem_25446 = split_1357[1]
        getitem_25463 = split_1357[2]
        getitem_25480 = split_1357[3]
        getitem_25497 = split_1357[4]
        getitem_25514 = split_1357[5]
        getitem_25531 = split_1357[6]
        getitem_25548 = split_1357[7]
        getitem_25565 = split_1357[8]
        getitem_25582 = split_1357[9]
        getitem_25599 = split_1357[10]
        getitem_25616 = split_1357[11]
        getitem_25633 = split_1357[12]
        getitem_25650 = split_1357[13]
        getitem_25667 = split_1357[14]
        getitem_25684 = split_1357[15];  split_1357 = None
        cat_414 = torch.ops.aten.cat.default([getitem_25429, getitem_25446, getitem_25463, getitem_25480, getitem_25497, getitem_25514, getitem_25531, getitem_25548, getitem_25565, getitem_25582, getitem_25599, getitem_25616, getitem_25633, getitem_25650, getitem_25667, getitem_25684]);  getitem_25429 = getitem_25446 = getitem_25463 = getitem_25480 = getitem_25497 = getitem_25514 = getitem_25531 = getitem_25548 = getitem_25565 = getitem_25582 = getitem_25599 = getitem_25616 = getitem_25633 = getitem_25650 = getitem_25667 = getitem_25684 = None
        reduce_scatter_tensor_315 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_414, 'sum', 16, '1025');  cat_414 = None
        wait_tensor_919 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_315);  reduce_scatter_tensor_315 = None
        index_put_96 = torch.ops.aten.index_put.default(full_480, [getitem_352], add_2110, True);  full_480 = getitem_352 = add_2110 = None
        slice_294 = torch.ops.aten.slice.Tensor(index_put_96, 0, 0, add_2111);  index_put_96 = add_2111 = None
        all_to_all_single_123 = torch.ops._c10d_functional.all_to_all_single.default(slice_294, [_local_scalar_dense_48, _local_scalar_dense_49, _local_scalar_dense_50, _local_scalar_dense_51, _local_scalar_dense_52, _local_scalar_dense_53, _local_scalar_dense_54, _local_scalar_dense_55], [_local_scalar_dense_56, _local_scalar_dense_57, _local_scalar_dense_58, _local_scalar_dense_59, _local_scalar_dense_60, _local_scalar_dense_61, _local_scalar_dense_62, _local_scalar_dense_63], '1033');  slice_294 = _local_scalar_dense_48 = _local_scalar_dense_49 = _local_scalar_dense_50 = _local_scalar_dense_51 = _local_scalar_dense_52 = _local_scalar_dense_53 = _local_scalar_dense_54 = _local_scalar_dense_55 = _local_scalar_dense_56 = _local_scalar_dense_57 = _local_scalar_dense_58 = _local_scalar_dense_59 = _local_scalar_dense_60 = _local_scalar_dense_61 = _local_scalar_dense_62 = _local_scalar_dense_63 = None
        wait_tensor_920 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_123);  all_to_all_single_123 = None
        index_put_97 = torch.ops.aten.index_put.default(full_default_52, [div_17], wait_tensor_920, True);  div_17 = wait_tensor_920 = None
        add_2115 = torch.ops.aten.add.Tensor(add_2107, index_put_97);  add_2107 = index_put_97 = None
        mul_2051 = torch.ops.aten.mul.Tensor(view_2201, 1.0);  view_2201 = None
        scatter_add_22 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_349, mul_2051);  getitem_349 = mul_2051 = None
        convert_element_type_227 = torch.ops.prims.convert_element_type.default(mm_35, torch.float32);  mm_35 = None
        sub_72 = torch.ops.aten.sub.Tensor(convert_element_type_227, amax_3);  convert_element_type_227 = amax_3 = None
        exp_10 = torch.ops.aten.exp.default(sub_72);  sub_72 = None
        div_16 = torch.ops.aten.div.Tensor(exp_10, sum_13);  exp_10 = sum_13 = None
        mul_2052 = torch.ops.aten.mul.Tensor(scatter_add_22, div_16);  scatter_add_22 = None
        sum_283 = torch.ops.aten.sum.dim_IntList(mul_2052, [1], True)
        neg_121 = torch.ops.aten.neg.default(div_16);  div_16 = None
        fma_22 = torch.ops.prims.fma.default(neg_121, sum_283, mul_2052);  neg_121 = sum_283 = mul_2052 = None
        convert_element_type_3112 = torch.ops.prims.convert_element_type.default(fma_22, torch.bfloat16);  fma_22 = None
        permute_1532 = torch.ops.aten.permute.default(convert_element_type_3112, [1, 0])
        mm_576 = torch.ops.aten.mm.default(permute_1532, view_259);  permute_1532 = view_259 = None
        convert_element_type_224 = torch.ops.prims.convert_element_type.default(primals_79, torch.bfloat16);  primals_79 = None
        all_gather_into_tensor_69 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_224, 128, '0');  convert_element_type_224 = None
        wait_tensor_81 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_69);  all_gather_into_tensor_69 = None
        slice_27 = torch.ops.aten.slice.Tensor(wait_tensor_81, 0, 0, 64);  wait_tensor_81 = None
        permute_64 = torch.ops.aten.permute.default(slice_27, [1, 0]);  slice_27 = None
        permute_1534 = torch.ops.aten.permute.default(permute_64, [1, 0]);  permute_64 = None
        mm_577 = torch.ops.aten.mm.default(convert_element_type_3112, permute_1534);  convert_element_type_3112 = permute_1534 = None
        add_2116 = torch.ops.aten.add.Tensor(add_2115, mm_577);  add_2115 = mm_577 = None
        convert_element_type_3117 = torch.ops.prims.convert_element_type.default(mm_576, torch.float32);  mm_576 = None
        split_1373 = torch.ops.aten.split.Tensor(convert_element_type_3117, 1);  convert_element_type_3117 = None
        getitem_25685 = split_1373[0]
        getitem_25686 = split_1373[1]
        getitem_25687 = split_1373[2]
        getitem_25688 = split_1373[3]
        getitem_25689 = split_1373[4]
        getitem_25690 = split_1373[5]
        getitem_25691 = split_1373[6]
        getitem_25692 = split_1373[7]
        getitem_25693 = split_1373[8]
        getitem_25694 = split_1373[9]
        getitem_25695 = split_1373[10]
        getitem_25696 = split_1373[11]
        getitem_25697 = split_1373[12]
        getitem_25698 = split_1373[13]
        getitem_25699 = split_1373[14]
        getitem_25700 = split_1373[15]
        getitem_25701 = split_1373[16]
        getitem_25702 = split_1373[17]
        getitem_25703 = split_1373[18]
        getitem_25704 = split_1373[19]
        getitem_25705 = split_1373[20]
        getitem_25706 = split_1373[21]
        getitem_25707 = split_1373[22]
        getitem_25708 = split_1373[23]
        getitem_25709 = split_1373[24]
        getitem_25710 = split_1373[25]
        getitem_25711 = split_1373[26]
        getitem_25712 = split_1373[27]
        getitem_25713 = split_1373[28]
        getitem_25714 = split_1373[29]
        getitem_25715 = split_1373[30]
        getitem_25716 = split_1373[31]
        getitem_25717 = split_1373[32]
        getitem_25718 = split_1373[33]
        getitem_25719 = split_1373[34]
        getitem_25720 = split_1373[35]
        getitem_25721 = split_1373[36]
        getitem_25722 = split_1373[37]
        getitem_25723 = split_1373[38]
        getitem_25724 = split_1373[39]
        getitem_25725 = split_1373[40]
        getitem_25726 = split_1373[41]
        getitem_25727 = split_1373[42]
        getitem_25728 = split_1373[43]
        getitem_25729 = split_1373[44]
        getitem_25730 = split_1373[45]
        getitem_25731 = split_1373[46]
        getitem_25732 = split_1373[47]
        getitem_25733 = split_1373[48]
        getitem_25734 = split_1373[49]
        getitem_25735 = split_1373[50]
        getitem_25736 = split_1373[51]
        getitem_25737 = split_1373[52]
        getitem_25738 = split_1373[53]
        getitem_25739 = split_1373[54]
        getitem_25740 = split_1373[55]
        getitem_25741 = split_1373[56]
        getitem_25742 = split_1373[57]
        getitem_25743 = split_1373[58]
        getitem_25744 = split_1373[59]
        getitem_25745 = split_1373[60]
        getitem_25746 = split_1373[61]
        getitem_25747 = split_1373[62]
        getitem_25748 = split_1373[63];  split_1373 = None
        cat_415 = torch.ops.aten.cat.default([getitem_25685, getitem_25686, getitem_25687, getitem_25688, getitem_25689, getitem_25690, getitem_25691, getitem_25692, getitem_25693, getitem_25694, getitem_25695, getitem_25696, getitem_25697, getitem_25698, getitem_25699, getitem_25700, getitem_25701, getitem_25702, getitem_25703, getitem_25704, getitem_25705, getitem_25706, getitem_25707, getitem_25708, getitem_25709, getitem_25710, getitem_25711, getitem_25712, getitem_25713, getitem_25714, getitem_25715, getitem_25716, getitem_25717, getitem_25718, getitem_25719, getitem_25720, getitem_25721, getitem_25722, getitem_25723, getitem_25724, getitem_25725, getitem_25726, getitem_25727, getitem_25728, getitem_25729, getitem_25730, getitem_25731, getitem_25732, getitem_25733, getitem_25734, getitem_25735, getitem_25736, getitem_25737, getitem_25738, getitem_25739, getitem_25740, getitem_25741, getitem_25742, getitem_25743, getitem_25744, getitem_25745, getitem_25746, getitem_25747, getitem_25748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_25685 = getitem_25686 = getitem_25687 = getitem_25688 = getitem_25689 = getitem_25690 = getitem_25691 = getitem_25692 = getitem_25693 = getitem_25694 = getitem_25695 = getitem_25696 = getitem_25697 = getitem_25698 = getitem_25699 = getitem_25700 = getitem_25701 = getitem_25702 = getitem_25703 = getitem_25704 = getitem_25705 = getitem_25706 = getitem_25707 = getitem_25708 = getitem_25709 = getitem_25710 = getitem_25711 = getitem_25712 = getitem_25713 = getitem_25714 = getitem_25715 = getitem_25716 = getitem_25717 = getitem_25718 = getitem_25719 = getitem_25720 = getitem_25721 = getitem_25722 = getitem_25723 = getitem_25724 = getitem_25725 = getitem_25726 = getitem_25727 = getitem_25728 = getitem_25729 = getitem_25730 = getitem_25731 = getitem_25732 = getitem_25733 = getitem_25734 = getitem_25735 = getitem_25736 = getitem_25737 = getitem_25738 = getitem_25739 = getitem_25740 = getitem_25741 = getitem_25742 = getitem_25743 = getitem_25744 = getitem_25745 = getitem_25746 = getitem_25747 = getitem_25748 = None
        reduce_scatter_tensor_316 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_415, 'avg', 128, '0');  cat_415 = None
        wait_tensor_921 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_316);  reduce_scatter_tensor_316 = None
        view_2203 = torch.ops.aten.view.default(add_2116, [2, 4096, 2048]);  add_2116 = None
        convert_element_type_3118 = torch.ops.prims.convert_element_type.default(view_2203, torch.float32);  view_2203 = None
        convert_element_type_221 = torch.ops.prims.convert_element_type.default(primals_77, torch.bfloat16);  primals_77 = None
        all_gather_into_tensor_68 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_221, 128, '0');  convert_element_type_221 = None
        wait_tensor_80 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_68);  all_gather_into_tensor_68 = None
        convert_element_type_3120 = torch.ops.prims.convert_element_type.default(wait_tensor_80, torch.float32);  wait_tensor_80 = None
        mul_2053 = torch.ops.aten.mul.Tensor(convert_element_type_3118, convert_element_type_3120);  convert_element_type_3120 = None
        convert_element_type_222 = torch.ops.prims.convert_element_type.default(add_212, torch.float32);  add_212 = None
        mul_162 = torch.ops.aten.mul.Tensor(convert_element_type_222, rsqrt_14);  convert_element_type_222 = None
        mul_2055 = torch.ops.aten.mul.Tensor(mul_162, mul_2053)
        sum_284 = torch.ops.aten.sum.dim_IntList(mul_2055, [2], True);  mul_2055 = None
        div_267 = torch.ops.aten.div.Tensor(mul_162, 2048)
        mul_2056 = torch.ops.aten.mul.Tensor(div_267, sum_284);  div_267 = sum_284 = None
        sub_760 = torch.ops.aten.sub.Tensor(mul_2053, mul_2056);  mul_2053 = mul_2056 = None
        mul_2057 = torch.ops.aten.mul.Tensor(sub_760, rsqrt_14);  sub_760 = rsqrt_14 = None
        mul_2058 = torch.ops.aten.mul.Tensor(convert_element_type_3118, mul_162);  convert_element_type_3118 = mul_162 = None
        sum_285 = torch.ops.aten.sum.dim_IntList(mul_2058, [0, 1]);  mul_2058 = None
        convert_element_type_3121 = torch.ops.prims.convert_element_type.default(mul_2057, torch.bfloat16);  mul_2057 = None
        add_2117 = torch.ops.aten.add.Tensor(add_2104, convert_element_type_3121);  add_2104 = convert_element_type_3121 = None
        convert_element_type_default_15 = torch.ops.prims.convert_element_type.default(sum_285, torch.float32);  sum_285 = None
        reduce_scatter_tensor_317 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_15, 'avg', 128, '0');  convert_element_type_default_15 = None
        wait_tensor_922 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_317);  reduce_scatter_tensor_317 = None
        view_2204 = torch.ops.aten.view.default(add_2117, [8192, 2048])
        permute_1536 = torch.ops.aten.permute.default(view_2204, [1, 0])
        permute_62 = torch.ops.aten.permute.default(getitem_345, [0, 2, 1, 3])
        view_254 = torch.ops.aten.view.default(permute_62, [2, 4096, -1]);  permute_62 = None
        view_256 = torch.ops.aten.view.default(view_254, [8192, 2048]);  view_254 = None
        mm_578 = torch.ops.aten.mm.default(permute_1536, view_256);  permute_1536 = view_256 = None
        convert_element_type_218 = torch.ops.prims.convert_element_type.default(primals_76, torch.bfloat16);  primals_76 = None
        all_gather_into_tensor_67 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_218, 128, '0');  convert_element_type_218 = None
        wait_tensor_79 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_67);  all_gather_into_tensor_67 = None
        permute_63 = torch.ops.aten.permute.default(wait_tensor_79, [1, 0]);  wait_tensor_79 = None
        permute_1538 = torch.ops.aten.permute.default(permute_63, [1, 0]);  permute_63 = None
        mm_579 = torch.ops.aten.mm.default(view_2204, permute_1538);  view_2204 = permute_1538 = None
        view_2205 = torch.ops.aten.view.default(mm_579, [2, 4096, 2048]);  mm_579 = None
        convert_element_type_3128 = torch.ops.prims.convert_element_type.default(mm_578, torch.float32);  mm_578 = None
        reduce_scatter_tensor_318 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3128, 'avg', 128, '0');  convert_element_type_3128 = None
        wait_tensor_923 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_318);  reduce_scatter_tensor_318 = None
        view_2206 = torch.ops.aten.view.default(view_2205, [2, 4096, 16, 128]);  view_2205 = None
        permute_1540 = torch.ops.aten.permute.default(view_2206, [0, 2, 1, 3]);  view_2206 = None
        fw_graph22 = self.fw_graph22
        joint_graph22 = self.joint_graph22
        mask_graph22 = self.mask_graph22
        flex_attention_backward_22 = torch.ops.higher_order.flex_attention_backward(permute_59, permute_60, permute_61, getitem_345, getitem_346, permute_1540, None, fw_graph22, joint_graph22, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph22), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_59 = permute_60 = permute_61 = getitem_345 = getitem_346 = permute_1540 = fw_graph22 = joint_graph22 = mask_graph22 = None
        getitem_25749 = flex_attention_backward_22[0]
        getitem_25750 = flex_attention_backward_22[1]
        getitem_25751 = flex_attention_backward_22[2];  flex_attention_backward_22 = None
        permute_1541 = torch.ops.aten.permute.default(getitem_25751, [0, 2, 1, 3]);  getitem_25751 = None
        permute_1542 = torch.ops.aten.permute.default(getitem_25750, [0, 2, 1, 3]);  getitem_25750 = None
        permute_1543 = torch.ops.aten.permute.default(getitem_25749, [0, 2, 1, 3]);  getitem_25749 = None
        slice_296 = torch.ops.aten.slice.Tensor(permute_1542, 3, 0, 128)
        slice_297 = torch.ops.aten.slice.Tensor(permute_1542, 3, 128, 192);  permute_1542 = None
        sum_286 = torch.ops.aten.sum.dim_IntList(slice_297, [2], True);  slice_297 = None
        cat_416 = torch.ops.aten.cat.default([slice_296, permute_1541], 3);  slice_296 = permute_1541 = None
        view_2207 = torch.ops.aten.view.default(cat_416, [2, 4096, 4096]);  cat_416 = None
        view_2208 = torch.ops.aten.view.default(view_2207, [8192, 4096]);  view_2207 = None
        permute_1544 = torch.ops.aten.permute.default(view_2208, [1, 0])
        mm_580 = torch.ops.aten.mm.default(permute_1544, view_251);  permute_1544 = view_251 = None
        convert_element_type_215 = torch.ops.prims.convert_element_type.default(primals_75, torch.bfloat16);  primals_75 = None
        all_gather_into_tensor_66 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_215, 128, '0');  convert_element_type_215 = None
        wait_tensor_78 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_66);  all_gather_into_tensor_66 = None
        permute_58 = torch.ops.aten.permute.default(wait_tensor_78, [1, 0]);  wait_tensor_78 = None
        permute_1546 = torch.ops.aten.permute.default(permute_58, [1, 0]);  permute_58 = None
        mm_581 = torch.ops.aten.mm.default(view_2208, permute_1546);  view_2208 = permute_1546 = None
        view_2209 = torch.ops.aten.view.default(mm_581, [2, 4096, 512]);  mm_581 = None
        convert_element_type_3133 = torch.ops.prims.convert_element_type.default(mm_580, torch.float32);  mm_580 = None
        reduce_scatter_tensor_319 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3133, 'avg', 128, '0');  convert_element_type_3133 = None
        wait_tensor_924 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_319);  reduce_scatter_tensor_319 = None
        convert_element_type_3134 = torch.ops.prims.convert_element_type.default(view_2209, torch.float32);  view_2209 = None
        convert_element_type_212 = torch.ops.prims.convert_element_type.default(primals_74, torch.bfloat16);  primals_74 = None
        all_gather_into_tensor_65 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_212, 128, '0');  convert_element_type_212 = None
        wait_tensor_77 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_65);  all_gather_into_tensor_65 = None
        convert_element_type_3136 = torch.ops.prims.convert_element_type.default(wait_tensor_77, torch.float32);  wait_tensor_77 = None
        mul_2059 = torch.ops.aten.mul.Tensor(convert_element_type_3134, convert_element_type_3136);  convert_element_type_3136 = None
        convert_element_type_213 = torch.ops.prims.convert_element_type.default(getitem_341, torch.float32);  getitem_341 = None
        mul_160 = torch.ops.aten.mul.Tensor(convert_element_type_213, rsqrt_13);  convert_element_type_213 = None
        mul_2061 = torch.ops.aten.mul.Tensor(mul_160, mul_2059)
        sum_287 = torch.ops.aten.sum.dim_IntList(mul_2061, [2], True);  mul_2061 = None
        div_268 = torch.ops.aten.div.Tensor(mul_160, 512)
        mul_2062 = torch.ops.aten.mul.Tensor(div_268, sum_287);  div_268 = sum_287 = None
        sub_761 = torch.ops.aten.sub.Tensor(mul_2059, mul_2062);  mul_2059 = mul_2062 = None
        mul_2063 = torch.ops.aten.mul.Tensor(sub_761, rsqrt_13);  sub_761 = rsqrt_13 = None
        mul_2064 = torch.ops.aten.mul.Tensor(convert_element_type_3134, mul_160);  convert_element_type_3134 = mul_160 = None
        sum_288 = torch.ops.aten.sum.dim_IntList(mul_2064, [0, 1]);  mul_2064 = None
        convert_element_type_3137 = torch.ops.prims.convert_element_type.default(mul_2063, torch.bfloat16);  mul_2063 = None
        convert_element_type_default_14 = torch.ops.prims.convert_element_type.default(sum_288, torch.float32);  sum_288 = None
        reduce_scatter_tensor_320 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_14, 'avg', 128, '0');  convert_element_type_default_14 = None
        wait_tensor_925 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_320);  reduce_scatter_tensor_320 = None
        convert_element_type_3140 = torch.ops.prims.convert_element_type.default(sum_286, torch.float32);  sum_286 = None
        view_2210 = torch.ops.aten.view.default(convert_element_type_3140, [2, 4096, 1, 32, 2]);  convert_element_type_3140 = None
        view_as_complex_98 = torch.ops.aten.view_as_complex.default(view_2210);  view_2210 = None
        mul_2065 = torch.ops.aten.mul.Tensor(view_as_complex_98, clone_9);  view_as_complex_98 = None
        view_as_real_98 = torch.ops.aten.view_as_real.default(mul_2065);  mul_2065 = None
        view_2211 = torch.ops.aten.view.default(view_as_real_98, [2, 4096, 1, 64]);  view_as_real_98 = None
        convert_element_type_3141 = torch.ops.prims.convert_element_type.default(view_2211, torch.bfloat16);  view_2211 = None
        squeeze_48 = torch.ops.aten.squeeze.dim(convert_element_type_3141, 2);  convert_element_type_3141 = None
        cat_417 = torch.ops.aten.cat.default([convert_element_type_3137, squeeze_48], 2);  convert_element_type_3137 = squeeze_48 = None
        view_2212 = torch.ops.aten.view.default(cat_417, [8192, 576]);  cat_417 = None
        permute_1548 = torch.ops.aten.permute.default(view_2212, [1, 0])
        mm_582 = torch.ops.aten.mm.default(permute_1548, view_237);  permute_1548 = None
        convert_element_type_207 = torch.ops.prims.convert_element_type.default(primals_73, torch.bfloat16);  primals_73 = None
        all_gather_into_tensor_64 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_207, 128, '0');  convert_element_type_207 = None
        wait_tensor_76 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_64);  all_gather_into_tensor_64 = None
        slice_25 = torch.ops.aten.slice.Tensor(wait_tensor_76, 0, 0, 576);  wait_tensor_76 = None
        permute_57 = torch.ops.aten.permute.default(slice_25, [1, 0]);  slice_25 = None
        permute_1550 = torch.ops.aten.permute.default(permute_57, [1, 0]);  permute_57 = None
        mm_583 = torch.ops.aten.mm.default(view_2212, permute_1550);  view_2212 = permute_1550 = None
        view_2213 = torch.ops.aten.view.default(mm_583, [2, 4096, 2048]);  mm_583 = None
        convert_element_type_3146 = torch.ops.prims.convert_element_type.default(mm_582, torch.float32);  mm_582 = None
        split_1374 = torch.ops.aten.split.Tensor(convert_element_type_3146, 5);  convert_element_type_3146 = None
        getitem_25753 = split_1374[0]
        getitem_25754 = split_1374[1]
        getitem_25755 = split_1374[2]
        getitem_25756 = split_1374[3]
        getitem_25757 = split_1374[4]
        getitem_25758 = split_1374[5]
        getitem_25759 = split_1374[6]
        getitem_25760 = split_1374[7]
        getitem_25761 = split_1374[8]
        getitem_25762 = split_1374[9]
        getitem_25763 = split_1374[10]
        getitem_25764 = split_1374[11]
        getitem_25765 = split_1374[12]
        getitem_25766 = split_1374[13]
        getitem_25767 = split_1374[14]
        getitem_25768 = split_1374[15]
        getitem_25769 = split_1374[16]
        getitem_25770 = split_1374[17]
        getitem_25771 = split_1374[18]
        getitem_25772 = split_1374[19]
        getitem_25773 = split_1374[20]
        getitem_25774 = split_1374[21]
        getitem_25775 = split_1374[22]
        getitem_25776 = split_1374[23]
        getitem_25777 = split_1374[24]
        getitem_25778 = split_1374[25]
        getitem_25779 = split_1374[26]
        getitem_25780 = split_1374[27]
        getitem_25781 = split_1374[28]
        getitem_25782 = split_1374[29]
        getitem_25783 = split_1374[30]
        getitem_25784 = split_1374[31]
        getitem_25785 = split_1374[32]
        getitem_25786 = split_1374[33]
        getitem_25787 = split_1374[34]
        getitem_25788 = split_1374[35]
        getitem_25789 = split_1374[36]
        getitem_25790 = split_1374[37]
        getitem_25791 = split_1374[38]
        getitem_25792 = split_1374[39]
        getitem_25793 = split_1374[40]
        getitem_25794 = split_1374[41]
        getitem_25795 = split_1374[42]
        getitem_25796 = split_1374[43]
        getitem_25797 = split_1374[44]
        getitem_25798 = split_1374[45]
        getitem_25799 = split_1374[46]
        getitem_25800 = split_1374[47]
        getitem_25801 = split_1374[48]
        getitem_25802 = split_1374[49]
        getitem_25803 = split_1374[50]
        getitem_25804 = split_1374[51]
        getitem_25805 = split_1374[52]
        getitem_25806 = split_1374[53]
        getitem_25807 = split_1374[54]
        getitem_25808 = split_1374[55]
        getitem_25809 = split_1374[56]
        getitem_25810 = split_1374[57]
        getitem_25811 = split_1374[58]
        getitem_25812 = split_1374[59]
        getitem_25813 = split_1374[60]
        getitem_25814 = split_1374[61]
        getitem_25815 = split_1374[62]
        getitem_25816 = split_1374[63]
        getitem_25817 = split_1374[64]
        getitem_25818 = split_1374[65]
        getitem_25819 = split_1374[66]
        getitem_25820 = split_1374[67]
        getitem_25821 = split_1374[68]
        getitem_25822 = split_1374[69]
        getitem_25823 = split_1374[70]
        getitem_25824 = split_1374[71]
        getitem_25825 = split_1374[72]
        getitem_25826 = split_1374[73]
        getitem_25827 = split_1374[74]
        getitem_25828 = split_1374[75]
        getitem_25829 = split_1374[76]
        getitem_25830 = split_1374[77]
        getitem_25831 = split_1374[78]
        getitem_25832 = split_1374[79]
        getitem_25833 = split_1374[80]
        getitem_25834 = split_1374[81]
        getitem_25835 = split_1374[82]
        getitem_25836 = split_1374[83]
        getitem_25837 = split_1374[84]
        getitem_25838 = split_1374[85]
        getitem_25839 = split_1374[86]
        getitem_25840 = split_1374[87]
        getitem_25841 = split_1374[88]
        getitem_25842 = split_1374[89]
        getitem_25843 = split_1374[90]
        getitem_25844 = split_1374[91]
        getitem_25845 = split_1374[92]
        getitem_25846 = split_1374[93]
        getitem_25847 = split_1374[94]
        getitem_25848 = split_1374[95]
        getitem_25849 = split_1374[96]
        getitem_25850 = split_1374[97]
        getitem_25851 = split_1374[98]
        getitem_25852 = split_1374[99]
        getitem_25853 = split_1374[100]
        getitem_25854 = split_1374[101]
        getitem_25855 = split_1374[102]
        getitem_25856 = split_1374[103]
        getitem_25857 = split_1374[104]
        getitem_25858 = split_1374[105]
        getitem_25859 = split_1374[106]
        getitem_25860 = split_1374[107]
        getitem_25861 = split_1374[108]
        getitem_25862 = split_1374[109]
        getitem_25863 = split_1374[110]
        getitem_25864 = split_1374[111]
        getitem_25865 = split_1374[112]
        getitem_25866 = split_1374[113]
        getitem_25867 = split_1374[114]
        getitem_25868 = split_1374[115];  split_1374 = None
        constant_pad_nd_1758 = torch.ops.aten.constant_pad_nd.default(getitem_25868, [0, 0, 0, 4], 0.0);  getitem_25868 = None
        cat_418 = torch.ops.aten.cat.default([getitem_25753, getitem_25754, getitem_25755, getitem_25756, getitem_25757, getitem_25758, getitem_25759, getitem_25760, getitem_25761, getitem_25762, getitem_25763, getitem_25764, getitem_25765, getitem_25766, getitem_25767, getitem_25768, getitem_25769, getitem_25770, getitem_25771, getitem_25772, getitem_25773, getitem_25774, getitem_25775, getitem_25776, getitem_25777, getitem_25778, getitem_25779, getitem_25780, getitem_25781, getitem_25782, getitem_25783, getitem_25784, getitem_25785, getitem_25786, getitem_25787, getitem_25788, getitem_25789, getitem_25790, getitem_25791, getitem_25792, getitem_25793, getitem_25794, getitem_25795, getitem_25796, getitem_25797, getitem_25798, getitem_25799, getitem_25800, getitem_25801, getitem_25802, getitem_25803, getitem_25804, getitem_25805, getitem_25806, getitem_25807, getitem_25808, getitem_25809, getitem_25810, getitem_25811, getitem_25812, getitem_25813, getitem_25814, getitem_25815, getitem_25816, getitem_25817, getitem_25818, getitem_25819, getitem_25820, getitem_25821, getitem_25822, getitem_25823, getitem_25824, getitem_25825, getitem_25826, getitem_25827, getitem_25828, getitem_25829, getitem_25830, getitem_25831, getitem_25832, getitem_25833, getitem_25834, getitem_25835, getitem_25836, getitem_25837, getitem_25838, getitem_25839, getitem_25840, getitem_25841, getitem_25842, getitem_25843, getitem_25844, getitem_25845, getitem_25846, getitem_25847, getitem_25848, getitem_25849, getitem_25850, getitem_25851, getitem_25852, getitem_25853, getitem_25854, getitem_25855, getitem_25856, getitem_25857, getitem_25858, getitem_25859, getitem_25860, getitem_25861, getitem_25862, getitem_25863, getitem_25864, getitem_25865, getitem_25866, getitem_25867, constant_pad_nd_1758, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_25753 = getitem_25754 = getitem_25755 = getitem_25756 = getitem_25757 = getitem_25758 = getitem_25759 = getitem_25760 = getitem_25761 = getitem_25762 = getitem_25763 = getitem_25764 = getitem_25765 = getitem_25766 = getitem_25767 = getitem_25768 = getitem_25769 = getitem_25770 = getitem_25771 = getitem_25772 = getitem_25773 = getitem_25774 = getitem_25775 = getitem_25776 = getitem_25777 = getitem_25778 = getitem_25779 = getitem_25780 = getitem_25781 = getitem_25782 = getitem_25783 = getitem_25784 = getitem_25785 = getitem_25786 = getitem_25787 = getitem_25788 = getitem_25789 = getitem_25790 = getitem_25791 = getitem_25792 = getitem_25793 = getitem_25794 = getitem_25795 = getitem_25796 = getitem_25797 = getitem_25798 = getitem_25799 = getitem_25800 = getitem_25801 = getitem_25802 = getitem_25803 = getitem_25804 = getitem_25805 = getitem_25806 = getitem_25807 = getitem_25808 = getitem_25809 = getitem_25810 = getitem_25811 = getitem_25812 = getitem_25813 = getitem_25814 = getitem_25815 = getitem_25816 = getitem_25817 = getitem_25818 = getitem_25819 = getitem_25820 = getitem_25821 = getitem_25822 = getitem_25823 = getitem_25824 = getitem_25825 = getitem_25826 = getitem_25827 = getitem_25828 = getitem_25829 = getitem_25830 = getitem_25831 = getitem_25832 = getitem_25833 = getitem_25834 = getitem_25835 = getitem_25836 = getitem_25837 = getitem_25838 = getitem_25839 = getitem_25840 = getitem_25841 = getitem_25842 = getitem_25843 = getitem_25844 = getitem_25845 = getitem_25846 = getitem_25847 = getitem_25848 = getitem_25849 = getitem_25850 = getitem_25851 = getitem_25852 = getitem_25853 = getitem_25854 = getitem_25855 = getitem_25856 = getitem_25857 = getitem_25858 = getitem_25859 = getitem_25860 = getitem_25861 = getitem_25862 = getitem_25863 = getitem_25864 = getitem_25865 = getitem_25866 = getitem_25867 = constant_pad_nd_1758 = None
        reduce_scatter_tensor_321 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_418, 'avg', 128, '0');  cat_418 = None
        wait_tensor_926 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_321);  reduce_scatter_tensor_321 = None
        slice_298 = torch.ops.aten.slice.Tensor(permute_1543, 3, 0, 128)
        slice_299 = torch.ops.aten.slice.Tensor(permute_1543, 3, 128, 192);  permute_1543 = None
        convert_element_type_3147 = torch.ops.prims.convert_element_type.default(slice_299, torch.float32);  slice_299 = None
        view_2214 = torch.ops.aten.view.default(convert_element_type_3147, [2, 4096, 16, 32, 2]);  convert_element_type_3147 = None
        view_as_complex_99 = torch.ops.aten.view_as_complex.default(view_2214);  view_2214 = None
        mul_2066 = torch.ops.aten.mul.Tensor(view_as_complex_99, clone_9);  view_as_complex_99 = None
        view_as_real_99 = torch.ops.aten.view_as_real.default(mul_2066);  mul_2066 = None
        view_2215 = torch.ops.aten.view.default(view_as_real_99, [2, 4096, 16, 64]);  view_as_real_99 = None
        convert_element_type_3148 = torch.ops.prims.convert_element_type.default(view_2215, torch.bfloat16);  view_2215 = None
        cat_419 = torch.ops.aten.cat.default([slice_298, convert_element_type_3148], 3);  slice_298 = convert_element_type_3148 = None
        view_2216 = torch.ops.aten.view.default(cat_419, [2, 4096, 3072]);  cat_419 = None
        view_2217 = torch.ops.aten.view.default(view_2216, [8192, 3072]);  view_2216 = None
        permute_1552 = torch.ops.aten.permute.default(view_2217, [1, 0])
        mm_584 = torch.ops.aten.mm.default(permute_1552, view_237);  permute_1552 = view_237 = None
        convert_element_type_202 = torch.ops.prims.convert_element_type.default(primals_72, torch.bfloat16);  primals_72 = None
        all_gather_into_tensor_63 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_202, 128, '0');  convert_element_type_202 = None
        wait_tensor_75 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_63);  all_gather_into_tensor_63 = None
        permute_56 = torch.ops.aten.permute.default(wait_tensor_75, [1, 0]);  wait_tensor_75 = None
        permute_1554 = torch.ops.aten.permute.default(permute_56, [1, 0]);  permute_56 = None
        mm_585 = torch.ops.aten.mm.default(view_2217, permute_1554);  view_2217 = permute_1554 = None
        view_2218 = torch.ops.aten.view.default(mm_585, [2, 4096, 2048]);  mm_585 = None
        add_2118 = torch.ops.aten.add.Tensor(view_2213, view_2218);  view_2213 = view_2218 = None
        convert_element_type_3153 = torch.ops.prims.convert_element_type.default(mm_584, torch.float32);  mm_584 = None
        reduce_scatter_tensor_322 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3153, 'avg', 128, '0');  convert_element_type_3153 = None
        wait_tensor_927 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_322);  reduce_scatter_tensor_322 = None
        convert_element_type_3154 = torch.ops.prims.convert_element_type.default(add_2118, torch.float32);  add_2118 = None
        convert_element_type_199 = torch.ops.prims.convert_element_type.default(primals_71, torch.bfloat16);  primals_71 = None
        all_gather_into_tensor_62 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_199, 128, '0');  convert_element_type_199 = None
        wait_tensor_74 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_62);  all_gather_into_tensor_62 = None
        convert_element_type_3156 = torch.ops.prims.convert_element_type.default(wait_tensor_74, torch.float32);  wait_tensor_74 = None
        mul_2067 = torch.ops.aten.mul.Tensor(convert_element_type_3154, convert_element_type_3156);  convert_element_type_3156 = None
        convert_element_type_200 = torch.ops.prims.convert_element_type.default(add_209, torch.float32);  add_209 = None
        mul_156 = torch.ops.aten.mul.Tensor(convert_element_type_200, rsqrt_12);  convert_element_type_200 = None
        mul_2069 = torch.ops.aten.mul.Tensor(mul_156, mul_2067)
        sum_289 = torch.ops.aten.sum.dim_IntList(mul_2069, [2], True);  mul_2069 = None
        div_269 = torch.ops.aten.div.Tensor(mul_156, 2048)
        mul_2070 = torch.ops.aten.mul.Tensor(div_269, sum_289);  div_269 = sum_289 = None
        sub_762 = torch.ops.aten.sub.Tensor(mul_2067, mul_2070);  mul_2067 = mul_2070 = None
        mul_2071 = torch.ops.aten.mul.Tensor(sub_762, rsqrt_12);  sub_762 = rsqrt_12 = None
        mul_2072 = torch.ops.aten.mul.Tensor(convert_element_type_3154, mul_156);  convert_element_type_3154 = mul_156 = None
        sum_290 = torch.ops.aten.sum.dim_IntList(mul_2072, [0, 1]);  mul_2072 = None
        convert_element_type_3157 = torch.ops.prims.convert_element_type.default(mul_2071, torch.bfloat16);  mul_2071 = None
        add_2119 = torch.ops.aten.add.Tensor(add_2117, convert_element_type_3157);  add_2117 = convert_element_type_3157 = None
        convert_element_type_default_13 = torch.ops.prims.convert_element_type.default(sum_290, torch.float32);  sum_290 = None
        reduce_scatter_tensor_323 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_13, 'avg', 128, '0');  convert_element_type_default_13 = None
        wait_tensor_928 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_323);  reduce_scatter_tensor_323 = None
        view_2219 = torch.ops.aten.view.default(add_2119, [8192, 2048])
        unsqueeze_76 = torch.ops.aten.unsqueeze.default(view_2219, 1)
        convert_element_type_3160 = torch.ops.prims.convert_element_type.default(unsqueeze_76, torch.float32);  unsqueeze_76 = None
        bmm_72 = torch.ops.aten.bmm.default(permute_1556, convert_element_type_3160);  permute_1556 = None
        bmm_73 = torch.ops.aten.bmm.default(convert_element_type_3160, permute_1557);  convert_element_type_3160 = permute_1557 = None
        convert_element_type_3161 = torch.ops.prims.convert_element_type.default(bmm_72, torch.bfloat16);  bmm_72 = None
        view_2220 = torch.ops.aten.view.default(bmm_73, [8192, 6]);  bmm_73 = None
        view_2221 = torch.ops.aten.view.default(convert_element_type_3161, [49152, 2048]);  convert_element_type_3161 = None
        index_98 = torch.ops.aten.index.Tensor(view_2221, [getitem_241]);  view_2221 = getitem_241 = None
        permute_1558 = torch.ops.aten.permute.default(view_2219, [1, 0])
        mm_586 = torch.ops.aten.mm.default(permute_1558, mul_153);  permute_1558 = mul_153 = None
        convert_element_type_194 = torch.ops.prims.convert_element_type.default(primals_70, torch.bfloat16);  primals_70 = None
        all_gather_into_tensor_61 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_194, 128, '0');  convert_element_type_194 = None
        wait_tensor_73 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_61);  all_gather_into_tensor_61 = None
        permute_55 = torch.ops.aten.permute.default(wait_tensor_73, [1, 0]);  wait_tensor_73 = None
        permute_1560 = torch.ops.aten.permute.default(permute_55, [1, 0]);  permute_55 = None
        mm_587 = torch.ops.aten.mm.default(view_2219, permute_1560);  view_2219 = permute_1560 = None
        convert_element_type_3166 = torch.ops.prims.convert_element_type.default(mm_586, torch.float32);  mm_586 = None
        reduce_scatter_tensor_324 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3166, 'avg', 128, '0');  convert_element_type_3166 = None
        wait_tensor_929 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_324);  reduce_scatter_tensor_324 = None
        convert_element_type_189 = torch.ops.prims.convert_element_type.default(mm_28, torch.float32);  mm_28 = None
        neg_6 = torch.ops.aten.neg.default(convert_element_type_189)
        exp_9 = torch.ops.aten.exp.default(neg_6);  neg_6 = None
        add_204 = torch.ops.aten.add.Tensor(exp_9, 1);  exp_9 = None
        div_15 = torch.ops.aten.div.Tensor(convert_element_type_189, add_204)
        convert_element_type_190 = torch.ops.prims.convert_element_type.default(div_15, torch.bfloat16);  div_15 = None
        mul_2073 = torch.ops.aten.mul.Tensor(mm_587, convert_element_type_190);  convert_element_type_190 = None
        mul_2074 = torch.ops.aten.mul.Tensor(mm_587, mm_29);  mm_587 = mm_29 = None
        permute_1562 = torch.ops.aten.permute.default(mul_2073, [1, 0])
        mm_588 = torch.ops.aten.mm.default(permute_1562, view_192);  permute_1562 = None
        convert_element_type_191 = torch.ops.prims.convert_element_type.default(primals_69, torch.bfloat16);  primals_69 = None
        all_gather_into_tensor_60 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_191, 128, '0');  convert_element_type_191 = None
        wait_tensor_72 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_60);  all_gather_into_tensor_60 = None
        permute_54 = torch.ops.aten.permute.default(wait_tensor_72, [1, 0]);  wait_tensor_72 = None
        permute_1564 = torch.ops.aten.permute.default(permute_54, [1, 0]);  permute_54 = None
        mm_589 = torch.ops.aten.mm.default(mul_2073, permute_1564);  mul_2073 = permute_1564 = None
        convert_element_type_3171 = torch.ops.prims.convert_element_type.default(mm_588, torch.float32);  mm_588 = None
        reduce_scatter_tensor_325 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3171, 'avg', 128, '0');  convert_element_type_3171 = None
        wait_tensor_930 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_325);  reduce_scatter_tensor_325 = None
        convert_element_type_3172 = torch.ops.prims.convert_element_type.default(mul_2074, torch.float32);  mul_2074 = None
        reciprocal_46 = torch.ops.aten.reciprocal.default(add_204);  add_204 = None
        mul_2075 = torch.ops.aten.mul.Tensor(reciprocal_46, 1);  reciprocal_46 = None
        mul_2076 = torch.ops.aten.mul.Tensor(convert_element_type_3172, mul_2075);  convert_element_type_3172 = None
        sub_763 = torch.ops.aten.sub.Tensor(1, mul_2075);  mul_2075 = None
        mul_2077 = torch.ops.aten.mul.Tensor(convert_element_type_189, sub_763);  convert_element_type_189 = sub_763 = None
        add_2121 = torch.ops.aten.add.Tensor(mul_2077, 1);  mul_2077 = None
        mul_2078 = torch.ops.aten.mul.Tensor(mul_2076, add_2121);  mul_2076 = add_2121 = None
        convert_element_type_3174 = torch.ops.prims.convert_element_type.default(mul_2078, torch.bfloat16);  mul_2078 = None
        permute_1566 = torch.ops.aten.permute.default(convert_element_type_3174, [1, 0])
        mm_590 = torch.ops.aten.mm.default(permute_1566, view_192);  permute_1566 = None
        convert_element_type_186 = torch.ops.prims.convert_element_type.default(primals_68, torch.bfloat16);  primals_68 = None
        all_gather_into_tensor_59 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_186, 128, '0');  convert_element_type_186 = None
        wait_tensor_71 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_59);  all_gather_into_tensor_59 = None
        permute_53 = torch.ops.aten.permute.default(wait_tensor_71, [1, 0]);  wait_tensor_71 = None
        permute_1568 = torch.ops.aten.permute.default(permute_53, [1, 0]);  permute_53 = None
        mm_591 = torch.ops.aten.mm.default(convert_element_type_3174, permute_1568);  convert_element_type_3174 = permute_1568 = None
        add_2122 = torch.ops.aten.add.Tensor(mm_589, mm_591);  mm_589 = mm_591 = None
        convert_element_type_3179 = torch.ops.prims.convert_element_type.default(mm_590, torch.float32);  mm_590 = None
        reduce_scatter_tensor_326 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3179, 'avg', 128, '0');  convert_element_type_3179 = None
        wait_tensor_931 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_326);  reduce_scatter_tensor_326 = None
        all_to_all_single_124 = torch.ops._c10d_functional.all_to_all_single.default(index_98, [_local_scalar_dense_40, _local_scalar_dense_41, _local_scalar_dense_42, _local_scalar_dense_43, _local_scalar_dense_44, _local_scalar_dense_45, _local_scalar_dense_46, _local_scalar_dense_47], [_local_scalar_dense_32, _local_scalar_dense_33, _local_scalar_dense_34, _local_scalar_dense_35, _local_scalar_dense_36, _local_scalar_dense_37, _local_scalar_dense_38, _local_scalar_dense_39], '1033');  index_98 = None
        wait_tensor_932 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_124);  all_to_all_single_124 = None
        full_486 = torch.ops.aten.full.default([sym_size_int_9, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_9 = None
        slice_scatter_23 = torch.ops.aten.slice_scatter.default(full_486, wait_tensor_932, 0, 0, -1);  wait_tensor_932 = None
        index_99 = torch.ops.aten.index.Tensor(slice_scatter_23, [getitem_242]);  slice_scatter_23 = None
        permute_1570 = torch.ops.aten.permute.default(index_99, [1, 0])
        _grouped_mm_216 = torch.ops.aten._grouped_mm.default(permute_1570, mul_133, cumsum_8);  permute_1570 = mul_133 = None
        _grouped_mm_217 = torch.ops.aten._grouped_mm.default(index_99, permute_1572, cumsum_8);  index_99 = permute_1572 = None
        convert_element_type_184 = torch.ops.prims.convert_element_type.default(_grouped_mm_6, torch.float32);  _grouped_mm_6 = None
        neg_5 = torch.ops.aten.neg.default(convert_element_type_184)
        exp_8 = torch.ops.aten.exp.default(neg_5);  neg_5 = None
        add_168 = torch.ops.aten.add.Tensor(exp_8, 1);  exp_8 = None
        div_14 = torch.ops.aten.div.Tensor(convert_element_type_184, add_168)
        convert_element_type_185 = torch.ops.prims.convert_element_type.default(div_14, torch.bfloat16);  div_14 = None
        mul_2079 = torch.ops.aten.mul.Tensor(_grouped_mm_217, convert_element_type_185);  convert_element_type_185 = None
        mul_2080 = torch.ops.aten.mul.Tensor(_grouped_mm_217, _grouped_mm_7);  _grouped_mm_217 = _grouped_mm_7 = None
        permute_1574 = torch.ops.aten.permute.default(mul_2079, [1, 0])
        _grouped_mm_218 = torch.ops.aten._grouped_mm.default(permute_1574, index_5, cumsum_8);  permute_1574 = None
        _grouped_mm_219 = torch.ops.aten._grouped_mm.default(mul_2079, permute_1576, cumsum_8);  mul_2079 = permute_1576 = None
        convert_element_type_3180 = torch.ops.prims.convert_element_type.default(mul_2080, torch.float32);  mul_2080 = None
        reciprocal_47 = torch.ops.aten.reciprocal.default(add_168);  add_168 = None
        mul_2081 = torch.ops.aten.mul.Tensor(reciprocal_47, 1);  reciprocal_47 = None
        mul_2082 = torch.ops.aten.mul.Tensor(convert_element_type_3180, mul_2081);  convert_element_type_3180 = None
        sub_764 = torch.ops.aten.sub.Tensor(1, mul_2081);  mul_2081 = None
        mul_2083 = torch.ops.aten.mul.Tensor(convert_element_type_184, sub_764);  convert_element_type_184 = sub_764 = None
        add_2124 = torch.ops.aten.add.Tensor(mul_2083, 1);  mul_2083 = None
        mul_2084 = torch.ops.aten.mul.Tensor(mul_2082, add_2124);  mul_2082 = add_2124 = None
        convert_element_type_3182 = torch.ops.prims.convert_element_type.default(mul_2084, torch.bfloat16);  mul_2084 = None
        permute_1578 = torch.ops.aten.permute.default(convert_element_type_3182, [1, 0])
        _grouped_mm_220 = torch.ops.aten._grouped_mm.default(permute_1578, index_5, cumsum_8);  permute_1578 = index_5 = None
        _grouped_mm_221 = torch.ops.aten._grouped_mm.default(convert_element_type_3182, permute_1580, cumsum_8);  convert_element_type_3182 = permute_1580 = cumsum_8 = None
        add_2125 = torch.ops.aten.add.Tensor(_grouped_mm_219, _grouped_mm_221);  _grouped_mm_219 = _grouped_mm_221 = None
        convert_element_type_3183 = torch.ops.prims.convert_element_type.default(_grouped_mm_218, torch.float32);  _grouped_mm_218 = None
        div_270 = torch.ops.aten.div.Tensor(convert_element_type_3183, 128);  convert_element_type_3183 = None
        split_1376 = torch.ops.aten.split.Tensor(div_270, 88, 1);  div_270 = None
        getitem_25885 = split_1376[0]
        getitem_25902 = split_1376[1]
        getitem_25919 = split_1376[2]
        getitem_25936 = split_1376[3]
        getitem_25953 = split_1376[4]
        getitem_25970 = split_1376[5]
        getitem_25987 = split_1376[6]
        getitem_26004 = split_1376[7]
        getitem_26021 = split_1376[8]
        getitem_26038 = split_1376[9]
        getitem_26055 = split_1376[10]
        getitem_26072 = split_1376[11]
        getitem_26089 = split_1376[12]
        getitem_26106 = split_1376[13]
        getitem_26123 = split_1376[14]
        getitem_26140 = split_1376[15];  split_1376 = None
        cat_420 = torch.ops.aten.cat.default([getitem_25885, getitem_25902, getitem_25919, getitem_25936, getitem_25953, getitem_25970, getitem_25987, getitem_26004, getitem_26021, getitem_26038, getitem_26055, getitem_26072, getitem_26089, getitem_26106, getitem_26123, getitem_26140]);  getitem_25885 = getitem_25902 = getitem_25919 = getitem_25936 = getitem_25953 = getitem_25970 = getitem_25987 = getitem_26004 = getitem_26021 = getitem_26038 = getitem_26055 = getitem_26072 = getitem_26089 = getitem_26106 = getitem_26123 = getitem_26140 = None
        reduce_scatter_tensor_327 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_420, 'sum', 16, '1025');  cat_420 = None
        wait_tensor_933 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_327);  reduce_scatter_tensor_327 = None
        convert_element_type_3184 = torch.ops.prims.convert_element_type.default(_grouped_mm_216, torch.float32);  _grouped_mm_216 = None
        div_271 = torch.ops.aten.div.Tensor(convert_element_type_3184, 128);  convert_element_type_3184 = None
        split_1393 = torch.ops.aten.split.Tensor(div_271, 128, 1);  div_271 = None
        getitem_26157 = split_1393[0]
        getitem_26174 = split_1393[1]
        getitem_26191 = split_1393[2]
        getitem_26208 = split_1393[3]
        getitem_26225 = split_1393[4]
        getitem_26242 = split_1393[5]
        getitem_26259 = split_1393[6]
        getitem_26276 = split_1393[7]
        getitem_26293 = split_1393[8]
        getitem_26310 = split_1393[9]
        getitem_26327 = split_1393[10]
        getitem_26344 = split_1393[11]
        getitem_26361 = split_1393[12]
        getitem_26378 = split_1393[13]
        getitem_26395 = split_1393[14]
        getitem_26412 = split_1393[15];  split_1393 = None
        cat_421 = torch.ops.aten.cat.default([getitem_26157, getitem_26174, getitem_26191, getitem_26208, getitem_26225, getitem_26242, getitem_26259, getitem_26276, getitem_26293, getitem_26310, getitem_26327, getitem_26344, getitem_26361, getitem_26378, getitem_26395, getitem_26412]);  getitem_26157 = getitem_26174 = getitem_26191 = getitem_26208 = getitem_26225 = getitem_26242 = getitem_26259 = getitem_26276 = getitem_26293 = getitem_26310 = getitem_26327 = getitem_26344 = getitem_26361 = getitem_26378 = getitem_26395 = getitem_26412 = None
        reduce_scatter_tensor_328 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_421, 'sum', 16, '1025');  cat_421 = None
        wait_tensor_934 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_328);  reduce_scatter_tensor_328 = None
        convert_element_type_3185 = torch.ops.prims.convert_element_type.default(_grouped_mm_220, torch.float32);  _grouped_mm_220 = None
        div_272 = torch.ops.aten.div.Tensor(convert_element_type_3185, 128);  convert_element_type_3185 = None
        split_1410 = torch.ops.aten.split.Tensor(div_272, 88, 1);  div_272 = None
        getitem_26429 = split_1410[0]
        getitem_26446 = split_1410[1]
        getitem_26463 = split_1410[2]
        getitem_26480 = split_1410[3]
        getitem_26497 = split_1410[4]
        getitem_26514 = split_1410[5]
        getitem_26531 = split_1410[6]
        getitem_26548 = split_1410[7]
        getitem_26565 = split_1410[8]
        getitem_26582 = split_1410[9]
        getitem_26599 = split_1410[10]
        getitem_26616 = split_1410[11]
        getitem_26633 = split_1410[12]
        getitem_26650 = split_1410[13]
        getitem_26667 = split_1410[14]
        getitem_26684 = split_1410[15];  split_1410 = None
        cat_422 = torch.ops.aten.cat.default([getitem_26429, getitem_26446, getitem_26463, getitem_26480, getitem_26497, getitem_26514, getitem_26531, getitem_26548, getitem_26565, getitem_26582, getitem_26599, getitem_26616, getitem_26633, getitem_26650, getitem_26667, getitem_26684]);  getitem_26429 = getitem_26446 = getitem_26463 = getitem_26480 = getitem_26497 = getitem_26514 = getitem_26531 = getitem_26548 = getitem_26565 = getitem_26582 = getitem_26599 = getitem_26616 = getitem_26633 = getitem_26650 = getitem_26667 = getitem_26684 = None
        reduce_scatter_tensor_329 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_422, 'sum', 16, '1025');  cat_422 = None
        wait_tensor_935 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_329);  reduce_scatter_tensor_329 = None
        index_put_98 = torch.ops.aten.index_put.default(full_486, [getitem_242], add_2125, True);  full_486 = getitem_242 = add_2125 = None
        slice_300 = torch.ops.aten.slice.Tensor(index_put_98, 0, 0, add_2126);  index_put_98 = add_2126 = None
        all_to_all_single_125 = torch.ops._c10d_functional.all_to_all_single.default(slice_300, [_local_scalar_dense_32, _local_scalar_dense_33, _local_scalar_dense_34, _local_scalar_dense_35, _local_scalar_dense_36, _local_scalar_dense_37, _local_scalar_dense_38, _local_scalar_dense_39], [_local_scalar_dense_40, _local_scalar_dense_41, _local_scalar_dense_42, _local_scalar_dense_43, _local_scalar_dense_44, _local_scalar_dense_45, _local_scalar_dense_46, _local_scalar_dense_47], '1033');  slice_300 = _local_scalar_dense_32 = _local_scalar_dense_33 = _local_scalar_dense_34 = _local_scalar_dense_35 = _local_scalar_dense_36 = _local_scalar_dense_37 = _local_scalar_dense_38 = _local_scalar_dense_39 = _local_scalar_dense_40 = _local_scalar_dense_41 = _local_scalar_dense_42 = _local_scalar_dense_43 = _local_scalar_dense_44 = _local_scalar_dense_45 = _local_scalar_dense_46 = _local_scalar_dense_47 = None
        wait_tensor_936 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_125);  all_to_all_single_125 = None
        index_put_99 = torch.ops.aten.index_put.default(full_default_52, [div_12], wait_tensor_936, True);  div_12 = wait_tensor_936 = None
        add_2130 = torch.ops.aten.add.Tensor(add_2122, index_put_99);  add_2122 = index_put_99 = None
        mul_2085 = torch.ops.aten.mul.Tensor(view_2220, 1.0);  view_2220 = None
        scatter_add_23 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_239, mul_2085);  getitem_239 = mul_2085 = None
        convert_element_type_173 = torch.ops.prims.convert_element_type.default(mm_27, torch.float32);  mm_27 = None
        sub_48 = torch.ops.aten.sub.Tensor(convert_element_type_173, amax_2);  convert_element_type_173 = amax_2 = None
        exp_7 = torch.ops.aten.exp.default(sub_48);  sub_48 = None
        div_11 = torch.ops.aten.div.Tensor(exp_7, sum_9);  exp_7 = sum_9 = None
        mul_2086 = torch.ops.aten.mul.Tensor(scatter_add_23, div_11);  scatter_add_23 = None
        sum_291 = torch.ops.aten.sum.dim_IntList(mul_2086, [1], True)
        neg_124 = torch.ops.aten.neg.default(div_11);  div_11 = None
        fma_23 = torch.ops.prims.fma.default(neg_124, sum_291, mul_2086);  neg_124 = sum_291 = mul_2086 = None
        convert_element_type_3186 = torch.ops.prims.convert_element_type.default(fma_23, torch.bfloat16);  fma_23 = None
        permute_1582 = torch.ops.aten.permute.default(convert_element_type_3186, [1, 0])
        mm_592 = torch.ops.aten.mm.default(permute_1582, view_192);  permute_1582 = view_192 = None
        convert_element_type_170 = torch.ops.prims.convert_element_type.default(primals_63, torch.bfloat16);  primals_63 = None
        all_gather_into_tensor_52 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_170, 128, '0');  convert_element_type_170 = None
        wait_tensor_60 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_52);  all_gather_into_tensor_52 = None
        slice_21 = torch.ops.aten.slice.Tensor(wait_tensor_60, 0, 0, 64);  wait_tensor_60 = None
        permute_49 = torch.ops.aten.permute.default(slice_21, [1, 0]);  slice_21 = None
        permute_1584 = torch.ops.aten.permute.default(permute_49, [1, 0]);  permute_49 = None
        mm_593 = torch.ops.aten.mm.default(convert_element_type_3186, permute_1584);  convert_element_type_3186 = permute_1584 = None
        add_2131 = torch.ops.aten.add.Tensor(add_2130, mm_593);  add_2130 = mm_593 = None
        convert_element_type_3191 = torch.ops.prims.convert_element_type.default(mm_592, torch.float32);  mm_592 = None
        split_1426 = torch.ops.aten.split.Tensor(convert_element_type_3191, 1);  convert_element_type_3191 = None
        getitem_26685 = split_1426[0]
        getitem_26686 = split_1426[1]
        getitem_26687 = split_1426[2]
        getitem_26688 = split_1426[3]
        getitem_26689 = split_1426[4]
        getitem_26690 = split_1426[5]
        getitem_26691 = split_1426[6]
        getitem_26692 = split_1426[7]
        getitem_26693 = split_1426[8]
        getitem_26694 = split_1426[9]
        getitem_26695 = split_1426[10]
        getitem_26696 = split_1426[11]
        getitem_26697 = split_1426[12]
        getitem_26698 = split_1426[13]
        getitem_26699 = split_1426[14]
        getitem_26700 = split_1426[15]
        getitem_26701 = split_1426[16]
        getitem_26702 = split_1426[17]
        getitem_26703 = split_1426[18]
        getitem_26704 = split_1426[19]
        getitem_26705 = split_1426[20]
        getitem_26706 = split_1426[21]
        getitem_26707 = split_1426[22]
        getitem_26708 = split_1426[23]
        getitem_26709 = split_1426[24]
        getitem_26710 = split_1426[25]
        getitem_26711 = split_1426[26]
        getitem_26712 = split_1426[27]
        getitem_26713 = split_1426[28]
        getitem_26714 = split_1426[29]
        getitem_26715 = split_1426[30]
        getitem_26716 = split_1426[31]
        getitem_26717 = split_1426[32]
        getitem_26718 = split_1426[33]
        getitem_26719 = split_1426[34]
        getitem_26720 = split_1426[35]
        getitem_26721 = split_1426[36]
        getitem_26722 = split_1426[37]
        getitem_26723 = split_1426[38]
        getitem_26724 = split_1426[39]
        getitem_26725 = split_1426[40]
        getitem_26726 = split_1426[41]
        getitem_26727 = split_1426[42]
        getitem_26728 = split_1426[43]
        getitem_26729 = split_1426[44]
        getitem_26730 = split_1426[45]
        getitem_26731 = split_1426[46]
        getitem_26732 = split_1426[47]
        getitem_26733 = split_1426[48]
        getitem_26734 = split_1426[49]
        getitem_26735 = split_1426[50]
        getitem_26736 = split_1426[51]
        getitem_26737 = split_1426[52]
        getitem_26738 = split_1426[53]
        getitem_26739 = split_1426[54]
        getitem_26740 = split_1426[55]
        getitem_26741 = split_1426[56]
        getitem_26742 = split_1426[57]
        getitem_26743 = split_1426[58]
        getitem_26744 = split_1426[59]
        getitem_26745 = split_1426[60]
        getitem_26746 = split_1426[61]
        getitem_26747 = split_1426[62]
        getitem_26748 = split_1426[63];  split_1426 = None
        cat_423 = torch.ops.aten.cat.default([getitem_26685, getitem_26686, getitem_26687, getitem_26688, getitem_26689, getitem_26690, getitem_26691, getitem_26692, getitem_26693, getitem_26694, getitem_26695, getitem_26696, getitem_26697, getitem_26698, getitem_26699, getitem_26700, getitem_26701, getitem_26702, getitem_26703, getitem_26704, getitem_26705, getitem_26706, getitem_26707, getitem_26708, getitem_26709, getitem_26710, getitem_26711, getitem_26712, getitem_26713, getitem_26714, getitem_26715, getitem_26716, getitem_26717, getitem_26718, getitem_26719, getitem_26720, getitem_26721, getitem_26722, getitem_26723, getitem_26724, getitem_26725, getitem_26726, getitem_26727, getitem_26728, getitem_26729, getitem_26730, getitem_26731, getitem_26732, getitem_26733, getitem_26734, getitem_26735, getitem_26736, getitem_26737, getitem_26738, getitem_26739, getitem_26740, getitem_26741, getitem_26742, getitem_26743, getitem_26744, getitem_26745, getitem_26746, getitem_26747, getitem_26748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_26685 = getitem_26686 = getitem_26687 = getitem_26688 = getitem_26689 = getitem_26690 = getitem_26691 = getitem_26692 = getitem_26693 = getitem_26694 = getitem_26695 = getitem_26696 = getitem_26697 = getitem_26698 = getitem_26699 = getitem_26700 = getitem_26701 = getitem_26702 = getitem_26703 = getitem_26704 = getitem_26705 = getitem_26706 = getitem_26707 = getitem_26708 = getitem_26709 = getitem_26710 = getitem_26711 = getitem_26712 = getitem_26713 = getitem_26714 = getitem_26715 = getitem_26716 = getitem_26717 = getitem_26718 = getitem_26719 = getitem_26720 = getitem_26721 = getitem_26722 = getitem_26723 = getitem_26724 = getitem_26725 = getitem_26726 = getitem_26727 = getitem_26728 = getitem_26729 = getitem_26730 = getitem_26731 = getitem_26732 = getitem_26733 = getitem_26734 = getitem_26735 = getitem_26736 = getitem_26737 = getitem_26738 = getitem_26739 = getitem_26740 = getitem_26741 = getitem_26742 = getitem_26743 = getitem_26744 = getitem_26745 = getitem_26746 = getitem_26747 = getitem_26748 = None
        reduce_scatter_tensor_330 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_423, 'avg', 128, '0');  cat_423 = None
        wait_tensor_937 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_330);  reduce_scatter_tensor_330 = None
        view_2222 = torch.ops.aten.view.default(add_2131, [2, 4096, 2048]);  add_2131 = None
        convert_element_type_3192 = torch.ops.prims.convert_element_type.default(view_2222, torch.float32);  view_2222 = None
        convert_element_type_167 = torch.ops.prims.convert_element_type.default(primals_61, torch.bfloat16);  primals_61 = None
        all_gather_into_tensor_51 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_167, 128, '0');  convert_element_type_167 = None
        wait_tensor_59 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_51);  all_gather_into_tensor_51 = None
        convert_element_type_3194 = torch.ops.prims.convert_element_type.default(wait_tensor_59, torch.float32);  wait_tensor_59 = None
        mul_2087 = torch.ops.aten.mul.Tensor(convert_element_type_3192, convert_element_type_3194);  convert_element_type_3194 = None
        convert_element_type_168 = torch.ops.prims.convert_element_type.default(add_144, torch.float32);  add_144 = None
        mul_113 = torch.ops.aten.mul.Tensor(convert_element_type_168, rsqrt_11);  convert_element_type_168 = None
        mul_2089 = torch.ops.aten.mul.Tensor(mul_113, mul_2087)
        sum_292 = torch.ops.aten.sum.dim_IntList(mul_2089, [2], True);  mul_2089 = None
        div_273 = torch.ops.aten.div.Tensor(mul_113, 2048)
        mul_2090 = torch.ops.aten.mul.Tensor(div_273, sum_292);  div_273 = sum_292 = None
        sub_766 = torch.ops.aten.sub.Tensor(mul_2087, mul_2090);  mul_2087 = mul_2090 = None
        mul_2091 = torch.ops.aten.mul.Tensor(sub_766, rsqrt_11);  sub_766 = rsqrt_11 = None
        mul_2092 = torch.ops.aten.mul.Tensor(convert_element_type_3192, mul_113);  convert_element_type_3192 = mul_113 = None
        sum_293 = torch.ops.aten.sum.dim_IntList(mul_2092, [0, 1]);  mul_2092 = None
        convert_element_type_3195 = torch.ops.prims.convert_element_type.default(mul_2091, torch.bfloat16);  mul_2091 = None
        add_2132 = torch.ops.aten.add.Tensor(add_2119, convert_element_type_3195);  add_2119 = convert_element_type_3195 = None
        convert_element_type_default_12 = torch.ops.prims.convert_element_type.default(sum_293, torch.float32);  sum_293 = None
        reduce_scatter_tensor_331 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_12, 'avg', 128, '0');  convert_element_type_default_12 = None
        wait_tensor_938 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_331);  reduce_scatter_tensor_331 = None
        view_2223 = torch.ops.aten.view.default(add_2132, [8192, 2048])
        permute_1586 = torch.ops.aten.permute.default(view_2223, [1, 0])
        permute_47 = torch.ops.aten.permute.default(getitem_235, [0, 2, 1, 3])
        view_187 = torch.ops.aten.view.default(permute_47, [2, 4096, -1]);  permute_47 = None
        view_189 = torch.ops.aten.view.default(view_187, [8192, 2048]);  view_187 = None
        mm_594 = torch.ops.aten.mm.default(permute_1586, view_189);  permute_1586 = view_189 = None
        convert_element_type_164 = torch.ops.prims.convert_element_type.default(primals_60, torch.bfloat16);  primals_60 = None
        all_gather_into_tensor_50 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_164, 128, '0');  convert_element_type_164 = None
        wait_tensor_58 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_50);  all_gather_into_tensor_50 = None
        permute_48 = torch.ops.aten.permute.default(wait_tensor_58, [1, 0]);  wait_tensor_58 = None
        permute_1588 = torch.ops.aten.permute.default(permute_48, [1, 0]);  permute_48 = None
        mm_595 = torch.ops.aten.mm.default(view_2223, permute_1588);  view_2223 = permute_1588 = None
        view_2224 = torch.ops.aten.view.default(mm_595, [2, 4096, 2048]);  mm_595 = None
        convert_element_type_3202 = torch.ops.prims.convert_element_type.default(mm_594, torch.float32);  mm_594 = None
        reduce_scatter_tensor_332 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3202, 'avg', 128, '0');  convert_element_type_3202 = None
        wait_tensor_939 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_332);  reduce_scatter_tensor_332 = None
        view_2225 = torch.ops.aten.view.default(view_2224, [2, 4096, 16, 128]);  view_2224 = None
        permute_1590 = torch.ops.aten.permute.default(view_2225, [0, 2, 1, 3]);  view_2225 = None
        fw_graph23 = self.fw_graph23
        joint_graph23 = self.joint_graph23
        mask_graph23 = self.mask_graph23
        flex_attention_backward_23 = torch.ops.higher_order.flex_attention_backward(permute_44, permute_45, permute_46, getitem_235, getitem_236, permute_1590, None, fw_graph23, joint_graph23, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph23), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_44 = permute_45 = permute_46 = getitem_235 = getitem_236 = permute_1590 = fw_graph23 = joint_graph23 = mask_graph23 = None
        getitem_26749 = flex_attention_backward_23[0]
        getitem_26750 = flex_attention_backward_23[1]
        getitem_26751 = flex_attention_backward_23[2];  flex_attention_backward_23 = None
        permute_1591 = torch.ops.aten.permute.default(getitem_26751, [0, 2, 1, 3]);  getitem_26751 = None
        permute_1592 = torch.ops.aten.permute.default(getitem_26750, [0, 2, 1, 3]);  getitem_26750 = None
        permute_1593 = torch.ops.aten.permute.default(getitem_26749, [0, 2, 1, 3]);  getitem_26749 = None
        slice_302 = torch.ops.aten.slice.Tensor(permute_1592, 3, 0, 128)
        slice_303 = torch.ops.aten.slice.Tensor(permute_1592, 3, 128, 192);  permute_1592 = None
        sum_294 = torch.ops.aten.sum.dim_IntList(slice_303, [2], True);  slice_303 = None
        cat_424 = torch.ops.aten.cat.default([slice_302, permute_1591], 3);  slice_302 = permute_1591 = None
        view_2226 = torch.ops.aten.view.default(cat_424, [2, 4096, 4096]);  cat_424 = None
        view_2227 = torch.ops.aten.view.default(view_2226, [8192, 4096]);  view_2226 = None
        permute_1594 = torch.ops.aten.permute.default(view_2227, [1, 0])
        mm_596 = torch.ops.aten.mm.default(permute_1594, view_184);  permute_1594 = view_184 = None
        convert_element_type_161 = torch.ops.prims.convert_element_type.default(primals_59, torch.bfloat16);  primals_59 = None
        all_gather_into_tensor_49 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_161, 128, '0');  convert_element_type_161 = None
        wait_tensor_57 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_49);  all_gather_into_tensor_49 = None
        permute_43 = torch.ops.aten.permute.default(wait_tensor_57, [1, 0]);  wait_tensor_57 = None
        permute_1596 = torch.ops.aten.permute.default(permute_43, [1, 0]);  permute_43 = None
        mm_597 = torch.ops.aten.mm.default(view_2227, permute_1596);  view_2227 = permute_1596 = None
        view_2228 = torch.ops.aten.view.default(mm_597, [2, 4096, 512]);  mm_597 = None
        convert_element_type_3207 = torch.ops.prims.convert_element_type.default(mm_596, torch.float32);  mm_596 = None
        reduce_scatter_tensor_333 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3207, 'avg', 128, '0');  convert_element_type_3207 = None
        wait_tensor_940 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_333);  reduce_scatter_tensor_333 = None
        convert_element_type_3208 = torch.ops.prims.convert_element_type.default(view_2228, torch.float32);  view_2228 = None
        convert_element_type_158 = torch.ops.prims.convert_element_type.default(primals_58, torch.bfloat16);  primals_58 = None
        all_gather_into_tensor_48 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_158, 128, '0');  convert_element_type_158 = None
        wait_tensor_56 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_48);  all_gather_into_tensor_48 = None
        convert_element_type_3210 = torch.ops.prims.convert_element_type.default(wait_tensor_56, torch.float32);  wait_tensor_56 = None
        mul_2093 = torch.ops.aten.mul.Tensor(convert_element_type_3208, convert_element_type_3210);  convert_element_type_3210 = None
        convert_element_type_159 = torch.ops.prims.convert_element_type.default(getitem_231, torch.float32);  getitem_231 = None
        mul_111 = torch.ops.aten.mul.Tensor(convert_element_type_159, rsqrt_10);  convert_element_type_159 = None
        mul_2095 = torch.ops.aten.mul.Tensor(mul_111, mul_2093)
        sum_295 = torch.ops.aten.sum.dim_IntList(mul_2095, [2], True);  mul_2095 = None
        div_274 = torch.ops.aten.div.Tensor(mul_111, 512)
        mul_2096 = torch.ops.aten.mul.Tensor(div_274, sum_295);  div_274 = sum_295 = None
        sub_767 = torch.ops.aten.sub.Tensor(mul_2093, mul_2096);  mul_2093 = mul_2096 = None
        mul_2097 = torch.ops.aten.mul.Tensor(sub_767, rsqrt_10);  sub_767 = rsqrt_10 = None
        mul_2098 = torch.ops.aten.mul.Tensor(convert_element_type_3208, mul_111);  convert_element_type_3208 = mul_111 = None
        sum_296 = torch.ops.aten.sum.dim_IntList(mul_2098, [0, 1]);  mul_2098 = None
        convert_element_type_3211 = torch.ops.prims.convert_element_type.default(mul_2097, torch.bfloat16);  mul_2097 = None
        convert_element_type_default_11 = torch.ops.prims.convert_element_type.default(sum_296, torch.float32);  sum_296 = None
        reduce_scatter_tensor_334 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_11, 'avg', 128, '0');  convert_element_type_default_11 = None
        wait_tensor_941 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_334);  reduce_scatter_tensor_334 = None
        convert_element_type_3214 = torch.ops.prims.convert_element_type.default(sum_294, torch.float32);  sum_294 = None
        view_2229 = torch.ops.aten.view.default(convert_element_type_3214, [2, 4096, 1, 32, 2]);  convert_element_type_3214 = None
        view_as_complex_100 = torch.ops.aten.view_as_complex.default(view_2229);  view_2229 = None
        mul_2099 = torch.ops.aten.mul.Tensor(view_as_complex_100, clone_9);  view_as_complex_100 = None
        view_as_real_100 = torch.ops.aten.view_as_real.default(mul_2099);  mul_2099 = None
        view_2230 = torch.ops.aten.view.default(view_as_real_100, [2, 4096, 1, 64]);  view_as_real_100 = None
        convert_element_type_3215 = torch.ops.prims.convert_element_type.default(view_2230, torch.bfloat16);  view_2230 = None
        squeeze_49 = torch.ops.aten.squeeze.dim(convert_element_type_3215, 2);  convert_element_type_3215 = None
        cat_425 = torch.ops.aten.cat.default([convert_element_type_3211, squeeze_49], 2);  convert_element_type_3211 = squeeze_49 = None
        view_2231 = torch.ops.aten.view.default(cat_425, [8192, 576]);  cat_425 = None
        permute_1598 = torch.ops.aten.permute.default(view_2231, [1, 0])
        mm_598 = torch.ops.aten.mm.default(permute_1598, view_170);  permute_1598 = None
        convert_element_type_153 = torch.ops.prims.convert_element_type.default(primals_57, torch.bfloat16);  primals_57 = None
        all_gather_into_tensor_47 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_153, 128, '0');  convert_element_type_153 = None
        wait_tensor_55 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_47);  all_gather_into_tensor_47 = None
        slice_19 = torch.ops.aten.slice.Tensor(wait_tensor_55, 0, 0, 576);  wait_tensor_55 = None
        permute_42 = torch.ops.aten.permute.default(slice_19, [1, 0]);  slice_19 = None
        permute_1600 = torch.ops.aten.permute.default(permute_42, [1, 0]);  permute_42 = None
        mm_599 = torch.ops.aten.mm.default(view_2231, permute_1600);  view_2231 = permute_1600 = None
        view_2232 = torch.ops.aten.view.default(mm_599, [2, 4096, 2048]);  mm_599 = None
        convert_element_type_3220 = torch.ops.prims.convert_element_type.default(mm_598, torch.float32);  mm_598 = None
        split_1427 = torch.ops.aten.split.Tensor(convert_element_type_3220, 5);  convert_element_type_3220 = None
        getitem_26753 = split_1427[0]
        getitem_26754 = split_1427[1]
        getitem_26755 = split_1427[2]
        getitem_26756 = split_1427[3]
        getitem_26757 = split_1427[4]
        getitem_26758 = split_1427[5]
        getitem_26759 = split_1427[6]
        getitem_26760 = split_1427[7]
        getitem_26761 = split_1427[8]
        getitem_26762 = split_1427[9]
        getitem_26763 = split_1427[10]
        getitem_26764 = split_1427[11]
        getitem_26765 = split_1427[12]
        getitem_26766 = split_1427[13]
        getitem_26767 = split_1427[14]
        getitem_26768 = split_1427[15]
        getitem_26769 = split_1427[16]
        getitem_26770 = split_1427[17]
        getitem_26771 = split_1427[18]
        getitem_26772 = split_1427[19]
        getitem_26773 = split_1427[20]
        getitem_26774 = split_1427[21]
        getitem_26775 = split_1427[22]
        getitem_26776 = split_1427[23]
        getitem_26777 = split_1427[24]
        getitem_26778 = split_1427[25]
        getitem_26779 = split_1427[26]
        getitem_26780 = split_1427[27]
        getitem_26781 = split_1427[28]
        getitem_26782 = split_1427[29]
        getitem_26783 = split_1427[30]
        getitem_26784 = split_1427[31]
        getitem_26785 = split_1427[32]
        getitem_26786 = split_1427[33]
        getitem_26787 = split_1427[34]
        getitem_26788 = split_1427[35]
        getitem_26789 = split_1427[36]
        getitem_26790 = split_1427[37]
        getitem_26791 = split_1427[38]
        getitem_26792 = split_1427[39]
        getitem_26793 = split_1427[40]
        getitem_26794 = split_1427[41]
        getitem_26795 = split_1427[42]
        getitem_26796 = split_1427[43]
        getitem_26797 = split_1427[44]
        getitem_26798 = split_1427[45]
        getitem_26799 = split_1427[46]
        getitem_26800 = split_1427[47]
        getitem_26801 = split_1427[48]
        getitem_26802 = split_1427[49]
        getitem_26803 = split_1427[50]
        getitem_26804 = split_1427[51]
        getitem_26805 = split_1427[52]
        getitem_26806 = split_1427[53]
        getitem_26807 = split_1427[54]
        getitem_26808 = split_1427[55]
        getitem_26809 = split_1427[56]
        getitem_26810 = split_1427[57]
        getitem_26811 = split_1427[58]
        getitem_26812 = split_1427[59]
        getitem_26813 = split_1427[60]
        getitem_26814 = split_1427[61]
        getitem_26815 = split_1427[62]
        getitem_26816 = split_1427[63]
        getitem_26817 = split_1427[64]
        getitem_26818 = split_1427[65]
        getitem_26819 = split_1427[66]
        getitem_26820 = split_1427[67]
        getitem_26821 = split_1427[68]
        getitem_26822 = split_1427[69]
        getitem_26823 = split_1427[70]
        getitem_26824 = split_1427[71]
        getitem_26825 = split_1427[72]
        getitem_26826 = split_1427[73]
        getitem_26827 = split_1427[74]
        getitem_26828 = split_1427[75]
        getitem_26829 = split_1427[76]
        getitem_26830 = split_1427[77]
        getitem_26831 = split_1427[78]
        getitem_26832 = split_1427[79]
        getitem_26833 = split_1427[80]
        getitem_26834 = split_1427[81]
        getitem_26835 = split_1427[82]
        getitem_26836 = split_1427[83]
        getitem_26837 = split_1427[84]
        getitem_26838 = split_1427[85]
        getitem_26839 = split_1427[86]
        getitem_26840 = split_1427[87]
        getitem_26841 = split_1427[88]
        getitem_26842 = split_1427[89]
        getitem_26843 = split_1427[90]
        getitem_26844 = split_1427[91]
        getitem_26845 = split_1427[92]
        getitem_26846 = split_1427[93]
        getitem_26847 = split_1427[94]
        getitem_26848 = split_1427[95]
        getitem_26849 = split_1427[96]
        getitem_26850 = split_1427[97]
        getitem_26851 = split_1427[98]
        getitem_26852 = split_1427[99]
        getitem_26853 = split_1427[100]
        getitem_26854 = split_1427[101]
        getitem_26855 = split_1427[102]
        getitem_26856 = split_1427[103]
        getitem_26857 = split_1427[104]
        getitem_26858 = split_1427[105]
        getitem_26859 = split_1427[106]
        getitem_26860 = split_1427[107]
        getitem_26861 = split_1427[108]
        getitem_26862 = split_1427[109]
        getitem_26863 = split_1427[110]
        getitem_26864 = split_1427[111]
        getitem_26865 = split_1427[112]
        getitem_26866 = split_1427[113]
        getitem_26867 = split_1427[114]
        getitem_26868 = split_1427[115];  split_1427 = None
        constant_pad_nd_1835 = torch.ops.aten.constant_pad_nd.default(getitem_26868, [0, 0, 0, 4], 0.0);  getitem_26868 = None
        cat_426 = torch.ops.aten.cat.default([getitem_26753, getitem_26754, getitem_26755, getitem_26756, getitem_26757, getitem_26758, getitem_26759, getitem_26760, getitem_26761, getitem_26762, getitem_26763, getitem_26764, getitem_26765, getitem_26766, getitem_26767, getitem_26768, getitem_26769, getitem_26770, getitem_26771, getitem_26772, getitem_26773, getitem_26774, getitem_26775, getitem_26776, getitem_26777, getitem_26778, getitem_26779, getitem_26780, getitem_26781, getitem_26782, getitem_26783, getitem_26784, getitem_26785, getitem_26786, getitem_26787, getitem_26788, getitem_26789, getitem_26790, getitem_26791, getitem_26792, getitem_26793, getitem_26794, getitem_26795, getitem_26796, getitem_26797, getitem_26798, getitem_26799, getitem_26800, getitem_26801, getitem_26802, getitem_26803, getitem_26804, getitem_26805, getitem_26806, getitem_26807, getitem_26808, getitem_26809, getitem_26810, getitem_26811, getitem_26812, getitem_26813, getitem_26814, getitem_26815, getitem_26816, getitem_26817, getitem_26818, getitem_26819, getitem_26820, getitem_26821, getitem_26822, getitem_26823, getitem_26824, getitem_26825, getitem_26826, getitem_26827, getitem_26828, getitem_26829, getitem_26830, getitem_26831, getitem_26832, getitem_26833, getitem_26834, getitem_26835, getitem_26836, getitem_26837, getitem_26838, getitem_26839, getitem_26840, getitem_26841, getitem_26842, getitem_26843, getitem_26844, getitem_26845, getitem_26846, getitem_26847, getitem_26848, getitem_26849, getitem_26850, getitem_26851, getitem_26852, getitem_26853, getitem_26854, getitem_26855, getitem_26856, getitem_26857, getitem_26858, getitem_26859, getitem_26860, getitem_26861, getitem_26862, getitem_26863, getitem_26864, getitem_26865, getitem_26866, getitem_26867, constant_pad_nd_1835, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_26753 = getitem_26754 = getitem_26755 = getitem_26756 = getitem_26757 = getitem_26758 = getitem_26759 = getitem_26760 = getitem_26761 = getitem_26762 = getitem_26763 = getitem_26764 = getitem_26765 = getitem_26766 = getitem_26767 = getitem_26768 = getitem_26769 = getitem_26770 = getitem_26771 = getitem_26772 = getitem_26773 = getitem_26774 = getitem_26775 = getitem_26776 = getitem_26777 = getitem_26778 = getitem_26779 = getitem_26780 = getitem_26781 = getitem_26782 = getitem_26783 = getitem_26784 = getitem_26785 = getitem_26786 = getitem_26787 = getitem_26788 = getitem_26789 = getitem_26790 = getitem_26791 = getitem_26792 = getitem_26793 = getitem_26794 = getitem_26795 = getitem_26796 = getitem_26797 = getitem_26798 = getitem_26799 = getitem_26800 = getitem_26801 = getitem_26802 = getitem_26803 = getitem_26804 = getitem_26805 = getitem_26806 = getitem_26807 = getitem_26808 = getitem_26809 = getitem_26810 = getitem_26811 = getitem_26812 = getitem_26813 = getitem_26814 = getitem_26815 = getitem_26816 = getitem_26817 = getitem_26818 = getitem_26819 = getitem_26820 = getitem_26821 = getitem_26822 = getitem_26823 = getitem_26824 = getitem_26825 = getitem_26826 = getitem_26827 = getitem_26828 = getitem_26829 = getitem_26830 = getitem_26831 = getitem_26832 = getitem_26833 = getitem_26834 = getitem_26835 = getitem_26836 = getitem_26837 = getitem_26838 = getitem_26839 = getitem_26840 = getitem_26841 = getitem_26842 = getitem_26843 = getitem_26844 = getitem_26845 = getitem_26846 = getitem_26847 = getitem_26848 = getitem_26849 = getitem_26850 = getitem_26851 = getitem_26852 = getitem_26853 = getitem_26854 = getitem_26855 = getitem_26856 = getitem_26857 = getitem_26858 = getitem_26859 = getitem_26860 = getitem_26861 = getitem_26862 = getitem_26863 = getitem_26864 = getitem_26865 = getitem_26866 = getitem_26867 = constant_pad_nd_1835 = None
        reduce_scatter_tensor_335 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_426, 'avg', 128, '0');  cat_426 = None
        wait_tensor_942 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_335);  reduce_scatter_tensor_335 = None
        slice_304 = torch.ops.aten.slice.Tensor(permute_1593, 3, 0, 128)
        slice_305 = torch.ops.aten.slice.Tensor(permute_1593, 3, 128, 192);  permute_1593 = None
        convert_element_type_3221 = torch.ops.prims.convert_element_type.default(slice_305, torch.float32);  slice_305 = None
        view_2233 = torch.ops.aten.view.default(convert_element_type_3221, [2, 4096, 16, 32, 2]);  convert_element_type_3221 = None
        view_as_complex_101 = torch.ops.aten.view_as_complex.default(view_2233);  view_2233 = None
        mul_2100 = torch.ops.aten.mul.Tensor(view_as_complex_101, clone_9);  view_as_complex_101 = None
        view_as_real_101 = torch.ops.aten.view_as_real.default(mul_2100);  mul_2100 = None
        view_2234 = torch.ops.aten.view.default(view_as_real_101, [2, 4096, 16, 64]);  view_as_real_101 = None
        convert_element_type_3222 = torch.ops.prims.convert_element_type.default(view_2234, torch.bfloat16);  view_2234 = None
        cat_427 = torch.ops.aten.cat.default([slice_304, convert_element_type_3222], 3);  slice_304 = convert_element_type_3222 = None
        view_2235 = torch.ops.aten.view.default(cat_427, [2, 4096, 3072]);  cat_427 = None
        view_2236 = torch.ops.aten.view.default(view_2235, [8192, 3072]);  view_2235 = None
        permute_1602 = torch.ops.aten.permute.default(view_2236, [1, 0])
        mm_600 = torch.ops.aten.mm.default(permute_1602, view_170);  permute_1602 = view_170 = None
        convert_element_type_148 = torch.ops.prims.convert_element_type.default(primals_56, torch.bfloat16);  primals_56 = None
        all_gather_into_tensor_46 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_148, 128, '0');  convert_element_type_148 = None
        wait_tensor_54 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_46);  all_gather_into_tensor_46 = None
        permute_41 = torch.ops.aten.permute.default(wait_tensor_54, [1, 0]);  wait_tensor_54 = None
        permute_1604 = torch.ops.aten.permute.default(permute_41, [1, 0]);  permute_41 = None
        mm_601 = torch.ops.aten.mm.default(view_2236, permute_1604);  view_2236 = permute_1604 = None
        view_2237 = torch.ops.aten.view.default(mm_601, [2, 4096, 2048]);  mm_601 = None
        add_2133 = torch.ops.aten.add.Tensor(view_2232, view_2237);  view_2232 = view_2237 = None
        convert_element_type_3227 = torch.ops.prims.convert_element_type.default(mm_600, torch.float32);  mm_600 = None
        reduce_scatter_tensor_336 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3227, 'avg', 128, '0');  convert_element_type_3227 = None
        wait_tensor_943 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_336);  reduce_scatter_tensor_336 = None
        convert_element_type_3228 = torch.ops.prims.convert_element_type.default(add_2133, torch.float32);  add_2133 = None
        convert_element_type_145 = torch.ops.prims.convert_element_type.default(primals_55, torch.bfloat16);  primals_55 = None
        all_gather_into_tensor_45 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_145, 128, '0');  convert_element_type_145 = None
        wait_tensor_53 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_45);  all_gather_into_tensor_45 = None
        convert_element_type_3230 = torch.ops.prims.convert_element_type.default(wait_tensor_53, torch.float32);  wait_tensor_53 = None
        mul_2101 = torch.ops.aten.mul.Tensor(convert_element_type_3228, convert_element_type_3230);  convert_element_type_3230 = None
        convert_element_type_146 = torch.ops.prims.convert_element_type.default(add_141, torch.float32);  add_141 = None
        mul_107 = torch.ops.aten.mul.Tensor(convert_element_type_146, rsqrt_9);  convert_element_type_146 = None
        mul_2103 = torch.ops.aten.mul.Tensor(mul_107, mul_2101)
        sum_297 = torch.ops.aten.sum.dim_IntList(mul_2103, [2], True);  mul_2103 = None
        div_275 = torch.ops.aten.div.Tensor(mul_107, 2048)
        mul_2104 = torch.ops.aten.mul.Tensor(div_275, sum_297);  div_275 = sum_297 = None
        sub_768 = torch.ops.aten.sub.Tensor(mul_2101, mul_2104);  mul_2101 = mul_2104 = None
        mul_2105 = torch.ops.aten.mul.Tensor(sub_768, rsqrt_9);  sub_768 = rsqrt_9 = None
        mul_2106 = torch.ops.aten.mul.Tensor(convert_element_type_3228, mul_107);  convert_element_type_3228 = mul_107 = None
        sum_298 = torch.ops.aten.sum.dim_IntList(mul_2106, [0, 1]);  mul_2106 = None
        convert_element_type_3231 = torch.ops.prims.convert_element_type.default(mul_2105, torch.bfloat16);  mul_2105 = None
        add_2134 = torch.ops.aten.add.Tensor(add_2132, convert_element_type_3231);  add_2132 = convert_element_type_3231 = None
        convert_element_type_default_10 = torch.ops.prims.convert_element_type.default(sum_298, torch.float32);  sum_298 = None
        reduce_scatter_tensor_337 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_10, 'avg', 128, '0');  convert_element_type_default_10 = None
        wait_tensor_944 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_337);  reduce_scatter_tensor_337 = None
        view_2238 = torch.ops.aten.view.default(add_2134, [8192, 2048])
        unsqueeze_77 = torch.ops.aten.unsqueeze.default(view_2238, 1)
        convert_element_type_3234 = torch.ops.prims.convert_element_type.default(unsqueeze_77, torch.float32);  unsqueeze_77 = None
        bmm_74 = torch.ops.aten.bmm.default(permute_1606, convert_element_type_3234);  permute_1606 = None
        bmm_75 = torch.ops.aten.bmm.default(convert_element_type_3234, permute_1607);  convert_element_type_3234 = permute_1607 = None
        convert_element_type_3235 = torch.ops.prims.convert_element_type.default(bmm_74, torch.bfloat16);  bmm_74 = None
        view_2239 = torch.ops.aten.view.default(bmm_75, [8192, 6]);  bmm_75 = None
        view_2240 = torch.ops.aten.view.default(convert_element_type_3235, [49152, 2048]);  convert_element_type_3235 = None
        index_100 = torch.ops.aten.index.Tensor(view_2240, [getitem_131]);  view_2240 = getitem_131 = None
        permute_1608 = torch.ops.aten.permute.default(view_2238, [1, 0])
        mm_602 = torch.ops.aten.mm.default(permute_1608, mul_104);  permute_1608 = mul_104 = None
        convert_element_type_140 = torch.ops.prims.convert_element_type.default(primals_54, torch.bfloat16);  primals_54 = None
        all_gather_into_tensor_44 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_140, 128, '0');  convert_element_type_140 = None
        wait_tensor_52 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_44);  all_gather_into_tensor_44 = None
        permute_40 = torch.ops.aten.permute.default(wait_tensor_52, [1, 0]);  wait_tensor_52 = None
        permute_1610 = torch.ops.aten.permute.default(permute_40, [1, 0]);  permute_40 = None
        mm_603 = torch.ops.aten.mm.default(view_2238, permute_1610);  view_2238 = permute_1610 = None
        convert_element_type_3240 = torch.ops.prims.convert_element_type.default(mm_602, torch.float32);  mm_602 = None
        reduce_scatter_tensor_338 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3240, 'avg', 128, '0');  convert_element_type_3240 = None
        wait_tensor_945 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_338);  reduce_scatter_tensor_338 = None
        convert_element_type_135 = torch.ops.prims.convert_element_type.default(mm_20, torch.float32);  mm_20 = None
        neg_4 = torch.ops.aten.neg.default(convert_element_type_135)
        exp_6 = torch.ops.aten.exp.default(neg_4);  neg_4 = None
        add_136 = torch.ops.aten.add.Tensor(exp_6, 1);  exp_6 = None
        div_10 = torch.ops.aten.div.Tensor(convert_element_type_135, add_136)
        convert_element_type_136 = torch.ops.prims.convert_element_type.default(div_10, torch.bfloat16);  div_10 = None
        mul_2107 = torch.ops.aten.mul.Tensor(mm_603, convert_element_type_136);  convert_element_type_136 = None
        mul_2108 = torch.ops.aten.mul.Tensor(mm_603, mm_21);  mm_603 = mm_21 = None
        permute_1612 = torch.ops.aten.permute.default(mul_2107, [1, 0])
        mm_604 = torch.ops.aten.mm.default(permute_1612, view_125);  permute_1612 = None
        convert_element_type_137 = torch.ops.prims.convert_element_type.default(primals_53, torch.bfloat16);  primals_53 = None
        all_gather_into_tensor_43 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_137, 128, '0');  convert_element_type_137 = None
        wait_tensor_51 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_43);  all_gather_into_tensor_43 = None
        permute_39 = torch.ops.aten.permute.default(wait_tensor_51, [1, 0]);  wait_tensor_51 = None
        permute_1614 = torch.ops.aten.permute.default(permute_39, [1, 0]);  permute_39 = None
        mm_605 = torch.ops.aten.mm.default(mul_2107, permute_1614);  mul_2107 = permute_1614 = None
        convert_element_type_3245 = torch.ops.prims.convert_element_type.default(mm_604, torch.float32);  mm_604 = None
        reduce_scatter_tensor_339 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3245, 'avg', 128, '0');  convert_element_type_3245 = None
        wait_tensor_946 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_339);  reduce_scatter_tensor_339 = None
        convert_element_type_3246 = torch.ops.prims.convert_element_type.default(mul_2108, torch.float32);  mul_2108 = None
        reciprocal_48 = torch.ops.aten.reciprocal.default(add_136);  add_136 = None
        mul_2109 = torch.ops.aten.mul.Tensor(reciprocal_48, 1);  reciprocal_48 = None
        mul_2110 = torch.ops.aten.mul.Tensor(convert_element_type_3246, mul_2109);  convert_element_type_3246 = None
        sub_769 = torch.ops.aten.sub.Tensor(1, mul_2109);  mul_2109 = None
        mul_2111 = torch.ops.aten.mul.Tensor(convert_element_type_135, sub_769);  convert_element_type_135 = sub_769 = None
        add_2136 = torch.ops.aten.add.Tensor(mul_2111, 1);  mul_2111 = None
        mul_2112 = torch.ops.aten.mul.Tensor(mul_2110, add_2136);  mul_2110 = add_2136 = None
        convert_element_type_3248 = torch.ops.prims.convert_element_type.default(mul_2112, torch.bfloat16);  mul_2112 = None
        permute_1616 = torch.ops.aten.permute.default(convert_element_type_3248, [1, 0])
        mm_606 = torch.ops.aten.mm.default(permute_1616, view_125);  permute_1616 = None
        convert_element_type_132 = torch.ops.prims.convert_element_type.default(primals_52, torch.bfloat16);  primals_52 = None
        all_gather_into_tensor_42 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_132, 128, '0');  convert_element_type_132 = None
        wait_tensor_50 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_42);  all_gather_into_tensor_42 = None
        permute_38 = torch.ops.aten.permute.default(wait_tensor_50, [1, 0]);  wait_tensor_50 = None
        permute_1618 = torch.ops.aten.permute.default(permute_38, [1, 0]);  permute_38 = None
        mm_607 = torch.ops.aten.mm.default(convert_element_type_3248, permute_1618);  convert_element_type_3248 = permute_1618 = None
        add_2137 = torch.ops.aten.add.Tensor(mm_605, mm_607);  mm_605 = mm_607 = None
        convert_element_type_3253 = torch.ops.prims.convert_element_type.default(mm_606, torch.float32);  mm_606 = None
        reduce_scatter_tensor_340 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3253, 'avg', 128, '0');  convert_element_type_3253 = None
        wait_tensor_947 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_340);  reduce_scatter_tensor_340 = None
        all_to_all_single_126 = torch.ops._c10d_functional.all_to_all_single.default(index_100, [_local_scalar_dense_24, _local_scalar_dense_25, _local_scalar_dense_26, _local_scalar_dense_27, _local_scalar_dense_28, _local_scalar_dense_29, _local_scalar_dense_30, _local_scalar_dense_31], [_local_scalar_dense_16, _local_scalar_dense_17, _local_scalar_dense_18, _local_scalar_dense_19, _local_scalar_dense_20, _local_scalar_dense_21, _local_scalar_dense_22, _local_scalar_dense_23], '1033');  index_100 = None
        wait_tensor_948 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_126);  all_to_all_single_126 = None
        full_492 = torch.ops.aten.full.default([sym_size_int_5, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_5 = None
        slice_scatter_24 = torch.ops.aten.slice_scatter.default(full_492, wait_tensor_948, 0, 0, -1);  wait_tensor_948 = None
        index_101 = torch.ops.aten.index.Tensor(slice_scatter_24, [getitem_132]);  slice_scatter_24 = None
        permute_1620 = torch.ops.aten.permute.default(index_101, [1, 0])
        _grouped_mm_222 = torch.ops.aten._grouped_mm.default(permute_1620, mul_84, cumsum_5);  permute_1620 = mul_84 = None
        _grouped_mm_223 = torch.ops.aten._grouped_mm.default(index_101, permute_1622, cumsum_5);  index_101 = permute_1622 = None
        convert_element_type_130 = torch.ops.prims.convert_element_type.default(_grouped_mm_3, torch.float32);  _grouped_mm_3 = None
        neg_3 = torch.ops.aten.neg.default(convert_element_type_130)
        exp_5 = torch.ops.aten.exp.default(neg_3);  neg_3 = None
        add_100 = torch.ops.aten.add.Tensor(exp_5, 1);  exp_5 = None
        div_9 = torch.ops.aten.div.Tensor(convert_element_type_130, add_100)
        convert_element_type_131 = torch.ops.prims.convert_element_type.default(div_9, torch.bfloat16);  div_9 = None
        mul_2113 = torch.ops.aten.mul.Tensor(_grouped_mm_223, convert_element_type_131);  convert_element_type_131 = None
        mul_2114 = torch.ops.aten.mul.Tensor(_grouped_mm_223, _grouped_mm_4);  _grouped_mm_223 = _grouped_mm_4 = None
        permute_1624 = torch.ops.aten.permute.default(mul_2113, [1, 0])
        _grouped_mm_224 = torch.ops.aten._grouped_mm.default(permute_1624, index_3, cumsum_5);  permute_1624 = None
        _grouped_mm_225 = torch.ops.aten._grouped_mm.default(mul_2113, permute_1626, cumsum_5);  mul_2113 = permute_1626 = None
        convert_element_type_3254 = torch.ops.prims.convert_element_type.default(mul_2114, torch.float32);  mul_2114 = None
        reciprocal_49 = torch.ops.aten.reciprocal.default(add_100);  add_100 = None
        mul_2115 = torch.ops.aten.mul.Tensor(reciprocal_49, 1);  reciprocal_49 = None
        mul_2116 = torch.ops.aten.mul.Tensor(convert_element_type_3254, mul_2115);  convert_element_type_3254 = None
        sub_770 = torch.ops.aten.sub.Tensor(1, mul_2115);  mul_2115 = None
        mul_2117 = torch.ops.aten.mul.Tensor(convert_element_type_130, sub_770);  convert_element_type_130 = sub_770 = None
        add_2139 = torch.ops.aten.add.Tensor(mul_2117, 1);  mul_2117 = None
        mul_2118 = torch.ops.aten.mul.Tensor(mul_2116, add_2139);  mul_2116 = add_2139 = None
        convert_element_type_3256 = torch.ops.prims.convert_element_type.default(mul_2118, torch.bfloat16);  mul_2118 = None
        permute_1628 = torch.ops.aten.permute.default(convert_element_type_3256, [1, 0])
        _grouped_mm_226 = torch.ops.aten._grouped_mm.default(permute_1628, index_3, cumsum_5);  permute_1628 = index_3 = None
        _grouped_mm_227 = torch.ops.aten._grouped_mm.default(convert_element_type_3256, permute_1630, cumsum_5);  convert_element_type_3256 = permute_1630 = cumsum_5 = None
        add_2140 = torch.ops.aten.add.Tensor(_grouped_mm_225, _grouped_mm_227);  _grouped_mm_225 = _grouped_mm_227 = None
        convert_element_type_3257 = torch.ops.prims.convert_element_type.default(_grouped_mm_224, torch.float32);  _grouped_mm_224 = None
        div_276 = torch.ops.aten.div.Tensor(convert_element_type_3257, 128);  convert_element_type_3257 = None
        split_1429 = torch.ops.aten.split.Tensor(div_276, 88, 1);  div_276 = None
        getitem_26885 = split_1429[0]
        getitem_26902 = split_1429[1]
        getitem_26919 = split_1429[2]
        getitem_26936 = split_1429[3]
        getitem_26953 = split_1429[4]
        getitem_26970 = split_1429[5]
        getitem_26987 = split_1429[6]
        getitem_27004 = split_1429[7]
        getitem_27021 = split_1429[8]
        getitem_27038 = split_1429[9]
        getitem_27055 = split_1429[10]
        getitem_27072 = split_1429[11]
        getitem_27089 = split_1429[12]
        getitem_27106 = split_1429[13]
        getitem_27123 = split_1429[14]
        getitem_27140 = split_1429[15];  split_1429 = None
        cat_428 = torch.ops.aten.cat.default([getitem_26885, getitem_26902, getitem_26919, getitem_26936, getitem_26953, getitem_26970, getitem_26987, getitem_27004, getitem_27021, getitem_27038, getitem_27055, getitem_27072, getitem_27089, getitem_27106, getitem_27123, getitem_27140]);  getitem_26885 = getitem_26902 = getitem_26919 = getitem_26936 = getitem_26953 = getitem_26970 = getitem_26987 = getitem_27004 = getitem_27021 = getitem_27038 = getitem_27055 = getitem_27072 = getitem_27089 = getitem_27106 = getitem_27123 = getitem_27140 = None
        reduce_scatter_tensor_341 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_428, 'sum', 16, '1025');  cat_428 = None
        wait_tensor_949 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_341);  reduce_scatter_tensor_341 = None
        convert_element_type_3258 = torch.ops.prims.convert_element_type.default(_grouped_mm_222, torch.float32);  _grouped_mm_222 = None
        div_277 = torch.ops.aten.div.Tensor(convert_element_type_3258, 128);  convert_element_type_3258 = None
        split_1446 = torch.ops.aten.split.Tensor(div_277, 128, 1);  div_277 = None
        getitem_27157 = split_1446[0]
        getitem_27174 = split_1446[1]
        getitem_27191 = split_1446[2]
        getitem_27208 = split_1446[3]
        getitem_27225 = split_1446[4]
        getitem_27242 = split_1446[5]
        getitem_27259 = split_1446[6]
        getitem_27276 = split_1446[7]
        getitem_27293 = split_1446[8]
        getitem_27310 = split_1446[9]
        getitem_27327 = split_1446[10]
        getitem_27344 = split_1446[11]
        getitem_27361 = split_1446[12]
        getitem_27378 = split_1446[13]
        getitem_27395 = split_1446[14]
        getitem_27412 = split_1446[15];  split_1446 = None
        cat_429 = torch.ops.aten.cat.default([getitem_27157, getitem_27174, getitem_27191, getitem_27208, getitem_27225, getitem_27242, getitem_27259, getitem_27276, getitem_27293, getitem_27310, getitem_27327, getitem_27344, getitem_27361, getitem_27378, getitem_27395, getitem_27412]);  getitem_27157 = getitem_27174 = getitem_27191 = getitem_27208 = getitem_27225 = getitem_27242 = getitem_27259 = getitem_27276 = getitem_27293 = getitem_27310 = getitem_27327 = getitem_27344 = getitem_27361 = getitem_27378 = getitem_27395 = getitem_27412 = None
        reduce_scatter_tensor_342 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_429, 'sum', 16, '1025');  cat_429 = None
        wait_tensor_950 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_342);  reduce_scatter_tensor_342 = None
        convert_element_type_3259 = torch.ops.prims.convert_element_type.default(_grouped_mm_226, torch.float32);  _grouped_mm_226 = None
        div_278 = torch.ops.aten.div.Tensor(convert_element_type_3259, 128);  convert_element_type_3259 = None
        split_1463 = torch.ops.aten.split.Tensor(div_278, 88, 1);  div_278 = None
        getitem_27429 = split_1463[0]
        getitem_27446 = split_1463[1]
        getitem_27463 = split_1463[2]
        getitem_27480 = split_1463[3]
        getitem_27497 = split_1463[4]
        getitem_27514 = split_1463[5]
        getitem_27531 = split_1463[6]
        getitem_27548 = split_1463[7]
        getitem_27565 = split_1463[8]
        getitem_27582 = split_1463[9]
        getitem_27599 = split_1463[10]
        getitem_27616 = split_1463[11]
        getitem_27633 = split_1463[12]
        getitem_27650 = split_1463[13]
        getitem_27667 = split_1463[14]
        getitem_27684 = split_1463[15];  split_1463 = None
        cat_430 = torch.ops.aten.cat.default([getitem_27429, getitem_27446, getitem_27463, getitem_27480, getitem_27497, getitem_27514, getitem_27531, getitem_27548, getitem_27565, getitem_27582, getitem_27599, getitem_27616, getitem_27633, getitem_27650, getitem_27667, getitem_27684]);  getitem_27429 = getitem_27446 = getitem_27463 = getitem_27480 = getitem_27497 = getitem_27514 = getitem_27531 = getitem_27548 = getitem_27565 = getitem_27582 = getitem_27599 = getitem_27616 = getitem_27633 = getitem_27650 = getitem_27667 = getitem_27684 = None
        reduce_scatter_tensor_343 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_430, 'sum', 16, '1025');  cat_430 = None
        wait_tensor_951 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_343);  reduce_scatter_tensor_343 = None
        index_put_100 = torch.ops.aten.index_put.default(full_492, [getitem_132], add_2140, True);  full_492 = getitem_132 = add_2140 = None
        slice_306 = torch.ops.aten.slice.Tensor(index_put_100, 0, 0, add_2141);  index_put_100 = add_2141 = None
        all_to_all_single_127 = torch.ops._c10d_functional.all_to_all_single.default(slice_306, [_local_scalar_dense_16, _local_scalar_dense_17, _local_scalar_dense_18, _local_scalar_dense_19, _local_scalar_dense_20, _local_scalar_dense_21, _local_scalar_dense_22, _local_scalar_dense_23], [_local_scalar_dense_24, _local_scalar_dense_25, _local_scalar_dense_26, _local_scalar_dense_27, _local_scalar_dense_28, _local_scalar_dense_29, _local_scalar_dense_30, _local_scalar_dense_31], '1033');  slice_306 = _local_scalar_dense_16 = _local_scalar_dense_17 = _local_scalar_dense_18 = _local_scalar_dense_19 = _local_scalar_dense_20 = _local_scalar_dense_21 = _local_scalar_dense_22 = _local_scalar_dense_23 = _local_scalar_dense_24 = _local_scalar_dense_25 = _local_scalar_dense_26 = _local_scalar_dense_27 = _local_scalar_dense_28 = _local_scalar_dense_29 = _local_scalar_dense_30 = _local_scalar_dense_31 = None
        wait_tensor_952 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_127);  all_to_all_single_127 = None
        index_put_101 = torch.ops.aten.index_put.default(full_default_52, [div_7], wait_tensor_952, True);  div_7 = wait_tensor_952 = None
        add_2145 = torch.ops.aten.add.Tensor(add_2137, index_put_101);  add_2137 = index_put_101 = None
        mul_2119 = torch.ops.aten.mul.Tensor(view_2239, 1.0);  view_2239 = None
        scatter_add_24 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_129, mul_2119);  getitem_129 = mul_2119 = None
        convert_element_type_119 = torch.ops.prims.convert_element_type.default(mm_19, torch.float32);  mm_19 = None
        sub_24 = torch.ops.aten.sub.Tensor(convert_element_type_119, amax_1);  convert_element_type_119 = amax_1 = None
        exp_4 = torch.ops.aten.exp.default(sub_24);  sub_24 = None
        div_6 = torch.ops.aten.div.Tensor(exp_4, sum_5);  exp_4 = sum_5 = None
        mul_2120 = torch.ops.aten.mul.Tensor(scatter_add_24, div_6);  scatter_add_24 = None
        sum_299 = torch.ops.aten.sum.dim_IntList(mul_2120, [1], True)
        neg_127 = torch.ops.aten.neg.default(div_6);  div_6 = None
        fma_24 = torch.ops.prims.fma.default(neg_127, sum_299, mul_2120);  neg_127 = sum_299 = mul_2120 = None
        convert_element_type_3260 = torch.ops.prims.convert_element_type.default(fma_24, torch.bfloat16);  fma_24 = None
        permute_1632 = torch.ops.aten.permute.default(convert_element_type_3260, [1, 0])
        mm_608 = torch.ops.aten.mm.default(permute_1632, view_125);  permute_1632 = view_125 = None
        convert_element_type_116 = torch.ops.prims.convert_element_type.default(primals_47, torch.bfloat16);  primals_47 = None
        all_gather_into_tensor_35 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_116, 128, '0');  convert_element_type_116 = None
        wait_tensor_39 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_35);  all_gather_into_tensor_35 = None
        slice_15 = torch.ops.aten.slice.Tensor(wait_tensor_39, 0, 0, 64);  wait_tensor_39 = None
        permute_34 = torch.ops.aten.permute.default(slice_15, [1, 0]);  slice_15 = None
        permute_1634 = torch.ops.aten.permute.default(permute_34, [1, 0]);  permute_34 = None
        mm_609 = torch.ops.aten.mm.default(convert_element_type_3260, permute_1634);  convert_element_type_3260 = permute_1634 = None
        add_2146 = torch.ops.aten.add.Tensor(add_2145, mm_609);  add_2145 = mm_609 = None
        convert_element_type_3265 = torch.ops.prims.convert_element_type.default(mm_608, torch.float32);  mm_608 = None
        split_1479 = torch.ops.aten.split.Tensor(convert_element_type_3265, 1);  convert_element_type_3265 = None
        getitem_27685 = split_1479[0]
        getitem_27686 = split_1479[1]
        getitem_27687 = split_1479[2]
        getitem_27688 = split_1479[3]
        getitem_27689 = split_1479[4]
        getitem_27690 = split_1479[5]
        getitem_27691 = split_1479[6]
        getitem_27692 = split_1479[7]
        getitem_27693 = split_1479[8]
        getitem_27694 = split_1479[9]
        getitem_27695 = split_1479[10]
        getitem_27696 = split_1479[11]
        getitem_27697 = split_1479[12]
        getitem_27698 = split_1479[13]
        getitem_27699 = split_1479[14]
        getitem_27700 = split_1479[15]
        getitem_27701 = split_1479[16]
        getitem_27702 = split_1479[17]
        getitem_27703 = split_1479[18]
        getitem_27704 = split_1479[19]
        getitem_27705 = split_1479[20]
        getitem_27706 = split_1479[21]
        getitem_27707 = split_1479[22]
        getitem_27708 = split_1479[23]
        getitem_27709 = split_1479[24]
        getitem_27710 = split_1479[25]
        getitem_27711 = split_1479[26]
        getitem_27712 = split_1479[27]
        getitem_27713 = split_1479[28]
        getitem_27714 = split_1479[29]
        getitem_27715 = split_1479[30]
        getitem_27716 = split_1479[31]
        getitem_27717 = split_1479[32]
        getitem_27718 = split_1479[33]
        getitem_27719 = split_1479[34]
        getitem_27720 = split_1479[35]
        getitem_27721 = split_1479[36]
        getitem_27722 = split_1479[37]
        getitem_27723 = split_1479[38]
        getitem_27724 = split_1479[39]
        getitem_27725 = split_1479[40]
        getitem_27726 = split_1479[41]
        getitem_27727 = split_1479[42]
        getitem_27728 = split_1479[43]
        getitem_27729 = split_1479[44]
        getitem_27730 = split_1479[45]
        getitem_27731 = split_1479[46]
        getitem_27732 = split_1479[47]
        getitem_27733 = split_1479[48]
        getitem_27734 = split_1479[49]
        getitem_27735 = split_1479[50]
        getitem_27736 = split_1479[51]
        getitem_27737 = split_1479[52]
        getitem_27738 = split_1479[53]
        getitem_27739 = split_1479[54]
        getitem_27740 = split_1479[55]
        getitem_27741 = split_1479[56]
        getitem_27742 = split_1479[57]
        getitem_27743 = split_1479[58]
        getitem_27744 = split_1479[59]
        getitem_27745 = split_1479[60]
        getitem_27746 = split_1479[61]
        getitem_27747 = split_1479[62]
        getitem_27748 = split_1479[63];  split_1479 = None
        cat_431 = torch.ops.aten.cat.default([getitem_27685, getitem_27686, getitem_27687, getitem_27688, getitem_27689, getitem_27690, getitem_27691, getitem_27692, getitem_27693, getitem_27694, getitem_27695, getitem_27696, getitem_27697, getitem_27698, getitem_27699, getitem_27700, getitem_27701, getitem_27702, getitem_27703, getitem_27704, getitem_27705, getitem_27706, getitem_27707, getitem_27708, getitem_27709, getitem_27710, getitem_27711, getitem_27712, getitem_27713, getitem_27714, getitem_27715, getitem_27716, getitem_27717, getitem_27718, getitem_27719, getitem_27720, getitem_27721, getitem_27722, getitem_27723, getitem_27724, getitem_27725, getitem_27726, getitem_27727, getitem_27728, getitem_27729, getitem_27730, getitem_27731, getitem_27732, getitem_27733, getitem_27734, getitem_27735, getitem_27736, getitem_27737, getitem_27738, getitem_27739, getitem_27740, getitem_27741, getitem_27742, getitem_27743, getitem_27744, getitem_27745, getitem_27746, getitem_27747, getitem_27748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_27685 = getitem_27686 = getitem_27687 = getitem_27688 = getitem_27689 = getitem_27690 = getitem_27691 = getitem_27692 = getitem_27693 = getitem_27694 = getitem_27695 = getitem_27696 = getitem_27697 = getitem_27698 = getitem_27699 = getitem_27700 = getitem_27701 = getitem_27702 = getitem_27703 = getitem_27704 = getitem_27705 = getitem_27706 = getitem_27707 = getitem_27708 = getitem_27709 = getitem_27710 = getitem_27711 = getitem_27712 = getitem_27713 = getitem_27714 = getitem_27715 = getitem_27716 = getitem_27717 = getitem_27718 = getitem_27719 = getitem_27720 = getitem_27721 = getitem_27722 = getitem_27723 = getitem_27724 = getitem_27725 = getitem_27726 = getitem_27727 = getitem_27728 = getitem_27729 = getitem_27730 = getitem_27731 = getitem_27732 = getitem_27733 = getitem_27734 = getitem_27735 = getitem_27736 = getitem_27737 = getitem_27738 = getitem_27739 = getitem_27740 = getitem_27741 = getitem_27742 = getitem_27743 = getitem_27744 = getitem_27745 = getitem_27746 = getitem_27747 = getitem_27748 = None
        reduce_scatter_tensor_344 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_431, 'avg', 128, '0');  cat_431 = None
        wait_tensor_953 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_344);  reduce_scatter_tensor_344 = None
        view_2241 = torch.ops.aten.view.default(add_2146, [2, 4096, 2048]);  add_2146 = None
        convert_element_type_3266 = torch.ops.prims.convert_element_type.default(view_2241, torch.float32);  view_2241 = None
        convert_element_type_113 = torch.ops.prims.convert_element_type.default(primals_45, torch.bfloat16);  primals_45 = None
        all_gather_into_tensor_34 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_113, 128, '0');  convert_element_type_113 = None
        wait_tensor_38 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_34);  all_gather_into_tensor_34 = None
        convert_element_type_3268 = torch.ops.prims.convert_element_type.default(wait_tensor_38, torch.float32);  wait_tensor_38 = None
        mul_2121 = torch.ops.aten.mul.Tensor(convert_element_type_3266, convert_element_type_3268);  convert_element_type_3268 = None
        convert_element_type_114 = torch.ops.prims.convert_element_type.default(add_76, torch.float32);  add_76 = None
        mul_64 = torch.ops.aten.mul.Tensor(convert_element_type_114, rsqrt_8);  convert_element_type_114 = None
        mul_2123 = torch.ops.aten.mul.Tensor(mul_64, mul_2121)
        sum_300 = torch.ops.aten.sum.dim_IntList(mul_2123, [2], True);  mul_2123 = None
        div_279 = torch.ops.aten.div.Tensor(mul_64, 2048)
        mul_2124 = torch.ops.aten.mul.Tensor(div_279, sum_300);  div_279 = sum_300 = None
        sub_772 = torch.ops.aten.sub.Tensor(mul_2121, mul_2124);  mul_2121 = mul_2124 = None
        mul_2125 = torch.ops.aten.mul.Tensor(sub_772, rsqrt_8);  sub_772 = rsqrt_8 = None
        mul_2126 = torch.ops.aten.mul.Tensor(convert_element_type_3266, mul_64);  convert_element_type_3266 = mul_64 = None
        sum_301 = torch.ops.aten.sum.dim_IntList(mul_2126, [0, 1]);  mul_2126 = None
        convert_element_type_3269 = torch.ops.prims.convert_element_type.default(mul_2125, torch.bfloat16);  mul_2125 = None
        add_2147 = torch.ops.aten.add.Tensor(add_2134, convert_element_type_3269);  add_2134 = convert_element_type_3269 = None
        convert_element_type_default_9 = torch.ops.prims.convert_element_type.default(sum_301, torch.float32);  sum_301 = None
        reduce_scatter_tensor_345 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_9, 'avg', 128, '0');  convert_element_type_default_9 = None
        wait_tensor_954 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_345);  reduce_scatter_tensor_345 = None
        view_2242 = torch.ops.aten.view.default(add_2147, [8192, 2048])
        permute_1636 = torch.ops.aten.permute.default(view_2242, [1, 0])
        permute_32 = torch.ops.aten.permute.default(getitem_125, [0, 2, 1, 3])
        view_120 = torch.ops.aten.view.default(permute_32, [2, 4096, -1]);  permute_32 = None
        view_122 = torch.ops.aten.view.default(view_120, [8192, 2048]);  view_120 = None
        mm_610 = torch.ops.aten.mm.default(permute_1636, view_122);  permute_1636 = view_122 = None
        convert_element_type_110 = torch.ops.prims.convert_element_type.default(primals_44, torch.bfloat16);  primals_44 = None
        all_gather_into_tensor_33 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_110, 128, '0');  convert_element_type_110 = None
        wait_tensor_37 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_33);  all_gather_into_tensor_33 = None
        permute_33 = torch.ops.aten.permute.default(wait_tensor_37, [1, 0]);  wait_tensor_37 = None
        permute_1638 = torch.ops.aten.permute.default(permute_33, [1, 0]);  permute_33 = None
        mm_611 = torch.ops.aten.mm.default(view_2242, permute_1638);  view_2242 = permute_1638 = None
        view_2243 = torch.ops.aten.view.default(mm_611, [2, 4096, 2048]);  mm_611 = None
        convert_element_type_3276 = torch.ops.prims.convert_element_type.default(mm_610, torch.float32);  mm_610 = None
        reduce_scatter_tensor_346 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3276, 'avg', 128, '0');  convert_element_type_3276 = None
        wait_tensor_955 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_346);  reduce_scatter_tensor_346 = None
        view_2244 = torch.ops.aten.view.default(view_2243, [2, 4096, 16, 128]);  view_2243 = None
        permute_1640 = torch.ops.aten.permute.default(view_2244, [0, 2, 1, 3]);  view_2244 = None
        fw_graph24 = self.fw_graph24
        joint_graph24 = self.joint_graph24
        mask_graph24 = self.mask_graph24
        flex_attention_backward_24 = torch.ops.higher_order.flex_attention_backward(permute_29, permute_30, permute_31, getitem_125, getitem_126, permute_1640, None, fw_graph24, joint_graph24, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph24), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_29 = permute_30 = permute_31 = getitem_125 = getitem_126 = permute_1640 = fw_graph24 = joint_graph24 = mask_graph24 = None
        getitem_27749 = flex_attention_backward_24[0]
        getitem_27750 = flex_attention_backward_24[1]
        getitem_27751 = flex_attention_backward_24[2];  flex_attention_backward_24 = None
        permute_1641 = torch.ops.aten.permute.default(getitem_27751, [0, 2, 1, 3]);  getitem_27751 = None
        permute_1642 = torch.ops.aten.permute.default(getitem_27750, [0, 2, 1, 3]);  getitem_27750 = None
        permute_1643 = torch.ops.aten.permute.default(getitem_27749, [0, 2, 1, 3]);  getitem_27749 = None
        slice_308 = torch.ops.aten.slice.Tensor(permute_1642, 3, 0, 128)
        slice_309 = torch.ops.aten.slice.Tensor(permute_1642, 3, 128, 192);  permute_1642 = None
        sum_302 = torch.ops.aten.sum.dim_IntList(slice_309, [2], True);  slice_309 = None
        cat_432 = torch.ops.aten.cat.default([slice_308, permute_1641], 3);  slice_308 = permute_1641 = None
        view_2245 = torch.ops.aten.view.default(cat_432, [2, 4096, 4096]);  cat_432 = None
        view_2246 = torch.ops.aten.view.default(view_2245, [8192, 4096]);  view_2245 = None
        permute_1644 = torch.ops.aten.permute.default(view_2246, [1, 0])
        mm_612 = torch.ops.aten.mm.default(permute_1644, view_117);  permute_1644 = view_117 = None
        convert_element_type_107 = torch.ops.prims.convert_element_type.default(primals_43, torch.bfloat16);  primals_43 = None
        all_gather_into_tensor_32 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_107, 128, '0');  convert_element_type_107 = None
        wait_tensor_36 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_32);  all_gather_into_tensor_32 = None
        permute_28 = torch.ops.aten.permute.default(wait_tensor_36, [1, 0]);  wait_tensor_36 = None
        permute_1646 = torch.ops.aten.permute.default(permute_28, [1, 0]);  permute_28 = None
        mm_613 = torch.ops.aten.mm.default(view_2246, permute_1646);  view_2246 = permute_1646 = None
        view_2247 = torch.ops.aten.view.default(mm_613, [2, 4096, 512]);  mm_613 = None
        convert_element_type_3281 = torch.ops.prims.convert_element_type.default(mm_612, torch.float32);  mm_612 = None
        reduce_scatter_tensor_347 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3281, 'avg', 128, '0');  convert_element_type_3281 = None
        wait_tensor_956 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_347);  reduce_scatter_tensor_347 = None
        convert_element_type_3282 = torch.ops.prims.convert_element_type.default(view_2247, torch.float32);  view_2247 = None
        convert_element_type_104 = torch.ops.prims.convert_element_type.default(primals_42, torch.bfloat16);  primals_42 = None
        all_gather_into_tensor_31 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_104, 128, '0');  convert_element_type_104 = None
        wait_tensor_35 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_31);  all_gather_into_tensor_31 = None
        convert_element_type_3284 = torch.ops.prims.convert_element_type.default(wait_tensor_35, torch.float32);  wait_tensor_35 = None
        mul_2127 = torch.ops.aten.mul.Tensor(convert_element_type_3282, convert_element_type_3284);  convert_element_type_3284 = None
        convert_element_type_105 = torch.ops.prims.convert_element_type.default(getitem_121, torch.float32);  getitem_121 = None
        mul_62 = torch.ops.aten.mul.Tensor(convert_element_type_105, rsqrt_7);  convert_element_type_105 = None
        mul_2129 = torch.ops.aten.mul.Tensor(mul_62, mul_2127)
        sum_303 = torch.ops.aten.sum.dim_IntList(mul_2129, [2], True);  mul_2129 = None
        div_280 = torch.ops.aten.div.Tensor(mul_62, 512)
        mul_2130 = torch.ops.aten.mul.Tensor(div_280, sum_303);  div_280 = sum_303 = None
        sub_773 = torch.ops.aten.sub.Tensor(mul_2127, mul_2130);  mul_2127 = mul_2130 = None
        mul_2131 = torch.ops.aten.mul.Tensor(sub_773, rsqrt_7);  sub_773 = rsqrt_7 = None
        mul_2132 = torch.ops.aten.mul.Tensor(convert_element_type_3282, mul_62);  convert_element_type_3282 = mul_62 = None
        sum_304 = torch.ops.aten.sum.dim_IntList(mul_2132, [0, 1]);  mul_2132 = None
        convert_element_type_3285 = torch.ops.prims.convert_element_type.default(mul_2131, torch.bfloat16);  mul_2131 = None
        convert_element_type_default_8 = torch.ops.prims.convert_element_type.default(sum_304, torch.float32);  sum_304 = None
        reduce_scatter_tensor_348 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_8, 'avg', 128, '0');  convert_element_type_default_8 = None
        wait_tensor_957 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_348);  reduce_scatter_tensor_348 = None
        convert_element_type_3288 = torch.ops.prims.convert_element_type.default(sum_302, torch.float32);  sum_302 = None
        view_2248 = torch.ops.aten.view.default(convert_element_type_3288, [2, 4096, 1, 32, 2]);  convert_element_type_3288 = None
        view_as_complex_102 = torch.ops.aten.view_as_complex.default(view_2248);  view_2248 = None
        mul_2133 = torch.ops.aten.mul.Tensor(view_as_complex_102, clone_9);  view_as_complex_102 = None
        view_as_real_102 = torch.ops.aten.view_as_real.default(mul_2133);  mul_2133 = None
        view_2249 = torch.ops.aten.view.default(view_as_real_102, [2, 4096, 1, 64]);  view_as_real_102 = None
        convert_element_type_3289 = torch.ops.prims.convert_element_type.default(view_2249, torch.bfloat16);  view_2249 = None
        squeeze_50 = torch.ops.aten.squeeze.dim(convert_element_type_3289, 2);  convert_element_type_3289 = None
        cat_433 = torch.ops.aten.cat.default([convert_element_type_3285, squeeze_50], 2);  convert_element_type_3285 = squeeze_50 = None
        view_2250 = torch.ops.aten.view.default(cat_433, [8192, 576]);  cat_433 = None
        permute_1648 = torch.ops.aten.permute.default(view_2250, [1, 0])
        mm_614 = torch.ops.aten.mm.default(permute_1648, view_103);  permute_1648 = None
        convert_element_type_99 = torch.ops.prims.convert_element_type.default(primals_41, torch.bfloat16);  primals_41 = None
        all_gather_into_tensor_30 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_99, 128, '0');  convert_element_type_99 = None
        wait_tensor_34 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_30);  all_gather_into_tensor_30 = None
        slice_13 = torch.ops.aten.slice.Tensor(wait_tensor_34, 0, 0, 576);  wait_tensor_34 = None
        permute_27 = torch.ops.aten.permute.default(slice_13, [1, 0]);  slice_13 = None
        permute_1650 = torch.ops.aten.permute.default(permute_27, [1, 0]);  permute_27 = None
        mm_615 = torch.ops.aten.mm.default(view_2250, permute_1650);  view_2250 = permute_1650 = None
        view_2251 = torch.ops.aten.view.default(mm_615, [2, 4096, 2048]);  mm_615 = None
        convert_element_type_3294 = torch.ops.prims.convert_element_type.default(mm_614, torch.float32);  mm_614 = None
        split_1480 = torch.ops.aten.split.Tensor(convert_element_type_3294, 5);  convert_element_type_3294 = None
        getitem_27753 = split_1480[0]
        getitem_27754 = split_1480[1]
        getitem_27755 = split_1480[2]
        getitem_27756 = split_1480[3]
        getitem_27757 = split_1480[4]
        getitem_27758 = split_1480[5]
        getitem_27759 = split_1480[6]
        getitem_27760 = split_1480[7]
        getitem_27761 = split_1480[8]
        getitem_27762 = split_1480[9]
        getitem_27763 = split_1480[10]
        getitem_27764 = split_1480[11]
        getitem_27765 = split_1480[12]
        getitem_27766 = split_1480[13]
        getitem_27767 = split_1480[14]
        getitem_27768 = split_1480[15]
        getitem_27769 = split_1480[16]
        getitem_27770 = split_1480[17]
        getitem_27771 = split_1480[18]
        getitem_27772 = split_1480[19]
        getitem_27773 = split_1480[20]
        getitem_27774 = split_1480[21]
        getitem_27775 = split_1480[22]
        getitem_27776 = split_1480[23]
        getitem_27777 = split_1480[24]
        getitem_27778 = split_1480[25]
        getitem_27779 = split_1480[26]
        getitem_27780 = split_1480[27]
        getitem_27781 = split_1480[28]
        getitem_27782 = split_1480[29]
        getitem_27783 = split_1480[30]
        getitem_27784 = split_1480[31]
        getitem_27785 = split_1480[32]
        getitem_27786 = split_1480[33]
        getitem_27787 = split_1480[34]
        getitem_27788 = split_1480[35]
        getitem_27789 = split_1480[36]
        getitem_27790 = split_1480[37]
        getitem_27791 = split_1480[38]
        getitem_27792 = split_1480[39]
        getitem_27793 = split_1480[40]
        getitem_27794 = split_1480[41]
        getitem_27795 = split_1480[42]
        getitem_27796 = split_1480[43]
        getitem_27797 = split_1480[44]
        getitem_27798 = split_1480[45]
        getitem_27799 = split_1480[46]
        getitem_27800 = split_1480[47]
        getitem_27801 = split_1480[48]
        getitem_27802 = split_1480[49]
        getitem_27803 = split_1480[50]
        getitem_27804 = split_1480[51]
        getitem_27805 = split_1480[52]
        getitem_27806 = split_1480[53]
        getitem_27807 = split_1480[54]
        getitem_27808 = split_1480[55]
        getitem_27809 = split_1480[56]
        getitem_27810 = split_1480[57]
        getitem_27811 = split_1480[58]
        getitem_27812 = split_1480[59]
        getitem_27813 = split_1480[60]
        getitem_27814 = split_1480[61]
        getitem_27815 = split_1480[62]
        getitem_27816 = split_1480[63]
        getitem_27817 = split_1480[64]
        getitem_27818 = split_1480[65]
        getitem_27819 = split_1480[66]
        getitem_27820 = split_1480[67]
        getitem_27821 = split_1480[68]
        getitem_27822 = split_1480[69]
        getitem_27823 = split_1480[70]
        getitem_27824 = split_1480[71]
        getitem_27825 = split_1480[72]
        getitem_27826 = split_1480[73]
        getitem_27827 = split_1480[74]
        getitem_27828 = split_1480[75]
        getitem_27829 = split_1480[76]
        getitem_27830 = split_1480[77]
        getitem_27831 = split_1480[78]
        getitem_27832 = split_1480[79]
        getitem_27833 = split_1480[80]
        getitem_27834 = split_1480[81]
        getitem_27835 = split_1480[82]
        getitem_27836 = split_1480[83]
        getitem_27837 = split_1480[84]
        getitem_27838 = split_1480[85]
        getitem_27839 = split_1480[86]
        getitem_27840 = split_1480[87]
        getitem_27841 = split_1480[88]
        getitem_27842 = split_1480[89]
        getitem_27843 = split_1480[90]
        getitem_27844 = split_1480[91]
        getitem_27845 = split_1480[92]
        getitem_27846 = split_1480[93]
        getitem_27847 = split_1480[94]
        getitem_27848 = split_1480[95]
        getitem_27849 = split_1480[96]
        getitem_27850 = split_1480[97]
        getitem_27851 = split_1480[98]
        getitem_27852 = split_1480[99]
        getitem_27853 = split_1480[100]
        getitem_27854 = split_1480[101]
        getitem_27855 = split_1480[102]
        getitem_27856 = split_1480[103]
        getitem_27857 = split_1480[104]
        getitem_27858 = split_1480[105]
        getitem_27859 = split_1480[106]
        getitem_27860 = split_1480[107]
        getitem_27861 = split_1480[108]
        getitem_27862 = split_1480[109]
        getitem_27863 = split_1480[110]
        getitem_27864 = split_1480[111]
        getitem_27865 = split_1480[112]
        getitem_27866 = split_1480[113]
        getitem_27867 = split_1480[114]
        getitem_27868 = split_1480[115];  split_1480 = None
        constant_pad_nd_1912 = torch.ops.aten.constant_pad_nd.default(getitem_27868, [0, 0, 0, 4], 0.0);  getitem_27868 = None
        cat_434 = torch.ops.aten.cat.default([getitem_27753, getitem_27754, getitem_27755, getitem_27756, getitem_27757, getitem_27758, getitem_27759, getitem_27760, getitem_27761, getitem_27762, getitem_27763, getitem_27764, getitem_27765, getitem_27766, getitem_27767, getitem_27768, getitem_27769, getitem_27770, getitem_27771, getitem_27772, getitem_27773, getitem_27774, getitem_27775, getitem_27776, getitem_27777, getitem_27778, getitem_27779, getitem_27780, getitem_27781, getitem_27782, getitem_27783, getitem_27784, getitem_27785, getitem_27786, getitem_27787, getitem_27788, getitem_27789, getitem_27790, getitem_27791, getitem_27792, getitem_27793, getitem_27794, getitem_27795, getitem_27796, getitem_27797, getitem_27798, getitem_27799, getitem_27800, getitem_27801, getitem_27802, getitem_27803, getitem_27804, getitem_27805, getitem_27806, getitem_27807, getitem_27808, getitem_27809, getitem_27810, getitem_27811, getitem_27812, getitem_27813, getitem_27814, getitem_27815, getitem_27816, getitem_27817, getitem_27818, getitem_27819, getitem_27820, getitem_27821, getitem_27822, getitem_27823, getitem_27824, getitem_27825, getitem_27826, getitem_27827, getitem_27828, getitem_27829, getitem_27830, getitem_27831, getitem_27832, getitem_27833, getitem_27834, getitem_27835, getitem_27836, getitem_27837, getitem_27838, getitem_27839, getitem_27840, getitem_27841, getitem_27842, getitem_27843, getitem_27844, getitem_27845, getitem_27846, getitem_27847, getitem_27848, getitem_27849, getitem_27850, getitem_27851, getitem_27852, getitem_27853, getitem_27854, getitem_27855, getitem_27856, getitem_27857, getitem_27858, getitem_27859, getitem_27860, getitem_27861, getitem_27862, getitem_27863, getitem_27864, getitem_27865, getitem_27866, getitem_27867, constant_pad_nd_1912, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_27753 = getitem_27754 = getitem_27755 = getitem_27756 = getitem_27757 = getitem_27758 = getitem_27759 = getitem_27760 = getitem_27761 = getitem_27762 = getitem_27763 = getitem_27764 = getitem_27765 = getitem_27766 = getitem_27767 = getitem_27768 = getitem_27769 = getitem_27770 = getitem_27771 = getitem_27772 = getitem_27773 = getitem_27774 = getitem_27775 = getitem_27776 = getitem_27777 = getitem_27778 = getitem_27779 = getitem_27780 = getitem_27781 = getitem_27782 = getitem_27783 = getitem_27784 = getitem_27785 = getitem_27786 = getitem_27787 = getitem_27788 = getitem_27789 = getitem_27790 = getitem_27791 = getitem_27792 = getitem_27793 = getitem_27794 = getitem_27795 = getitem_27796 = getitem_27797 = getitem_27798 = getitem_27799 = getitem_27800 = getitem_27801 = getitem_27802 = getitem_27803 = getitem_27804 = getitem_27805 = getitem_27806 = getitem_27807 = getitem_27808 = getitem_27809 = getitem_27810 = getitem_27811 = getitem_27812 = getitem_27813 = getitem_27814 = getitem_27815 = getitem_27816 = getitem_27817 = getitem_27818 = getitem_27819 = getitem_27820 = getitem_27821 = getitem_27822 = getitem_27823 = getitem_27824 = getitem_27825 = getitem_27826 = getitem_27827 = getitem_27828 = getitem_27829 = getitem_27830 = getitem_27831 = getitem_27832 = getitem_27833 = getitem_27834 = getitem_27835 = getitem_27836 = getitem_27837 = getitem_27838 = getitem_27839 = getitem_27840 = getitem_27841 = getitem_27842 = getitem_27843 = getitem_27844 = getitem_27845 = getitem_27846 = getitem_27847 = getitem_27848 = getitem_27849 = getitem_27850 = getitem_27851 = getitem_27852 = getitem_27853 = getitem_27854 = getitem_27855 = getitem_27856 = getitem_27857 = getitem_27858 = getitem_27859 = getitem_27860 = getitem_27861 = getitem_27862 = getitem_27863 = getitem_27864 = getitem_27865 = getitem_27866 = getitem_27867 = constant_pad_nd_1912 = None
        reduce_scatter_tensor_349 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_434, 'avg', 128, '0');  cat_434 = None
        wait_tensor_958 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_349);  reduce_scatter_tensor_349 = None
        slice_310 = torch.ops.aten.slice.Tensor(permute_1643, 3, 0, 128)
        slice_311 = torch.ops.aten.slice.Tensor(permute_1643, 3, 128, 192);  permute_1643 = None
        convert_element_type_3295 = torch.ops.prims.convert_element_type.default(slice_311, torch.float32);  slice_311 = None
        view_2252 = torch.ops.aten.view.default(convert_element_type_3295, [2, 4096, 16, 32, 2]);  convert_element_type_3295 = None
        view_as_complex_103 = torch.ops.aten.view_as_complex.default(view_2252);  view_2252 = None
        mul_2134 = torch.ops.aten.mul.Tensor(view_as_complex_103, clone_9);  view_as_complex_103 = None
        view_as_real_103 = torch.ops.aten.view_as_real.default(mul_2134);  mul_2134 = None
        view_2253 = torch.ops.aten.view.default(view_as_real_103, [2, 4096, 16, 64]);  view_as_real_103 = None
        convert_element_type_3296 = torch.ops.prims.convert_element_type.default(view_2253, torch.bfloat16);  view_2253 = None
        cat_435 = torch.ops.aten.cat.default([slice_310, convert_element_type_3296], 3);  slice_310 = convert_element_type_3296 = None
        view_2254 = torch.ops.aten.view.default(cat_435, [2, 4096, 3072]);  cat_435 = None
        view_2255 = torch.ops.aten.view.default(view_2254, [8192, 3072]);  view_2254 = None
        permute_1652 = torch.ops.aten.permute.default(view_2255, [1, 0])
        mm_616 = torch.ops.aten.mm.default(permute_1652, view_103);  permute_1652 = view_103 = None
        convert_element_type_94 = torch.ops.prims.convert_element_type.default(primals_40, torch.bfloat16);  primals_40 = None
        all_gather_into_tensor_29 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_94, 128, '0');  convert_element_type_94 = None
        wait_tensor_33 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_29);  all_gather_into_tensor_29 = None
        permute_26 = torch.ops.aten.permute.default(wait_tensor_33, [1, 0]);  wait_tensor_33 = None
        permute_1654 = torch.ops.aten.permute.default(permute_26, [1, 0]);  permute_26 = None
        mm_617 = torch.ops.aten.mm.default(view_2255, permute_1654);  view_2255 = permute_1654 = None
        view_2256 = torch.ops.aten.view.default(mm_617, [2, 4096, 2048]);  mm_617 = None
        add_2148 = torch.ops.aten.add.Tensor(view_2251, view_2256);  view_2251 = view_2256 = None
        convert_element_type_3301 = torch.ops.prims.convert_element_type.default(mm_616, torch.float32);  mm_616 = None
        reduce_scatter_tensor_350 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3301, 'avg', 128, '0');  convert_element_type_3301 = None
        wait_tensor_959 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_350);  reduce_scatter_tensor_350 = None
        convert_element_type_3302 = torch.ops.prims.convert_element_type.default(add_2148, torch.float32);  add_2148 = None
        convert_element_type_91 = torch.ops.prims.convert_element_type.default(primals_39, torch.bfloat16);  primals_39 = None
        all_gather_into_tensor_28 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_91, 128, '0');  convert_element_type_91 = None
        wait_tensor_32 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_28);  all_gather_into_tensor_28 = None
        convert_element_type_3304 = torch.ops.prims.convert_element_type.default(wait_tensor_32, torch.float32);  wait_tensor_32 = None
        mul_2135 = torch.ops.aten.mul.Tensor(convert_element_type_3302, convert_element_type_3304);  convert_element_type_3304 = None
        convert_element_type_92 = torch.ops.prims.convert_element_type.default(add_73, torch.float32);  add_73 = None
        mul_58 = torch.ops.aten.mul.Tensor(convert_element_type_92, rsqrt_6);  convert_element_type_92 = None
        mul_2137 = torch.ops.aten.mul.Tensor(mul_58, mul_2135)
        sum_305 = torch.ops.aten.sum.dim_IntList(mul_2137, [2], True);  mul_2137 = None
        div_281 = torch.ops.aten.div.Tensor(mul_58, 2048)
        mul_2138 = torch.ops.aten.mul.Tensor(div_281, sum_305);  div_281 = sum_305 = None
        sub_774 = torch.ops.aten.sub.Tensor(mul_2135, mul_2138);  mul_2135 = mul_2138 = None
        mul_2139 = torch.ops.aten.mul.Tensor(sub_774, rsqrt_6);  sub_774 = rsqrt_6 = None
        mul_2140 = torch.ops.aten.mul.Tensor(convert_element_type_3302, mul_58);  convert_element_type_3302 = mul_58 = None
        sum_306 = torch.ops.aten.sum.dim_IntList(mul_2140, [0, 1]);  mul_2140 = None
        convert_element_type_3305 = torch.ops.prims.convert_element_type.default(mul_2139, torch.bfloat16);  mul_2139 = None
        add_2149 = torch.ops.aten.add.Tensor(add_2147, convert_element_type_3305);  add_2147 = convert_element_type_3305 = None
        convert_element_type_default_7 = torch.ops.prims.convert_element_type.default(sum_306, torch.float32);  sum_306 = None
        reduce_scatter_tensor_351 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_7, 'avg', 128, '0');  convert_element_type_default_7 = None
        wait_tensor_960 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_351);  reduce_scatter_tensor_351 = None
        view_2257 = torch.ops.aten.view.default(add_2149, [8192, 2048])
        unsqueeze_78 = torch.ops.aten.unsqueeze.default(view_2257, 1)
        convert_element_type_3308 = torch.ops.prims.convert_element_type.default(unsqueeze_78, torch.float32);  unsqueeze_78 = None
        bmm_76 = torch.ops.aten.bmm.default(permute_1656, convert_element_type_3308);  permute_1656 = None
        bmm_77 = torch.ops.aten.bmm.default(convert_element_type_3308, permute_1657);  convert_element_type_3308 = permute_1657 = None
        convert_element_type_3309 = torch.ops.prims.convert_element_type.default(bmm_76, torch.bfloat16);  bmm_76 = None
        view_2258 = torch.ops.aten.view.default(bmm_77, [8192, 6]);  bmm_77 = None
        view_2259 = torch.ops.aten.view.default(convert_element_type_3309, [49152, 2048]);  convert_element_type_3309 = None
        index_102 = torch.ops.aten.index.Tensor(view_2259, [getitem_21]);  view_2259 = getitem_21 = None
        permute_1658 = torch.ops.aten.permute.default(view_2257, [1, 0])
        mm_618 = torch.ops.aten.mm.default(permute_1658, mul_55);  permute_1658 = mul_55 = None
        convert_element_type_86 = torch.ops.prims.convert_element_type.default(primals_38, torch.bfloat16);  primals_38 = None
        all_gather_into_tensor_27 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_86, 128, '0');  convert_element_type_86 = None
        wait_tensor_31 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_27);  all_gather_into_tensor_27 = None
        permute_25 = torch.ops.aten.permute.default(wait_tensor_31, [1, 0]);  wait_tensor_31 = None
        permute_1660 = torch.ops.aten.permute.default(permute_25, [1, 0]);  permute_25 = None
        mm_619 = torch.ops.aten.mm.default(view_2257, permute_1660);  view_2257 = permute_1660 = None
        convert_element_type_3314 = torch.ops.prims.convert_element_type.default(mm_618, torch.float32);  mm_618 = None
        reduce_scatter_tensor_352 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3314, 'avg', 128, '0');  convert_element_type_3314 = None
        wait_tensor_961 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_352);  reduce_scatter_tensor_352 = None
        convert_element_type_81 = torch.ops.prims.convert_element_type.default(mm_12, torch.float32);  mm_12 = None
        neg_2 = torch.ops.aten.neg.default(convert_element_type_81)
        exp_3 = torch.ops.aten.exp.default(neg_2);  neg_2 = None
        add_68 = torch.ops.aten.add.Tensor(exp_3, 1);  exp_3 = None
        div_5 = torch.ops.aten.div.Tensor(convert_element_type_81, add_68)
        convert_element_type_82 = torch.ops.prims.convert_element_type.default(div_5, torch.bfloat16);  div_5 = None
        mul_2141 = torch.ops.aten.mul.Tensor(mm_619, convert_element_type_82);  convert_element_type_82 = None
        mul_2142 = torch.ops.aten.mul.Tensor(mm_619, mm_13);  mm_619 = mm_13 = None
        permute_1662 = torch.ops.aten.permute.default(mul_2141, [1, 0])
        mm_620 = torch.ops.aten.mm.default(permute_1662, view_58);  permute_1662 = None
        convert_element_type_83 = torch.ops.prims.convert_element_type.default(primals_37, torch.bfloat16);  primals_37 = None
        all_gather_into_tensor_26 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_83, 128, '0');  convert_element_type_83 = None
        wait_tensor_30 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_26);  all_gather_into_tensor_26 = None
        permute_24 = torch.ops.aten.permute.default(wait_tensor_30, [1, 0]);  wait_tensor_30 = None
        permute_1664 = torch.ops.aten.permute.default(permute_24, [1, 0]);  permute_24 = None
        mm_621 = torch.ops.aten.mm.default(mul_2141, permute_1664);  mul_2141 = permute_1664 = None
        convert_element_type_3319 = torch.ops.prims.convert_element_type.default(mm_620, torch.float32);  mm_620 = None
        reduce_scatter_tensor_353 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3319, 'avg', 128, '0');  convert_element_type_3319 = None
        wait_tensor_962 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_353);  reduce_scatter_tensor_353 = None
        convert_element_type_3320 = torch.ops.prims.convert_element_type.default(mul_2142, torch.float32);  mul_2142 = None
        reciprocal_50 = torch.ops.aten.reciprocal.default(add_68);  add_68 = None
        mul_2143 = torch.ops.aten.mul.Tensor(reciprocal_50, 1);  reciprocal_50 = None
        mul_2144 = torch.ops.aten.mul.Tensor(convert_element_type_3320, mul_2143);  convert_element_type_3320 = None
        sub_775 = torch.ops.aten.sub.Tensor(1, mul_2143);  mul_2143 = None
        mul_2145 = torch.ops.aten.mul.Tensor(convert_element_type_81, sub_775);  convert_element_type_81 = sub_775 = None
        add_2151 = torch.ops.aten.add.Tensor(mul_2145, 1);  mul_2145 = None
        mul_2146 = torch.ops.aten.mul.Tensor(mul_2144, add_2151);  mul_2144 = add_2151 = None
        convert_element_type_3322 = torch.ops.prims.convert_element_type.default(mul_2146, torch.bfloat16);  mul_2146 = None
        permute_1666 = torch.ops.aten.permute.default(convert_element_type_3322, [1, 0])
        mm_622 = torch.ops.aten.mm.default(permute_1666, view_58);  permute_1666 = None
        convert_element_type_78 = torch.ops.prims.convert_element_type.default(primals_36, torch.bfloat16);  primals_36 = None
        all_gather_into_tensor_25 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_78, 128, '0');  convert_element_type_78 = None
        wait_tensor_29 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_25);  all_gather_into_tensor_25 = None
        permute_23 = torch.ops.aten.permute.default(wait_tensor_29, [1, 0]);  wait_tensor_29 = None
        permute_1668 = torch.ops.aten.permute.default(permute_23, [1, 0]);  permute_23 = None
        mm_623 = torch.ops.aten.mm.default(convert_element_type_3322, permute_1668);  convert_element_type_3322 = permute_1668 = None
        add_2152 = torch.ops.aten.add.Tensor(mm_621, mm_623);  mm_621 = mm_623 = None
        convert_element_type_3327 = torch.ops.prims.convert_element_type.default(mm_622, torch.float32);  mm_622 = None
        reduce_scatter_tensor_354 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3327, 'avg', 128, '0');  convert_element_type_3327 = None
        wait_tensor_963 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_354);  reduce_scatter_tensor_354 = None
        all_to_all_single_128 = torch.ops._c10d_functional.all_to_all_single.default(index_102, [_local_scalar_dense_8, _local_scalar_dense_9, _local_scalar_dense_10, _local_scalar_dense_11, _local_scalar_dense_12, _local_scalar_dense_13, _local_scalar_dense_14, _local_scalar_dense_15], [_local_scalar_dense, _local_scalar_dense_1, _local_scalar_dense_2, _local_scalar_dense_3, _local_scalar_dense_4, _local_scalar_dense_5, _local_scalar_dense_6, _local_scalar_dense_7], '1033');  index_102 = None
        wait_tensor_964 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_128);  all_to_all_single_128 = None
        full_498 = torch.ops.aten.full.default([sym_size_int_1, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False);  sym_size_int_1 = None
        slice_scatter_25 = torch.ops.aten.slice_scatter.default(full_498, wait_tensor_964, 0, 0, -1);  wait_tensor_964 = None
        index_103 = torch.ops.aten.index.Tensor(slice_scatter_25, [getitem_22]);  slice_scatter_25 = None
        permute_1670 = torch.ops.aten.permute.default(index_103, [1, 0])
        _grouped_mm_228 = torch.ops.aten._grouped_mm.default(permute_1670, mul_35, cumsum_2);  permute_1670 = mul_35 = None
        _grouped_mm_229 = torch.ops.aten._grouped_mm.default(index_103, permute_1672, cumsum_2);  index_103 = permute_1672 = None
        convert_element_type_76 = torch.ops.prims.convert_element_type.default(_grouped_mm, torch.float32);  _grouped_mm = None
        neg_1 = torch.ops.aten.neg.default(convert_element_type_76)
        exp_2 = torch.ops.aten.exp.default(neg_1);  neg_1 = None
        add_32 = torch.ops.aten.add.Tensor(exp_2, 1);  exp_2 = None
        div_4 = torch.ops.aten.div.Tensor(convert_element_type_76, add_32)
        convert_element_type_77 = torch.ops.prims.convert_element_type.default(div_4, torch.bfloat16);  div_4 = None
        mul_2147 = torch.ops.aten.mul.Tensor(_grouped_mm_229, convert_element_type_77);  convert_element_type_77 = None
        mul_2148 = torch.ops.aten.mul.Tensor(_grouped_mm_229, _grouped_mm_1);  _grouped_mm_229 = _grouped_mm_1 = None
        permute_1674 = torch.ops.aten.permute.default(mul_2147, [1, 0])
        _grouped_mm_230 = torch.ops.aten._grouped_mm.default(permute_1674, index_1, cumsum_2);  permute_1674 = None
        _grouped_mm_231 = torch.ops.aten._grouped_mm.default(mul_2147, permute_1676, cumsum_2);  mul_2147 = permute_1676 = None
        convert_element_type_3328 = torch.ops.prims.convert_element_type.default(mul_2148, torch.float32);  mul_2148 = None
        reciprocal_51 = torch.ops.aten.reciprocal.default(add_32);  add_32 = None
        mul_2149 = torch.ops.aten.mul.Tensor(reciprocal_51, 1);  reciprocal_51 = None
        mul_2150 = torch.ops.aten.mul.Tensor(convert_element_type_3328, mul_2149);  convert_element_type_3328 = None
        sub_776 = torch.ops.aten.sub.Tensor(1, mul_2149);  mul_2149 = None
        mul_2151 = torch.ops.aten.mul.Tensor(convert_element_type_76, sub_776);  convert_element_type_76 = sub_776 = None
        add_2154 = torch.ops.aten.add.Tensor(mul_2151, 1);  mul_2151 = None
        mul_2152 = torch.ops.aten.mul.Tensor(mul_2150, add_2154);  mul_2150 = add_2154 = None
        convert_element_type_3330 = torch.ops.prims.convert_element_type.default(mul_2152, torch.bfloat16);  mul_2152 = None
        permute_1678 = torch.ops.aten.permute.default(convert_element_type_3330, [1, 0])
        _grouped_mm_232 = torch.ops.aten._grouped_mm.default(permute_1678, index_1, cumsum_2);  permute_1678 = index_1 = None
        _grouped_mm_233 = torch.ops.aten._grouped_mm.default(convert_element_type_3330, permute_1680, cumsum_2);  convert_element_type_3330 = permute_1680 = cumsum_2 = None
        add_2155 = torch.ops.aten.add.Tensor(_grouped_mm_231, _grouped_mm_233);  _grouped_mm_231 = _grouped_mm_233 = None
        convert_element_type_3331 = torch.ops.prims.convert_element_type.default(_grouped_mm_230, torch.float32);  _grouped_mm_230 = None
        div_282 = torch.ops.aten.div.Tensor(convert_element_type_3331, 128);  convert_element_type_3331 = None
        split_1482 = torch.ops.aten.split.Tensor(div_282, 88, 1);  div_282 = None
        getitem_27885 = split_1482[0]
        getitem_27902 = split_1482[1]
        getitem_27919 = split_1482[2]
        getitem_27936 = split_1482[3]
        getitem_27953 = split_1482[4]
        getitem_27970 = split_1482[5]
        getitem_27987 = split_1482[6]
        getitem_28004 = split_1482[7]
        getitem_28021 = split_1482[8]
        getitem_28038 = split_1482[9]
        getitem_28055 = split_1482[10]
        getitem_28072 = split_1482[11]
        getitem_28089 = split_1482[12]
        getitem_28106 = split_1482[13]
        getitem_28123 = split_1482[14]
        getitem_28140 = split_1482[15];  split_1482 = None
        cat_436 = torch.ops.aten.cat.default([getitem_27885, getitem_27902, getitem_27919, getitem_27936, getitem_27953, getitem_27970, getitem_27987, getitem_28004, getitem_28021, getitem_28038, getitem_28055, getitem_28072, getitem_28089, getitem_28106, getitem_28123, getitem_28140]);  getitem_27885 = getitem_27902 = getitem_27919 = getitem_27936 = getitem_27953 = getitem_27970 = getitem_27987 = getitem_28004 = getitem_28021 = getitem_28038 = getitem_28055 = getitem_28072 = getitem_28089 = getitem_28106 = getitem_28123 = getitem_28140 = None
        reduce_scatter_tensor_355 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_436, 'sum', 16, '1025');  cat_436 = None
        wait_tensor_965 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_355);  reduce_scatter_tensor_355 = None
        convert_element_type_3332 = torch.ops.prims.convert_element_type.default(_grouped_mm_228, torch.float32);  _grouped_mm_228 = None
        div_283 = torch.ops.aten.div.Tensor(convert_element_type_3332, 128);  convert_element_type_3332 = None
        split_1499 = torch.ops.aten.split.Tensor(div_283, 128, 1);  div_283 = None
        getitem_28157 = split_1499[0]
        getitem_28174 = split_1499[1]
        getitem_28191 = split_1499[2]
        getitem_28208 = split_1499[3]
        getitem_28225 = split_1499[4]
        getitem_28242 = split_1499[5]
        getitem_28259 = split_1499[6]
        getitem_28276 = split_1499[7]
        getitem_28293 = split_1499[8]
        getitem_28310 = split_1499[9]
        getitem_28327 = split_1499[10]
        getitem_28344 = split_1499[11]
        getitem_28361 = split_1499[12]
        getitem_28378 = split_1499[13]
        getitem_28395 = split_1499[14]
        getitem_28412 = split_1499[15];  split_1499 = None
        cat_437 = torch.ops.aten.cat.default([getitem_28157, getitem_28174, getitem_28191, getitem_28208, getitem_28225, getitem_28242, getitem_28259, getitem_28276, getitem_28293, getitem_28310, getitem_28327, getitem_28344, getitem_28361, getitem_28378, getitem_28395, getitem_28412]);  getitem_28157 = getitem_28174 = getitem_28191 = getitem_28208 = getitem_28225 = getitem_28242 = getitem_28259 = getitem_28276 = getitem_28293 = getitem_28310 = getitem_28327 = getitem_28344 = getitem_28361 = getitem_28378 = getitem_28395 = getitem_28412 = None
        reduce_scatter_tensor_356 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_437, 'sum', 16, '1025');  cat_437 = None
        wait_tensor_966 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_356);  reduce_scatter_tensor_356 = None
        convert_element_type_3333 = torch.ops.prims.convert_element_type.default(_grouped_mm_232, torch.float32);  _grouped_mm_232 = None
        div_284 = torch.ops.aten.div.Tensor(convert_element_type_3333, 128);  convert_element_type_3333 = None
        split_1516 = torch.ops.aten.split.Tensor(div_284, 88, 1);  div_284 = None
        getitem_28429 = split_1516[0]
        getitem_28446 = split_1516[1]
        getitem_28463 = split_1516[2]
        getitem_28480 = split_1516[3]
        getitem_28497 = split_1516[4]
        getitem_28514 = split_1516[5]
        getitem_28531 = split_1516[6]
        getitem_28548 = split_1516[7]
        getitem_28565 = split_1516[8]
        getitem_28582 = split_1516[9]
        getitem_28599 = split_1516[10]
        getitem_28616 = split_1516[11]
        getitem_28633 = split_1516[12]
        getitem_28650 = split_1516[13]
        getitem_28667 = split_1516[14]
        getitem_28684 = split_1516[15];  split_1516 = None
        cat_438 = torch.ops.aten.cat.default([getitem_28429, getitem_28446, getitem_28463, getitem_28480, getitem_28497, getitem_28514, getitem_28531, getitem_28548, getitem_28565, getitem_28582, getitem_28599, getitem_28616, getitem_28633, getitem_28650, getitem_28667, getitem_28684]);  getitem_28429 = getitem_28446 = getitem_28463 = getitem_28480 = getitem_28497 = getitem_28514 = getitem_28531 = getitem_28548 = getitem_28565 = getitem_28582 = getitem_28599 = getitem_28616 = getitem_28633 = getitem_28650 = getitem_28667 = getitem_28684 = None
        reduce_scatter_tensor_357 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_438, 'sum', 16, '1025');  cat_438 = None
        wait_tensor_967 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_357);  reduce_scatter_tensor_357 = None
        index_put_102 = torch.ops.aten.index_put.default(full_498, [getitem_22], add_2155, True);  full_498 = getitem_22 = add_2155 = None
        slice_312 = torch.ops.aten.slice.Tensor(index_put_102, 0, 0, add_2156);  index_put_102 = add_2156 = None
        all_to_all_single_129 = torch.ops._c10d_functional.all_to_all_single.default(slice_312, [_local_scalar_dense, _local_scalar_dense_1, _local_scalar_dense_2, _local_scalar_dense_3, _local_scalar_dense_4, _local_scalar_dense_5, _local_scalar_dense_6, _local_scalar_dense_7], [_local_scalar_dense_8, _local_scalar_dense_9, _local_scalar_dense_10, _local_scalar_dense_11, _local_scalar_dense_12, _local_scalar_dense_13, _local_scalar_dense_14, _local_scalar_dense_15], '1033');  slice_312 = _local_scalar_dense = _local_scalar_dense_1 = _local_scalar_dense_2 = _local_scalar_dense_3 = _local_scalar_dense_4 = _local_scalar_dense_5 = _local_scalar_dense_6 = _local_scalar_dense_7 = _local_scalar_dense_8 = _local_scalar_dense_9 = _local_scalar_dense_10 = _local_scalar_dense_11 = _local_scalar_dense_12 = _local_scalar_dense_13 = _local_scalar_dense_14 = _local_scalar_dense_15 = None
        wait_tensor_968 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_129);  all_to_all_single_129 = None
        index_put_103 = torch.ops.aten.index_put.default(full_default_52, [div_2], wait_tensor_968, True);  full_default_52 = div_2 = wait_tensor_968 = None
        add_2160 = torch.ops.aten.add.Tensor(add_2152, index_put_103);  add_2152 = index_put_103 = None
        mul_2153 = torch.ops.aten.mul.Tensor(view_2258, 1.0);  view_2258 = None
        scatter_add_25 = torch.ops.aten.scatter_add.default(full_default_53, 1, getitem_19, mul_2153);  full_default_53 = getitem_19 = mul_2153 = None
        convert_element_type_65 = torch.ops.prims.convert_element_type.default(mm_11, torch.float32);  mm_11 = None
        sub = torch.ops.aten.sub.Tensor(convert_element_type_65, amax);  convert_element_type_65 = amax = None
        exp_1 = torch.ops.aten.exp.default(sub);  sub = None
        div_1 = torch.ops.aten.div.Tensor(exp_1, sum_1);  exp_1 = sum_1 = None
        mul_2154 = torch.ops.aten.mul.Tensor(scatter_add_25, div_1);  scatter_add_25 = None
        sum_307 = torch.ops.aten.sum.dim_IntList(mul_2154, [1], True)
        neg_130 = torch.ops.aten.neg.default(div_1);  div_1 = None
        fma_25 = torch.ops.prims.fma.default(neg_130, sum_307, mul_2154);  neg_130 = sum_307 = mul_2154 = None
        convert_element_type_3334 = torch.ops.prims.convert_element_type.default(fma_25, torch.bfloat16);  fma_25 = None
        permute_1682 = torch.ops.aten.permute.default(convert_element_type_3334, [1, 0])
        mm_624 = torch.ops.aten.mm.default(permute_1682, view_58);  permute_1682 = view_58 = None
        convert_element_type_62 = torch.ops.prims.convert_element_type.default(primals_31, torch.bfloat16);  primals_31 = None
        all_gather_into_tensor_18 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_62, 128, '0');  convert_element_type_62 = None
        wait_tensor_18 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_18);  all_gather_into_tensor_18 = None
        slice_9 = torch.ops.aten.slice.Tensor(wait_tensor_18, 0, 0, 64);  wait_tensor_18 = None
        permute_19 = torch.ops.aten.permute.default(slice_9, [1, 0]);  slice_9 = None
        permute_1684 = torch.ops.aten.permute.default(permute_19, [1, 0]);  permute_19 = None
        mm_625 = torch.ops.aten.mm.default(convert_element_type_3334, permute_1684);  convert_element_type_3334 = permute_1684 = None
        add_2161 = torch.ops.aten.add.Tensor(add_2160, mm_625);  add_2160 = mm_625 = None
        convert_element_type_3339 = torch.ops.prims.convert_element_type.default(mm_624, torch.float32);  mm_624 = None
        split_1532 = torch.ops.aten.split.Tensor(convert_element_type_3339, 1);  convert_element_type_3339 = None
        getitem_28685 = split_1532[0]
        getitem_28686 = split_1532[1]
        getitem_28687 = split_1532[2]
        getitem_28688 = split_1532[3]
        getitem_28689 = split_1532[4]
        getitem_28690 = split_1532[5]
        getitem_28691 = split_1532[6]
        getitem_28692 = split_1532[7]
        getitem_28693 = split_1532[8]
        getitem_28694 = split_1532[9]
        getitem_28695 = split_1532[10]
        getitem_28696 = split_1532[11]
        getitem_28697 = split_1532[12]
        getitem_28698 = split_1532[13]
        getitem_28699 = split_1532[14]
        getitem_28700 = split_1532[15]
        getitem_28701 = split_1532[16]
        getitem_28702 = split_1532[17]
        getitem_28703 = split_1532[18]
        getitem_28704 = split_1532[19]
        getitem_28705 = split_1532[20]
        getitem_28706 = split_1532[21]
        getitem_28707 = split_1532[22]
        getitem_28708 = split_1532[23]
        getitem_28709 = split_1532[24]
        getitem_28710 = split_1532[25]
        getitem_28711 = split_1532[26]
        getitem_28712 = split_1532[27]
        getitem_28713 = split_1532[28]
        getitem_28714 = split_1532[29]
        getitem_28715 = split_1532[30]
        getitem_28716 = split_1532[31]
        getitem_28717 = split_1532[32]
        getitem_28718 = split_1532[33]
        getitem_28719 = split_1532[34]
        getitem_28720 = split_1532[35]
        getitem_28721 = split_1532[36]
        getitem_28722 = split_1532[37]
        getitem_28723 = split_1532[38]
        getitem_28724 = split_1532[39]
        getitem_28725 = split_1532[40]
        getitem_28726 = split_1532[41]
        getitem_28727 = split_1532[42]
        getitem_28728 = split_1532[43]
        getitem_28729 = split_1532[44]
        getitem_28730 = split_1532[45]
        getitem_28731 = split_1532[46]
        getitem_28732 = split_1532[47]
        getitem_28733 = split_1532[48]
        getitem_28734 = split_1532[49]
        getitem_28735 = split_1532[50]
        getitem_28736 = split_1532[51]
        getitem_28737 = split_1532[52]
        getitem_28738 = split_1532[53]
        getitem_28739 = split_1532[54]
        getitem_28740 = split_1532[55]
        getitem_28741 = split_1532[56]
        getitem_28742 = split_1532[57]
        getitem_28743 = split_1532[58]
        getitem_28744 = split_1532[59]
        getitem_28745 = split_1532[60]
        getitem_28746 = split_1532[61]
        getitem_28747 = split_1532[62]
        getitem_28748 = split_1532[63];  split_1532 = None
        cat_439 = torch.ops.aten.cat.default([getitem_28685, getitem_28686, getitem_28687, getitem_28688, getitem_28689, getitem_28690, getitem_28691, getitem_28692, getitem_28693, getitem_28694, getitem_28695, getitem_28696, getitem_28697, getitem_28698, getitem_28699, getitem_28700, getitem_28701, getitem_28702, getitem_28703, getitem_28704, getitem_28705, getitem_28706, getitem_28707, getitem_28708, getitem_28709, getitem_28710, getitem_28711, getitem_28712, getitem_28713, getitem_28714, getitem_28715, getitem_28716, getitem_28717, getitem_28718, getitem_28719, getitem_28720, getitem_28721, getitem_28722, getitem_28723, getitem_28724, getitem_28725, getitem_28726, getitem_28727, getitem_28728, getitem_28729, getitem_28730, getitem_28731, getitem_28732, getitem_28733, getitem_28734, getitem_28735, getitem_28736, getitem_28737, getitem_28738, getitem_28739, getitem_28740, getitem_28741, getitem_28742, getitem_28743, getitem_28744, getitem_28745, getitem_28746, getitem_28747, getitem_28748, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd, constant_pad_nd]);  getitem_28685 = getitem_28686 = getitem_28687 = getitem_28688 = getitem_28689 = getitem_28690 = getitem_28691 = getitem_28692 = getitem_28693 = getitem_28694 = getitem_28695 = getitem_28696 = getitem_28697 = getitem_28698 = getitem_28699 = getitem_28700 = getitem_28701 = getitem_28702 = getitem_28703 = getitem_28704 = getitem_28705 = getitem_28706 = getitem_28707 = getitem_28708 = getitem_28709 = getitem_28710 = getitem_28711 = getitem_28712 = getitem_28713 = getitem_28714 = getitem_28715 = getitem_28716 = getitem_28717 = getitem_28718 = getitem_28719 = getitem_28720 = getitem_28721 = getitem_28722 = getitem_28723 = getitem_28724 = getitem_28725 = getitem_28726 = getitem_28727 = getitem_28728 = getitem_28729 = getitem_28730 = getitem_28731 = getitem_28732 = getitem_28733 = getitem_28734 = getitem_28735 = getitem_28736 = getitem_28737 = getitem_28738 = getitem_28739 = getitem_28740 = getitem_28741 = getitem_28742 = getitem_28743 = getitem_28744 = getitem_28745 = getitem_28746 = getitem_28747 = getitem_28748 = constant_pad_nd = None
        reduce_scatter_tensor_358 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_439, 'avg', 128, '0');  cat_439 = None
        wait_tensor_969 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_358);  reduce_scatter_tensor_358 = None
        view_2260 = torch.ops.aten.view.default(add_2161, [2, 4096, 2048]);  add_2161 = None
        convert_element_type_3340 = torch.ops.prims.convert_element_type.default(view_2260, torch.float32);  view_2260 = None
        convert_element_type_59 = torch.ops.prims.convert_element_type.default(primals_29, torch.bfloat16);  primals_29 = None
        all_gather_into_tensor_17 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_59, 128, '0');  convert_element_type_59 = None
        wait_tensor_17 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_17);  all_gather_into_tensor_17 = None
        convert_element_type_3342 = torch.ops.prims.convert_element_type.default(wait_tensor_17, torch.float32);  wait_tensor_17 = None
        mul_2155 = torch.ops.aten.mul.Tensor(convert_element_type_3340, convert_element_type_3342);  convert_element_type_3342 = None
        convert_element_type_60 = torch.ops.prims.convert_element_type.default(add_8, torch.float32);  add_8 = None
        mul_15 = torch.ops.aten.mul.Tensor(convert_element_type_60, rsqrt_5);  convert_element_type_60 = None
        mul_2157 = torch.ops.aten.mul.Tensor(mul_15, mul_2155)
        sum_308 = torch.ops.aten.sum.dim_IntList(mul_2157, [2], True);  mul_2157 = None
        div_285 = torch.ops.aten.div.Tensor(mul_15, 2048)
        mul_2158 = torch.ops.aten.mul.Tensor(div_285, sum_308);  div_285 = sum_308 = None
        sub_778 = torch.ops.aten.sub.Tensor(mul_2155, mul_2158);  mul_2155 = mul_2158 = None
        mul_2159 = torch.ops.aten.mul.Tensor(sub_778, rsqrt_5);  sub_778 = rsqrt_5 = None
        mul_2160 = torch.ops.aten.mul.Tensor(convert_element_type_3340, mul_15);  convert_element_type_3340 = mul_15 = None
        sum_309 = torch.ops.aten.sum.dim_IntList(mul_2160, [0, 1]);  mul_2160 = None
        convert_element_type_3343 = torch.ops.prims.convert_element_type.default(mul_2159, torch.bfloat16);  mul_2159 = None
        add_2162 = torch.ops.aten.add.Tensor(add_2149, convert_element_type_3343);  add_2149 = convert_element_type_3343 = None
        convert_element_type_default_6 = torch.ops.prims.convert_element_type.default(sum_309, torch.float32);  sum_309 = None
        reduce_scatter_tensor_359 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_6, 'avg', 128, '0');  convert_element_type_default_6 = None
        wait_tensor_970 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_359);  reduce_scatter_tensor_359 = None
        view_2261 = torch.ops.aten.view.default(add_2162, [8192, 2048])
        permute_1686 = torch.ops.aten.permute.default(view_2261, [1, 0])
        permute_17 = torch.ops.aten.permute.default(getitem_15, [0, 2, 1, 3])
        view_53 = torch.ops.aten.view.default(permute_17, [2, 4096, -1]);  permute_17 = None
        view_55 = torch.ops.aten.view.default(view_53, [8192, 2048]);  view_53 = None
        mm_626 = torch.ops.aten.mm.default(permute_1686, view_55);  permute_1686 = view_55 = None
        convert_element_type_56 = torch.ops.prims.convert_element_type.default(primals_28, torch.bfloat16);  primals_28 = None
        all_gather_into_tensor_16 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_56, 128, '0');  convert_element_type_56 = None
        wait_tensor_16 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_16);  all_gather_into_tensor_16 = None
        permute_18 = torch.ops.aten.permute.default(wait_tensor_16, [1, 0]);  wait_tensor_16 = None
        permute_1688 = torch.ops.aten.permute.default(permute_18, [1, 0]);  permute_18 = None
        mm_627 = torch.ops.aten.mm.default(view_2261, permute_1688);  view_2261 = permute_1688 = None
        view_2262 = torch.ops.aten.view.default(mm_627, [2, 4096, 2048]);  mm_627 = None
        convert_element_type_3350 = torch.ops.prims.convert_element_type.default(mm_626, torch.float32);  mm_626 = None
        reduce_scatter_tensor_360 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3350, 'avg', 128, '0');  convert_element_type_3350 = None
        wait_tensor_971 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_360);  reduce_scatter_tensor_360 = None
        view_2263 = torch.ops.aten.view.default(view_2262, [2, 4096, 16, 128]);  view_2262 = None
        permute_1690 = torch.ops.aten.permute.default(view_2263, [0, 2, 1, 3]);  view_2263 = None
        fw_graph25 = self.fw_graph25
        joint_graph25 = self.joint_graph25
        mask_graph25 = self.mask_graph25
        flex_attention_backward_25 = torch.ops.higher_order.flex_attention_backward(permute_14, permute_15, permute_16, getitem_15, getitem_16, permute_1690, None, fw_graph25, joint_graph25, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph25), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_14 = permute_15 = permute_16 = getitem_15 = getitem_16 = permute_1690 = fw_graph25 = joint_graph25 = mask_graph25 = None
        getitem_28749 = flex_attention_backward_25[0]
        getitem_28750 = flex_attention_backward_25[1]
        getitem_28751 = flex_attention_backward_25[2];  flex_attention_backward_25 = None
        permute_1691 = torch.ops.aten.permute.default(getitem_28751, [0, 2, 1, 3]);  getitem_28751 = None
        permute_1692 = torch.ops.aten.permute.default(getitem_28750, [0, 2, 1, 3]);  getitem_28750 = None
        permute_1693 = torch.ops.aten.permute.default(getitem_28749, [0, 2, 1, 3]);  getitem_28749 = None
        slice_314 = torch.ops.aten.slice.Tensor(permute_1692, 3, 0, 128)
        slice_315 = torch.ops.aten.slice.Tensor(permute_1692, 3, 128, 192);  permute_1692 = None
        sum_310 = torch.ops.aten.sum.dim_IntList(slice_315, [2], True);  slice_315 = None
        cat_440 = torch.ops.aten.cat.default([slice_314, permute_1691], 3);  slice_314 = permute_1691 = None
        view_2264 = torch.ops.aten.view.default(cat_440, [2, 4096, 4096]);  cat_440 = None
        view_2265 = torch.ops.aten.view.default(view_2264, [8192, 4096]);  view_2264 = None
        permute_1694 = torch.ops.aten.permute.default(view_2265, [1, 0])
        mm_628 = torch.ops.aten.mm.default(permute_1694, view_50);  permute_1694 = view_50 = None
        convert_element_type_53 = torch.ops.prims.convert_element_type.default(primals_27, torch.bfloat16);  primals_27 = None
        all_gather_into_tensor_15 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_53, 128, '0');  convert_element_type_53 = None
        wait_tensor_15 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_15);  all_gather_into_tensor_15 = None
        permute_13 = torch.ops.aten.permute.default(wait_tensor_15, [1, 0]);  wait_tensor_15 = None
        permute_1696 = torch.ops.aten.permute.default(permute_13, [1, 0]);  permute_13 = None
        mm_629 = torch.ops.aten.mm.default(view_2265, permute_1696);  view_2265 = permute_1696 = None
        view_2266 = torch.ops.aten.view.default(mm_629, [2, 4096, 512]);  mm_629 = None
        convert_element_type_3355 = torch.ops.prims.convert_element_type.default(mm_628, torch.float32);  mm_628 = None
        reduce_scatter_tensor_361 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3355, 'avg', 128, '0');  convert_element_type_3355 = None
        wait_tensor_972 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_361);  reduce_scatter_tensor_361 = None
        convert_element_type_3356 = torch.ops.prims.convert_element_type.default(view_2266, torch.float32);  view_2266 = None
        convert_element_type_50 = torch.ops.prims.convert_element_type.default(primals_26, torch.bfloat16);  primals_26 = None
        all_gather_into_tensor_14 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_50, 128, '0');  convert_element_type_50 = None
        wait_tensor_14 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_14);  all_gather_into_tensor_14 = None
        convert_element_type_3358 = torch.ops.prims.convert_element_type.default(wait_tensor_14, torch.float32);  wait_tensor_14 = None
        mul_2161 = torch.ops.aten.mul.Tensor(convert_element_type_3356, convert_element_type_3358);  convert_element_type_3358 = None
        convert_element_type_51 = torch.ops.prims.convert_element_type.default(getitem_11, torch.float32);  getitem_11 = None
        mul_13 = torch.ops.aten.mul.Tensor(convert_element_type_51, rsqrt_4);  convert_element_type_51 = None
        mul_2163 = torch.ops.aten.mul.Tensor(mul_13, mul_2161)
        sum_311 = torch.ops.aten.sum.dim_IntList(mul_2163, [2], True);  mul_2163 = None
        div_286 = torch.ops.aten.div.Tensor(mul_13, 512)
        mul_2164 = torch.ops.aten.mul.Tensor(div_286, sum_311);  div_286 = sum_311 = None
        sub_779 = torch.ops.aten.sub.Tensor(mul_2161, mul_2164);  mul_2161 = mul_2164 = None
        mul_2165 = torch.ops.aten.mul.Tensor(sub_779, rsqrt_4);  sub_779 = rsqrt_4 = None
        mul_2166 = torch.ops.aten.mul.Tensor(convert_element_type_3356, mul_13);  convert_element_type_3356 = mul_13 = None
        sum_312 = torch.ops.aten.sum.dim_IntList(mul_2166, [0, 1]);  mul_2166 = None
        convert_element_type_3359 = torch.ops.prims.convert_element_type.default(mul_2165, torch.bfloat16);  mul_2165 = None
        convert_element_type_default_5 = torch.ops.prims.convert_element_type.default(sum_312, torch.float32);  sum_312 = None
        reduce_scatter_tensor_362 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_5, 'avg', 128, '0');  convert_element_type_default_5 = None
        wait_tensor_973 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_362);  reduce_scatter_tensor_362 = None
        convert_element_type_3362 = torch.ops.prims.convert_element_type.default(sum_310, torch.float32);  sum_310 = None
        view_2267 = torch.ops.aten.view.default(convert_element_type_3362, [2, 4096, 1, 32, 2]);  convert_element_type_3362 = None
        view_as_complex_104 = torch.ops.aten.view_as_complex.default(view_2267);  view_2267 = None
        mul_2167 = torch.ops.aten.mul.Tensor(view_as_complex_104, clone_9);  view_as_complex_104 = None
        view_as_real_104 = torch.ops.aten.view_as_real.default(mul_2167);  mul_2167 = None
        view_2268 = torch.ops.aten.view.default(view_as_real_104, [2, 4096, 1, 64]);  view_as_real_104 = None
        convert_element_type_3363 = torch.ops.prims.convert_element_type.default(view_2268, torch.bfloat16);  view_2268 = None
        squeeze_51 = torch.ops.aten.squeeze.dim(convert_element_type_3363, 2);  convert_element_type_3363 = None
        cat_441 = torch.ops.aten.cat.default([convert_element_type_3359, squeeze_51], 2);  convert_element_type_3359 = squeeze_51 = None
        view_2269 = torch.ops.aten.view.default(cat_441, [8192, 576]);  cat_441 = None
        permute_1698 = torch.ops.aten.permute.default(view_2269, [1, 0])
        mm_630 = torch.ops.aten.mm.default(permute_1698, view_36);  permute_1698 = None
        convert_element_type_45 = torch.ops.prims.convert_element_type.default(primals_25, torch.bfloat16);  primals_25 = None
        all_gather_into_tensor_13 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_45, 128, '0');  convert_element_type_45 = None
        wait_tensor_13 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_13);  all_gather_into_tensor_13 = None
        slice_7 = torch.ops.aten.slice.Tensor(wait_tensor_13, 0, 0, 576);  wait_tensor_13 = None
        permute_12 = torch.ops.aten.permute.default(slice_7, [1, 0]);  slice_7 = None
        permute_1700 = torch.ops.aten.permute.default(permute_12, [1, 0]);  permute_12 = None
        mm_631 = torch.ops.aten.mm.default(view_2269, permute_1700);  view_2269 = permute_1700 = None
        view_2270 = torch.ops.aten.view.default(mm_631, [2, 4096, 2048]);  mm_631 = None
        convert_element_type_3368 = torch.ops.prims.convert_element_type.default(mm_630, torch.float32);  mm_630 = None
        split_1533 = torch.ops.aten.split.Tensor(convert_element_type_3368, 5);  convert_element_type_3368 = None
        getitem_28753 = split_1533[0]
        getitem_28754 = split_1533[1]
        getitem_28755 = split_1533[2]
        getitem_28756 = split_1533[3]
        getitem_28757 = split_1533[4]
        getitem_28758 = split_1533[5]
        getitem_28759 = split_1533[6]
        getitem_28760 = split_1533[7]
        getitem_28761 = split_1533[8]
        getitem_28762 = split_1533[9]
        getitem_28763 = split_1533[10]
        getitem_28764 = split_1533[11]
        getitem_28765 = split_1533[12]
        getitem_28766 = split_1533[13]
        getitem_28767 = split_1533[14]
        getitem_28768 = split_1533[15]
        getitem_28769 = split_1533[16]
        getitem_28770 = split_1533[17]
        getitem_28771 = split_1533[18]
        getitem_28772 = split_1533[19]
        getitem_28773 = split_1533[20]
        getitem_28774 = split_1533[21]
        getitem_28775 = split_1533[22]
        getitem_28776 = split_1533[23]
        getitem_28777 = split_1533[24]
        getitem_28778 = split_1533[25]
        getitem_28779 = split_1533[26]
        getitem_28780 = split_1533[27]
        getitem_28781 = split_1533[28]
        getitem_28782 = split_1533[29]
        getitem_28783 = split_1533[30]
        getitem_28784 = split_1533[31]
        getitem_28785 = split_1533[32]
        getitem_28786 = split_1533[33]
        getitem_28787 = split_1533[34]
        getitem_28788 = split_1533[35]
        getitem_28789 = split_1533[36]
        getitem_28790 = split_1533[37]
        getitem_28791 = split_1533[38]
        getitem_28792 = split_1533[39]
        getitem_28793 = split_1533[40]
        getitem_28794 = split_1533[41]
        getitem_28795 = split_1533[42]
        getitem_28796 = split_1533[43]
        getitem_28797 = split_1533[44]
        getitem_28798 = split_1533[45]
        getitem_28799 = split_1533[46]
        getitem_28800 = split_1533[47]
        getitem_28801 = split_1533[48]
        getitem_28802 = split_1533[49]
        getitem_28803 = split_1533[50]
        getitem_28804 = split_1533[51]
        getitem_28805 = split_1533[52]
        getitem_28806 = split_1533[53]
        getitem_28807 = split_1533[54]
        getitem_28808 = split_1533[55]
        getitem_28809 = split_1533[56]
        getitem_28810 = split_1533[57]
        getitem_28811 = split_1533[58]
        getitem_28812 = split_1533[59]
        getitem_28813 = split_1533[60]
        getitem_28814 = split_1533[61]
        getitem_28815 = split_1533[62]
        getitem_28816 = split_1533[63]
        getitem_28817 = split_1533[64]
        getitem_28818 = split_1533[65]
        getitem_28819 = split_1533[66]
        getitem_28820 = split_1533[67]
        getitem_28821 = split_1533[68]
        getitem_28822 = split_1533[69]
        getitem_28823 = split_1533[70]
        getitem_28824 = split_1533[71]
        getitem_28825 = split_1533[72]
        getitem_28826 = split_1533[73]
        getitem_28827 = split_1533[74]
        getitem_28828 = split_1533[75]
        getitem_28829 = split_1533[76]
        getitem_28830 = split_1533[77]
        getitem_28831 = split_1533[78]
        getitem_28832 = split_1533[79]
        getitem_28833 = split_1533[80]
        getitem_28834 = split_1533[81]
        getitem_28835 = split_1533[82]
        getitem_28836 = split_1533[83]
        getitem_28837 = split_1533[84]
        getitem_28838 = split_1533[85]
        getitem_28839 = split_1533[86]
        getitem_28840 = split_1533[87]
        getitem_28841 = split_1533[88]
        getitem_28842 = split_1533[89]
        getitem_28843 = split_1533[90]
        getitem_28844 = split_1533[91]
        getitem_28845 = split_1533[92]
        getitem_28846 = split_1533[93]
        getitem_28847 = split_1533[94]
        getitem_28848 = split_1533[95]
        getitem_28849 = split_1533[96]
        getitem_28850 = split_1533[97]
        getitem_28851 = split_1533[98]
        getitem_28852 = split_1533[99]
        getitem_28853 = split_1533[100]
        getitem_28854 = split_1533[101]
        getitem_28855 = split_1533[102]
        getitem_28856 = split_1533[103]
        getitem_28857 = split_1533[104]
        getitem_28858 = split_1533[105]
        getitem_28859 = split_1533[106]
        getitem_28860 = split_1533[107]
        getitem_28861 = split_1533[108]
        getitem_28862 = split_1533[109]
        getitem_28863 = split_1533[110]
        getitem_28864 = split_1533[111]
        getitem_28865 = split_1533[112]
        getitem_28866 = split_1533[113]
        getitem_28867 = split_1533[114]
        getitem_28868 = split_1533[115];  split_1533 = None
        constant_pad_nd_1989 = torch.ops.aten.constant_pad_nd.default(getitem_28868, [0, 0, 0, 4], 0.0);  getitem_28868 = None
        cat_442 = torch.ops.aten.cat.default([getitem_28753, getitem_28754, getitem_28755, getitem_28756, getitem_28757, getitem_28758, getitem_28759, getitem_28760, getitem_28761, getitem_28762, getitem_28763, getitem_28764, getitem_28765, getitem_28766, getitem_28767, getitem_28768, getitem_28769, getitem_28770, getitem_28771, getitem_28772, getitem_28773, getitem_28774, getitem_28775, getitem_28776, getitem_28777, getitem_28778, getitem_28779, getitem_28780, getitem_28781, getitem_28782, getitem_28783, getitem_28784, getitem_28785, getitem_28786, getitem_28787, getitem_28788, getitem_28789, getitem_28790, getitem_28791, getitem_28792, getitem_28793, getitem_28794, getitem_28795, getitem_28796, getitem_28797, getitem_28798, getitem_28799, getitem_28800, getitem_28801, getitem_28802, getitem_28803, getitem_28804, getitem_28805, getitem_28806, getitem_28807, getitem_28808, getitem_28809, getitem_28810, getitem_28811, getitem_28812, getitem_28813, getitem_28814, getitem_28815, getitem_28816, getitem_28817, getitem_28818, getitem_28819, getitem_28820, getitem_28821, getitem_28822, getitem_28823, getitem_28824, getitem_28825, getitem_28826, getitem_28827, getitem_28828, getitem_28829, getitem_28830, getitem_28831, getitem_28832, getitem_28833, getitem_28834, getitem_28835, getitem_28836, getitem_28837, getitem_28838, getitem_28839, getitem_28840, getitem_28841, getitem_28842, getitem_28843, getitem_28844, getitem_28845, getitem_28846, getitem_28847, getitem_28848, getitem_28849, getitem_28850, getitem_28851, getitem_28852, getitem_28853, getitem_28854, getitem_28855, getitem_28856, getitem_28857, getitem_28858, getitem_28859, getitem_28860, getitem_28861, getitem_28862, getitem_28863, getitem_28864, getitem_28865, getitem_28866, getitem_28867, constant_pad_nd_1989, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_28753 = getitem_28754 = getitem_28755 = getitem_28756 = getitem_28757 = getitem_28758 = getitem_28759 = getitem_28760 = getitem_28761 = getitem_28762 = getitem_28763 = getitem_28764 = getitem_28765 = getitem_28766 = getitem_28767 = getitem_28768 = getitem_28769 = getitem_28770 = getitem_28771 = getitem_28772 = getitem_28773 = getitem_28774 = getitem_28775 = getitem_28776 = getitem_28777 = getitem_28778 = getitem_28779 = getitem_28780 = getitem_28781 = getitem_28782 = getitem_28783 = getitem_28784 = getitem_28785 = getitem_28786 = getitem_28787 = getitem_28788 = getitem_28789 = getitem_28790 = getitem_28791 = getitem_28792 = getitem_28793 = getitem_28794 = getitem_28795 = getitem_28796 = getitem_28797 = getitem_28798 = getitem_28799 = getitem_28800 = getitem_28801 = getitem_28802 = getitem_28803 = getitem_28804 = getitem_28805 = getitem_28806 = getitem_28807 = getitem_28808 = getitem_28809 = getitem_28810 = getitem_28811 = getitem_28812 = getitem_28813 = getitem_28814 = getitem_28815 = getitem_28816 = getitem_28817 = getitem_28818 = getitem_28819 = getitem_28820 = getitem_28821 = getitem_28822 = getitem_28823 = getitem_28824 = getitem_28825 = getitem_28826 = getitem_28827 = getitem_28828 = getitem_28829 = getitem_28830 = getitem_28831 = getitem_28832 = getitem_28833 = getitem_28834 = getitem_28835 = getitem_28836 = getitem_28837 = getitem_28838 = getitem_28839 = getitem_28840 = getitem_28841 = getitem_28842 = getitem_28843 = getitem_28844 = getitem_28845 = getitem_28846 = getitem_28847 = getitem_28848 = getitem_28849 = getitem_28850 = getitem_28851 = getitem_28852 = getitem_28853 = getitem_28854 = getitem_28855 = getitem_28856 = getitem_28857 = getitem_28858 = getitem_28859 = getitem_28860 = getitem_28861 = getitem_28862 = getitem_28863 = getitem_28864 = getitem_28865 = getitem_28866 = getitem_28867 = constant_pad_nd_1989 = None
        reduce_scatter_tensor_363 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_442, 'avg', 128, '0');  cat_442 = None
        wait_tensor_974 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_363);  reduce_scatter_tensor_363 = None
        slice_316 = torch.ops.aten.slice.Tensor(permute_1693, 3, 0, 128)
        slice_317 = torch.ops.aten.slice.Tensor(permute_1693, 3, 128, 192);  permute_1693 = None
        convert_element_type_3369 = torch.ops.prims.convert_element_type.default(slice_317, torch.float32);  slice_317 = None
        view_2271 = torch.ops.aten.view.default(convert_element_type_3369, [2, 4096, 16, 32, 2]);  convert_element_type_3369 = None
        view_as_complex_105 = torch.ops.aten.view_as_complex.default(view_2271);  view_2271 = None
        mul_2168 = torch.ops.aten.mul.Tensor(view_as_complex_105, clone_9);  view_as_complex_105 = None
        view_as_real_105 = torch.ops.aten.view_as_real.default(mul_2168);  mul_2168 = None
        view_2272 = torch.ops.aten.view.default(view_as_real_105, [2, 4096, 16, 64]);  view_as_real_105 = None
        convert_element_type_3370 = torch.ops.prims.convert_element_type.default(view_2272, torch.bfloat16);  view_2272 = None
        cat_443 = torch.ops.aten.cat.default([slice_316, convert_element_type_3370], 3);  slice_316 = convert_element_type_3370 = None
        view_2273 = torch.ops.aten.view.default(cat_443, [2, 4096, 3072]);  cat_443 = None
        view_2274 = torch.ops.aten.view.default(view_2273, [8192, 3072]);  view_2273 = None
        permute_1702 = torch.ops.aten.permute.default(view_2274, [1, 0])
        mm_632 = torch.ops.aten.mm.default(permute_1702, view_36);  permute_1702 = view_36 = None
        convert_element_type_40 = torch.ops.prims.convert_element_type.default(primals_24, torch.bfloat16);  primals_24 = None
        all_gather_into_tensor_12 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_40, 128, '0');  convert_element_type_40 = None
        wait_tensor_12 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_12);  all_gather_into_tensor_12 = None
        permute_11 = torch.ops.aten.permute.default(wait_tensor_12, [1, 0]);  wait_tensor_12 = None
        permute_1704 = torch.ops.aten.permute.default(permute_11, [1, 0]);  permute_11 = None
        mm_633 = torch.ops.aten.mm.default(view_2274, permute_1704);  view_2274 = permute_1704 = None
        view_2275 = torch.ops.aten.view.default(mm_633, [2, 4096, 2048]);  mm_633 = None
        add_2163 = torch.ops.aten.add.Tensor(view_2270, view_2275);  view_2270 = view_2275 = None
        convert_element_type_3375 = torch.ops.prims.convert_element_type.default(mm_632, torch.float32);  mm_632 = None
        reduce_scatter_tensor_364 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3375, 'avg', 128, '0');  convert_element_type_3375 = None
        wait_tensor_975 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_364);  reduce_scatter_tensor_364 = None
        convert_element_type_3376 = torch.ops.prims.convert_element_type.default(add_2163, torch.float32);  add_2163 = None
        convert_element_type_37 = torch.ops.prims.convert_element_type.default(primals_23, torch.bfloat16);  primals_23 = None
        all_gather_into_tensor_11 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_37, 128, '0');  convert_element_type_37 = None
        wait_tensor_11 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_11);  all_gather_into_tensor_11 = None
        convert_element_type_3378 = torch.ops.prims.convert_element_type.default(wait_tensor_11, torch.float32);  wait_tensor_11 = None
        mul_2169 = torch.ops.aten.mul.Tensor(convert_element_type_3376, convert_element_type_3378);  convert_element_type_3378 = None
        convert_element_type_38 = torch.ops.prims.convert_element_type.default(add_5, torch.float32);  add_5 = None
        mul_9 = torch.ops.aten.mul.Tensor(convert_element_type_38, rsqrt_3);  convert_element_type_38 = None
        mul_2171 = torch.ops.aten.mul.Tensor(mul_9, mul_2169)
        sum_313 = torch.ops.aten.sum.dim_IntList(mul_2171, [2], True);  mul_2171 = None
        div_287 = torch.ops.aten.div.Tensor(mul_9, 2048)
        mul_2172 = torch.ops.aten.mul.Tensor(div_287, sum_313);  div_287 = sum_313 = None
        sub_780 = torch.ops.aten.sub.Tensor(mul_2169, mul_2172);  mul_2169 = mul_2172 = None
        mul_2173 = torch.ops.aten.mul.Tensor(sub_780, rsqrt_3);  sub_780 = rsqrt_3 = None
        mul_2174 = torch.ops.aten.mul.Tensor(convert_element_type_3376, mul_9);  convert_element_type_3376 = mul_9 = None
        sum_314 = torch.ops.aten.sum.dim_IntList(mul_2174, [0, 1]);  mul_2174 = None
        convert_element_type_3379 = torch.ops.prims.convert_element_type.default(mul_2173, torch.bfloat16);  mul_2173 = None
        add_2164 = torch.ops.aten.add.Tensor(add_2162, convert_element_type_3379);  add_2162 = convert_element_type_3379 = None
        convert_element_type_default_4 = torch.ops.prims.convert_element_type.default(sum_314, torch.float32);  sum_314 = None
        reduce_scatter_tensor_365 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_4, 'avg', 128, '0');  convert_element_type_default_4 = None
        wait_tensor_976 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_365);  reduce_scatter_tensor_365 = None
        view_2276 = torch.ops.aten.view.default(add_2164, [8192, 2048])
        permute_1706 = torch.ops.aten.permute.default(view_2276, [1, 0])
        mm_634 = torch.ops.aten.mm.default(permute_1706, view_32);  permute_1706 = view_32 = None
        convert_element_type_34 = torch.ops.prims.convert_element_type.default(primals_22, torch.bfloat16);  primals_22 = None
        all_gather_into_tensor_10 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_34, 128, '0');  convert_element_type_34 = None
        wait_tensor_10 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_10);  all_gather_into_tensor_10 = None
        permute_10 = torch.ops.aten.permute.default(wait_tensor_10, [1, 0]);  wait_tensor_10 = None
        permute_1708 = torch.ops.aten.permute.default(permute_10, [1, 0]);  permute_10 = None
        mm_635 = torch.ops.aten.mm.default(view_2276, permute_1708);  view_2276 = permute_1708 = None
        view_2277 = torch.ops.aten.view.default(mm_635, [2, 4096, 10944]);  mm_635 = None
        convert_element_type_3386 = torch.ops.prims.convert_element_type.default(mm_634, torch.float32);  mm_634 = None
        reduce_scatter_tensor_366 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3386, 'avg', 128, '0');  convert_element_type_3386 = None
        wait_tensor_977 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_366);  reduce_scatter_tensor_366 = None
        view_27 = torch.ops.aten.view.default(mm_4, [2, 4096, 10944]);  mm_4 = None
        convert_element_type_29 = torch.ops.prims.convert_element_type.default(view_27, torch.float32);  view_27 = None
        neg = torch.ops.aten.neg.default(convert_element_type_29)
        exp = torch.ops.aten.exp.default(neg);  neg = None
        add_4 = torch.ops.aten.add.Tensor(exp, 1);  exp = None
        div = torch.ops.aten.div.Tensor(convert_element_type_29, add_4)
        convert_element_type_30 = torch.ops.prims.convert_element_type.default(div, torch.bfloat16);  div = None
        mul_2175 = torch.ops.aten.mul.Tensor(view_2277, convert_element_type_30);  convert_element_type_30 = None
        view_30 = torch.ops.aten.view.default(mm_5, [2, 4096, 10944]);  mm_5 = None
        mul_2176 = torch.ops.aten.mul.Tensor(view_2277, view_30);  view_2277 = view_30 = None
        view_2278 = torch.ops.aten.view.default(mul_2175, [8192, 10944]);  mul_2175 = None
        permute_1710 = torch.ops.aten.permute.default(view_2278, [1, 0])
        mm_636 = torch.ops.aten.mm.default(permute_1710, view_26);  permute_1710 = None
        convert_element_type_31 = torch.ops.prims.convert_element_type.default(primals_21, torch.bfloat16);  primals_21 = None
        all_gather_into_tensor_9 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_31, 128, '0');  convert_element_type_31 = None
        wait_tensor_9 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_9);  all_gather_into_tensor_9 = None
        slice_5 = torch.ops.aten.slice.Tensor(wait_tensor_9, 0, 0, 10944);  wait_tensor_9 = None
        permute_9 = torch.ops.aten.permute.default(slice_5, [1, 0]);  slice_5 = None
        permute_1712 = torch.ops.aten.permute.default(permute_9, [1, 0]);  permute_9 = None
        mm_637 = torch.ops.aten.mm.default(view_2278, permute_1712);  view_2278 = permute_1712 = None
        view_2279 = torch.ops.aten.view.default(mm_637, [2, 4096, 2048]);  mm_637 = None
        convert_element_type_3391 = torch.ops.prims.convert_element_type.default(mm_636, torch.float32);  mm_636 = None
        split_1534 = torch.ops.aten.split.Tensor(convert_element_type_3391, 86);  convert_element_type_3391 = None
        getitem_28869 = split_1534[0]
        getitem_28870 = split_1534[1]
        getitem_28871 = split_1534[2]
        getitem_28872 = split_1534[3]
        getitem_28873 = split_1534[4]
        getitem_28874 = split_1534[5]
        getitem_28875 = split_1534[6]
        getitem_28876 = split_1534[7]
        getitem_28877 = split_1534[8]
        getitem_28878 = split_1534[9]
        getitem_28879 = split_1534[10]
        getitem_28880 = split_1534[11]
        getitem_28881 = split_1534[12]
        getitem_28882 = split_1534[13]
        getitem_28883 = split_1534[14]
        getitem_28884 = split_1534[15]
        getitem_28885 = split_1534[16]
        getitem_28886 = split_1534[17]
        getitem_28887 = split_1534[18]
        getitem_28888 = split_1534[19]
        getitem_28889 = split_1534[20]
        getitem_28890 = split_1534[21]
        getitem_28891 = split_1534[22]
        getitem_28892 = split_1534[23]
        getitem_28893 = split_1534[24]
        getitem_28894 = split_1534[25]
        getitem_28895 = split_1534[26]
        getitem_28896 = split_1534[27]
        getitem_28897 = split_1534[28]
        getitem_28898 = split_1534[29]
        getitem_28899 = split_1534[30]
        getitem_28900 = split_1534[31]
        getitem_28901 = split_1534[32]
        getitem_28902 = split_1534[33]
        getitem_28903 = split_1534[34]
        getitem_28904 = split_1534[35]
        getitem_28905 = split_1534[36]
        getitem_28906 = split_1534[37]
        getitem_28907 = split_1534[38]
        getitem_28908 = split_1534[39]
        getitem_28909 = split_1534[40]
        getitem_28910 = split_1534[41]
        getitem_28911 = split_1534[42]
        getitem_28912 = split_1534[43]
        getitem_28913 = split_1534[44]
        getitem_28914 = split_1534[45]
        getitem_28915 = split_1534[46]
        getitem_28916 = split_1534[47]
        getitem_28917 = split_1534[48]
        getitem_28918 = split_1534[49]
        getitem_28919 = split_1534[50]
        getitem_28920 = split_1534[51]
        getitem_28921 = split_1534[52]
        getitem_28922 = split_1534[53]
        getitem_28923 = split_1534[54]
        getitem_28924 = split_1534[55]
        getitem_28925 = split_1534[56]
        getitem_28926 = split_1534[57]
        getitem_28927 = split_1534[58]
        getitem_28928 = split_1534[59]
        getitem_28929 = split_1534[60]
        getitem_28930 = split_1534[61]
        getitem_28931 = split_1534[62]
        getitem_28932 = split_1534[63]
        getitem_28933 = split_1534[64]
        getitem_28934 = split_1534[65]
        getitem_28935 = split_1534[66]
        getitem_28936 = split_1534[67]
        getitem_28937 = split_1534[68]
        getitem_28938 = split_1534[69]
        getitem_28939 = split_1534[70]
        getitem_28940 = split_1534[71]
        getitem_28941 = split_1534[72]
        getitem_28942 = split_1534[73]
        getitem_28943 = split_1534[74]
        getitem_28944 = split_1534[75]
        getitem_28945 = split_1534[76]
        getitem_28946 = split_1534[77]
        getitem_28947 = split_1534[78]
        getitem_28948 = split_1534[79]
        getitem_28949 = split_1534[80]
        getitem_28950 = split_1534[81]
        getitem_28951 = split_1534[82]
        getitem_28952 = split_1534[83]
        getitem_28953 = split_1534[84]
        getitem_28954 = split_1534[85]
        getitem_28955 = split_1534[86]
        getitem_28956 = split_1534[87]
        getitem_28957 = split_1534[88]
        getitem_28958 = split_1534[89]
        getitem_28959 = split_1534[90]
        getitem_28960 = split_1534[91]
        getitem_28961 = split_1534[92]
        getitem_28962 = split_1534[93]
        getitem_28963 = split_1534[94]
        getitem_28964 = split_1534[95]
        getitem_28965 = split_1534[96]
        getitem_28966 = split_1534[97]
        getitem_28967 = split_1534[98]
        getitem_28968 = split_1534[99]
        getitem_28969 = split_1534[100]
        getitem_28970 = split_1534[101]
        getitem_28971 = split_1534[102]
        getitem_28972 = split_1534[103]
        getitem_28973 = split_1534[104]
        getitem_28974 = split_1534[105]
        getitem_28975 = split_1534[106]
        getitem_28976 = split_1534[107]
        getitem_28977 = split_1534[108]
        getitem_28978 = split_1534[109]
        getitem_28979 = split_1534[110]
        getitem_28980 = split_1534[111]
        getitem_28981 = split_1534[112]
        getitem_28982 = split_1534[113]
        getitem_28983 = split_1534[114]
        getitem_28984 = split_1534[115]
        getitem_28985 = split_1534[116]
        getitem_28986 = split_1534[117]
        getitem_28987 = split_1534[118]
        getitem_28988 = split_1534[119]
        getitem_28989 = split_1534[120]
        getitem_28990 = split_1534[121]
        getitem_28991 = split_1534[122]
        getitem_28992 = split_1534[123]
        getitem_28993 = split_1534[124]
        getitem_28994 = split_1534[125]
        getitem_28995 = split_1534[126]
        getitem_28996 = split_1534[127];  split_1534 = None
        constant_pad_nd_2002 = torch.ops.aten.constant_pad_nd.default(getitem_28996, [0, 0, 0, 64], 0.0);  getitem_28996 = None
        cat_444 = torch.ops.aten.cat.default([getitem_28869, getitem_28870, getitem_28871, getitem_28872, getitem_28873, getitem_28874, getitem_28875, getitem_28876, getitem_28877, getitem_28878, getitem_28879, getitem_28880, getitem_28881, getitem_28882, getitem_28883, getitem_28884, getitem_28885, getitem_28886, getitem_28887, getitem_28888, getitem_28889, getitem_28890, getitem_28891, getitem_28892, getitem_28893, getitem_28894, getitem_28895, getitem_28896, getitem_28897, getitem_28898, getitem_28899, getitem_28900, getitem_28901, getitem_28902, getitem_28903, getitem_28904, getitem_28905, getitem_28906, getitem_28907, getitem_28908, getitem_28909, getitem_28910, getitem_28911, getitem_28912, getitem_28913, getitem_28914, getitem_28915, getitem_28916, getitem_28917, getitem_28918, getitem_28919, getitem_28920, getitem_28921, getitem_28922, getitem_28923, getitem_28924, getitem_28925, getitem_28926, getitem_28927, getitem_28928, getitem_28929, getitem_28930, getitem_28931, getitem_28932, getitem_28933, getitem_28934, getitem_28935, getitem_28936, getitem_28937, getitem_28938, getitem_28939, getitem_28940, getitem_28941, getitem_28942, getitem_28943, getitem_28944, getitem_28945, getitem_28946, getitem_28947, getitem_28948, getitem_28949, getitem_28950, getitem_28951, getitem_28952, getitem_28953, getitem_28954, getitem_28955, getitem_28956, getitem_28957, getitem_28958, getitem_28959, getitem_28960, getitem_28961, getitem_28962, getitem_28963, getitem_28964, getitem_28965, getitem_28966, getitem_28967, getitem_28968, getitem_28969, getitem_28970, getitem_28971, getitem_28972, getitem_28973, getitem_28974, getitem_28975, getitem_28976, getitem_28977, getitem_28978, getitem_28979, getitem_28980, getitem_28981, getitem_28982, getitem_28983, getitem_28984, getitem_28985, getitem_28986, getitem_28987, getitem_28988, getitem_28989, getitem_28990, getitem_28991, getitem_28992, getitem_28993, getitem_28994, getitem_28995, constant_pad_nd_2002]);  getitem_28869 = getitem_28870 = getitem_28871 = getitem_28872 = getitem_28873 = getitem_28874 = getitem_28875 = getitem_28876 = getitem_28877 = getitem_28878 = getitem_28879 = getitem_28880 = getitem_28881 = getitem_28882 = getitem_28883 = getitem_28884 = getitem_28885 = getitem_28886 = getitem_28887 = getitem_28888 = getitem_28889 = getitem_28890 = getitem_28891 = getitem_28892 = getitem_28893 = getitem_28894 = getitem_28895 = getitem_28896 = getitem_28897 = getitem_28898 = getitem_28899 = getitem_28900 = getitem_28901 = getitem_28902 = getitem_28903 = getitem_28904 = getitem_28905 = getitem_28906 = getitem_28907 = getitem_28908 = getitem_28909 = getitem_28910 = getitem_28911 = getitem_28912 = getitem_28913 = getitem_28914 = getitem_28915 = getitem_28916 = getitem_28917 = getitem_28918 = getitem_28919 = getitem_28920 = getitem_28921 = getitem_28922 = getitem_28923 = getitem_28924 = getitem_28925 = getitem_28926 = getitem_28927 = getitem_28928 = getitem_28929 = getitem_28930 = getitem_28931 = getitem_28932 = getitem_28933 = getitem_28934 = getitem_28935 = getitem_28936 = getitem_28937 = getitem_28938 = getitem_28939 = getitem_28940 = getitem_28941 = getitem_28942 = getitem_28943 = getitem_28944 = getitem_28945 = getitem_28946 = getitem_28947 = getitem_28948 = getitem_28949 = getitem_28950 = getitem_28951 = getitem_28952 = getitem_28953 = getitem_28954 = getitem_28955 = getitem_28956 = getitem_28957 = getitem_28958 = getitem_28959 = getitem_28960 = getitem_28961 = getitem_28962 = getitem_28963 = getitem_28964 = getitem_28965 = getitem_28966 = getitem_28967 = getitem_28968 = getitem_28969 = getitem_28970 = getitem_28971 = getitem_28972 = getitem_28973 = getitem_28974 = getitem_28975 = getitem_28976 = getitem_28977 = getitem_28978 = getitem_28979 = getitem_28980 = getitem_28981 = getitem_28982 = getitem_28983 = getitem_28984 = getitem_28985 = getitem_28986 = getitem_28987 = getitem_28988 = getitem_28989 = getitem_28990 = getitem_28991 = getitem_28992 = getitem_28993 = getitem_28994 = getitem_28995 = constant_pad_nd_2002 = None
        reduce_scatter_tensor_367 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_444, 'avg', 128, '0');  cat_444 = None
        wait_tensor_978 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_367);  reduce_scatter_tensor_367 = None
        convert_element_type_3392 = torch.ops.prims.convert_element_type.default(mul_2176, torch.float32);  mul_2176 = None
        reciprocal_52 = torch.ops.aten.reciprocal.default(add_4);  add_4 = None
        mul_2177 = torch.ops.aten.mul.Tensor(reciprocal_52, 1);  reciprocal_52 = None
        mul_2178 = torch.ops.aten.mul.Tensor(convert_element_type_3392, mul_2177);  convert_element_type_3392 = None
        sub_781 = torch.ops.aten.sub.Tensor(1, mul_2177);  mul_2177 = None
        mul_2179 = torch.ops.aten.mul.Tensor(convert_element_type_29, sub_781);  convert_element_type_29 = sub_781 = None
        add_2166 = torch.ops.aten.add.Tensor(mul_2179, 1);  mul_2179 = None
        mul_2180 = torch.ops.aten.mul.Tensor(mul_2178, add_2166);  mul_2178 = add_2166 = None
        convert_element_type_3394 = torch.ops.prims.convert_element_type.default(mul_2180, torch.bfloat16);  mul_2180 = None
        view_2280 = torch.ops.aten.view.default(convert_element_type_3394, [8192, 10944]);  convert_element_type_3394 = None
        permute_1714 = torch.ops.aten.permute.default(view_2280, [1, 0])
        mm_638 = torch.ops.aten.mm.default(permute_1714, view_26);  permute_1714 = view_26 = None
        convert_element_type_26 = torch.ops.prims.convert_element_type.default(primals_20, torch.bfloat16);  primals_20 = None
        all_gather_into_tensor_8 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_26, 128, '0');  convert_element_type_26 = None
        wait_tensor_8 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_8);  all_gather_into_tensor_8 = None
        slice_4 = torch.ops.aten.slice.Tensor(wait_tensor_8, 0, 0, 10944);  wait_tensor_8 = None
        permute_8 = torch.ops.aten.permute.default(slice_4, [1, 0]);  slice_4 = None
        permute_1716 = torch.ops.aten.permute.default(permute_8, [1, 0]);  permute_8 = None
        mm_639 = torch.ops.aten.mm.default(view_2280, permute_1716);  view_2280 = permute_1716 = None
        view_2281 = torch.ops.aten.view.default(mm_639, [2, 4096, 2048]);  mm_639 = None
        add_2167 = torch.ops.aten.add.Tensor(view_2279, view_2281);  view_2279 = view_2281 = None
        convert_element_type_3399 = torch.ops.prims.convert_element_type.default(mm_638, torch.float32);  mm_638 = None
        split_1535 = torch.ops.aten.split.Tensor(convert_element_type_3399, 86);  convert_element_type_3399 = None
        getitem_28997 = split_1535[0]
        getitem_28998 = split_1535[1]
        getitem_28999 = split_1535[2]
        getitem_29000 = split_1535[3]
        getitem_29001 = split_1535[4]
        getitem_29002 = split_1535[5]
        getitem_29003 = split_1535[6]
        getitem_29004 = split_1535[7]
        getitem_29005 = split_1535[8]
        getitem_29006 = split_1535[9]
        getitem_29007 = split_1535[10]
        getitem_29008 = split_1535[11]
        getitem_29009 = split_1535[12]
        getitem_29010 = split_1535[13]
        getitem_29011 = split_1535[14]
        getitem_29012 = split_1535[15]
        getitem_29013 = split_1535[16]
        getitem_29014 = split_1535[17]
        getitem_29015 = split_1535[18]
        getitem_29016 = split_1535[19]
        getitem_29017 = split_1535[20]
        getitem_29018 = split_1535[21]
        getitem_29019 = split_1535[22]
        getitem_29020 = split_1535[23]
        getitem_29021 = split_1535[24]
        getitem_29022 = split_1535[25]
        getitem_29023 = split_1535[26]
        getitem_29024 = split_1535[27]
        getitem_29025 = split_1535[28]
        getitem_29026 = split_1535[29]
        getitem_29027 = split_1535[30]
        getitem_29028 = split_1535[31]
        getitem_29029 = split_1535[32]
        getitem_29030 = split_1535[33]
        getitem_29031 = split_1535[34]
        getitem_29032 = split_1535[35]
        getitem_29033 = split_1535[36]
        getitem_29034 = split_1535[37]
        getitem_29035 = split_1535[38]
        getitem_29036 = split_1535[39]
        getitem_29037 = split_1535[40]
        getitem_29038 = split_1535[41]
        getitem_29039 = split_1535[42]
        getitem_29040 = split_1535[43]
        getitem_29041 = split_1535[44]
        getitem_29042 = split_1535[45]
        getitem_29043 = split_1535[46]
        getitem_29044 = split_1535[47]
        getitem_29045 = split_1535[48]
        getitem_29046 = split_1535[49]
        getitem_29047 = split_1535[50]
        getitem_29048 = split_1535[51]
        getitem_29049 = split_1535[52]
        getitem_29050 = split_1535[53]
        getitem_29051 = split_1535[54]
        getitem_29052 = split_1535[55]
        getitem_29053 = split_1535[56]
        getitem_29054 = split_1535[57]
        getitem_29055 = split_1535[58]
        getitem_29056 = split_1535[59]
        getitem_29057 = split_1535[60]
        getitem_29058 = split_1535[61]
        getitem_29059 = split_1535[62]
        getitem_29060 = split_1535[63]
        getitem_29061 = split_1535[64]
        getitem_29062 = split_1535[65]
        getitem_29063 = split_1535[66]
        getitem_29064 = split_1535[67]
        getitem_29065 = split_1535[68]
        getitem_29066 = split_1535[69]
        getitem_29067 = split_1535[70]
        getitem_29068 = split_1535[71]
        getitem_29069 = split_1535[72]
        getitem_29070 = split_1535[73]
        getitem_29071 = split_1535[74]
        getitem_29072 = split_1535[75]
        getitem_29073 = split_1535[76]
        getitem_29074 = split_1535[77]
        getitem_29075 = split_1535[78]
        getitem_29076 = split_1535[79]
        getitem_29077 = split_1535[80]
        getitem_29078 = split_1535[81]
        getitem_29079 = split_1535[82]
        getitem_29080 = split_1535[83]
        getitem_29081 = split_1535[84]
        getitem_29082 = split_1535[85]
        getitem_29083 = split_1535[86]
        getitem_29084 = split_1535[87]
        getitem_29085 = split_1535[88]
        getitem_29086 = split_1535[89]
        getitem_29087 = split_1535[90]
        getitem_29088 = split_1535[91]
        getitem_29089 = split_1535[92]
        getitem_29090 = split_1535[93]
        getitem_29091 = split_1535[94]
        getitem_29092 = split_1535[95]
        getitem_29093 = split_1535[96]
        getitem_29094 = split_1535[97]
        getitem_29095 = split_1535[98]
        getitem_29096 = split_1535[99]
        getitem_29097 = split_1535[100]
        getitem_29098 = split_1535[101]
        getitem_29099 = split_1535[102]
        getitem_29100 = split_1535[103]
        getitem_29101 = split_1535[104]
        getitem_29102 = split_1535[105]
        getitem_29103 = split_1535[106]
        getitem_29104 = split_1535[107]
        getitem_29105 = split_1535[108]
        getitem_29106 = split_1535[109]
        getitem_29107 = split_1535[110]
        getitem_29108 = split_1535[111]
        getitem_29109 = split_1535[112]
        getitem_29110 = split_1535[113]
        getitem_29111 = split_1535[114]
        getitem_29112 = split_1535[115]
        getitem_29113 = split_1535[116]
        getitem_29114 = split_1535[117]
        getitem_29115 = split_1535[118]
        getitem_29116 = split_1535[119]
        getitem_29117 = split_1535[120]
        getitem_29118 = split_1535[121]
        getitem_29119 = split_1535[122]
        getitem_29120 = split_1535[123]
        getitem_29121 = split_1535[124]
        getitem_29122 = split_1535[125]
        getitem_29123 = split_1535[126]
        getitem_29124 = split_1535[127];  split_1535 = None
        constant_pad_nd_2003 = torch.ops.aten.constant_pad_nd.default(getitem_29124, [0, 0, 0, 64], 0.0);  getitem_29124 = None
        cat_445 = torch.ops.aten.cat.default([getitem_28997, getitem_28998, getitem_28999, getitem_29000, getitem_29001, getitem_29002, getitem_29003, getitem_29004, getitem_29005, getitem_29006, getitem_29007, getitem_29008, getitem_29009, getitem_29010, getitem_29011, getitem_29012, getitem_29013, getitem_29014, getitem_29015, getitem_29016, getitem_29017, getitem_29018, getitem_29019, getitem_29020, getitem_29021, getitem_29022, getitem_29023, getitem_29024, getitem_29025, getitem_29026, getitem_29027, getitem_29028, getitem_29029, getitem_29030, getitem_29031, getitem_29032, getitem_29033, getitem_29034, getitem_29035, getitem_29036, getitem_29037, getitem_29038, getitem_29039, getitem_29040, getitem_29041, getitem_29042, getitem_29043, getitem_29044, getitem_29045, getitem_29046, getitem_29047, getitem_29048, getitem_29049, getitem_29050, getitem_29051, getitem_29052, getitem_29053, getitem_29054, getitem_29055, getitem_29056, getitem_29057, getitem_29058, getitem_29059, getitem_29060, getitem_29061, getitem_29062, getitem_29063, getitem_29064, getitem_29065, getitem_29066, getitem_29067, getitem_29068, getitem_29069, getitem_29070, getitem_29071, getitem_29072, getitem_29073, getitem_29074, getitem_29075, getitem_29076, getitem_29077, getitem_29078, getitem_29079, getitem_29080, getitem_29081, getitem_29082, getitem_29083, getitem_29084, getitem_29085, getitem_29086, getitem_29087, getitem_29088, getitem_29089, getitem_29090, getitem_29091, getitem_29092, getitem_29093, getitem_29094, getitem_29095, getitem_29096, getitem_29097, getitem_29098, getitem_29099, getitem_29100, getitem_29101, getitem_29102, getitem_29103, getitem_29104, getitem_29105, getitem_29106, getitem_29107, getitem_29108, getitem_29109, getitem_29110, getitem_29111, getitem_29112, getitem_29113, getitem_29114, getitem_29115, getitem_29116, getitem_29117, getitem_29118, getitem_29119, getitem_29120, getitem_29121, getitem_29122, getitem_29123, constant_pad_nd_2003]);  getitem_28997 = getitem_28998 = getitem_28999 = getitem_29000 = getitem_29001 = getitem_29002 = getitem_29003 = getitem_29004 = getitem_29005 = getitem_29006 = getitem_29007 = getitem_29008 = getitem_29009 = getitem_29010 = getitem_29011 = getitem_29012 = getitem_29013 = getitem_29014 = getitem_29015 = getitem_29016 = getitem_29017 = getitem_29018 = getitem_29019 = getitem_29020 = getitem_29021 = getitem_29022 = getitem_29023 = getitem_29024 = getitem_29025 = getitem_29026 = getitem_29027 = getitem_29028 = getitem_29029 = getitem_29030 = getitem_29031 = getitem_29032 = getitem_29033 = getitem_29034 = getitem_29035 = getitem_29036 = getitem_29037 = getitem_29038 = getitem_29039 = getitem_29040 = getitem_29041 = getitem_29042 = getitem_29043 = getitem_29044 = getitem_29045 = getitem_29046 = getitem_29047 = getitem_29048 = getitem_29049 = getitem_29050 = getitem_29051 = getitem_29052 = getitem_29053 = getitem_29054 = getitem_29055 = getitem_29056 = getitem_29057 = getitem_29058 = getitem_29059 = getitem_29060 = getitem_29061 = getitem_29062 = getitem_29063 = getitem_29064 = getitem_29065 = getitem_29066 = getitem_29067 = getitem_29068 = getitem_29069 = getitem_29070 = getitem_29071 = getitem_29072 = getitem_29073 = getitem_29074 = getitem_29075 = getitem_29076 = getitem_29077 = getitem_29078 = getitem_29079 = getitem_29080 = getitem_29081 = getitem_29082 = getitem_29083 = getitem_29084 = getitem_29085 = getitem_29086 = getitem_29087 = getitem_29088 = getitem_29089 = getitem_29090 = getitem_29091 = getitem_29092 = getitem_29093 = getitem_29094 = getitem_29095 = getitem_29096 = getitem_29097 = getitem_29098 = getitem_29099 = getitem_29100 = getitem_29101 = getitem_29102 = getitem_29103 = getitem_29104 = getitem_29105 = getitem_29106 = getitem_29107 = getitem_29108 = getitem_29109 = getitem_29110 = getitem_29111 = getitem_29112 = getitem_29113 = getitem_29114 = getitem_29115 = getitem_29116 = getitem_29117 = getitem_29118 = getitem_29119 = getitem_29120 = getitem_29121 = getitem_29122 = getitem_29123 = constant_pad_nd_2003 = None
        reduce_scatter_tensor_368 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_445, 'avg', 128, '0');  cat_445 = None
        wait_tensor_979 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_368);  reduce_scatter_tensor_368 = None
        convert_element_type_3400 = torch.ops.prims.convert_element_type.default(add_2167, torch.float32);  add_2167 = None
        convert_element_type_23 = torch.ops.prims.convert_element_type.default(primals_19, torch.bfloat16);  primals_19 = None
        all_gather_into_tensor_7 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_23, 128, '0');  convert_element_type_23 = None
        wait_tensor_7 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_7);  all_gather_into_tensor_7 = None
        convert_element_type_3402 = torch.ops.prims.convert_element_type.default(wait_tensor_7, torch.float32);  wait_tensor_7 = None
        mul_2181 = torch.ops.aten.mul.Tensor(convert_element_type_3400, convert_element_type_3402);  convert_element_type_3402 = None
        view_23 = torch.ops.aten.view.default(mm_3, [2, 4096, 2048]);  mm_3 = None
        add_2 = torch.ops.aten.add.Tensor(embedding, view_23);  view_23 = None
        convert_element_type_24 = torch.ops.prims.convert_element_type.default(add_2, torch.float32);  add_2 = None
        mul_6 = torch.ops.aten.mul.Tensor(convert_element_type_24, rsqrt_2);  convert_element_type_24 = None
        mul_2183 = torch.ops.aten.mul.Tensor(mul_6, mul_2181)
        sum_315 = torch.ops.aten.sum.dim_IntList(mul_2183, [2], True);  mul_2183 = None
        div_288 = torch.ops.aten.div.Tensor(mul_6, 2048)
        mul_2184 = torch.ops.aten.mul.Tensor(div_288, sum_315);  div_288 = sum_315 = None
        sub_782 = torch.ops.aten.sub.Tensor(mul_2181, mul_2184);  mul_2181 = mul_2184 = None
        mul_2185 = torch.ops.aten.mul.Tensor(sub_782, rsqrt_2);  sub_782 = rsqrt_2 = None
        mul_2186 = torch.ops.aten.mul.Tensor(convert_element_type_3400, mul_6);  convert_element_type_3400 = mul_6 = None
        sum_316 = torch.ops.aten.sum.dim_IntList(mul_2186, [0, 1]);  mul_2186 = None
        convert_element_type_3403 = torch.ops.prims.convert_element_type.default(mul_2185, torch.bfloat16);  mul_2185 = None
        add_2168 = torch.ops.aten.add.Tensor(add_2164, convert_element_type_3403);  add_2164 = convert_element_type_3403 = None
        convert_element_type_default_3 = torch.ops.prims.convert_element_type.default(sum_316, torch.float32);  sum_316 = None
        reduce_scatter_tensor_369 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_3, 'avg', 128, '0');  convert_element_type_default_3 = None
        wait_tensor_980 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_369);  reduce_scatter_tensor_369 = None
        view_2282 = torch.ops.aten.view.default(add_2168, [8192, 2048])
        permute_1718 = torch.ops.aten.permute.default(view_2282, [1, 0])
        permute_6 = torch.ops.aten.permute.default(getitem_6, [0, 2, 1, 3])
        view_20 = torch.ops.aten.view.default(permute_6, [2, 4096, -1]);  permute_6 = None
        view_22 = torch.ops.aten.view.default(view_20, [8192, 2048]);  view_20 = None
        mm_640 = torch.ops.aten.mm.default(permute_1718, view_22);  permute_1718 = view_22 = None
        convert_element_type_20 = torch.ops.prims.convert_element_type.default(primals_18, torch.bfloat16);  primals_18 = None
        all_gather_into_tensor_6 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_20, 128, '0');  convert_element_type_20 = None
        wait_tensor_6 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_6);  all_gather_into_tensor_6 = None
        permute_7 = torch.ops.aten.permute.default(wait_tensor_6, [1, 0]);  wait_tensor_6 = None
        permute_1720 = torch.ops.aten.permute.default(permute_7, [1, 0]);  permute_7 = None
        mm_641 = torch.ops.aten.mm.default(view_2282, permute_1720);  view_2282 = permute_1720 = None
        view_2283 = torch.ops.aten.view.default(mm_641, [2, 4096, 2048]);  mm_641 = None
        convert_element_type_3410 = torch.ops.prims.convert_element_type.default(mm_640, torch.float32);  mm_640 = None
        reduce_scatter_tensor_370 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3410, 'avg', 128, '0');  convert_element_type_3410 = None
        wait_tensor_981 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_370);  reduce_scatter_tensor_370 = None
        view_2284 = torch.ops.aten.view.default(view_2283, [2, 4096, 16, 128]);  view_2283 = None
        permute_1722 = torch.ops.aten.permute.default(view_2284, [0, 2, 1, 3]);  view_2284 = None
        fw_graph26 = self.fw_graph26
        joint_graph26 = self.joint_graph26
        mask_graph26 = self.mask_graph26
        flex_attention_backward_26 = torch.ops.higher_order.flex_attention_backward(permute_3, permute_4, permute_5, getitem_6, getitem_7, permute_1722, None, fw_graph26, joint_graph26, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, mask_graph26), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  permute_3 = permute_4 = permute_5 = getitem_6 = getitem_7 = permute_1722 = fw_graph26 = joint_graph26 = primals_10 = primals_9 = primals_12 = primals_13 = primals_14 = primals_15 = primals_16 = primals_17 = mask_graph26 = primals_11 = None
        getitem_29125 = flex_attention_backward_26[0]
        getitem_29126 = flex_attention_backward_26[1]
        getitem_29127 = flex_attention_backward_26[2];  flex_attention_backward_26 = None
        permute_1723 = torch.ops.aten.permute.default(getitem_29127, [0, 2, 1, 3]);  getitem_29127 = None
        permute_1724 = torch.ops.aten.permute.default(getitem_29126, [0, 2, 1, 3]);  getitem_29126 = None
        permute_1725 = torch.ops.aten.permute.default(getitem_29125, [0, 2, 1, 3]);  getitem_29125 = None
        slice_318 = torch.ops.aten.slice.Tensor(permute_1724, 3, 0, 128)
        slice_319 = torch.ops.aten.slice.Tensor(permute_1724, 3, 128, 192);  permute_1724 = None
        sum_317 = torch.ops.aten.sum.dim_IntList(slice_319, [2], True);  slice_319 = None
        cat_446 = torch.ops.aten.cat.default([slice_318, permute_1723], 3);  slice_318 = permute_1723 = None
        view_2285 = torch.ops.aten.view.default(cat_446, [2, 4096, 4096]);  cat_446 = None
        view_2286 = torch.ops.aten.view.default(view_2285, [8192, 4096]);  view_2285 = None
        permute_1726 = torch.ops.aten.permute.default(view_2286, [1, 0])
        mm_642 = torch.ops.aten.mm.default(permute_1726, view_17);  permute_1726 = view_17 = None
        convert_element_type_17 = torch.ops.prims.convert_element_type.default(primals_8, torch.bfloat16);  primals_8 = None
        all_gather_into_tensor_5 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_17, 128, '0');  convert_element_type_17 = None
        wait_tensor_5 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_5);  all_gather_into_tensor_5 = None
        permute_2 = torch.ops.aten.permute.default(wait_tensor_5, [1, 0]);  wait_tensor_5 = None
        permute_1728 = torch.ops.aten.permute.default(permute_2, [1, 0]);  permute_2 = None
        mm_643 = torch.ops.aten.mm.default(view_2286, permute_1728);  view_2286 = permute_1728 = None
        view_2287 = torch.ops.aten.view.default(mm_643, [2, 4096, 512]);  mm_643 = None
        convert_element_type_3415 = torch.ops.prims.convert_element_type.default(mm_642, torch.float32);  mm_642 = None
        reduce_scatter_tensor_371 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3415, 'avg', 128, '0');  convert_element_type_3415 = None
        wait_tensor_982 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_371);  reduce_scatter_tensor_371 = None
        convert_element_type_3416 = torch.ops.prims.convert_element_type.default(view_2287, torch.float32);  view_2287 = None
        convert_element_type_14 = torch.ops.prims.convert_element_type.default(primals_7, torch.bfloat16);  primals_7 = None
        all_gather_into_tensor_4 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_14, 128, '0');  convert_element_type_14 = None
        wait_tensor_4 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_4);  all_gather_into_tensor_4 = None
        convert_element_type_3418 = torch.ops.prims.convert_element_type.default(wait_tensor_4, torch.float32);  wait_tensor_4 = None
        mul_2187 = torch.ops.aten.mul.Tensor(convert_element_type_3416, convert_element_type_3418);  convert_element_type_3418 = None
        convert_element_type_15 = torch.ops.prims.convert_element_type.default(getitem_2, torch.float32);  getitem_2 = None
        mul_4 = torch.ops.aten.mul.Tensor(convert_element_type_15, rsqrt_1);  convert_element_type_15 = None
        mul_2189 = torch.ops.aten.mul.Tensor(mul_4, mul_2187)
        sum_318 = torch.ops.aten.sum.dim_IntList(mul_2189, [2], True);  mul_2189 = None
        div_289 = torch.ops.aten.div.Tensor(mul_4, 512)
        mul_2190 = torch.ops.aten.mul.Tensor(div_289, sum_318);  div_289 = sum_318 = None
        sub_783 = torch.ops.aten.sub.Tensor(mul_2187, mul_2190);  mul_2187 = mul_2190 = None
        mul_2191 = torch.ops.aten.mul.Tensor(sub_783, rsqrt_1);  sub_783 = rsqrt_1 = None
        mul_2192 = torch.ops.aten.mul.Tensor(convert_element_type_3416, mul_4);  convert_element_type_3416 = mul_4 = None
        sum_319 = torch.ops.aten.sum.dim_IntList(mul_2192, [0, 1]);  mul_2192 = None
        convert_element_type_3419 = torch.ops.prims.convert_element_type.default(mul_2191, torch.bfloat16);  mul_2191 = None
        convert_element_type_default_2 = torch.ops.prims.convert_element_type.default(sum_319, torch.float32);  sum_319 = None
        reduce_scatter_tensor_372 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_2, 'avg', 128, '0');  convert_element_type_default_2 = None
        wait_tensor_983 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_372);  reduce_scatter_tensor_372 = None
        convert_element_type_3422 = torch.ops.prims.convert_element_type.default(sum_317, torch.float32);  sum_317 = None
        view_2288 = torch.ops.aten.view.default(convert_element_type_3422, [2, 4096, 1, 32, 2]);  convert_element_type_3422 = None
        view_as_complex_106 = torch.ops.aten.view_as_complex.default(view_2288);  view_2288 = None
        mul_2193 = torch.ops.aten.mul.Tensor(view_as_complex_106, clone_9);  view_as_complex_106 = None
        view_as_real_106 = torch.ops.aten.view_as_real.default(mul_2193);  mul_2193 = None
        view_2289 = torch.ops.aten.view.default(view_as_real_106, [2, 4096, 1, 64]);  view_as_real_106 = None
        convert_element_type_3423 = torch.ops.prims.convert_element_type.default(view_2289, torch.bfloat16);  view_2289 = None
        squeeze_52 = torch.ops.aten.squeeze.dim(convert_element_type_3423, 2);  convert_element_type_3423 = None
        cat_447 = torch.ops.aten.cat.default([convert_element_type_3419, squeeze_52], 2);  convert_element_type_3419 = squeeze_52 = None
        view_2290 = torch.ops.aten.view.default(cat_447, [8192, 576]);  cat_447 = None
        permute_1730 = torch.ops.aten.permute.default(view_2290, [1, 0])
        mm_644 = torch.ops.aten.mm.default(permute_1730, view_3);  permute_1730 = None
        convert_element_type_9 = torch.ops.prims.convert_element_type.default(primals_6, torch.bfloat16);  primals_6 = None
        all_gather_into_tensor_3 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_9, 128, '0');  convert_element_type_9 = None
        wait_tensor_3 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_3);  all_gather_into_tensor_3 = None
        slice_2 = torch.ops.aten.slice.Tensor(wait_tensor_3, 0, 0, 576);  wait_tensor_3 = None
        permute_1 = torch.ops.aten.permute.default(slice_2, [1, 0]);  slice_2 = None
        permute_1732 = torch.ops.aten.permute.default(permute_1, [1, 0]);  permute_1 = None
        mm_645 = torch.ops.aten.mm.default(view_2290, permute_1732);  view_2290 = permute_1732 = None
        view_2291 = torch.ops.aten.view.default(mm_645, [2, 4096, 2048]);  mm_645 = None
        convert_element_type_3428 = torch.ops.prims.convert_element_type.default(mm_644, torch.float32);  mm_644 = None
        split_1536 = torch.ops.aten.split.Tensor(convert_element_type_3428, 5);  convert_element_type_3428 = None
        getitem_29129 = split_1536[0]
        getitem_29130 = split_1536[1]
        getitem_29131 = split_1536[2]
        getitem_29132 = split_1536[3]
        getitem_29133 = split_1536[4]
        getitem_29134 = split_1536[5]
        getitem_29135 = split_1536[6]
        getitem_29136 = split_1536[7]
        getitem_29137 = split_1536[8]
        getitem_29138 = split_1536[9]
        getitem_29139 = split_1536[10]
        getitem_29140 = split_1536[11]
        getitem_29141 = split_1536[12]
        getitem_29142 = split_1536[13]
        getitem_29143 = split_1536[14]
        getitem_29144 = split_1536[15]
        getitem_29145 = split_1536[16]
        getitem_29146 = split_1536[17]
        getitem_29147 = split_1536[18]
        getitem_29148 = split_1536[19]
        getitem_29149 = split_1536[20]
        getitem_29150 = split_1536[21]
        getitem_29151 = split_1536[22]
        getitem_29152 = split_1536[23]
        getitem_29153 = split_1536[24]
        getitem_29154 = split_1536[25]
        getitem_29155 = split_1536[26]
        getitem_29156 = split_1536[27]
        getitem_29157 = split_1536[28]
        getitem_29158 = split_1536[29]
        getitem_29159 = split_1536[30]
        getitem_29160 = split_1536[31]
        getitem_29161 = split_1536[32]
        getitem_29162 = split_1536[33]
        getitem_29163 = split_1536[34]
        getitem_29164 = split_1536[35]
        getitem_29165 = split_1536[36]
        getitem_29166 = split_1536[37]
        getitem_29167 = split_1536[38]
        getitem_29168 = split_1536[39]
        getitem_29169 = split_1536[40]
        getitem_29170 = split_1536[41]
        getitem_29171 = split_1536[42]
        getitem_29172 = split_1536[43]
        getitem_29173 = split_1536[44]
        getitem_29174 = split_1536[45]
        getitem_29175 = split_1536[46]
        getitem_29176 = split_1536[47]
        getitem_29177 = split_1536[48]
        getitem_29178 = split_1536[49]
        getitem_29179 = split_1536[50]
        getitem_29180 = split_1536[51]
        getitem_29181 = split_1536[52]
        getitem_29182 = split_1536[53]
        getitem_29183 = split_1536[54]
        getitem_29184 = split_1536[55]
        getitem_29185 = split_1536[56]
        getitem_29186 = split_1536[57]
        getitem_29187 = split_1536[58]
        getitem_29188 = split_1536[59]
        getitem_29189 = split_1536[60]
        getitem_29190 = split_1536[61]
        getitem_29191 = split_1536[62]
        getitem_29192 = split_1536[63]
        getitem_29193 = split_1536[64]
        getitem_29194 = split_1536[65]
        getitem_29195 = split_1536[66]
        getitem_29196 = split_1536[67]
        getitem_29197 = split_1536[68]
        getitem_29198 = split_1536[69]
        getitem_29199 = split_1536[70]
        getitem_29200 = split_1536[71]
        getitem_29201 = split_1536[72]
        getitem_29202 = split_1536[73]
        getitem_29203 = split_1536[74]
        getitem_29204 = split_1536[75]
        getitem_29205 = split_1536[76]
        getitem_29206 = split_1536[77]
        getitem_29207 = split_1536[78]
        getitem_29208 = split_1536[79]
        getitem_29209 = split_1536[80]
        getitem_29210 = split_1536[81]
        getitem_29211 = split_1536[82]
        getitem_29212 = split_1536[83]
        getitem_29213 = split_1536[84]
        getitem_29214 = split_1536[85]
        getitem_29215 = split_1536[86]
        getitem_29216 = split_1536[87]
        getitem_29217 = split_1536[88]
        getitem_29218 = split_1536[89]
        getitem_29219 = split_1536[90]
        getitem_29220 = split_1536[91]
        getitem_29221 = split_1536[92]
        getitem_29222 = split_1536[93]
        getitem_29223 = split_1536[94]
        getitem_29224 = split_1536[95]
        getitem_29225 = split_1536[96]
        getitem_29226 = split_1536[97]
        getitem_29227 = split_1536[98]
        getitem_29228 = split_1536[99]
        getitem_29229 = split_1536[100]
        getitem_29230 = split_1536[101]
        getitem_29231 = split_1536[102]
        getitem_29232 = split_1536[103]
        getitem_29233 = split_1536[104]
        getitem_29234 = split_1536[105]
        getitem_29235 = split_1536[106]
        getitem_29236 = split_1536[107]
        getitem_29237 = split_1536[108]
        getitem_29238 = split_1536[109]
        getitem_29239 = split_1536[110]
        getitem_29240 = split_1536[111]
        getitem_29241 = split_1536[112]
        getitem_29242 = split_1536[113]
        getitem_29243 = split_1536[114]
        getitem_29244 = split_1536[115];  split_1536 = None
        constant_pad_nd_2004 = torch.ops.aten.constant_pad_nd.default(getitem_29244, [0, 0, 0, 4], 0.0);  getitem_29244 = None
        cat_448 = torch.ops.aten.cat.default([getitem_29129, getitem_29130, getitem_29131, getitem_29132, getitem_29133, getitem_29134, getitem_29135, getitem_29136, getitem_29137, getitem_29138, getitem_29139, getitem_29140, getitem_29141, getitem_29142, getitem_29143, getitem_29144, getitem_29145, getitem_29146, getitem_29147, getitem_29148, getitem_29149, getitem_29150, getitem_29151, getitem_29152, getitem_29153, getitem_29154, getitem_29155, getitem_29156, getitem_29157, getitem_29158, getitem_29159, getitem_29160, getitem_29161, getitem_29162, getitem_29163, getitem_29164, getitem_29165, getitem_29166, getitem_29167, getitem_29168, getitem_29169, getitem_29170, getitem_29171, getitem_29172, getitem_29173, getitem_29174, getitem_29175, getitem_29176, getitem_29177, getitem_29178, getitem_29179, getitem_29180, getitem_29181, getitem_29182, getitem_29183, getitem_29184, getitem_29185, getitem_29186, getitem_29187, getitem_29188, getitem_29189, getitem_29190, getitem_29191, getitem_29192, getitem_29193, getitem_29194, getitem_29195, getitem_29196, getitem_29197, getitem_29198, getitem_29199, getitem_29200, getitem_29201, getitem_29202, getitem_29203, getitem_29204, getitem_29205, getitem_29206, getitem_29207, getitem_29208, getitem_29209, getitem_29210, getitem_29211, getitem_29212, getitem_29213, getitem_29214, getitem_29215, getitem_29216, getitem_29217, getitem_29218, getitem_29219, getitem_29220, getitem_29221, getitem_29222, getitem_29223, getitem_29224, getitem_29225, getitem_29226, getitem_29227, getitem_29228, getitem_29229, getitem_29230, getitem_29231, getitem_29232, getitem_29233, getitem_29234, getitem_29235, getitem_29236, getitem_29237, getitem_29238, getitem_29239, getitem_29240, getitem_29241, getitem_29242, getitem_29243, constant_pad_nd_2004, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65, constant_pad_nd_65]);  getitem_29129 = getitem_29130 = getitem_29131 = getitem_29132 = getitem_29133 = getitem_29134 = getitem_29135 = getitem_29136 = getitem_29137 = getitem_29138 = getitem_29139 = getitem_29140 = getitem_29141 = getitem_29142 = getitem_29143 = getitem_29144 = getitem_29145 = getitem_29146 = getitem_29147 = getitem_29148 = getitem_29149 = getitem_29150 = getitem_29151 = getitem_29152 = getitem_29153 = getitem_29154 = getitem_29155 = getitem_29156 = getitem_29157 = getitem_29158 = getitem_29159 = getitem_29160 = getitem_29161 = getitem_29162 = getitem_29163 = getitem_29164 = getitem_29165 = getitem_29166 = getitem_29167 = getitem_29168 = getitem_29169 = getitem_29170 = getitem_29171 = getitem_29172 = getitem_29173 = getitem_29174 = getitem_29175 = getitem_29176 = getitem_29177 = getitem_29178 = getitem_29179 = getitem_29180 = getitem_29181 = getitem_29182 = getitem_29183 = getitem_29184 = getitem_29185 = getitem_29186 = getitem_29187 = getitem_29188 = getitem_29189 = getitem_29190 = getitem_29191 = getitem_29192 = getitem_29193 = getitem_29194 = getitem_29195 = getitem_29196 = getitem_29197 = getitem_29198 = getitem_29199 = getitem_29200 = getitem_29201 = getitem_29202 = getitem_29203 = getitem_29204 = getitem_29205 = getitem_29206 = getitem_29207 = getitem_29208 = getitem_29209 = getitem_29210 = getitem_29211 = getitem_29212 = getitem_29213 = getitem_29214 = getitem_29215 = getitem_29216 = getitem_29217 = getitem_29218 = getitem_29219 = getitem_29220 = getitem_29221 = getitem_29222 = getitem_29223 = getitem_29224 = getitem_29225 = getitem_29226 = getitem_29227 = getitem_29228 = getitem_29229 = getitem_29230 = getitem_29231 = getitem_29232 = getitem_29233 = getitem_29234 = getitem_29235 = getitem_29236 = getitem_29237 = getitem_29238 = getitem_29239 = getitem_29240 = getitem_29241 = getitem_29242 = getitem_29243 = constant_pad_nd_2004 = constant_pad_nd_65 = None
        reduce_scatter_tensor_373 = torch.ops._c10d_functional.reduce_scatter_tensor.default(cat_448, 'avg', 128, '0');  cat_448 = None
        wait_tensor_984 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_373);  reduce_scatter_tensor_373 = None
        slice_320 = torch.ops.aten.slice.Tensor(permute_1725, 3, 0, 128)
        slice_321 = torch.ops.aten.slice.Tensor(permute_1725, 3, 128, 192);  permute_1725 = None
        convert_element_type_3429 = torch.ops.prims.convert_element_type.default(slice_321, torch.float32);  slice_321 = None
        view_2292 = torch.ops.aten.view.default(convert_element_type_3429, [2, 4096, 16, 32, 2]);  convert_element_type_3429 = None
        view_as_complex_107 = torch.ops.aten.view_as_complex.default(view_2292);  view_2292 = None
        mul_2194 = torch.ops.aten.mul.Tensor(view_as_complex_107, clone_9);  view_as_complex_107 = clone_9 = None
        view_as_real_107 = torch.ops.aten.view_as_real.default(mul_2194);  mul_2194 = None
        view_2293 = torch.ops.aten.view.default(view_as_real_107, [2, 4096, 16, 64]);  view_as_real_107 = None
        convert_element_type_3430 = torch.ops.prims.convert_element_type.default(view_2293, torch.bfloat16);  view_2293 = None
        cat_449 = torch.ops.aten.cat.default([slice_320, convert_element_type_3430], 3);  slice_320 = convert_element_type_3430 = None
        view_2294 = torch.ops.aten.view.default(cat_449, [2, 4096, 3072]);  cat_449 = None
        view_2295 = torch.ops.aten.view.default(view_2294, [8192, 3072]);  view_2294 = None
        permute_1734 = torch.ops.aten.permute.default(view_2295, [1, 0])
        mm_646 = torch.ops.aten.mm.default(permute_1734, view_3);  permute_1734 = view_3 = None
        convert_element_type_4 = torch.ops.prims.convert_element_type.default(primals_5, torch.bfloat16);  primals_5 = None
        all_gather_into_tensor_2 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_4, 128, '0');  convert_element_type_4 = None
        wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_2);  all_gather_into_tensor_2 = None
        permute = torch.ops.aten.permute.default(wait_tensor_2, [1, 0]);  wait_tensor_2 = None
        permute_1736 = torch.ops.aten.permute.default(permute, [1, 0]);  permute = None
        mm_647 = torch.ops.aten.mm.default(view_2295, permute_1736);  view_2295 = permute_1736 = None
        view_2296 = torch.ops.aten.view.default(mm_647, [2, 4096, 2048]);  mm_647 = None
        add_2169 = torch.ops.aten.add.Tensor(view_2291, view_2296);  view_2291 = view_2296 = None
        convert_element_type_3435 = torch.ops.prims.convert_element_type.default(mm_646, torch.float32);  mm_646 = None
        reduce_scatter_tensor_374 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_3435, 'avg', 128, '0');  convert_element_type_3435 = None
        wait_tensor_985 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_374);  reduce_scatter_tensor_374 = None
        convert_element_type_3436 = torch.ops.prims.convert_element_type.default(add_2169, torch.float32);  add_2169 = None
        convert_element_type_1 = torch.ops.prims.convert_element_type.default(primals_4, torch.bfloat16);  primals_4 = None
        all_gather_into_tensor_1 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1, 128, '0');  convert_element_type_1 = None
        wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_1);  all_gather_into_tensor_1 = None
        convert_element_type_3438 = torch.ops.prims.convert_element_type.default(wait_tensor_1, torch.float32);  wait_tensor_1 = None
        mul_2195 = torch.ops.aten.mul.Tensor(convert_element_type_3436, convert_element_type_3438);  convert_element_type_3438 = None
        convert_element_type_2 = torch.ops.prims.convert_element_type.default(embedding, torch.float32);  embedding = None
        mul = torch.ops.aten.mul.Tensor(convert_element_type_2, rsqrt);  convert_element_type_2 = None
        mul_2197 = torch.ops.aten.mul.Tensor(mul, mul_2195)
        sum_320 = torch.ops.aten.sum.dim_IntList(mul_2197, [2], True);  mul_2197 = None
        div_290 = torch.ops.aten.div.Tensor(mul, 2048)
        mul_2198 = torch.ops.aten.mul.Tensor(div_290, sum_320);  div_290 = sum_320 = None
        sub_784 = torch.ops.aten.sub.Tensor(mul_2195, mul_2198);  mul_2195 = mul_2198 = None
        mul_2199 = torch.ops.aten.mul.Tensor(sub_784, rsqrt);  sub_784 = rsqrt = None
        mul_2200 = torch.ops.aten.mul.Tensor(convert_element_type_3436, mul);  convert_element_type_3436 = mul = None
        sum_321 = torch.ops.aten.sum.dim_IntList(mul_2200, [0, 1]);  mul_2200 = None
        convert_element_type_3439 = torch.ops.prims.convert_element_type.default(mul_2199, torch.bfloat16);  mul_2199 = None
        add_2170 = torch.ops.aten.add.Tensor(add_2168, convert_element_type_3439);  add_2168 = convert_element_type_3439 = None
        convert_element_type_default_1 = torch.ops.prims.convert_element_type.default(sum_321, torch.float32);  sum_321 = None
        reduce_scatter_tensor_375 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default_1, 'avg', 128, '0');  convert_element_type_default_1 = None
        wait_tensor_986 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_375);  reduce_scatter_tensor_375 = None
        convert_element_type_3442 = torch.ops.prims.convert_element_type.default(add_2170, torch.float32);  add_2170 = None
        eq_572 = torch.ops.aten.eq.Scalar(primals_2, -1)
        unsqueeze_79 = torch.ops.aten.unsqueeze.default(eq_572, -1);  eq_572 = None
        full_default_157 = torch.ops.aten.full.default([], 0.0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        where = torch.ops.aten.where.self(unsqueeze_79, full_default_157, convert_element_type_3442);  unsqueeze_79 = full_default_157 = convert_element_type_3442 = None
        full_default_158 = torch.ops.aten.full.default([102400, 2048], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_104 = torch.ops.aten.index_put.default(full_default_158, [primals_2], where, True);  full_default_158 = primals_2 = where = None
        convert_element_type_default = torch.ops.prims.convert_element_type.default(index_put_104, torch.float32);  index_put_104 = None
        reduce_scatter_tensor_376 = torch.ops._c10d_functional.reduce_scatter_tensor.default(convert_element_type_default, 'avg', 128, '0');  convert_element_type_default = None
        wait_tensor_987 = torch.ops._c10d_functional.wait_tensor.default(reduce_scatter_tensor_376);  reduce_scatter_tensor_376 = None
        return (wait_tensor_987, None, None, wait_tensor_986, wait_tensor_985, wait_tensor_984, wait_tensor_983, wait_tensor_982, None, None, None, None, None, None, None, None, None, wait_tensor_981, wait_tensor_980, wait_tensor_979, wait_tensor_978, wait_tensor_977, wait_tensor_976, wait_tensor_975, wait_tensor_974, wait_tensor_973, wait_tensor_972, wait_tensor_971, wait_tensor_970, None, wait_tensor_969, None, wait_tensor_967, wait_tensor_966, wait_tensor_965, wait_tensor_963, wait_tensor_962, wait_tensor_961, wait_tensor_960, wait_tensor_959, wait_tensor_958, wait_tensor_957, wait_tensor_956, wait_tensor_955, wait_tensor_954, None, wait_tensor_953, None, wait_tensor_951, wait_tensor_950, wait_tensor_949, wait_tensor_947, wait_tensor_946, wait_tensor_945, wait_tensor_944, wait_tensor_943, wait_tensor_942, wait_tensor_941, wait_tensor_940, wait_tensor_939, wait_tensor_938, None, wait_tensor_937, None, wait_tensor_935, wait_tensor_934, wait_tensor_933, wait_tensor_931, wait_tensor_930, wait_tensor_929, wait_tensor_928, wait_tensor_927, wait_tensor_926, wait_tensor_925, wait_tensor_924, wait_tensor_923, wait_tensor_922, None, wait_tensor_921, None, wait_tensor_919, wait_tensor_918, wait_tensor_917, wait_tensor_915, wait_tensor_914, wait_tensor_913, wait_tensor_912, wait_tensor_911, wait_tensor_910, wait_tensor_909, wait_tensor_908, wait_tensor_907, wait_tensor_906, None, wait_tensor_905, None, wait_tensor_903, wait_tensor_902, wait_tensor_901, wait_tensor_899, wait_tensor_898, wait_tensor_897, wait_tensor_896, wait_tensor_895, wait_tensor_894, wait_tensor_893, wait_tensor_892, wait_tensor_891, wait_tensor_890, None, wait_tensor_889, None, wait_tensor_887, wait_tensor_886, wait_tensor_885, wait_tensor_883, wait_tensor_882, wait_tensor_881, wait_tensor_880, wait_tensor_879, wait_tensor_878, wait_tensor_877, wait_tensor_876, wait_tensor_875, wait_tensor_874, None, wait_tensor_873, None, wait_tensor_871, wait_tensor_870, wait_tensor_869, wait_tensor_867, wait_tensor_866, wait_tensor_865, wait_tensor_864, wait_tensor_863, wait_tensor_862, wait_tensor_861, wait_tensor_860, wait_tensor_859, wait_tensor_858, None, wait_tensor_857, None, wait_tensor_855, wait_tensor_854, wait_tensor_853, wait_tensor_851, wait_tensor_850, wait_tensor_849, wait_tensor_848, wait_tensor_847, wait_tensor_846, wait_tensor_845, wait_tensor_844, wait_tensor_843, wait_tensor_842, None, wait_tensor_841, None, wait_tensor_839, wait_tensor_838, wait_tensor_837, wait_tensor_835, wait_tensor_834, wait_tensor_833, wait_tensor_832, wait_tensor_831, wait_tensor_830, wait_tensor_829, wait_tensor_828, wait_tensor_827, wait_tensor_826, None, wait_tensor_825, None, wait_tensor_823, wait_tensor_822, wait_tensor_821, wait_tensor_819, wait_tensor_818, wait_tensor_817, wait_tensor_816, wait_tensor_815, wait_tensor_814, wait_tensor_813, wait_tensor_812, wait_tensor_811, wait_tensor_810, None, wait_tensor_809, None, wait_tensor_807, wait_tensor_806, wait_tensor_805, wait_tensor_803, wait_tensor_802, wait_tensor_801, wait_tensor_800, wait_tensor_799, wait_tensor_798, wait_tensor_797, wait_tensor_796, wait_tensor_795, wait_tensor_794, None, wait_tensor_793, None, wait_tensor_791, wait_tensor_790, wait_tensor_789, wait_tensor_787, wait_tensor_786, wait_tensor_785, wait_tensor_784, wait_tensor_783, wait_tensor_782, wait_tensor_781, wait_tensor_780, wait_tensor_779, wait_tensor_778, None, wait_tensor_777, None, wait_tensor_775, wait_tensor_774, wait_tensor_773, wait_tensor_771, wait_tensor_770, wait_tensor_769, wait_tensor_768, wait_tensor_767, wait_tensor_766, wait_tensor_765, wait_tensor_764, wait_tensor_763, wait_tensor_762, None, wait_tensor_761, None, wait_tensor_759, wait_tensor_758, wait_tensor_757, wait_tensor_755, wait_tensor_754, wait_tensor_753, wait_tensor_752, wait_tensor_751, wait_tensor_750, wait_tensor_749, wait_tensor_748, wait_tensor_747, wait_tensor_746, None, wait_tensor_745, None, wait_tensor_743, wait_tensor_742, wait_tensor_741, wait_tensor_739, wait_tensor_738, wait_tensor_737, wait_tensor_736, wait_tensor_735, wait_tensor_734, wait_tensor_733, wait_tensor_732, wait_tensor_731, wait_tensor_730, None, wait_tensor_729, None, wait_tensor_727, wait_tensor_726, wait_tensor_725, wait_tensor_723, wait_tensor_722, wait_tensor_721, wait_tensor_720, wait_tensor_719, wait_tensor_718, wait_tensor_717, wait_tensor_716, wait_tensor_715, wait_tensor_714, None, wait_tensor_713, None, wait_tensor_711, wait_tensor_710, wait_tensor_709, wait_tensor_707, wait_tensor_706, wait_tensor_705, wait_tensor_704, wait_tensor_703, wait_tensor_702, wait_tensor_701, wait_tensor_700, wait_tensor_699, wait_tensor_698, None, wait_tensor_697, None, wait_tensor_695, wait_tensor_694, wait_tensor_693, wait_tensor_691, wait_tensor_690, wait_tensor_689, wait_tensor_688, wait_tensor_687, wait_tensor_686, wait_tensor_685, wait_tensor_684, wait_tensor_683, wait_tensor_682, None, wait_tensor_681, None, wait_tensor_679, wait_tensor_678, wait_tensor_677, wait_tensor_675, wait_tensor_674, wait_tensor_673, wait_tensor_672, wait_tensor_671, wait_tensor_670, wait_tensor_669, wait_tensor_668, wait_tensor_667, wait_tensor_666, None, wait_tensor_665, None, wait_tensor_663, wait_tensor_662, wait_tensor_661, wait_tensor_659, wait_tensor_658, wait_tensor_657, wait_tensor_656, wait_tensor_655, wait_tensor_654, wait_tensor_653, wait_tensor_652, wait_tensor_651, wait_tensor_650, None, wait_tensor_649, None, wait_tensor_647, wait_tensor_646, wait_tensor_645, wait_tensor_643, wait_tensor_642, wait_tensor_641, wait_tensor_640, wait_tensor_639, wait_tensor_638, wait_tensor_637, wait_tensor_636, wait_tensor_635, wait_tensor_634, None, wait_tensor_633, None, wait_tensor_631, wait_tensor_630, wait_tensor_629, wait_tensor_627, wait_tensor_626, wait_tensor_625, wait_tensor_624, wait_tensor_623, wait_tensor_622, wait_tensor_621, wait_tensor_620, wait_tensor_619, wait_tensor_618, None, wait_tensor_617, None, wait_tensor_615, wait_tensor_614, wait_tensor_613, wait_tensor_611, wait_tensor_610, wait_tensor_609, wait_tensor_608, wait_tensor_607, wait_tensor_606, wait_tensor_605, wait_tensor_604, wait_tensor_603, wait_tensor_602, None, wait_tensor_601, None, wait_tensor_599, wait_tensor_598, wait_tensor_597, wait_tensor_595, wait_tensor_594, wait_tensor_593, wait_tensor_592, wait_tensor_591, wait_tensor_590, wait_tensor_589, wait_tensor_588, wait_tensor_587, wait_tensor_586, None, wait_tensor_585, None, wait_tensor_583, wait_tensor_582, wait_tensor_581, wait_tensor_579, wait_tensor_578, wait_tensor_577, wait_tensor_576, wait_tensor_575, wait_tensor_574, wait_tensor_573, wait_tensor_572, wait_tensor_571, wait_tensor_570, None, wait_tensor_569, None, wait_tensor_567, wait_tensor_566, wait_tensor_565, wait_tensor_563, wait_tensor_562, wait_tensor_561, wait_tensor_560, wait_tensor_559)

def load_args(reader):
    # MoE expert token counts (approximate uniform distribution)
    u8 = u9 = u10 = u11 = u12 = u13 = u14 = u15 = u24 = u25 = u26 = u27 = u28 = u29 = u30 = u31 = u40 = u41 = u42 = u43 = u44 = u45 = u46 = u47 = u56 = u57 = u58 = u59 = u60 = u61 = u62 = u63 = u72 = u73 = u74 = u75 = u76 = u77 = u78 = u79 = u88 = u89 = u90 = u91 = u92 = u93 = u94 = u95 = u104 = u105 = u106 = u107 = u108 = u109 = u110 = u111 = u120 = u121 = u122 = u123 = u124 = u125 = u126 = u127 = u136 = u137 = u138 = u139 = u140 = u141 = u142 = u143 = u152 = u153 = u154 = u155 = u156 = u157 = u158 = u159 = u168 = u169 = u170 = u171 = u172 = u173 = u174 = u175 = u184 = u185 = u186 = u187 = u188 = u189 = u190 = u191 = u200 = u201 = u202 = u203 = u204 = u205 = u206 = u207 = u216 = u217 = u218 = u219 = u220 = u221 = u222 = u223 = u232 = u233 = u234 = u235 = u236 = u237 = u238 = u239 = u248 = u249 = u250 = u251 = u252 = u253 = u254 = u255 = u264 = u265 = u266 = u267 = u268 = u269 = u270 = u271 = u280 = u281 = u282 = u283 = u284 = u285 = u286 = u287 = u296 = u297 = u298 = u299 = u300 = u301 = u302 = u303 = u312 = u313 = u314 = u315 = u316 = u317 = u318 = u319 = u328 = u329 = u330 = u331 = u332 = u333 = u334 = u335 = u344 = u345 = u346 = u347 = u348 = u349 = u350 = u351 = u360 = u361 = u362 = u363 = u364 = u365 = u366 = u367 = u376 = u377 = u378 = u379 = u380 = u381 = u382 = u383 = u392 = u393 = u394 = u395 = u396 = u397 = u398 = u399 = u408 = u409 = u410 = u411 = u412 = u413 = u414 = u415 = 512
    reader.symint(512)  # _local_scalar_dense
    reader.symint(512)  # _local_scalar_dense_1
    reader.symint(512)  # _local_scalar_dense_2
    reader.symint(512)  # _local_scalar_dense_3
    reader.symint(512)  # _local_scalar_dense_4
    reader.symint(512)  # _local_scalar_dense_5
    reader.symint(512)  # _local_scalar_dense_6
    reader.symint(512)  # _local_scalar_dense_7
    reader.symint(512)  # _local_scalar_dense_8
    reader.symint(512)  # _local_scalar_dense_9
    reader.symint(512)  # _local_scalar_dense_10
    reader.symint(512)  # _local_scalar_dense_11
    reader.symint(512)  # _local_scalar_dense_12
    reader.symint(512)  # _local_scalar_dense_13
    reader.symint(512)  # _local_scalar_dense_14
    reader.symint(512)  # _local_scalar_dense_15
    reader.symint(512)  # _local_scalar_dense_16
    reader.symint(512)  # _local_scalar_dense_17
    reader.symint(512)  # _local_scalar_dense_18
    reader.symint(512)  # _local_scalar_dense_19
    reader.symint(512)  # _local_scalar_dense_20
    reader.symint(512)  # _local_scalar_dense_21
    reader.symint(512)  # _local_scalar_dense_22
    reader.symint(512)  # _local_scalar_dense_23
    reader.symint(512)  # _local_scalar_dense_24
    reader.symint(512)  # _local_scalar_dense_25
    reader.symint(512)  # _local_scalar_dense_26
    reader.symint(512)  # _local_scalar_dense_27
    reader.symint(512)  # _local_scalar_dense_28
    reader.symint(512)  # _local_scalar_dense_29
    reader.symint(512)  # _local_scalar_dense_30
    reader.symint(512)  # _local_scalar_dense_31
    reader.symint(512)  # _local_scalar_dense_32
    reader.symint(512)  # _local_scalar_dense_33
    reader.symint(512)  # _local_scalar_dense_34
    reader.symint(512)  # _local_scalar_dense_35
    reader.symint(512)  # _local_scalar_dense_36
    reader.symint(512)  # _local_scalar_dense_37
    reader.symint(512)  # _local_scalar_dense_38
    reader.symint(512)  # _local_scalar_dense_39
    reader.symint(512)  # _local_scalar_dense_40
    reader.symint(512)  # _local_scalar_dense_41
    reader.symint(512)  # _local_scalar_dense_42
    reader.symint(512)  # _local_scalar_dense_43
    reader.symint(512)  # _local_scalar_dense_44
    reader.symint(512)  # _local_scalar_dense_45
    reader.symint(512)  # _local_scalar_dense_46
    reader.symint(512)  # _local_scalar_dense_47
    reader.symint(512)  # _local_scalar_dense_48
    reader.symint(512)  # _local_scalar_dense_49
    reader.symint(512)  # _local_scalar_dense_50
    reader.symint(512)  # _local_scalar_dense_51
    reader.symint(512)  # _local_scalar_dense_52
    reader.symint(512)  # _local_scalar_dense_53
    reader.symint(512)  # _local_scalar_dense_54
    reader.symint(512)  # _local_scalar_dense_55
    reader.symint(512)  # _local_scalar_dense_56
    reader.symint(512)  # _local_scalar_dense_57
    reader.symint(512)  # _local_scalar_dense_58
    reader.symint(512)  # _local_scalar_dense_59
    reader.symint(512)  # _local_scalar_dense_60
    reader.symint(512)  # _local_scalar_dense_61
    reader.symint(512)  # _local_scalar_dense_62
    reader.symint(512)  # _local_scalar_dense_63
    reader.symint(512)  # _local_scalar_dense_64
    reader.symint(512)  # _local_scalar_dense_65
    reader.symint(512)  # _local_scalar_dense_66
    reader.symint(512)  # _local_scalar_dense_67
    reader.symint(512)  # _local_scalar_dense_68
    reader.symint(512)  # _local_scalar_dense_69
    reader.symint(512)  # _local_scalar_dense_70
    reader.symint(512)  # _local_scalar_dense_71
    reader.symint(512)  # _local_scalar_dense_72
    reader.symint(512)  # _local_scalar_dense_73
    reader.symint(512)  # _local_scalar_dense_74
    reader.symint(512)  # _local_scalar_dense_75
    reader.symint(512)  # _local_scalar_dense_76
    reader.symint(512)  # _local_scalar_dense_77
    reader.symint(512)  # _local_scalar_dense_78
    reader.symint(512)  # _local_scalar_dense_79
    reader.symint(512)  # _local_scalar_dense_80
    reader.symint(512)  # _local_scalar_dense_81
    reader.symint(512)  # _local_scalar_dense_82
    reader.symint(512)  # _local_scalar_dense_83
    reader.symint(512)  # _local_scalar_dense_84
    reader.symint(512)  # _local_scalar_dense_85
    reader.symint(512)  # _local_scalar_dense_86
    reader.symint(512)  # _local_scalar_dense_87
    reader.symint(512)  # _local_scalar_dense_88
    reader.symint(512)  # _local_scalar_dense_89
    reader.symint(512)  # _local_scalar_dense_90
    reader.symint(512)  # _local_scalar_dense_91
    reader.symint(512)  # _local_scalar_dense_92
    reader.symint(512)  # _local_scalar_dense_93
    reader.symint(512)  # _local_scalar_dense_94
    reader.symint(512)  # _local_scalar_dense_95
    reader.symint(512)  # _local_scalar_dense_96
    reader.symint(512)  # _local_scalar_dense_97
    reader.symint(512)  # _local_scalar_dense_98
    reader.symint(512)  # _local_scalar_dense_99
    reader.symint(512)  # _local_scalar_dense_100
    reader.symint(512)  # _local_scalar_dense_101
    reader.symint(512)  # _local_scalar_dense_102
    reader.symint(512)  # _local_scalar_dense_103
    reader.symint(512)  # _local_scalar_dense_104
    reader.symint(512)  # _local_scalar_dense_105
    reader.symint(512)  # _local_scalar_dense_106
    reader.symint(512)  # _local_scalar_dense_107
    reader.symint(512)  # _local_scalar_dense_108
    reader.symint(512)  # _local_scalar_dense_109
    reader.symint(512)  # _local_scalar_dense_110
    reader.symint(512)  # _local_scalar_dense_111
    reader.symint(512)  # _local_scalar_dense_112
    reader.symint(512)  # _local_scalar_dense_113
    reader.symint(512)  # _local_scalar_dense_114
    reader.symint(512)  # _local_scalar_dense_115
    reader.symint(512)  # _local_scalar_dense_116
    reader.symint(512)  # _local_scalar_dense_117
    reader.symint(512)  # _local_scalar_dense_118
    reader.symint(512)  # _local_scalar_dense_119
    reader.symint(512)  # _local_scalar_dense_120
    reader.symint(512)  # _local_scalar_dense_121
    reader.symint(512)  # _local_scalar_dense_122
    reader.symint(512)  # _local_scalar_dense_123
    reader.symint(512)  # _local_scalar_dense_124
    reader.symint(512)  # _local_scalar_dense_125
    reader.symint(512)  # _local_scalar_dense_126
    reader.symint(512)  # _local_scalar_dense_127
    reader.symint(512)  # _local_scalar_dense_128
    reader.symint(512)  # _local_scalar_dense_129
    reader.symint(512)  # _local_scalar_dense_130
    reader.symint(512)  # _local_scalar_dense_131
    reader.symint(512)  # _local_scalar_dense_132
    reader.symint(512)  # _local_scalar_dense_133
    reader.symint(512)  # _local_scalar_dense_134
    reader.symint(512)  # _local_scalar_dense_135
    reader.symint(512)  # _local_scalar_dense_136
    reader.symint(512)  # _local_scalar_dense_137
    reader.symint(512)  # _local_scalar_dense_138
    reader.symint(512)  # _local_scalar_dense_139
    reader.symint(512)  # _local_scalar_dense_140
    reader.symint(512)  # _local_scalar_dense_141
    reader.symint(512)  # _local_scalar_dense_142
    reader.symint(512)  # _local_scalar_dense_143
    reader.symint(512)  # _local_scalar_dense_144
    reader.symint(512)  # _local_scalar_dense_145
    reader.symint(512)  # _local_scalar_dense_146
    reader.symint(512)  # _local_scalar_dense_147
    reader.symint(512)  # _local_scalar_dense_148
    reader.symint(512)  # _local_scalar_dense_149
    reader.symint(512)  # _local_scalar_dense_150
    reader.symint(512)  # _local_scalar_dense_151
    reader.symint(512)  # _local_scalar_dense_152
    reader.symint(512)  # _local_scalar_dense_153
    reader.symint(512)  # _local_scalar_dense_154
    reader.symint(512)  # _local_scalar_dense_155
    reader.symint(512)  # _local_scalar_dense_156
    reader.symint(512)  # _local_scalar_dense_157
    reader.symint(512)  # _local_scalar_dense_158
    reader.symint(512)  # _local_scalar_dense_159
    reader.symint(512)  # _local_scalar_dense_160
    reader.symint(512)  # _local_scalar_dense_161
    reader.symint(512)  # _local_scalar_dense_162
    reader.symint(512)  # _local_scalar_dense_163
    reader.symint(512)  # _local_scalar_dense_164
    reader.symint(512)  # _local_scalar_dense_165
    reader.symint(512)  # _local_scalar_dense_166
    reader.symint(512)  # _local_scalar_dense_167
    reader.symint(512)  # _local_scalar_dense_168
    reader.symint(512)  # _local_scalar_dense_169
    reader.symint(512)  # _local_scalar_dense_170
    reader.symint(512)  # _local_scalar_dense_171
    reader.symint(512)  # _local_scalar_dense_172
    reader.symint(512)  # _local_scalar_dense_173
    reader.symint(512)  # _local_scalar_dense_174
    reader.symint(512)  # _local_scalar_dense_175
    reader.symint(512)  # _local_scalar_dense_176
    reader.symint(512)  # _local_scalar_dense_177
    reader.symint(512)  # _local_scalar_dense_178
    reader.symint(512)  # _local_scalar_dense_179
    reader.symint(512)  # _local_scalar_dense_180
    reader.symint(512)  # _local_scalar_dense_181
    reader.symint(512)  # _local_scalar_dense_182
    reader.symint(512)  # _local_scalar_dense_183
    reader.symint(512)  # _local_scalar_dense_184
    reader.symint(512)  # _local_scalar_dense_185
    reader.symint(512)  # _local_scalar_dense_186
    reader.symint(512)  # _local_scalar_dense_187
    reader.symint(512)  # _local_scalar_dense_188
    reader.symint(512)  # _local_scalar_dense_189
    reader.symint(512)  # _local_scalar_dense_190
    reader.symint(512)  # _local_scalar_dense_191
    reader.symint(512)  # _local_scalar_dense_192
    reader.symint(512)  # _local_scalar_dense_193
    reader.symint(512)  # _local_scalar_dense_194
    reader.symint(512)  # _local_scalar_dense_195
    reader.symint(512)  # _local_scalar_dense_196
    reader.symint(512)  # _local_scalar_dense_197
    reader.symint(512)  # _local_scalar_dense_198
    reader.symint(512)  # _local_scalar_dense_199
    reader.symint(512)  # _local_scalar_dense_200
    reader.symint(512)  # _local_scalar_dense_201
    reader.symint(512)  # _local_scalar_dense_202
    reader.symint(512)  # _local_scalar_dense_203
    reader.symint(512)  # _local_scalar_dense_204
    reader.symint(512)  # _local_scalar_dense_205
    reader.symint(512)  # _local_scalar_dense_206
    reader.symint(512)  # _local_scalar_dense_207
    reader.symint(512)  # _local_scalar_dense_208
    reader.symint(512)  # _local_scalar_dense_209
    reader.symint(512)  # _local_scalar_dense_210
    reader.symint(512)  # _local_scalar_dense_211
    reader.symint(512)  # _local_scalar_dense_212
    reader.symint(512)  # _local_scalar_dense_213
    reader.symint(512)  # _local_scalar_dense_214
    reader.symint(512)  # _local_scalar_dense_215
    reader.symint(512)  # _local_scalar_dense_216
    reader.symint(512)  # _local_scalar_dense_217
    reader.symint(512)  # _local_scalar_dense_218
    reader.symint(512)  # _local_scalar_dense_219
    reader.symint(512)  # _local_scalar_dense_220
    reader.symint(512)  # _local_scalar_dense_221
    reader.symint(512)  # _local_scalar_dense_222
    reader.symint(512)  # _local_scalar_dense_223
    reader.symint(512)  # _local_scalar_dense_224
    reader.symint(512)  # _local_scalar_dense_225
    reader.symint(512)  # _local_scalar_dense_226
    reader.symint(512)  # _local_scalar_dense_227
    reader.symint(512)  # _local_scalar_dense_228
    reader.symint(512)  # _local_scalar_dense_229
    reader.symint(512)  # _local_scalar_dense_230
    reader.symint(512)  # _local_scalar_dense_231
    reader.symint(512)  # _local_scalar_dense_232
    reader.symint(512)  # _local_scalar_dense_233
    reader.symint(512)  # _local_scalar_dense_234
    reader.symint(512)  # _local_scalar_dense_235
    reader.symint(512)  # _local_scalar_dense_236
    reader.symint(512)  # _local_scalar_dense_237
    reader.symint(512)  # _local_scalar_dense_238
    reader.symint(512)  # _local_scalar_dense_239
    reader.symint(512)  # _local_scalar_dense_240
    reader.symint(512)  # _local_scalar_dense_241
    reader.symint(512)  # _local_scalar_dense_242
    reader.symint(512)  # _local_scalar_dense_243
    reader.symint(512)  # _local_scalar_dense_244
    reader.symint(512)  # _local_scalar_dense_245
    reader.symint(512)  # _local_scalar_dense_246
    reader.symint(512)  # _local_scalar_dense_247
    reader.symint(512)  # _local_scalar_dense_248
    reader.symint(512)  # _local_scalar_dense_249
    reader.symint(512)  # _local_scalar_dense_250
    reader.symint(512)  # _local_scalar_dense_251
    reader.symint(512)  # _local_scalar_dense_252
    reader.symint(512)  # _local_scalar_dense_253
    reader.symint(512)  # _local_scalar_dense_254
    reader.symint(512)  # _local_scalar_dense_255
    reader.symint(512)  # _local_scalar_dense_256
    reader.symint(512)  # _local_scalar_dense_257
    reader.symint(512)  # _local_scalar_dense_258
    reader.symint(512)  # _local_scalar_dense_259
    reader.symint(512)  # _local_scalar_dense_260
    reader.symint(512)  # _local_scalar_dense_261
    reader.symint(512)  # _local_scalar_dense_262
    reader.symint(512)  # _local_scalar_dense_263
    reader.symint(512)  # _local_scalar_dense_264
    reader.symint(512)  # _local_scalar_dense_265
    reader.symint(512)  # _local_scalar_dense_266
    reader.symint(512)  # _local_scalar_dense_267
    reader.symint(512)  # _local_scalar_dense_268
    reader.symint(512)  # _local_scalar_dense_269
    reader.symint(512)  # _local_scalar_dense_270
    reader.symint(512)  # _local_scalar_dense_271
    reader.symint(512)  # _local_scalar_dense_272
    reader.symint(512)  # _local_scalar_dense_273
    reader.symint(512)  # _local_scalar_dense_274
    reader.symint(512)  # _local_scalar_dense_275
    reader.symint(512)  # _local_scalar_dense_276
    reader.symint(512)  # _local_scalar_dense_277
    reader.symint(512)  # _local_scalar_dense_278
    reader.symint(512)  # _local_scalar_dense_279
    reader.symint(512)  # _local_scalar_dense_280
    reader.symint(512)  # _local_scalar_dense_281
    reader.symint(512)  # _local_scalar_dense_282
    reader.symint(512)  # _local_scalar_dense_283
    reader.symint(512)  # _local_scalar_dense_284
    reader.symint(512)  # _local_scalar_dense_285
    reader.symint(512)  # _local_scalar_dense_286
    reader.symint(512)  # _local_scalar_dense_287
    reader.symint(512)  # _local_scalar_dense_288
    reader.symint(512)  # _local_scalar_dense_289
    reader.symint(512)  # _local_scalar_dense_290
    reader.symint(512)  # _local_scalar_dense_291
    reader.symint(512)  # _local_scalar_dense_292
    reader.symint(512)  # _local_scalar_dense_293
    reader.symint(512)  # _local_scalar_dense_294
    reader.symint(512)  # _local_scalar_dense_295
    reader.symint(512)  # _local_scalar_dense_296
    reader.symint(512)  # _local_scalar_dense_297
    reader.symint(512)  # _local_scalar_dense_298
    reader.symint(512)  # _local_scalar_dense_299
    reader.symint(512)  # _local_scalar_dense_300
    reader.symint(512)  # _local_scalar_dense_301
    reader.symint(512)  # _local_scalar_dense_302
    reader.symint(512)  # _local_scalar_dense_303
    reader.symint(512)  # _local_scalar_dense_304
    reader.symint(512)  # _local_scalar_dense_305
    reader.symint(512)  # _local_scalar_dense_306
    reader.symint(512)  # _local_scalar_dense_307
    reader.symint(512)  # _local_scalar_dense_308
    reader.symint(512)  # _local_scalar_dense_309
    reader.symint(512)  # _local_scalar_dense_310
    reader.symint(512)  # _local_scalar_dense_311
    reader.symint(512)  # _local_scalar_dense_312
    reader.symint(512)  # _local_scalar_dense_313
    reader.symint(512)  # _local_scalar_dense_314
    reader.symint(512)  # _local_scalar_dense_315
    reader.symint(512)  # _local_scalar_dense_316
    reader.symint(512)  # _local_scalar_dense_317
    reader.symint(512)  # _local_scalar_dense_318
    reader.symint(512)  # _local_scalar_dense_319
    reader.symint(512)  # _local_scalar_dense_320
    reader.symint(512)  # _local_scalar_dense_321
    reader.symint(512)  # _local_scalar_dense_322
    reader.symint(512)  # _local_scalar_dense_323
    reader.symint(512)  # _local_scalar_dense_324
    reader.symint(512)  # _local_scalar_dense_325
    reader.symint(512)  # _local_scalar_dense_326
    reader.symint(512)  # _local_scalar_dense_327
    reader.symint(512)  # _local_scalar_dense_328
    reader.symint(512)  # _local_scalar_dense_329
    reader.symint(512)  # _local_scalar_dense_330
    reader.symint(512)  # _local_scalar_dense_331
    reader.symint(512)  # _local_scalar_dense_332
    reader.symint(512)  # _local_scalar_dense_333
    reader.symint(512)  # _local_scalar_dense_334
    reader.symint(512)  # _local_scalar_dense_335
    reader.symint(512)  # _local_scalar_dense_336
    reader.symint(512)  # _local_scalar_dense_337
    reader.symint(512)  # _local_scalar_dense_338
    reader.symint(512)  # _local_scalar_dense_339
    reader.symint(512)  # _local_scalar_dense_340
    reader.symint(512)  # _local_scalar_dense_341
    reader.symint(512)  # _local_scalar_dense_342
    reader.symint(512)  # _local_scalar_dense_343
    reader.symint(512)  # _local_scalar_dense_344
    reader.symint(512)  # _local_scalar_dense_345
    reader.symint(512)  # _local_scalar_dense_346
    reader.symint(512)  # _local_scalar_dense_347
    reader.symint(512)  # _local_scalar_dense_348
    reader.symint(512)  # _local_scalar_dense_349
    reader.symint(512)  # _local_scalar_dense_350
    reader.symint(512)  # _local_scalar_dense_351
    reader.symint(512)  # _local_scalar_dense_352
    reader.symint(512)  # _local_scalar_dense_353
    reader.symint(512)  # _local_scalar_dense_354
    reader.symint(512)  # _local_scalar_dense_355
    reader.symint(512)  # _local_scalar_dense_356
    reader.symint(512)  # _local_scalar_dense_357
    reader.symint(512)  # _local_scalar_dense_358
    reader.symint(512)  # _local_scalar_dense_359
    reader.symint(512)  # _local_scalar_dense_360
    reader.symint(512)  # _local_scalar_dense_361
    reader.symint(512)  # _local_scalar_dense_362
    reader.symint(512)  # _local_scalar_dense_363
    reader.symint(512)  # _local_scalar_dense_364
    reader.symint(512)  # _local_scalar_dense_365
    reader.symint(512)  # _local_scalar_dense_366
    reader.symint(512)  # _local_scalar_dense_367
    reader.symint(512)  # _local_scalar_dense_368
    reader.symint(512)  # _local_scalar_dense_369
    reader.symint(512)  # _local_scalar_dense_370
    reader.symint(512)  # _local_scalar_dense_371
    reader.symint(512)  # _local_scalar_dense_372
    reader.symint(512)  # _local_scalar_dense_373
    reader.symint(512)  # _local_scalar_dense_374
    reader.symint(512)  # _local_scalar_dense_375
    reader.symint(512)  # _local_scalar_dense_376
    reader.symint(512)  # _local_scalar_dense_377
    reader.symint(512)  # _local_scalar_dense_378
    reader.symint(512)  # _local_scalar_dense_379
    reader.symint(512)  # _local_scalar_dense_380
    reader.symint(512)  # _local_scalar_dense_381
    reader.symint(512)  # _local_scalar_dense_382
    reader.symint(512)  # _local_scalar_dense_383
    reader.symint(512)  # _local_scalar_dense_384
    reader.symint(512)  # _local_scalar_dense_385
    reader.symint(512)  # _local_scalar_dense_386
    reader.symint(512)  # _local_scalar_dense_387
    reader.symint(512)  # _local_scalar_dense_388
    reader.symint(512)  # _local_scalar_dense_389
    reader.symint(512)  # _local_scalar_dense_390
    reader.symint(512)  # _local_scalar_dense_391
    reader.symint(512)  # _local_scalar_dense_392
    reader.symint(512)  # _local_scalar_dense_393
    reader.symint(512)  # _local_scalar_dense_394
    reader.symint(512)  # _local_scalar_dense_395
    reader.symint(512)  # _local_scalar_dense_396
    reader.symint(512)  # _local_scalar_dense_397
    reader.symint(512)  # _local_scalar_dense_398
    reader.symint(512)  # _local_scalar_dense_399
    reader.symint(512)  # _local_scalar_dense_400
    reader.symint(512)  # _local_scalar_dense_401
    reader.symint(512)  # _local_scalar_dense_402
    reader.symint(512)  # _local_scalar_dense_403
    reader.symint(512)  # _local_scalar_dense_404
    reader.symint(512)  # _local_scalar_dense_405
    reader.symint(512)  # _local_scalar_dense_406
    reader.symint(512)  # _local_scalar_dense_407
    reader.symint(512)  # _local_scalar_dense_408
    reader.symint(512)  # _local_scalar_dense_409
    reader.symint(512)  # _local_scalar_dense_410
    reader.symint(512)  # _local_scalar_dense_411
    reader.symint(512)  # _local_scalar_dense_412
    reader.symint(512)  # _local_scalar_dense_413
    reader.symint(512)  # _local_scalar_dense_414
    reader.symint(512)  # _local_scalar_dense_415
    reader.symint(512)  # sym_size_int_1
    reader.symint(512)  # sym_size_int_5
    reader.symint(512)  # sym_size_int_9
    reader.symint(512)  # sym_size_int_13
    reader.symint(512)  # sym_size_int_17
    reader.symint(512)  # sym_size_int_21
    reader.symint(512)  # sym_size_int_25
    reader.symint(512)  # sym_size_int_29
    reader.symint(512)  # sym_size_int_33
    reader.symint(512)  # sym_size_int_37
    reader.symint(512)  # sym_size_int_41
    reader.symint(512)  # sym_size_int_45
    reader.symint(512)  # sym_size_int_49
    reader.symint(512)  # sym_size_int_53
    reader.symint(512)  # sym_size_int_57
    reader.symint(512)  # sym_size_int_61
    reader.symint(512)  # sym_size_int_65
    reader.symint(512)  # sym_size_int_69
    reader.symint(512)  # sym_size_int_73
    reader.symint(512)  # sym_size_int_77
    reader.symint(512)  # sym_size_int_81
    reader.symint(512)  # sym_size_int_85
    reader.symint(512)  # sym_size_int_89
    reader.symint(512)  # sym_size_int_93
    reader.symint(512)  # sym_size_int_97
    reader.symint(512)  # sym_size_int_101
    reader.symint(512)  # add_1781
    reader.symint(512)  # add_1796
    reader.symint(512)  # add_1811
    reader.symint(512)  # add_1826
    reader.symint(512)  # add_1841
    reader.symint(512)  # add_1856
    reader.symint(512)  # add_1871
    reader.symint(512)  # add_1886
    reader.symint(512)  # add_1901
    reader.symint(512)  # add_1916
    reader.symint(512)  # add_1931
    reader.symint(512)  # add_1946
    reader.symint(512)  # add_1961
    reader.symint(512)  # add_1976
    reader.symint(512)  # add_1991
    reader.symint(512)  # add_2006
    reader.symint(512)  # add_2021
    reader.symint(512)  # add_2036
    reader.symint(512)  # add_2051
    reader.symint(512)  # add_2066
    reader.symint(512)  # add_2081
    reader.symint(512)  # add_2096
    reader.symint(512)  # add_2111
    reader.symint(512)  # add_2126
    reader.symint(512)  # add_2141
    reader.symint(512)  # add_2156
    buf0 = reader.storage(None, 6553600, device=device(type='cuda', index=0))
    reader.tensor(buf0, (800, 2048), is_leaf=True)  # primals_1
    buf1 = reader.storage(None, 65536, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1, (2, 4096), dtype=torch.int64, is_leaf=True)  # primals_2
    buf2 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.complex64)
    reader.tensor(buf2, (4096, 32), dtype=torch.complex64, is_leaf=True)  # primals_3
    buf3 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf3, (16,), is_leaf=True)  # primals_4
    buf4 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf4, (24, 2048), is_leaf=True)  # primals_5
    buf5 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf5, (5, 2048), is_leaf=True)  # primals_6
    buf6 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf6, (4,), is_leaf=True)  # primals_7
    buf7 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf7, (32, 512), is_leaf=True)  # primals_8
    buf8 = reader.storage(None, 8192, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf8, (2, 1, 32, 32), dtype=torch.int32, is_leaf=True)  # primals_9
    buf9 = reader.storage(None, 256, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf9, (2, 1, 32), dtype=torch.int32, is_leaf=True)  # primals_10
    buf10 = reader.storage(None, 32768, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf10, (2, 4096), dtype=torch.int32, is_leaf=True)  # primals_11
    buf11 = reader.storage(None, 256, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf11, (2, 1, 32), dtype=torch.int32, is_leaf=True)  # primals_12
    buf12 = reader.storage(None, 8192, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf12, (2, 1, 32, 32), dtype=torch.int32, is_leaf=True)  # primals_13
    buf13 = reader.storage(None, 256, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf13, (2, 1, 32), dtype=torch.int32, is_leaf=True)  # primals_14
    buf14 = reader.storage(None, 8192, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf14, (2, 1, 32, 32), dtype=torch.int32, is_leaf=True)  # primals_15
    buf15 = reader.storage(None, 256, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf15, (2, 1, 32), dtype=torch.int32, is_leaf=True)  # primals_16
    buf16 = reader.storage(None, 8192, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf16, (2, 1, 32, 32), dtype=torch.int32, is_leaf=True)  # primals_17
    buf17 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf17, (16, 2048), is_leaf=True)  # primals_18
    buf18 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf18, (16,), is_leaf=True)  # primals_19
    buf19 = reader.storage(None, 704512, device=device(type='cuda', index=0))
    reader.tensor(buf19, (86, 2048), is_leaf=True)  # primals_20
    buf20 = reader.storage(None, 704512, device=device(type='cuda', index=0))
    reader.tensor(buf20, (86, 2048), is_leaf=True)  # primals_21
    buf21 = reader.storage(None, 700416, device=device(type='cuda', index=0))
    reader.tensor(buf21, (16, 10944), is_leaf=True)  # primals_22
    buf22 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf22, (16,), is_leaf=True)  # primals_23
    buf23 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf23, (24, 2048), is_leaf=True)  # primals_24
    buf24 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf24, (5, 2048), is_leaf=True)  # primals_25
    buf25 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf25, (4,), is_leaf=True)  # primals_26
    buf26 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf26, (32, 512), is_leaf=True)  # primals_27
    buf27 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf27, (16, 2048), is_leaf=True)  # primals_28
    buf28 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf28, (16,), is_leaf=True)  # primals_29
    buf29 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf29, (1, 2048), is_leaf=True)  # primals_31
    buf30 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf30, (8, 88, 2048), is_leaf=True)  # primals_33
    buf31 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf31, (8, 128, 1408), is_leaf=True)  # primals_34
    buf32 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf32, (8, 88, 2048), is_leaf=True)  # primals_35
    buf33 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf33, (22, 2048), is_leaf=True)  # primals_36
    buf34 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf34, (22, 2048), is_leaf=True)  # primals_37
    buf35 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf35, (16, 2816), is_leaf=True)  # primals_38
    buf36 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf36, (16,), is_leaf=True)  # primals_39
    buf37 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf37, (24, 2048), is_leaf=True)  # primals_40
    buf38 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf38, (5, 2048), is_leaf=True)  # primals_41
    buf39 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf39, (4,), is_leaf=True)  # primals_42
    buf40 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf40, (32, 512), is_leaf=True)  # primals_43
    buf41 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf41, (16, 2048), is_leaf=True)  # primals_44
    buf42 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf42, (16,), is_leaf=True)  # primals_45
    buf43 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf43, (1, 2048), is_leaf=True)  # primals_47
    buf44 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf44, (8, 88, 2048), is_leaf=True)  # primals_49
    buf45 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf45, (8, 128, 1408), is_leaf=True)  # primals_50
    buf46 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf46, (8, 88, 2048), is_leaf=True)  # primals_51
    buf47 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf47, (22, 2048), is_leaf=True)  # primals_52
    buf48 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf48, (22, 2048), is_leaf=True)  # primals_53
    buf49 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf49, (16, 2816), is_leaf=True)  # primals_54
    buf50 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf50, (16,), is_leaf=True)  # primals_55
    buf51 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf51, (24, 2048), is_leaf=True)  # primals_56
    buf52 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf52, (5, 2048), is_leaf=True)  # primals_57
    buf53 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf53, (4,), is_leaf=True)  # primals_58
    buf54 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf54, (32, 512), is_leaf=True)  # primals_59
    buf55 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf55, (16, 2048), is_leaf=True)  # primals_60
    buf56 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf56, (16,), is_leaf=True)  # primals_61
    buf57 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf57, (1, 2048), is_leaf=True)  # primals_63
    buf58 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf58, (8, 88, 2048), is_leaf=True)  # primals_65
    buf59 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf59, (8, 128, 1408), is_leaf=True)  # primals_66
    buf60 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf60, (8, 88, 2048), is_leaf=True)  # primals_67
    buf61 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf61, (22, 2048), is_leaf=True)  # primals_68
    buf62 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf62, (22, 2048), is_leaf=True)  # primals_69
    buf63 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf63, (16, 2816), is_leaf=True)  # primals_70
    buf64 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf64, (16,), is_leaf=True)  # primals_71
    buf65 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf65, (24, 2048), is_leaf=True)  # primals_72
    buf66 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf66, (5, 2048), is_leaf=True)  # primals_73
    buf67 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf67, (4,), is_leaf=True)  # primals_74
    buf68 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf68, (32, 512), is_leaf=True)  # primals_75
    buf69 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf69, (16, 2048), is_leaf=True)  # primals_76
    buf70 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf70, (16,), is_leaf=True)  # primals_77
    buf71 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf71, (1, 2048), is_leaf=True)  # primals_79
    buf72 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf72, (8, 88, 2048), is_leaf=True)  # primals_81
    buf73 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf73, (8, 128, 1408), is_leaf=True)  # primals_82
    buf74 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf74, (8, 88, 2048), is_leaf=True)  # primals_83
    buf75 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf75, (22, 2048), is_leaf=True)  # primals_84
    buf76 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf76, (22, 2048), is_leaf=True)  # primals_85
    buf77 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf77, (16, 2816), is_leaf=True)  # primals_86
    buf78 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf78, (16,), is_leaf=True)  # primals_87
    buf79 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf79, (24, 2048), is_leaf=True)  # primals_88
    buf80 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf80, (5, 2048), is_leaf=True)  # primals_89
    buf81 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf81, (4,), is_leaf=True)  # primals_90
    buf82 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf82, (32, 512), is_leaf=True)  # primals_91
    buf83 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf83, (16, 2048), is_leaf=True)  # primals_92
    buf84 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf84, (16,), is_leaf=True)  # primals_93
    buf85 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf85, (1, 2048), is_leaf=True)  # primals_95
    buf86 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf86, (8, 88, 2048), is_leaf=True)  # primals_97
    buf87 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf87, (8, 128, 1408), is_leaf=True)  # primals_98
    buf88 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf88, (8, 88, 2048), is_leaf=True)  # primals_99
    buf89 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf89, (22, 2048), is_leaf=True)  # primals_100
    buf90 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf90, (22, 2048), is_leaf=True)  # primals_101
    buf91 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf91, (16, 2816), is_leaf=True)  # primals_102
    buf92 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf92, (16,), is_leaf=True)  # primals_103
    buf93 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf93, (24, 2048), is_leaf=True)  # primals_104
    buf94 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf94, (5, 2048), is_leaf=True)  # primals_105
    buf95 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf95, (4,), is_leaf=True)  # primals_106
    buf96 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf96, (32, 512), is_leaf=True)  # primals_107
    buf97 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf97, (16, 2048), is_leaf=True)  # primals_108
    buf98 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf98, (16,), is_leaf=True)  # primals_109
    buf99 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf99, (1, 2048), is_leaf=True)  # primals_111
    buf100 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf100, (8, 88, 2048), is_leaf=True)  # primals_113
    buf101 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf101, (8, 128, 1408), is_leaf=True)  # primals_114
    buf102 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf102, (8, 88, 2048), is_leaf=True)  # primals_115
    buf103 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf103, (22, 2048), is_leaf=True)  # primals_116
    buf104 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf104, (22, 2048), is_leaf=True)  # primals_117
    buf105 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf105, (16, 2816), is_leaf=True)  # primals_118
    buf106 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf106, (16,), is_leaf=True)  # primals_119
    buf107 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf107, (24, 2048), is_leaf=True)  # primals_120
    buf108 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf108, (5, 2048), is_leaf=True)  # primals_121
    buf109 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf109, (4,), is_leaf=True)  # primals_122
    buf110 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf110, (32, 512), is_leaf=True)  # primals_123
    buf111 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf111, (16, 2048), is_leaf=True)  # primals_124
    buf112 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf112, (16,), is_leaf=True)  # primals_125
    buf113 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf113, (1, 2048), is_leaf=True)  # primals_127
    buf114 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf114, (8, 88, 2048), is_leaf=True)  # primals_129
    buf115 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf115, (8, 128, 1408), is_leaf=True)  # primals_130
    buf116 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf116, (8, 88, 2048), is_leaf=True)  # primals_131
    buf117 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf117, (22, 2048), is_leaf=True)  # primals_132
    buf118 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf118, (22, 2048), is_leaf=True)  # primals_133
    buf119 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf119, (16, 2816), is_leaf=True)  # primals_134
    buf120 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf120, (16,), is_leaf=True)  # primals_135
    buf121 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf121, (24, 2048), is_leaf=True)  # primals_136
    buf122 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf122, (5, 2048), is_leaf=True)  # primals_137
    buf123 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf123, (4,), is_leaf=True)  # primals_138
    buf124 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf124, (32, 512), is_leaf=True)  # primals_139
    buf125 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf125, (16, 2048), is_leaf=True)  # primals_140
    buf126 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf126, (16,), is_leaf=True)  # primals_141
    buf127 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf127, (1, 2048), is_leaf=True)  # primals_143
    buf128 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf128, (8, 88, 2048), is_leaf=True)  # primals_145
    buf129 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf129, (8, 128, 1408), is_leaf=True)  # primals_146
    buf130 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf130, (8, 88, 2048), is_leaf=True)  # primals_147
    buf131 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf131, (22, 2048), is_leaf=True)  # primals_148
    buf132 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf132, (22, 2048), is_leaf=True)  # primals_149
    buf133 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf133, (16, 2816), is_leaf=True)  # primals_150
    buf134 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf134, (16,), is_leaf=True)  # primals_151
    buf135 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf135, (24, 2048), is_leaf=True)  # primals_152
    buf136 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf136, (5, 2048), is_leaf=True)  # primals_153
    buf137 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf137, (4,), is_leaf=True)  # primals_154
    buf138 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf138, (32, 512), is_leaf=True)  # primals_155
    buf139 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf139, (16, 2048), is_leaf=True)  # primals_156
    buf140 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf140, (16,), is_leaf=True)  # primals_157
    buf141 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf141, (1, 2048), is_leaf=True)  # primals_159
    buf142 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf142, (8, 88, 2048), is_leaf=True)  # primals_161
    buf143 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf143, (8, 128, 1408), is_leaf=True)  # primals_162
    buf144 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf144, (8, 88, 2048), is_leaf=True)  # primals_163
    buf145 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf145, (22, 2048), is_leaf=True)  # primals_164
    buf146 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf146, (22, 2048), is_leaf=True)  # primals_165
    buf147 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf147, (16, 2816), is_leaf=True)  # primals_166
    buf148 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf148, (16,), is_leaf=True)  # primals_167
    buf149 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf149, (24, 2048), is_leaf=True)  # primals_168
    buf150 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf150, (5, 2048), is_leaf=True)  # primals_169
    buf151 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf151, (4,), is_leaf=True)  # primals_170
    buf152 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf152, (32, 512), is_leaf=True)  # primals_171
    buf153 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf153, (16, 2048), is_leaf=True)  # primals_172
    buf154 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf154, (16,), is_leaf=True)  # primals_173
    buf155 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf155, (1, 2048), is_leaf=True)  # primals_175
    buf156 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf156, (8, 88, 2048), is_leaf=True)  # primals_177
    buf157 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf157, (8, 128, 1408), is_leaf=True)  # primals_178
    buf158 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf158, (8, 88, 2048), is_leaf=True)  # primals_179
    buf159 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf159, (22, 2048), is_leaf=True)  # primals_180
    buf160 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf160, (22, 2048), is_leaf=True)  # primals_181
    buf161 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf161, (16, 2816), is_leaf=True)  # primals_182
    buf162 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf162, (16,), is_leaf=True)  # primals_183
    buf163 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf163, (24, 2048), is_leaf=True)  # primals_184
    buf164 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf164, (5, 2048), is_leaf=True)  # primals_185
    buf165 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf165, (4,), is_leaf=True)  # primals_186
    buf166 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf166, (32, 512), is_leaf=True)  # primals_187
    buf167 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf167, (16, 2048), is_leaf=True)  # primals_188
    buf168 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf168, (16,), is_leaf=True)  # primals_189
    buf169 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf169, (1, 2048), is_leaf=True)  # primals_191
    buf170 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf170, (8, 88, 2048), is_leaf=True)  # primals_193
    buf171 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf171, (8, 128, 1408), is_leaf=True)  # primals_194
    buf172 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf172, (8, 88, 2048), is_leaf=True)  # primals_195
    buf173 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf173, (22, 2048), is_leaf=True)  # primals_196
    buf174 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf174, (22, 2048), is_leaf=True)  # primals_197
    buf175 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf175, (16, 2816), is_leaf=True)  # primals_198
    buf176 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf176, (16,), is_leaf=True)  # primals_199
    buf177 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf177, (24, 2048), is_leaf=True)  # primals_200
    buf178 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf178, (5, 2048), is_leaf=True)  # primals_201
    buf179 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf179, (4,), is_leaf=True)  # primals_202
    buf180 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf180, (32, 512), is_leaf=True)  # primals_203
    buf181 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf181, (16, 2048), is_leaf=True)  # primals_204
    buf182 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf182, (16,), is_leaf=True)  # primals_205
    buf183 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf183, (1, 2048), is_leaf=True)  # primals_207
    buf184 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf184, (8, 88, 2048), is_leaf=True)  # primals_209
    buf185 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf185, (8, 128, 1408), is_leaf=True)  # primals_210
    buf186 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf186, (8, 88, 2048), is_leaf=True)  # primals_211
    buf187 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf187, (22, 2048), is_leaf=True)  # primals_212
    buf188 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf188, (22, 2048), is_leaf=True)  # primals_213
    buf189 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf189, (16, 2816), is_leaf=True)  # primals_214
    buf190 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf190, (16,), is_leaf=True)  # primals_215
    buf191 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf191, (24, 2048), is_leaf=True)  # primals_216
    buf192 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf192, (5, 2048), is_leaf=True)  # primals_217
    buf193 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf193, (4,), is_leaf=True)  # primals_218
    buf194 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf194, (32, 512), is_leaf=True)  # primals_219
    buf195 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf195, (16, 2048), is_leaf=True)  # primals_220
    buf196 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf196, (16,), is_leaf=True)  # primals_221
    buf197 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf197, (1, 2048), is_leaf=True)  # primals_223
    buf198 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf198, (8, 88, 2048), is_leaf=True)  # primals_225
    buf199 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf199, (8, 128, 1408), is_leaf=True)  # primals_226
    buf200 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf200, (8, 88, 2048), is_leaf=True)  # primals_227
    buf201 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf201, (22, 2048), is_leaf=True)  # primals_228
    buf202 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf202, (22, 2048), is_leaf=True)  # primals_229
    buf203 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf203, (16, 2816), is_leaf=True)  # primals_230
    buf204 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf204, (16,), is_leaf=True)  # primals_231
    buf205 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf205, (24, 2048), is_leaf=True)  # primals_232
    buf206 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf206, (5, 2048), is_leaf=True)  # primals_233
    buf207 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf207, (4,), is_leaf=True)  # primals_234
    buf208 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf208, (32, 512), is_leaf=True)  # primals_235
    buf209 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf209, (16, 2048), is_leaf=True)  # primals_236
    buf210 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf210, (16,), is_leaf=True)  # primals_237
    buf211 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf211, (1, 2048), is_leaf=True)  # primals_239
    buf212 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf212, (8, 88, 2048), is_leaf=True)  # primals_241
    buf213 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf213, (8, 128, 1408), is_leaf=True)  # primals_242
    buf214 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf214, (8, 88, 2048), is_leaf=True)  # primals_243
    buf215 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf215, (22, 2048), is_leaf=True)  # primals_244
    buf216 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf216, (22, 2048), is_leaf=True)  # primals_245
    buf217 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf217, (16, 2816), is_leaf=True)  # primals_246
    buf218 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf218, (16,), is_leaf=True)  # primals_247
    buf219 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf219, (24, 2048), is_leaf=True)  # primals_248
    buf220 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf220, (5, 2048), is_leaf=True)  # primals_249
    buf221 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf221, (4,), is_leaf=True)  # primals_250
    buf222 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf222, (32, 512), is_leaf=True)  # primals_251
    buf223 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf223, (16, 2048), is_leaf=True)  # primals_252
    buf224 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf224, (16,), is_leaf=True)  # primals_253
    buf225 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf225, (1, 2048), is_leaf=True)  # primals_255
    buf226 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf226, (8, 88, 2048), is_leaf=True)  # primals_257
    buf227 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf227, (8, 128, 1408), is_leaf=True)  # primals_258
    buf228 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf228, (8, 88, 2048), is_leaf=True)  # primals_259
    buf229 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf229, (22, 2048), is_leaf=True)  # primals_260
    buf230 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf230, (22, 2048), is_leaf=True)  # primals_261
    buf231 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf231, (16, 2816), is_leaf=True)  # primals_262
    buf232 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf232, (16,), is_leaf=True)  # primals_263
    buf233 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf233, (24, 2048), is_leaf=True)  # primals_264
    buf234 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf234, (5, 2048), is_leaf=True)  # primals_265
    buf235 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf235, (4,), is_leaf=True)  # primals_266
    buf236 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf236, (32, 512), is_leaf=True)  # primals_267
    buf237 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf237, (16, 2048), is_leaf=True)  # primals_268
    buf238 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf238, (16,), is_leaf=True)  # primals_269
    buf239 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf239, (1, 2048), is_leaf=True)  # primals_271
    buf240 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf240, (8, 88, 2048), is_leaf=True)  # primals_273
    buf241 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf241, (8, 128, 1408), is_leaf=True)  # primals_274
    buf242 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf242, (8, 88, 2048), is_leaf=True)  # primals_275
    buf243 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf243, (22, 2048), is_leaf=True)  # primals_276
    buf244 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf244, (22, 2048), is_leaf=True)  # primals_277
    buf245 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf245, (16, 2816), is_leaf=True)  # primals_278
    buf246 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf246, (16,), is_leaf=True)  # primals_279
    buf247 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf247, (24, 2048), is_leaf=True)  # primals_280
    buf248 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf248, (5, 2048), is_leaf=True)  # primals_281
    buf249 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf249, (4,), is_leaf=True)  # primals_282
    buf250 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf250, (32, 512), is_leaf=True)  # primals_283
    buf251 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf251, (16, 2048), is_leaf=True)  # primals_284
    buf252 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf252, (16,), is_leaf=True)  # primals_285
    buf253 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf253, (1, 2048), is_leaf=True)  # primals_287
    buf254 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf254, (8, 88, 2048), is_leaf=True)  # primals_289
    buf255 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf255, (8, 128, 1408), is_leaf=True)  # primals_290
    buf256 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf256, (8, 88, 2048), is_leaf=True)  # primals_291
    buf257 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf257, (22, 2048), is_leaf=True)  # primals_292
    buf258 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf258, (22, 2048), is_leaf=True)  # primals_293
    buf259 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf259, (16, 2816), is_leaf=True)  # primals_294
    buf260 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf260, (16,), is_leaf=True)  # primals_295
    buf261 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf261, (24, 2048), is_leaf=True)  # primals_296
    buf262 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf262, (5, 2048), is_leaf=True)  # primals_297
    buf263 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf263, (4,), is_leaf=True)  # primals_298
    buf264 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf264, (32, 512), is_leaf=True)  # primals_299
    buf265 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf265, (16, 2048), is_leaf=True)  # primals_300
    buf266 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf266, (16,), is_leaf=True)  # primals_301
    buf267 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf267, (1, 2048), is_leaf=True)  # primals_303
    buf268 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf268, (8, 88, 2048), is_leaf=True)  # primals_305
    buf269 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf269, (8, 128, 1408), is_leaf=True)  # primals_306
    buf270 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf270, (8, 88, 2048), is_leaf=True)  # primals_307
    buf271 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf271, (22, 2048), is_leaf=True)  # primals_308
    buf272 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf272, (22, 2048), is_leaf=True)  # primals_309
    buf273 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf273, (16, 2816), is_leaf=True)  # primals_310
    buf274 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf274, (16,), is_leaf=True)  # primals_311
    buf275 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf275, (24, 2048), is_leaf=True)  # primals_312
    buf276 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf276, (5, 2048), is_leaf=True)  # primals_313
    buf277 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf277, (4,), is_leaf=True)  # primals_314
    buf278 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf278, (32, 512), is_leaf=True)  # primals_315
    buf279 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf279, (16, 2048), is_leaf=True)  # primals_316
    buf280 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf280, (16,), is_leaf=True)  # primals_317
    buf281 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf281, (1, 2048), is_leaf=True)  # primals_319
    buf282 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf282, (8, 88, 2048), is_leaf=True)  # primals_321
    buf283 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf283, (8, 128, 1408), is_leaf=True)  # primals_322
    buf284 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf284, (8, 88, 2048), is_leaf=True)  # primals_323
    buf285 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf285, (22, 2048), is_leaf=True)  # primals_324
    buf286 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf286, (22, 2048), is_leaf=True)  # primals_325
    buf287 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf287, (16, 2816), is_leaf=True)  # primals_326
    buf288 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf288, (16,), is_leaf=True)  # primals_327
    buf289 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf289, (24, 2048), is_leaf=True)  # primals_328
    buf290 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf290, (5, 2048), is_leaf=True)  # primals_329
    buf291 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf291, (4,), is_leaf=True)  # primals_330
    buf292 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf292, (32, 512), is_leaf=True)  # primals_331
    buf293 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf293, (16, 2048), is_leaf=True)  # primals_332
    buf294 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf294, (16,), is_leaf=True)  # primals_333
    buf295 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf295, (1, 2048), is_leaf=True)  # primals_335
    buf296 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf296, (8, 88, 2048), is_leaf=True)  # primals_337
    buf297 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf297, (8, 128, 1408), is_leaf=True)  # primals_338
    buf298 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf298, (8, 88, 2048), is_leaf=True)  # primals_339
    buf299 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf299, (22, 2048), is_leaf=True)  # primals_340
    buf300 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf300, (22, 2048), is_leaf=True)  # primals_341
    buf301 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf301, (16, 2816), is_leaf=True)  # primals_342
    buf302 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf302, (16,), is_leaf=True)  # primals_343
    buf303 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf303, (24, 2048), is_leaf=True)  # primals_344
    buf304 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf304, (5, 2048), is_leaf=True)  # primals_345
    buf305 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf305, (4,), is_leaf=True)  # primals_346
    buf306 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf306, (32, 512), is_leaf=True)  # primals_347
    buf307 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf307, (16, 2048), is_leaf=True)  # primals_348
    buf308 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf308, (16,), is_leaf=True)  # primals_349
    buf309 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf309, (1, 2048), is_leaf=True)  # primals_351
    buf310 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf310, (8, 88, 2048), is_leaf=True)  # primals_353
    buf311 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf311, (8, 128, 1408), is_leaf=True)  # primals_354
    buf312 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf312, (8, 88, 2048), is_leaf=True)  # primals_355
    buf313 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf313, (22, 2048), is_leaf=True)  # primals_356
    buf314 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf314, (22, 2048), is_leaf=True)  # primals_357
    buf315 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf315, (16, 2816), is_leaf=True)  # primals_358
    buf316 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf316, (16,), is_leaf=True)  # primals_359
    buf317 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf317, (24, 2048), is_leaf=True)  # primals_360
    buf318 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf318, (5, 2048), is_leaf=True)  # primals_361
    buf319 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf319, (4,), is_leaf=True)  # primals_362
    buf320 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf320, (32, 512), is_leaf=True)  # primals_363
    buf321 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf321, (16, 2048), is_leaf=True)  # primals_364
    buf322 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf322, (16,), is_leaf=True)  # primals_365
    buf323 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf323, (1, 2048), is_leaf=True)  # primals_367
    buf324 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf324, (8, 88, 2048), is_leaf=True)  # primals_369
    buf325 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf325, (8, 128, 1408), is_leaf=True)  # primals_370
    buf326 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf326, (8, 88, 2048), is_leaf=True)  # primals_371
    buf327 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf327, (22, 2048), is_leaf=True)  # primals_372
    buf328 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf328, (22, 2048), is_leaf=True)  # primals_373
    buf329 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf329, (16, 2816), is_leaf=True)  # primals_374
    buf330 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf330, (16,), is_leaf=True)  # primals_375
    buf331 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf331, (24, 2048), is_leaf=True)  # primals_376
    buf332 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf332, (5, 2048), is_leaf=True)  # primals_377
    buf333 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf333, (4,), is_leaf=True)  # primals_378
    buf334 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf334, (32, 512), is_leaf=True)  # primals_379
    buf335 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf335, (16, 2048), is_leaf=True)  # primals_380
    buf336 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf336, (16,), is_leaf=True)  # primals_381
    buf337 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf337, (1, 2048), is_leaf=True)  # primals_383
    buf338 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf338, (8, 88, 2048), is_leaf=True)  # primals_385
    buf339 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf339, (8, 128, 1408), is_leaf=True)  # primals_386
    buf340 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf340, (8, 88, 2048), is_leaf=True)  # primals_387
    buf341 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf341, (22, 2048), is_leaf=True)  # primals_388
    buf342 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf342, (22, 2048), is_leaf=True)  # primals_389
    buf343 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf343, (16, 2816), is_leaf=True)  # primals_390
    buf344 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf344, (16,), is_leaf=True)  # primals_391
    buf345 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf345, (24, 2048), is_leaf=True)  # primals_392
    buf346 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf346, (5, 2048), is_leaf=True)  # primals_393
    buf347 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf347, (4,), is_leaf=True)  # primals_394
    buf348 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf348, (32, 512), is_leaf=True)  # primals_395
    buf349 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf349, (16, 2048), is_leaf=True)  # primals_396
    buf350 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf350, (16,), is_leaf=True)  # primals_397
    buf351 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf351, (1, 2048), is_leaf=True)  # primals_399
    buf352 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf352, (8, 88, 2048), is_leaf=True)  # primals_401
    buf353 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf353, (8, 128, 1408), is_leaf=True)  # primals_402
    buf354 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf354, (8, 88, 2048), is_leaf=True)  # primals_403
    buf355 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf355, (22, 2048), is_leaf=True)  # primals_404
    buf356 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf356, (22, 2048), is_leaf=True)  # primals_405
    buf357 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf357, (16, 2816), is_leaf=True)  # primals_406
    buf358 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf358, (16,), is_leaf=True)  # primals_407
    buf359 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf359, (24, 2048), is_leaf=True)  # primals_408
    buf360 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf360, (5, 2048), is_leaf=True)  # primals_409
    buf361 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf361, (4,), is_leaf=True)  # primals_410
    buf362 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf362, (32, 512), is_leaf=True)  # primals_411
    buf363 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf363, (16, 2048), is_leaf=True)  # primals_412
    buf364 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf364, (16,), is_leaf=True)  # primals_413
    buf365 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf365, (1, 2048), is_leaf=True)  # primals_415
    buf366 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf366, (8, 88, 2048), is_leaf=True)  # primals_417
    buf367 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf367, (8, 128, 1408), is_leaf=True)  # primals_418
    buf368 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf368, (8, 88, 2048), is_leaf=True)  # primals_419
    buf369 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf369, (22, 2048), is_leaf=True)  # primals_420
    buf370 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf370, (22, 2048), is_leaf=True)  # primals_421
    buf371 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf371, (16, 2816), is_leaf=True)  # primals_422
    buf372 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf372, (16,), is_leaf=True)  # primals_423
    buf373 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf373, (24, 2048), is_leaf=True)  # primals_424
    buf374 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf374, (5, 2048), is_leaf=True)  # primals_425
    buf375 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf375, (4,), is_leaf=True)  # primals_426
    buf376 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf376, (32, 512), is_leaf=True)  # primals_427
    buf377 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf377, (16, 2048), is_leaf=True)  # primals_428
    buf378 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf378, (16,), is_leaf=True)  # primals_429
    buf379 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf379, (1, 2048), is_leaf=True)  # primals_431
    buf380 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf380, (8, 88, 2048), is_leaf=True)  # primals_433
    buf381 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf381, (8, 128, 1408), is_leaf=True)  # primals_434
    buf382 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf382, (8, 88, 2048), is_leaf=True)  # primals_435
    buf383 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf383, (22, 2048), is_leaf=True)  # primals_436
    buf384 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf384, (22, 2048), is_leaf=True)  # primals_437
    buf385 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf385, (16, 2816), is_leaf=True)  # primals_438
    buf386 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf386, (16,), is_leaf=True)  # primals_439
    buf387 = reader.storage(None, 6553600, device=device(type='cuda', index=0))
    reader.tensor(buf387, (800, 2048), is_leaf=True)  # primals_440
    buf388 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf388, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # embedding
    buf389 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf389, (2, 4096, 1), is_leaf=True)  # rsqrt
    buf390 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf390, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_3
    buf391 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf391, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2
    buf392 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf392, (2, 4096, 1), is_leaf=True)  # rsqrt_1
    buf393 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf393, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_17
    buf394 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf394, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_3
    buf395 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf395, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_4
    buf396 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf396, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_5
    buf397 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf397, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_6
    buf398 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf398, (2, 16, 4096), is_leaf=True)  # getitem_7
    buf399 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf399, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # mm_3
    buf400 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf400, (2, 4096, 1), is_leaf=True)  # rsqrt_2
    buf401 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf401, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_26
    buf402 = reader.storage(None, 179306496, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf402, (8192, 10944), dtype=torch.bfloat16, is_leaf=True)  # mm_4
    buf403 = reader.storage(None, 179306496, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf403, (8192, 10944), dtype=torch.bfloat16, is_leaf=True)  # mm_5
    buf404 = reader.storage(None, 179306496, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf404, (8192, 10944), dtype=torch.bfloat16, is_leaf=True)  # view_32
    buf405 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf405, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_5
    buf406 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf406, (2, 4096, 1), is_leaf=True)  # rsqrt_3
    buf407 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf407, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_36
    buf408 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf408, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_11
    buf409 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf409, (2, 4096, 1), is_leaf=True)  # rsqrt_4
    buf410 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf410, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_50
    buf411 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf411, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_14
    buf412 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf412, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_15
    buf413 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf413, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_16
    buf414 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf414, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_15
    buf415 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf415, (2, 16, 4096), is_leaf=True)  # getitem_16
    buf416 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf416, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_8
    buf417 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf417, (2, 4096, 1), is_leaf=True)  # rsqrt_5
    buf418 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf418, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_58
    buf419 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf419, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_11
    buf420 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf420, (8192, 1), is_leaf=True)  # amax
    buf421 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf421, (8192, 1), is_leaf=True)  # sum_1
    buf422 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf422, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_19
    buf423 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf423, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_21
    buf424 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf424, (49152,), dtype=torch.int64, is_leaf=True)  # div_2
    buf425 = reader.storage(None, 32*(((u10 + u11 + u12 + u13 + u14 + u15 + u8 + u9 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf425, (8*(((u10 + u11 + u12 + u13 + u14 + u15 + u8 + u9 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_22
    buf426 = reader.storage(None, 32768*(((u10 + u11 + u12 + u13 + u14 + u15 + u8 + u9 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf426, (8*(((u10 + u11 + u12 + u13 + u14 + u15 + u8 + u9 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_1
    buf427 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf427, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_2
    buf428 = reader.storage(None, 22528*(((u10 + u11 + u12 + u13 + u14 + u15 + u8 + u9 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf428, (8*(((u10 + u11 + u12 + u13 + u14 + u15 + u8 + u9 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm
    buf429 = reader.storage(None, 22528*(((u10 + u11 + u12 + u13 + u14 + u15 + u8 + u9 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf429, (8*(((u10 + u11 + u12 + u13 + u14 + u15 + u8 + u9 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_1
    buf430 = reader.storage(None, 22528*(((u10 + u11 + u12 + u13 + u14 + u15 + u8 + u9 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf430, (8*(((u10 + u11 + u12 + u13 + u14 + u15 + u8 + u9 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_35
    buf431 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf431, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_12
    buf432 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf432, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_13
    buf433 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf433, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_55
    buf434 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf434, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_73
    buf435 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf435, (2, 4096, 1), is_leaf=True)  # rsqrt_6
    buf436 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf436, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_103
    buf437 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf437, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_121
    buf438 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf438, (2, 4096, 1), is_leaf=True)  # rsqrt_7
    buf439 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf439, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_117
    buf440 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf440, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_29
    buf441 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf441, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_30
    buf442 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf442, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_31
    buf443 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf443, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_125
    buf444 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf444, (2, 16, 4096), is_leaf=True)  # getitem_126
    buf445 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf445, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_76
    buf446 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf446, (2, 4096, 1), is_leaf=True)  # rsqrt_8
    buf447 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf447, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_125
    buf448 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf448, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_19
    buf449 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf449, (8192, 1), is_leaf=True)  # amax_1
    buf450 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf450, (8192, 1), is_leaf=True)  # sum_5
    buf451 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf451, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_129
    buf452 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf452, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_131
    buf453 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf453, (49152,), dtype=torch.int64, is_leaf=True)  # div_7
    buf454 = reader.storage(None, 32*(((u24 + u25 + u26 + u27 + u28 + u29 + u30 + u31 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf454, (8*(((u24 + u25 + u26 + u27 + u28 + u29 + u30 + u31 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_132
    buf455 = reader.storage(None, 32768*(((u24 + u25 + u26 + u27 + u28 + u29 + u30 + u31 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf455, (8*(((u24 + u25 + u26 + u27 + u28 + u29 + u30 + u31 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_3
    buf456 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf456, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_5
    buf457 = reader.storage(None, 22528*(((u24 + u25 + u26 + u27 + u28 + u29 + u30 + u31 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf457, (8*(((u24 + u25 + u26 + u27 + u28 + u29 + u30 + u31 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_3
    buf458 = reader.storage(None, 22528*(((u24 + u25 + u26 + u27 + u28 + u29 + u30 + u31 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf458, (8*(((u24 + u25 + u26 + u27 + u28 + u29 + u30 + u31 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_4
    buf459 = reader.storage(None, 22528*(((u24 + u25 + u26 + u27 + u28 + u29 + u30 + u31 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf459, (8*(((u24 + u25 + u26 + u27 + u28 + u29 + u30 + u31 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_84
    buf460 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf460, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_20
    buf461 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf461, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_21
    buf462 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf462, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_104
    buf463 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf463, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_141
    buf464 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf464, (2, 4096, 1), is_leaf=True)  # rsqrt_9
    buf465 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf465, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_170
    buf466 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf466, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_231
    buf467 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf467, (2, 4096, 1), is_leaf=True)  # rsqrt_10
    buf468 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf468, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_184
    buf469 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf469, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_44
    buf470 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf470, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_45
    buf471 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf471, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_46
    buf472 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf472, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_235
    buf473 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf473, (2, 16, 4096), is_leaf=True)  # getitem_236
    buf474 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf474, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_144
    buf475 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf475, (2, 4096, 1), is_leaf=True)  # rsqrt_11
    buf476 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf476, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_192
    buf477 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf477, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_27
    buf478 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf478, (8192, 1), is_leaf=True)  # amax_2
    buf479 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf479, (8192, 1), is_leaf=True)  # sum_9
    buf480 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf480, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_239
    buf481 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf481, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_241
    buf482 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf482, (49152,), dtype=torch.int64, is_leaf=True)  # div_12
    buf483 = reader.storage(None, 32*(((u40 + u41 + u42 + u43 + u44 + u45 + u46 + u47 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf483, (8*(((u40 + u41 + u42 + u43 + u44 + u45 + u46 + u47 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_242
    buf484 = reader.storage(None, 32768*(((u40 + u41 + u42 + u43 + u44 + u45 + u46 + u47 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf484, (8*(((u40 + u41 + u42 + u43 + u44 + u45 + u46 + u47 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_5
    buf485 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf485, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_8
    buf486 = reader.storage(None, 22528*(((u40 + u41 + u42 + u43 + u44 + u45 + u46 + u47 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf486, (8*(((u40 + u41 + u42 + u43 + u44 + u45 + u46 + u47 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_6
    buf487 = reader.storage(None, 22528*(((u40 + u41 + u42 + u43 + u44 + u45 + u46 + u47 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf487, (8*(((u40 + u41 + u42 + u43 + u44 + u45 + u46 + u47 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_7
    buf488 = reader.storage(None, 22528*(((u40 + u41 + u42 + u43 + u44 + u45 + u46 + u47 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf488, (8*(((u40 + u41 + u42 + u43 + u44 + u45 + u46 + u47 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_133
    buf489 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf489, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_28
    buf490 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf490, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_29
    buf491 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf491, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_153
    buf492 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf492, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_209
    buf493 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf493, (2, 4096, 1), is_leaf=True)  # rsqrt_12
    buf494 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf494, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_237
    buf495 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf495, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_341
    buf496 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf496, (2, 4096, 1), is_leaf=True)  # rsqrt_13
    buf497 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf497, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_251
    buf498 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf498, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_59
    buf499 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf499, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_60
    buf500 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf500, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_61
    buf501 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf501, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_345
    buf502 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf502, (2, 16, 4096), is_leaf=True)  # getitem_346
    buf503 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf503, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_212
    buf504 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf504, (2, 4096, 1), is_leaf=True)  # rsqrt_14
    buf505 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf505, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_259
    buf506 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf506, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_35
    buf507 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf507, (8192, 1), is_leaf=True)  # amax_3
    buf508 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf508, (8192, 1), is_leaf=True)  # sum_13
    buf509 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf509, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_349
    buf510 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf510, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_351
    buf511 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf511, (49152,), dtype=torch.int64, is_leaf=True)  # div_17
    buf512 = reader.storage(None, 32*(((u56 + u57 + u58 + u59 + u60 + u61 + u62 + u63 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf512, (8*(((u56 + u57 + u58 + u59 + u60 + u61 + u62 + u63 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_352
    buf513 = reader.storage(None, 32768*(((u56 + u57 + u58 + u59 + u60 + u61 + u62 + u63 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf513, (8*(((u56 + u57 + u58 + u59 + u60 + u61 + u62 + u63 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_7
    buf514 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf514, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_11
    buf515 = reader.storage(None, 22528*(((u56 + u57 + u58 + u59 + u60 + u61 + u62 + u63 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf515, (8*(((u56 + u57 + u58 + u59 + u60 + u61 + u62 + u63 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_9
    buf516 = reader.storage(None, 22528*(((u56 + u57 + u58 + u59 + u60 + u61 + u62 + u63 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf516, (8*(((u56 + u57 + u58 + u59 + u60 + u61 + u62 + u63 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_10
    buf517 = reader.storage(None, 22528*(((u56 + u57 + u58 + u59 + u60 + u61 + u62 + u63 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf517, (8*(((u56 + u57 + u58 + u59 + u60 + u61 + u62 + u63 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_182
    buf518 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf518, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_36
    buf519 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf519, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_37
    buf520 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf520, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_202
    buf521 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf521, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_277
    buf522 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf522, (2, 4096, 1), is_leaf=True)  # rsqrt_15
    buf523 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf523, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_304
    buf524 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf524, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_451
    buf525 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf525, (2, 4096, 1), is_leaf=True)  # rsqrt_16
    buf526 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf526, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_318
    buf527 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf527, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_74
    buf528 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf528, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_75
    buf529 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf529, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_76
    buf530 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf530, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_455
    buf531 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf531, (2, 16, 4096), is_leaf=True)  # getitem_456
    buf532 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf532, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_280
    buf533 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf533, (2, 4096, 1), is_leaf=True)  # rsqrt_17
    buf534 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf534, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_326
    buf535 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf535, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_43
    buf536 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf536, (8192, 1), is_leaf=True)  # amax_4
    buf537 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf537, (8192, 1), is_leaf=True)  # sum_17
    buf538 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf538, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_459
    buf539 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf539, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_461
    buf540 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf540, (49152,), dtype=torch.int64, is_leaf=True)  # div_22
    buf541 = reader.storage(None, 32*(((u72 + u73 + u74 + u75 + u76 + u77 + u78 + u79 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf541, (8*(((u72 + u73 + u74 + u75 + u76 + u77 + u78 + u79 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_462
    buf542 = reader.storage(None, 32768*(((u72 + u73 + u74 + u75 + u76 + u77 + u78 + u79 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf542, (8*(((u72 + u73 + u74 + u75 + u76 + u77 + u78 + u79 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_9
    buf543 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf543, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_14
    buf544 = reader.storage(None, 22528*(((u72 + u73 + u74 + u75 + u76 + u77 + u78 + u79 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf544, (8*(((u72 + u73 + u74 + u75 + u76 + u77 + u78 + u79 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_12
    buf545 = reader.storage(None, 22528*(((u72 + u73 + u74 + u75 + u76 + u77 + u78 + u79 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf545, (8*(((u72 + u73 + u74 + u75 + u76 + u77 + u78 + u79 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_13
    buf546 = reader.storage(None, 22528*(((u72 + u73 + u74 + u75 + u76 + u77 + u78 + u79 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf546, (8*(((u72 + u73 + u74 + u75 + u76 + u77 + u78 + u79 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_231
    buf547 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf547, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_44
    buf548 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf548, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_45
    buf549 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf549, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_251
    buf550 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf550, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_345
    buf551 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf551, (2, 4096, 1), is_leaf=True)  # rsqrt_18
    buf552 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf552, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_371
    buf553 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf553, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_561
    buf554 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf554, (2, 4096, 1), is_leaf=True)  # rsqrt_19
    buf555 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf555, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_385
    buf556 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf556, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_89
    buf557 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf557, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_90
    buf558 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf558, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_91
    buf559 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf559, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_565
    buf560 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf560, (2, 16, 4096), is_leaf=True)  # getitem_566
    buf561 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf561, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_348
    buf562 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf562, (2, 4096, 1), is_leaf=True)  # rsqrt_20
    buf563 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf563, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_393
    buf564 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf564, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_51
    buf565 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf565, (8192, 1), is_leaf=True)  # amax_5
    buf566 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf566, (8192, 1), is_leaf=True)  # sum_21
    buf567 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf567, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_569
    buf568 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf568, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_571
    buf569 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf569, (49152,), dtype=torch.int64, is_leaf=True)  # div_27
    buf570 = reader.storage(None, 32*(((u88 + u89 + u90 + u91 + u92 + u93 + u94 + u95 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf570, (8*(((u88 + u89 + u90 + u91 + u92 + u93 + u94 + u95 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_572
    buf571 = reader.storage(None, 32768*(((u88 + u89 + u90 + u91 + u92 + u93 + u94 + u95 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf571, (8*(((u88 + u89 + u90 + u91 + u92 + u93 + u94 + u95 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_11
    buf572 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf572, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_17
    buf573 = reader.storage(None, 22528*(((u88 + u89 + u90 + u91 + u92 + u93 + u94 + u95 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf573, (8*(((u88 + u89 + u90 + u91 + u92 + u93 + u94 + u95 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_15
    buf574 = reader.storage(None, 22528*(((u88 + u89 + u90 + u91 + u92 + u93 + u94 + u95 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf574, (8*(((u88 + u89 + u90 + u91 + u92 + u93 + u94 + u95 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_16
    buf575 = reader.storage(None, 22528*(((u88 + u89 + u90 + u91 + u92 + u93 + u94 + u95 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf575, (8*(((u88 + u89 + u90 + u91 + u92 + u93 + u94 + u95 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_280
    buf576 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf576, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_52
    buf577 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf577, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_53
    buf578 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf578, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_300
    buf579 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf579, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_413
    buf580 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf580, (2, 4096, 1), is_leaf=True)  # rsqrt_21
    buf581 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf581, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_438
    buf582 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf582, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_671
    buf583 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf583, (2, 4096, 1), is_leaf=True)  # rsqrt_22
    buf584 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf584, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_452
    buf585 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf585, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_104
    buf586 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf586, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_105
    buf587 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf587, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_106
    buf588 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf588, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_675
    buf589 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf589, (2, 16, 4096), is_leaf=True)  # getitem_676
    buf590 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf590, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_416
    buf591 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf591, (2, 4096, 1), is_leaf=True)  # rsqrt_23
    buf592 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf592, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_460
    buf593 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf593, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_59
    buf594 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf594, (8192, 1), is_leaf=True)  # amax_6
    buf595 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf595, (8192, 1), is_leaf=True)  # sum_25
    buf596 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf596, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_679
    buf597 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf597, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_681
    buf598 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf598, (49152,), dtype=torch.int64, is_leaf=True)  # div_32
    buf599 = reader.storage(None, 32*(((u104 + u105 + u106 + u107 + u108 + u109 + u110 + u111 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf599, (8*(((u104 + u105 + u106 + u107 + u108 + u109 + u110 + u111 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_682
    buf600 = reader.storage(None, 32768*(((u104 + u105 + u106 + u107 + u108 + u109 + u110 + u111 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf600, (8*(((u104 + u105 + u106 + u107 + u108 + u109 + u110 + u111 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_13
    buf601 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf601, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_20
    buf602 = reader.storage(None, 22528*(((u104 + u105 + u106 + u107 + u108 + u109 + u110 + u111 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf602, (8*(((u104 + u105 + u106 + u107 + u108 + u109 + u110 + u111 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_18
    buf603 = reader.storage(None, 22528*(((u104 + u105 + u106 + u107 + u108 + u109 + u110 + u111 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf603, (8*(((u104 + u105 + u106 + u107 + u108 + u109 + u110 + u111 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_19
    buf604 = reader.storage(None, 22528*(((u104 + u105 + u106 + u107 + u108 + u109 + u110 + u111 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf604, (8*(((u104 + u105 + u106 + u107 + u108 + u109 + u110 + u111 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_329
    buf605 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf605, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_60
    buf606 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf606, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_61
    buf607 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf607, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_349
    buf608 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf608, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_481
    buf609 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf609, (2, 4096, 1), is_leaf=True)  # rsqrt_24
    buf610 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf610, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_505
    buf611 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf611, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_781
    buf612 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf612, (2, 4096, 1), is_leaf=True)  # rsqrt_25
    buf613 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf613, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_519
    buf614 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf614, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_119
    buf615 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf615, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_120
    buf616 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf616, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_121
    buf617 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf617, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_785
    buf618 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf618, (2, 16, 4096), is_leaf=True)  # getitem_786
    buf619 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf619, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_484
    buf620 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf620, (2, 4096, 1), is_leaf=True)  # rsqrt_26
    buf621 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf621, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_527
    buf622 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf622, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_67
    buf623 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf623, (8192, 1), is_leaf=True)  # amax_7
    buf624 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf624, (8192, 1), is_leaf=True)  # sum_29
    buf625 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf625, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_789
    buf626 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf626, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_791
    buf627 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf627, (49152,), dtype=torch.int64, is_leaf=True)  # div_37
    buf628 = reader.storage(None, 32*(((u120 + u121 + u122 + u123 + u124 + u125 + u126 + u127 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf628, (8*(((u120 + u121 + u122 + u123 + u124 + u125 + u126 + u127 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_792
    buf629 = reader.storage(None, 32768*(((u120 + u121 + u122 + u123 + u124 + u125 + u126 + u127 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf629, (8*(((u120 + u121 + u122 + u123 + u124 + u125 + u126 + u127 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_15
    buf630 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf630, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_23
    buf631 = reader.storage(None, 22528*(((u120 + u121 + u122 + u123 + u124 + u125 + u126 + u127 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf631, (8*(((u120 + u121 + u122 + u123 + u124 + u125 + u126 + u127 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_21
    buf632 = reader.storage(None, 22528*(((u120 + u121 + u122 + u123 + u124 + u125 + u126 + u127 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf632, (8*(((u120 + u121 + u122 + u123 + u124 + u125 + u126 + u127 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_22
    buf633 = reader.storage(None, 22528*(((u120 + u121 + u122 + u123 + u124 + u125 + u126 + u127 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf633, (8*(((u120 + u121 + u122 + u123 + u124 + u125 + u126 + u127 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_378
    buf634 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf634, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_68
    buf635 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf635, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_69
    buf636 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf636, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_398
    buf637 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf637, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_549
    buf638 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf638, (2, 4096, 1), is_leaf=True)  # rsqrt_27
    buf639 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf639, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_572
    buf640 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf640, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_891
    buf641 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf641, (2, 4096, 1), is_leaf=True)  # rsqrt_28
    buf642 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf642, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_586
    buf643 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf643, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_134
    buf644 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf644, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_135
    buf645 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf645, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_136
    buf646 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf646, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_895
    buf647 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf647, (2, 16, 4096), is_leaf=True)  # getitem_896
    buf648 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf648, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_552
    buf649 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf649, (2, 4096, 1), is_leaf=True)  # rsqrt_29
    buf650 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf650, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_594
    buf651 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf651, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_75
    buf652 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf652, (8192, 1), is_leaf=True)  # amax_8
    buf653 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf653, (8192, 1), is_leaf=True)  # sum_33
    buf654 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf654, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_899
    buf655 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf655, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_901
    buf656 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf656, (49152,), dtype=torch.int64, is_leaf=True)  # div_42
    buf657 = reader.storage(None, 32*(((u136 + u137 + u138 + u139 + u140 + u141 + u142 + u143 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf657, (8*(((u136 + u137 + u138 + u139 + u140 + u141 + u142 + u143 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_902
    buf658 = reader.storage(None, 32768*(((u136 + u137 + u138 + u139 + u140 + u141 + u142 + u143 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf658, (8*(((u136 + u137 + u138 + u139 + u140 + u141 + u142 + u143 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_17
    buf659 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf659, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_26
    buf660 = reader.storage(None, 22528*(((u136 + u137 + u138 + u139 + u140 + u141 + u142 + u143 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf660, (8*(((u136 + u137 + u138 + u139 + u140 + u141 + u142 + u143 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_24
    buf661 = reader.storage(None, 22528*(((u136 + u137 + u138 + u139 + u140 + u141 + u142 + u143 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf661, (8*(((u136 + u137 + u138 + u139 + u140 + u141 + u142 + u143 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_25
    buf662 = reader.storage(None, 22528*(((u136 + u137 + u138 + u139 + u140 + u141 + u142 + u143 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf662, (8*(((u136 + u137 + u138 + u139 + u140 + u141 + u142 + u143 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_427
    buf663 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf663, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_76
    buf664 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf664, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_77
    buf665 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf665, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_447
    buf666 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf666, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_617
    buf667 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf667, (2, 4096, 1), is_leaf=True)  # rsqrt_30
    buf668 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf668, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_639
    buf669 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf669, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1001
    buf670 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf670, (2, 4096, 1), is_leaf=True)  # rsqrt_31
    buf671 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf671, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_653
    buf672 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf672, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_149
    buf673 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf673, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_150
    buf674 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf674, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_151
    buf675 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf675, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1005
    buf676 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf676, (2, 16, 4096), is_leaf=True)  # getitem_1006
    buf677 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf677, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_620
    buf678 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf678, (2, 4096, 1), is_leaf=True)  # rsqrt_32
    buf679 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf679, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_661
    buf680 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf680, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_83
    buf681 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf681, (8192, 1), is_leaf=True)  # amax_9
    buf682 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf682, (8192, 1), is_leaf=True)  # sum_37
    buf683 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf683, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_1009
    buf684 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf684, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_1011
    buf685 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf685, (49152,), dtype=torch.int64, is_leaf=True)  # div_47
    buf686 = reader.storage(None, 32*(((u152 + u153 + u154 + u155 + u156 + u157 + u158 + u159 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf686, (8*(((u152 + u153 + u154 + u155 + u156 + u157 + u158 + u159 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_1012
    buf687 = reader.storage(None, 32768*(((u152 + u153 + u154 + u155 + u156 + u157 + u158 + u159 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf687, (8*(((u152 + u153 + u154 + u155 + u156 + u157 + u158 + u159 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_19
    buf688 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf688, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_29
    buf689 = reader.storage(None, 22528*(((u152 + u153 + u154 + u155 + u156 + u157 + u158 + u159 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf689, (8*(((u152 + u153 + u154 + u155 + u156 + u157 + u158 + u159 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_27
    buf690 = reader.storage(None, 22528*(((u152 + u153 + u154 + u155 + u156 + u157 + u158 + u159 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf690, (8*(((u152 + u153 + u154 + u155 + u156 + u157 + u158 + u159 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_28
    buf691 = reader.storage(None, 22528*(((u152 + u153 + u154 + u155 + u156 + u157 + u158 + u159 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf691, (8*(((u152 + u153 + u154 + u155 + u156 + u157 + u158 + u159 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_476
    buf692 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf692, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_84
    buf693 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf693, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_85
    buf694 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf694, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_496
    buf695 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf695, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_685
    buf696 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf696, (2, 4096, 1), is_leaf=True)  # rsqrt_33
    buf697 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf697, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_706
    buf698 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf698, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1111
    buf699 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf699, (2, 4096, 1), is_leaf=True)  # rsqrt_34
    buf700 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf700, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_720
    buf701 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf701, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_164
    buf702 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf702, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_165
    buf703 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf703, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_166
    buf704 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf704, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1115
    buf705 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf705, (2, 16, 4096), is_leaf=True)  # getitem_1116
    buf706 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf706, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_688
    buf707 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf707, (2, 4096, 1), is_leaf=True)  # rsqrt_35
    buf708 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf708, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_728
    buf709 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf709, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_91
    buf710 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf710, (8192, 1), is_leaf=True)  # amax_10
    buf711 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf711, (8192, 1), is_leaf=True)  # sum_41
    buf712 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf712, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_1119
    buf713 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf713, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_1121
    buf714 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf714, (49152,), dtype=torch.int64, is_leaf=True)  # div_52
    buf715 = reader.storage(None, 32*(((u168 + u169 + u170 + u171 + u172 + u173 + u174 + u175 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf715, (8*(((u168 + u169 + u170 + u171 + u172 + u173 + u174 + u175 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_1122
    buf716 = reader.storage(None, 32768*(((u168 + u169 + u170 + u171 + u172 + u173 + u174 + u175 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf716, (8*(((u168 + u169 + u170 + u171 + u172 + u173 + u174 + u175 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_21
    buf717 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf717, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_32
    buf718 = reader.storage(None, 22528*(((u168 + u169 + u170 + u171 + u172 + u173 + u174 + u175 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf718, (8*(((u168 + u169 + u170 + u171 + u172 + u173 + u174 + u175 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_30
    buf719 = reader.storage(None, 22528*(((u168 + u169 + u170 + u171 + u172 + u173 + u174 + u175 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf719, (8*(((u168 + u169 + u170 + u171 + u172 + u173 + u174 + u175 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_31
    buf720 = reader.storage(None, 22528*(((u168 + u169 + u170 + u171 + u172 + u173 + u174 + u175 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf720, (8*(((u168 + u169 + u170 + u171 + u172 + u173 + u174 + u175 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_525
    buf721 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf721, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_92
    buf722 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf722, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_93
    buf723 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf723, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_545
    buf724 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf724, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_753
    buf725 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf725, (2, 4096, 1), is_leaf=True)  # rsqrt_36
    buf726 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf726, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_773
    buf727 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf727, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1221
    buf728 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf728, (2, 4096, 1), is_leaf=True)  # rsqrt_37
    buf729 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf729, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_787
    buf730 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf730, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_179
    buf731 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf731, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_180
    buf732 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf732, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_181
    buf733 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf733, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1225
    buf734 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf734, (2, 16, 4096), is_leaf=True)  # getitem_1226
    buf735 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf735, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_756
    buf736 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf736, (2, 4096, 1), is_leaf=True)  # rsqrt_38
    buf737 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf737, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_795
    buf738 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf738, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_99
    buf739 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf739, (8192, 1), is_leaf=True)  # amax_11
    buf740 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf740, (8192, 1), is_leaf=True)  # sum_45
    buf741 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf741, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_1229
    buf742 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf742, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_1231
    buf743 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf743, (49152,), dtype=torch.int64, is_leaf=True)  # div_57
    buf744 = reader.storage(None, 32*(((u184 + u185 + u186 + u187 + u188 + u189 + u190 + u191 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf744, (8*(((u184 + u185 + u186 + u187 + u188 + u189 + u190 + u191 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_1232
    buf745 = reader.storage(None, 32768*(((u184 + u185 + u186 + u187 + u188 + u189 + u190 + u191 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf745, (8*(((u184 + u185 + u186 + u187 + u188 + u189 + u190 + u191 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_23
    buf746 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf746, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_35
    buf747 = reader.storage(None, 22528*(((u184 + u185 + u186 + u187 + u188 + u189 + u190 + u191 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf747, (8*(((u184 + u185 + u186 + u187 + u188 + u189 + u190 + u191 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_33
    buf748 = reader.storage(None, 22528*(((u184 + u185 + u186 + u187 + u188 + u189 + u190 + u191 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf748, (8*(((u184 + u185 + u186 + u187 + u188 + u189 + u190 + u191 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_34
    buf749 = reader.storage(None, 22528*(((u184 + u185 + u186 + u187 + u188 + u189 + u190 + u191 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf749, (8*(((u184 + u185 + u186 + u187 + u188 + u189 + u190 + u191 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_574
    buf750 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf750, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_100
    buf751 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf751, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_101
    buf752 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf752, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_594
    buf753 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf753, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_821
    buf754 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf754, (2, 4096, 1), is_leaf=True)  # rsqrt_39
    buf755 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf755, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_840
    buf756 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf756, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1331
    buf757 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf757, (2, 4096, 1), is_leaf=True)  # rsqrt_40
    buf758 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf758, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_854
    buf759 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf759, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_194
    buf760 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf760, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_195
    buf761 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf761, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_196
    buf762 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf762, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1335
    buf763 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf763, (2, 16, 4096), is_leaf=True)  # getitem_1336
    buf764 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf764, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_824
    buf765 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf765, (2, 4096, 1), is_leaf=True)  # rsqrt_41
    buf766 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf766, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_862
    buf767 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf767, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_107
    buf768 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf768, (8192, 1), is_leaf=True)  # amax_12
    buf769 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf769, (8192, 1), is_leaf=True)  # sum_49
    buf770 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf770, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_1339
    buf771 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf771, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_1341
    buf772 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf772, (49152,), dtype=torch.int64, is_leaf=True)  # div_62
    buf773 = reader.storage(None, 32*(((u200 + u201 + u202 + u203 + u204 + u205 + u206 + u207 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf773, (8*(((u200 + u201 + u202 + u203 + u204 + u205 + u206 + u207 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_1342
    buf774 = reader.storage(None, 32768*(((u200 + u201 + u202 + u203 + u204 + u205 + u206 + u207 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf774, (8*(((u200 + u201 + u202 + u203 + u204 + u205 + u206 + u207 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_25
    buf775 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf775, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_38
    buf776 = reader.storage(None, 22528*(((u200 + u201 + u202 + u203 + u204 + u205 + u206 + u207 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf776, (8*(((u200 + u201 + u202 + u203 + u204 + u205 + u206 + u207 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_36
    buf777 = reader.storage(None, 22528*(((u200 + u201 + u202 + u203 + u204 + u205 + u206 + u207 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf777, (8*(((u200 + u201 + u202 + u203 + u204 + u205 + u206 + u207 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_37
    buf778 = reader.storage(None, 22528*(((u200 + u201 + u202 + u203 + u204 + u205 + u206 + u207 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf778, (8*(((u200 + u201 + u202 + u203 + u204 + u205 + u206 + u207 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_623
    buf779 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf779, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_108
    buf780 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf780, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_109
    buf781 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf781, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_643
    buf782 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf782, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_889
    buf783 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf783, (2, 4096, 1), is_leaf=True)  # rsqrt_42
    buf784 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf784, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_907
    buf785 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf785, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1441
    buf786 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf786, (2, 4096, 1), is_leaf=True)  # rsqrt_43
    buf787 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf787, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_921
    buf788 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf788, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_209
    buf789 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf789, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_210
    buf790 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf790, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_211
    buf791 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf791, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1445
    buf792 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf792, (2, 16, 4096), is_leaf=True)  # getitem_1446
    buf793 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf793, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_892
    buf794 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf794, (2, 4096, 1), is_leaf=True)  # rsqrt_44
    buf795 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf795, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_929
    buf796 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf796, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_115
    buf797 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf797, (8192, 1), is_leaf=True)  # amax_13
    buf798 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf798, (8192, 1), is_leaf=True)  # sum_53
    buf799 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf799, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_1449
    buf800 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf800, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_1451
    buf801 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf801, (49152,), dtype=torch.int64, is_leaf=True)  # div_67
    buf802 = reader.storage(None, 32*(((u216 + u217 + u218 + u219 + u220 + u221 + u222 + u223 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf802, (8*(((u216 + u217 + u218 + u219 + u220 + u221 + u222 + u223 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_1452
    buf803 = reader.storage(None, 32768*(((u216 + u217 + u218 + u219 + u220 + u221 + u222 + u223 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf803, (8*(((u216 + u217 + u218 + u219 + u220 + u221 + u222 + u223 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_27
    buf804 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf804, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_41
    buf805 = reader.storage(None, 22528*(((u216 + u217 + u218 + u219 + u220 + u221 + u222 + u223 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf805, (8*(((u216 + u217 + u218 + u219 + u220 + u221 + u222 + u223 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_39
    buf806 = reader.storage(None, 22528*(((u216 + u217 + u218 + u219 + u220 + u221 + u222 + u223 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf806, (8*(((u216 + u217 + u218 + u219 + u220 + u221 + u222 + u223 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_40
    buf807 = reader.storage(None, 22528*(((u216 + u217 + u218 + u219 + u220 + u221 + u222 + u223 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf807, (8*(((u216 + u217 + u218 + u219 + u220 + u221 + u222 + u223 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_672
    buf808 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf808, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_116
    buf809 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf809, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_117
    buf810 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf810, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_692
    buf811 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf811, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_957
    buf812 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf812, (2, 4096, 1), is_leaf=True)  # rsqrt_45
    buf813 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf813, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_974
    buf814 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf814, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1551
    buf815 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf815, (2, 4096, 1), is_leaf=True)  # rsqrt_46
    buf816 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf816, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_988
    buf817 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf817, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_224
    buf818 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf818, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_225
    buf819 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf819, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_226
    buf820 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf820, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1555
    buf821 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf821, (2, 16, 4096), is_leaf=True)  # getitem_1556
    buf822 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf822, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_960
    buf823 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf823, (2, 4096, 1), is_leaf=True)  # rsqrt_47
    buf824 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf824, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_996
    buf825 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf825, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_123
    buf826 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf826, (8192, 1), is_leaf=True)  # amax_14
    buf827 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf827, (8192, 1), is_leaf=True)  # sum_57
    buf828 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf828, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_1559
    buf829 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf829, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_1561
    buf830 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf830, (49152,), dtype=torch.int64, is_leaf=True)  # div_72
    buf831 = reader.storage(None, 32*(((u232 + u233 + u234 + u235 + u236 + u237 + u238 + u239 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf831, (8*(((u232 + u233 + u234 + u235 + u236 + u237 + u238 + u239 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_1562
    buf832 = reader.storage(None, 32768*(((u232 + u233 + u234 + u235 + u236 + u237 + u238 + u239 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf832, (8*(((u232 + u233 + u234 + u235 + u236 + u237 + u238 + u239 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_29
    buf833 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf833, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_44
    buf834 = reader.storage(None, 22528*(((u232 + u233 + u234 + u235 + u236 + u237 + u238 + u239 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf834, (8*(((u232 + u233 + u234 + u235 + u236 + u237 + u238 + u239 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_42
    buf835 = reader.storage(None, 22528*(((u232 + u233 + u234 + u235 + u236 + u237 + u238 + u239 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf835, (8*(((u232 + u233 + u234 + u235 + u236 + u237 + u238 + u239 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_43
    buf836 = reader.storage(None, 22528*(((u232 + u233 + u234 + u235 + u236 + u237 + u238 + u239 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf836, (8*(((u232 + u233 + u234 + u235 + u236 + u237 + u238 + u239 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_721
    buf837 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf837, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_124
    buf838 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf838, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_125
    buf839 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf839, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_741
    buf840 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf840, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1025
    buf841 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf841, (2, 4096, 1), is_leaf=True)  # rsqrt_48
    buf842 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf842, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1041
    buf843 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf843, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1661
    buf844 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf844, (2, 4096, 1), is_leaf=True)  # rsqrt_49
    buf845 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf845, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1055
    buf846 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf846, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_239
    buf847 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf847, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_240
    buf848 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf848, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_241
    buf849 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf849, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1665
    buf850 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf850, (2, 16, 4096), is_leaf=True)  # getitem_1666
    buf851 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf851, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1028
    buf852 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf852, (2, 4096, 1), is_leaf=True)  # rsqrt_50
    buf853 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf853, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1063
    buf854 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf854, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_131
    buf855 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf855, (8192, 1), is_leaf=True)  # amax_15
    buf856 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf856, (8192, 1), is_leaf=True)  # sum_61
    buf857 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf857, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_1669
    buf858 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf858, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_1671
    buf859 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf859, (49152,), dtype=torch.int64, is_leaf=True)  # div_77
    buf860 = reader.storage(None, 32*(((u248 + u249 + u250 + u251 + u252 + u253 + u254 + u255 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf860, (8*(((u248 + u249 + u250 + u251 + u252 + u253 + u254 + u255 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_1672
    buf861 = reader.storage(None, 32768*(((u248 + u249 + u250 + u251 + u252 + u253 + u254 + u255 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf861, (8*(((u248 + u249 + u250 + u251 + u252 + u253 + u254 + u255 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_31
    buf862 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf862, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_47
    buf863 = reader.storage(None, 22528*(((u248 + u249 + u250 + u251 + u252 + u253 + u254 + u255 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf863, (8*(((u248 + u249 + u250 + u251 + u252 + u253 + u254 + u255 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_45
    buf864 = reader.storage(None, 22528*(((u248 + u249 + u250 + u251 + u252 + u253 + u254 + u255 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf864, (8*(((u248 + u249 + u250 + u251 + u252 + u253 + u254 + u255 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_46
    buf865 = reader.storage(None, 22528*(((u248 + u249 + u250 + u251 + u252 + u253 + u254 + u255 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf865, (8*(((u248 + u249 + u250 + u251 + u252 + u253 + u254 + u255 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_770
    buf866 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf866, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_132
    buf867 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf867, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_133
    buf868 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf868, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_790
    buf869 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf869, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1093
    buf870 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf870, (2, 4096, 1), is_leaf=True)  # rsqrt_51
    buf871 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf871, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1108
    buf872 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf872, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1771
    buf873 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf873, (2, 4096, 1), is_leaf=True)  # rsqrt_52
    buf874 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf874, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1122
    buf875 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf875, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_254
    buf876 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf876, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_255
    buf877 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf877, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_256
    buf878 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf878, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1775
    buf879 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf879, (2, 16, 4096), is_leaf=True)  # getitem_1776
    buf880 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf880, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1096
    buf881 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf881, (2, 4096, 1), is_leaf=True)  # rsqrt_53
    buf882 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf882, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1130
    buf883 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf883, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_139
    buf884 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf884, (8192, 1), is_leaf=True)  # amax_16
    buf885 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf885, (8192, 1), is_leaf=True)  # sum_65
    buf886 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf886, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_1779
    buf887 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf887, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_1781
    buf888 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf888, (49152,), dtype=torch.int64, is_leaf=True)  # div_82
    buf889 = reader.storage(None, 32*(((u264 + u265 + u266 + u267 + u268 + u269 + u270 + u271 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf889, (8*(((u264 + u265 + u266 + u267 + u268 + u269 + u270 + u271 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_1782
    buf890 = reader.storage(None, 32768*(((u264 + u265 + u266 + u267 + u268 + u269 + u270 + u271 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf890, (8*(((u264 + u265 + u266 + u267 + u268 + u269 + u270 + u271 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_33
    buf891 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf891, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_50
    buf892 = reader.storage(None, 22528*(((u264 + u265 + u266 + u267 + u268 + u269 + u270 + u271 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf892, (8*(((u264 + u265 + u266 + u267 + u268 + u269 + u270 + u271 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_48
    buf893 = reader.storage(None, 22528*(((u264 + u265 + u266 + u267 + u268 + u269 + u270 + u271 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf893, (8*(((u264 + u265 + u266 + u267 + u268 + u269 + u270 + u271 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_49
    buf894 = reader.storage(None, 22528*(((u264 + u265 + u266 + u267 + u268 + u269 + u270 + u271 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf894, (8*(((u264 + u265 + u266 + u267 + u268 + u269 + u270 + u271 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_819
    buf895 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf895, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_140
    buf896 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf896, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_141
    buf897 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf897, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_839
    buf898 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf898, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1161
    buf899 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf899, (2, 4096, 1), is_leaf=True)  # rsqrt_54
    buf900 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf900, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1175
    buf901 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf901, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1881
    buf902 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf902, (2, 4096, 1), is_leaf=True)  # rsqrt_55
    buf903 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf903, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1189
    buf904 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf904, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_269
    buf905 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf905, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_270
    buf906 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf906, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_271
    buf907 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf907, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1885
    buf908 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf908, (2, 16, 4096), is_leaf=True)  # getitem_1886
    buf909 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf909, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1164
    buf910 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf910, (2, 4096, 1), is_leaf=True)  # rsqrt_56
    buf911 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf911, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1197
    buf912 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf912, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_147
    buf913 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf913, (8192, 1), is_leaf=True)  # amax_17
    buf914 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf914, (8192, 1), is_leaf=True)  # sum_69
    buf915 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf915, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_1889
    buf916 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf916, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_1891
    buf917 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf917, (49152,), dtype=torch.int64, is_leaf=True)  # div_87
    buf918 = reader.storage(None, 32*(((u280 + u281 + u282 + u283 + u284 + u285 + u286 + u287 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf918, (8*(((u280 + u281 + u282 + u283 + u284 + u285 + u286 + u287 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_1892
    buf919 = reader.storage(None, 32768*(((u280 + u281 + u282 + u283 + u284 + u285 + u286 + u287 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf919, (8*(((u280 + u281 + u282 + u283 + u284 + u285 + u286 + u287 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_35
    buf920 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf920, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_53
    buf921 = reader.storage(None, 22528*(((u280 + u281 + u282 + u283 + u284 + u285 + u286 + u287 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf921, (8*(((u280 + u281 + u282 + u283 + u284 + u285 + u286 + u287 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_51
    buf922 = reader.storage(None, 22528*(((u280 + u281 + u282 + u283 + u284 + u285 + u286 + u287 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf922, (8*(((u280 + u281 + u282 + u283 + u284 + u285 + u286 + u287 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_52
    buf923 = reader.storage(None, 22528*(((u280 + u281 + u282 + u283 + u284 + u285 + u286 + u287 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf923, (8*(((u280 + u281 + u282 + u283 + u284 + u285 + u286 + u287 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_868
    buf924 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf924, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_148
    buf925 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf925, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_149
    buf926 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf926, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_888
    buf927 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf927, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1229
    buf928 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf928, (2, 4096, 1), is_leaf=True)  # rsqrt_57
    buf929 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf929, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1242
    buf930 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf930, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1991
    buf931 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf931, (2, 4096, 1), is_leaf=True)  # rsqrt_58
    buf932 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf932, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1256
    buf933 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf933, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_284
    buf934 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf934, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_285
    buf935 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf935, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_286
    buf936 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf936, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_1995
    buf937 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf937, (2, 16, 4096), is_leaf=True)  # getitem_1996
    buf938 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf938, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1232
    buf939 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf939, (2, 4096, 1), is_leaf=True)  # rsqrt_59
    buf940 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf940, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1264
    buf941 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf941, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_155
    buf942 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf942, (8192, 1), is_leaf=True)  # amax_18
    buf943 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf943, (8192, 1), is_leaf=True)  # sum_73
    buf944 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf944, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_1999
    buf945 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf945, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_2001
    buf946 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf946, (49152,), dtype=torch.int64, is_leaf=True)  # div_92
    buf947 = reader.storage(None, 32*(((u296 + u297 + u298 + u299 + u300 + u301 + u302 + u303 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf947, (8*(((u296 + u297 + u298 + u299 + u300 + u301 + u302 + u303 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_2002
    buf948 = reader.storage(None, 32768*(((u296 + u297 + u298 + u299 + u300 + u301 + u302 + u303 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf948, (8*(((u296 + u297 + u298 + u299 + u300 + u301 + u302 + u303 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_37
    buf949 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf949, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_56
    buf950 = reader.storage(None, 22528*(((u296 + u297 + u298 + u299 + u300 + u301 + u302 + u303 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf950, (8*(((u296 + u297 + u298 + u299 + u300 + u301 + u302 + u303 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_54
    buf951 = reader.storage(None, 22528*(((u296 + u297 + u298 + u299 + u300 + u301 + u302 + u303 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf951, (8*(((u296 + u297 + u298 + u299 + u300 + u301 + u302 + u303 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_55
    buf952 = reader.storage(None, 22528*(((u296 + u297 + u298 + u299 + u300 + u301 + u302 + u303 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf952, (8*(((u296 + u297 + u298 + u299 + u300 + u301 + u302 + u303 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_917
    buf953 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf953, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_156
    buf954 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf954, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_157
    buf955 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf955, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_937
    buf956 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf956, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1297
    buf957 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf957, (2, 4096, 1), is_leaf=True)  # rsqrt_60
    buf958 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf958, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1309
    buf959 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf959, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2101
    buf960 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf960, (2, 4096, 1), is_leaf=True)  # rsqrt_61
    buf961 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf961, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1323
    buf962 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf962, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_299
    buf963 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf963, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_300
    buf964 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf964, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_301
    buf965 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf965, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2105
    buf966 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf966, (2, 16, 4096), is_leaf=True)  # getitem_2106
    buf967 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf967, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1300
    buf968 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf968, (2, 4096, 1), is_leaf=True)  # rsqrt_62
    buf969 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf969, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1331
    buf970 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf970, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_163
    buf971 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf971, (8192, 1), is_leaf=True)  # amax_19
    buf972 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf972, (8192, 1), is_leaf=True)  # sum_77
    buf973 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf973, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_2109
    buf974 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf974, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_2111
    buf975 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf975, (49152,), dtype=torch.int64, is_leaf=True)  # div_97
    buf976 = reader.storage(None, 32*(((u312 + u313 + u314 + u315 + u316 + u317 + u318 + u319 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf976, (8*(((u312 + u313 + u314 + u315 + u316 + u317 + u318 + u319 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_2112
    buf977 = reader.storage(None, 32768*(((u312 + u313 + u314 + u315 + u316 + u317 + u318 + u319 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf977, (8*(((u312 + u313 + u314 + u315 + u316 + u317 + u318 + u319 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_39
    buf978 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf978, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_59
    buf979 = reader.storage(None, 22528*(((u312 + u313 + u314 + u315 + u316 + u317 + u318 + u319 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf979, (8*(((u312 + u313 + u314 + u315 + u316 + u317 + u318 + u319 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_57
    buf980 = reader.storage(None, 22528*(((u312 + u313 + u314 + u315 + u316 + u317 + u318 + u319 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf980, (8*(((u312 + u313 + u314 + u315 + u316 + u317 + u318 + u319 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_58
    buf981 = reader.storage(None, 22528*(((u312 + u313 + u314 + u315 + u316 + u317 + u318 + u319 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf981, (8*(((u312 + u313 + u314 + u315 + u316 + u317 + u318 + u319 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_966
    buf982 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf982, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_164
    buf983 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf983, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_165
    buf984 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf984, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_986
    buf985 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf985, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1365
    buf986 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf986, (2, 4096, 1), is_leaf=True)  # rsqrt_63
    buf987 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf987, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1376
    buf988 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf988, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2211
    buf989 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf989, (2, 4096, 1), is_leaf=True)  # rsqrt_64
    buf990 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf990, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1390
    buf991 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf991, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_314
    buf992 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf992, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_315
    buf993 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf993, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_316
    buf994 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf994, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2215
    buf995 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf995, (2, 16, 4096), is_leaf=True)  # getitem_2216
    buf996 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf996, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1368
    buf997 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf997, (2, 4096, 1), is_leaf=True)  # rsqrt_65
    buf998 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf998, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1398
    buf999 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf999, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_171
    buf1000 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1000, (8192, 1), is_leaf=True)  # amax_20
    buf1001 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1001, (8192, 1), is_leaf=True)  # sum_81
    buf1002 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1002, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_2219
    buf1003 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1003, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_2221
    buf1004 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1004, (49152,), dtype=torch.int64, is_leaf=True)  # div_102
    buf1005 = reader.storage(None, 32*(((u328 + u329 + u330 + u331 + u332 + u333 + u334 + u335 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1005, (8*(((u328 + u329 + u330 + u331 + u332 + u333 + u334 + u335 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_2222
    buf1006 = reader.storage(None, 32768*(((u328 + u329 + u330 + u331 + u332 + u333 + u334 + u335 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1006, (8*(((u328 + u329 + u330 + u331 + u332 + u333 + u334 + u335 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_41
    buf1007 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1007, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_62
    buf1008 = reader.storage(None, 22528*(((u328 + u329 + u330 + u331 + u332 + u333 + u334 + u335 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1008, (8*(((u328 + u329 + u330 + u331 + u332 + u333 + u334 + u335 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_60
    buf1009 = reader.storage(None, 22528*(((u328 + u329 + u330 + u331 + u332 + u333 + u334 + u335 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1009, (8*(((u328 + u329 + u330 + u331 + u332 + u333 + u334 + u335 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_61
    buf1010 = reader.storage(None, 22528*(((u328 + u329 + u330 + u331 + u332 + u333 + u334 + u335 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1010, (8*(((u328 + u329 + u330 + u331 + u332 + u333 + u334 + u335 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_1015
    buf1011 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1011, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_172
    buf1012 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1012, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_173
    buf1013 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1013, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_1035
    buf1014 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1014, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1433
    buf1015 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1015, (2, 4096, 1), is_leaf=True)  # rsqrt_66
    buf1016 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1016, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1443
    buf1017 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1017, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2321
    buf1018 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1018, (2, 4096, 1), is_leaf=True)  # rsqrt_67
    buf1019 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1019, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1457
    buf1020 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1020, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_329
    buf1021 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1021, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_330
    buf1022 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1022, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_331
    buf1023 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1023, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2325
    buf1024 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf1024, (2, 16, 4096), is_leaf=True)  # getitem_2326
    buf1025 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1025, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1436
    buf1026 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1026, (2, 4096, 1), is_leaf=True)  # rsqrt_68
    buf1027 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1027, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1465
    buf1028 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1028, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_179
    buf1029 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1029, (8192, 1), is_leaf=True)  # amax_21
    buf1030 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1030, (8192, 1), is_leaf=True)  # sum_85
    buf1031 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1031, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_2329
    buf1032 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1032, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_2331
    buf1033 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1033, (49152,), dtype=torch.int64, is_leaf=True)  # div_107
    buf1034 = reader.storage(None, 32*(((u344 + u345 + u346 + u347 + u348 + u349 + u350 + u351 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1034, (8*(((u344 + u345 + u346 + u347 + u348 + u349 + u350 + u351 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_2332
    buf1035 = reader.storage(None, 32768*(((u344 + u345 + u346 + u347 + u348 + u349 + u350 + u351 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1035, (8*(((u344 + u345 + u346 + u347 + u348 + u349 + u350 + u351 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_43
    buf1036 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1036, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_65
    buf1037 = reader.storage(None, 22528*(((u344 + u345 + u346 + u347 + u348 + u349 + u350 + u351 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1037, (8*(((u344 + u345 + u346 + u347 + u348 + u349 + u350 + u351 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_63
    buf1038 = reader.storage(None, 22528*(((u344 + u345 + u346 + u347 + u348 + u349 + u350 + u351 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1038, (8*(((u344 + u345 + u346 + u347 + u348 + u349 + u350 + u351 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_64
    buf1039 = reader.storage(None, 22528*(((u344 + u345 + u346 + u347 + u348 + u349 + u350 + u351 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1039, (8*(((u344 + u345 + u346 + u347 + u348 + u349 + u350 + u351 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_1064
    buf1040 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1040, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_180
    buf1041 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1041, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_181
    buf1042 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1042, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_1084
    buf1043 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1043, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1501
    buf1044 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1044, (2, 4096, 1), is_leaf=True)  # rsqrt_69
    buf1045 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1045, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1510
    buf1046 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1046, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2431
    buf1047 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1047, (2, 4096, 1), is_leaf=True)  # rsqrt_70
    buf1048 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1048, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1524
    buf1049 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1049, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_344
    buf1050 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1050, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_345
    buf1051 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1051, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_346
    buf1052 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1052, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2435
    buf1053 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf1053, (2, 16, 4096), is_leaf=True)  # getitem_2436
    buf1054 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1054, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1504
    buf1055 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1055, (2, 4096, 1), is_leaf=True)  # rsqrt_71
    buf1056 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1056, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1532
    buf1057 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1057, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_187
    buf1058 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1058, (8192, 1), is_leaf=True)  # amax_22
    buf1059 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1059, (8192, 1), is_leaf=True)  # sum_89
    buf1060 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1060, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_2439
    buf1061 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1061, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_2441
    buf1062 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1062, (49152,), dtype=torch.int64, is_leaf=True)  # div_112
    buf1063 = reader.storage(None, 32*(((u360 + u361 + u362 + u363 + u364 + u365 + u366 + u367 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1063, (8*(((u360 + u361 + u362 + u363 + u364 + u365 + u366 + u367 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_2442
    buf1064 = reader.storage(None, 32768*(((u360 + u361 + u362 + u363 + u364 + u365 + u366 + u367 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1064, (8*(((u360 + u361 + u362 + u363 + u364 + u365 + u366 + u367 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_45
    buf1065 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1065, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_68
    buf1066 = reader.storage(None, 22528*(((u360 + u361 + u362 + u363 + u364 + u365 + u366 + u367 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1066, (8*(((u360 + u361 + u362 + u363 + u364 + u365 + u366 + u367 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_66
    buf1067 = reader.storage(None, 22528*(((u360 + u361 + u362 + u363 + u364 + u365 + u366 + u367 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1067, (8*(((u360 + u361 + u362 + u363 + u364 + u365 + u366 + u367 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_67
    buf1068 = reader.storage(None, 22528*(((u360 + u361 + u362 + u363 + u364 + u365 + u366 + u367 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1068, (8*(((u360 + u361 + u362 + u363 + u364 + u365 + u366 + u367 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_1113
    buf1069 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1069, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_188
    buf1070 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1070, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_189
    buf1071 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1071, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_1133
    buf1072 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1072, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1569
    buf1073 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1073, (2, 4096, 1), is_leaf=True)  # rsqrt_72
    buf1074 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1074, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1577
    buf1075 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1075, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2541
    buf1076 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1076, (2, 4096, 1), is_leaf=True)  # rsqrt_73
    buf1077 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1077, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1591
    buf1078 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1078, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_359
    buf1079 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1079, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_360
    buf1080 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1080, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_361
    buf1081 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1081, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2545
    buf1082 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf1082, (2, 16, 4096), is_leaf=True)  # getitem_2546
    buf1083 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1083, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1572
    buf1084 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1084, (2, 4096, 1), is_leaf=True)  # rsqrt_74
    buf1085 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1085, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1599
    buf1086 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1086, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_195
    buf1087 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1087, (8192, 1), is_leaf=True)  # amax_23
    buf1088 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1088, (8192, 1), is_leaf=True)  # sum_93
    buf1089 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1089, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_2549
    buf1090 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1090, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_2551
    buf1091 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1091, (49152,), dtype=torch.int64, is_leaf=True)  # div_117
    buf1092 = reader.storage(None, 32*(((u376 + u377 + u378 + u379 + u380 + u381 + u382 + u383 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1092, (8*(((u376 + u377 + u378 + u379 + u380 + u381 + u382 + u383 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_2552
    buf1093 = reader.storage(None, 32768*(((u376 + u377 + u378 + u379 + u380 + u381 + u382 + u383 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1093, (8*(((u376 + u377 + u378 + u379 + u380 + u381 + u382 + u383 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_47
    buf1094 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1094, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_71
    buf1095 = reader.storage(None, 22528*(((u376 + u377 + u378 + u379 + u380 + u381 + u382 + u383 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1095, (8*(((u376 + u377 + u378 + u379 + u380 + u381 + u382 + u383 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_69
    buf1096 = reader.storage(None, 22528*(((u376 + u377 + u378 + u379 + u380 + u381 + u382 + u383 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1096, (8*(((u376 + u377 + u378 + u379 + u380 + u381 + u382 + u383 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_70
    buf1097 = reader.storage(None, 22528*(((u376 + u377 + u378 + u379 + u380 + u381 + u382 + u383 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1097, (8*(((u376 + u377 + u378 + u379 + u380 + u381 + u382 + u383 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_1162
    buf1098 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1098, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_196
    buf1099 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1099, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_197
    buf1100 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1100, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_1182
    buf1101 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1101, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1637
    buf1102 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1102, (2, 4096, 1), is_leaf=True)  # rsqrt_75
    buf1103 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1103, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1644
    buf1104 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1104, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2651
    buf1105 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1105, (2, 4096, 1), is_leaf=True)  # rsqrt_76
    buf1106 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1106, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1658
    buf1107 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1107, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_374
    buf1108 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1108, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_375
    buf1109 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1109, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_376
    buf1110 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1110, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2655
    buf1111 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf1111, (2, 16, 4096), is_leaf=True)  # getitem_2656
    buf1112 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1112, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1640
    buf1113 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1113, (2, 4096, 1), is_leaf=True)  # rsqrt_77
    buf1114 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1114, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1666
    buf1115 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1115, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_203
    buf1116 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1116, (8192, 1), is_leaf=True)  # amax_24
    buf1117 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1117, (8192, 1), is_leaf=True)  # sum_97
    buf1118 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1118, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_2659
    buf1119 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1119, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_2661
    buf1120 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1120, (49152,), dtype=torch.int64, is_leaf=True)  # div_122
    buf1121 = reader.storage(None, 32*(((u392 + u393 + u394 + u395 + u396 + u397 + u398 + u399 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1121, (8*(((u392 + u393 + u394 + u395 + u396 + u397 + u398 + u399 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_2662
    buf1122 = reader.storage(None, 32768*(((u392 + u393 + u394 + u395 + u396 + u397 + u398 + u399 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1122, (8*(((u392 + u393 + u394 + u395 + u396 + u397 + u398 + u399 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_49
    buf1123 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1123, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_74
    buf1124 = reader.storage(None, 22528*(((u392 + u393 + u394 + u395 + u396 + u397 + u398 + u399 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1124, (8*(((u392 + u393 + u394 + u395 + u396 + u397 + u398 + u399 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_72
    buf1125 = reader.storage(None, 22528*(((u392 + u393 + u394 + u395 + u396 + u397 + u398 + u399 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1125, (8*(((u392 + u393 + u394 + u395 + u396 + u397 + u398 + u399 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_73
    buf1126 = reader.storage(None, 22528*(((u392 + u393 + u394 + u395 + u396 + u397 + u398 + u399 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1126, (8*(((u392 + u393 + u394 + u395 + u396 + u397 + u398 + u399 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_1211
    buf1127 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1127, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_204
    buf1128 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1128, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_205
    buf1129 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1129, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_1231
    buf1130 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1130, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1705
    buf1131 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1131, (2, 4096, 1), is_leaf=True)  # rsqrt_78
    buf1132 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1132, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1711
    buf1133 = reader.storage(None, 9437184, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1133, (2, 4096, 512), (2359296, 576, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2761
    buf1134 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1134, (2, 4096, 1), is_leaf=True)  # rsqrt_79
    buf1135 = reader.storage(None, 8388608, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1135, (8192, 512), dtype=torch.bfloat16, is_leaf=True)  # view_1725
    buf1136 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1136, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_389
    buf1137 = reader.storage(None, 50331648, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1137, (2, 16, 4096, 192), (12582912, 192, 3072, 1), dtype=torch.bfloat16, is_leaf=True)  # permute_390
    buf1138 = reader.storage(None, 67108864, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1138, (2, 16, 4096, 128), (16777216, 256, 4096, 1), dtype=torch.bfloat16, storage_offset=128, is_leaf=True)  # permute_391
    buf1139 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1139, (2, 16, 4096, 128), (8388608, 128, 2048, 1), dtype=torch.bfloat16, is_leaf=True)  # getitem_2765
    buf1140 = reader.storage(None, 524288, device=device(type='cuda', index=0))
    reader.tensor(buf1140, (2, 16, 4096), is_leaf=True)  # getitem_2766
    buf1141 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1141, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1708
    buf1142 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1142, (2, 4096, 1), is_leaf=True)  # rsqrt_80
    buf1143 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1143, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1733
    buf1144 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1144, (8192, 64), dtype=torch.bfloat16, is_leaf=True)  # mm_211
    buf1145 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1145, (8192, 1), is_leaf=True)  # amax_25
    buf1146 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1146, (8192, 1), is_leaf=True)  # sum_101
    buf1147 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1147, (8192, 6), dtype=torch.int64, is_leaf=True)  # getitem_2769
    buf1148 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1148, (49152,), dtype=torch.int64, is_leaf=True)  # getitem_2771
    buf1149 = reader.storage(None, 393216, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1149, (49152,), dtype=torch.int64, is_leaf=True)  # div_127
    buf1150 = reader.storage(None, 32*(((u408 + u409 + u410 + u411 + u412 + u413 + u414 + u415 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1150, (8*(((u408 + u409 + u410 + u411 + u412 + u413 + u414 + u415 + 71)//8)),), dtype=torch.int32, is_leaf=True)  # getitem_2772
    buf1151 = reader.storage(None, 32768*(((u408 + u409 + u410 + u411 + u412 + u413 + u414 + u415 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1151, (8*(((u408 + u409 + u410 + u411 + u412 + u413 + u414 + u415 + 71)//8)), 2048), dtype=torch.bfloat16, is_leaf=True)  # index_51
    buf1152 = reader.storage(None, 32, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf1152, (8,), dtype=torch.int32, is_leaf=True)  # cumsum_77
    buf1153 = reader.storage(None, 22528*(((u408 + u409 + u410 + u411 + u412 + u413 + u414 + u415 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1153, (8*(((u408 + u409 + u410 + u411 + u412 + u413 + u414 + u415 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_75
    buf1154 = reader.storage(None, 22528*(((u408 + u409 + u410 + u411 + u412 + u413 + u414 + u415 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1154, (8*(((u408 + u409 + u410 + u411 + u412 + u413 + u414 + u415 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # _grouped_mm_76
    buf1155 = reader.storage(None, 22528*(((u408 + u409 + u410 + u411 + u412 + u413 + u414 + u415 + 71)//8)), device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1155, (8*(((u408 + u409 + u410 + u411 + u412 + u413 + u414 + u415 + 71)//8)), 1408), dtype=torch.bfloat16, is_leaf=True)  # mul_1260
    buf1156 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1156, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_212
    buf1157 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1157, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mm_213
    buf1158 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1158, (8192, 2816), dtype=torch.bfloat16, is_leaf=True)  # mul_1280
    buf1159 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1159, (2, 4096, 2048), dtype=torch.bfloat16, is_leaf=True)  # add_1773
    buf1160 = reader.storage(None, 32768, device=device(type='cuda', index=0))
    reader.tensor(buf1160, (2, 4096, 1), is_leaf=True)  # rsqrt_81
    buf1161 = reader.storage(None, 33554432, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1161, (8192, 2048), dtype=torch.bfloat16, is_leaf=True)  # view_1778
    buf1162 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1162, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_406
    buf1163 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1163, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_407
    buf1164 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1164, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_422
    buf1165 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1165, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_426
    buf1166 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1166, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_430
    buf1167 = reader.storage(None, 0, device=device(type='cuda', index=0))
    reader.tensor(buf1167, (0, 2048), is_leaf=True)  # full_default_54
    buf1168 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1168, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_456
    buf1169 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1169, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_457
    buf1170 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1170, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_472
    buf1171 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1171, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_476
    buf1172 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1172, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_480
    buf1173 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1173, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_506
    buf1174 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1174, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_507
    buf1175 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1175, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_522
    buf1176 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1176, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_526
    buf1177 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1177, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_530
    buf1178 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1178, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_556
    buf1179 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1179, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_557
    buf1180 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1180, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_572
    buf1181 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1181, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_576
    buf1182 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1182, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_580
    buf1183 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1183, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_606
    buf1184 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1184, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_607
    buf1185 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1185, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_622
    buf1186 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1186, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_626
    buf1187 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1187, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_630
    buf1188 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1188, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_656
    buf1189 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1189, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_657
    buf1190 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1190, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_672
    buf1191 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1191, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_676
    buf1192 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1192, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_680
    buf1193 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1193, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_706
    buf1194 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1194, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_707
    buf1195 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1195, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_722
    buf1196 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1196, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_726
    buf1197 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1197, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_730
    buf1198 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1198, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_756
    buf1199 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1199, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_757
    buf1200 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1200, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_772
    buf1201 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1201, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_776
    buf1202 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1202, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_780
    buf1203 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1203, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_806
    buf1204 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1204, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_807
    buf1205 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1205, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_822
    buf1206 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1206, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_826
    buf1207 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1207, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_830
    buf1208 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1208, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_856
    buf1209 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1209, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_857
    buf1210 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1210, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_872
    buf1211 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1211, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_876
    buf1212 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1212, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_880
    buf1213 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1213, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_906
    buf1214 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1214, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_907
    buf1215 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1215, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_922
    buf1216 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1216, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_926
    buf1217 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1217, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_930
    buf1218 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1218, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_956
    buf1219 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1219, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_957
    buf1220 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1220, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_972
    buf1221 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1221, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_976
    buf1222 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1222, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_980
    buf1223 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1223, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1006
    buf1224 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1224, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1007
    buf1225 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1225, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1022
    buf1226 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1226, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1026
    buf1227 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1227, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1030
    buf1228 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1228, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1056
    buf1229 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1229, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1057
    buf1230 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1230, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1072
    buf1231 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1231, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1076
    buf1232 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1232, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1080
    buf1233 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1233, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1106
    buf1234 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1234, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1107
    buf1235 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1235, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1122
    buf1236 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1236, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1126
    buf1237 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1237, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1130
    buf1238 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1238, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1156
    buf1239 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1239, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1157
    buf1240 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1240, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1172
    buf1241 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1241, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1176
    buf1242 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1242, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1180
    buf1243 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1243, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1206
    buf1244 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1244, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1207
    buf1245 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1245, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1222
    buf1246 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1246, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1226
    buf1247 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1247, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1230
    buf1248 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1248, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1256
    buf1249 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1249, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1257
    buf1250 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1250, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1272
    buf1251 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1251, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1276
    buf1252 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1252, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1280
    buf1253 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1253, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1306
    buf1254 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1254, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1307
    buf1255 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1255, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1322
    buf1256 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1256, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1326
    buf1257 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1257, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1330
    buf1258 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1258, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1356
    buf1259 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1259, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1357
    buf1260 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1260, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1372
    buf1261 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1261, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1376
    buf1262 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1262, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1380
    buf1263 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1263, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1406
    buf1264 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1264, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1407
    buf1265 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1265, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1422
    buf1266 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1266, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1426
    buf1267 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1267, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1430
    buf1268 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1268, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1456
    buf1269 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1269, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1457
    buf1270 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1270, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1472
    buf1271 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1271, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1476
    buf1272 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1272, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1480
    buf1273 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1273, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1506
    buf1274 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1274, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1507
    buf1275 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1275, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1522
    buf1276 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1276, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1526
    buf1277 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1277, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1530
    buf1278 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1278, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1556
    buf1279 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1279, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1557
    buf1280 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1280, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1572
    buf1281 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1281, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1576
    buf1282 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1282, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1580
    buf1283 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1283, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1606
    buf1284 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1284, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1607
    buf1285 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1285, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1622
    buf1286 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1286, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1626
    buf1287 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1287, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1630
    buf1288 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf1288, (8192, 6, 1), (6, 1, 6), is_leaf=True)  # permute_1656
    buf1289 = reader.storage(None, 402653184, device=device(type='cuda', index=0))
    reader.tensor(buf1289, (8192, 2048, 6), (12288, 1, 2048), is_leaf=True)  # permute_1657
    buf1290 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1290, (8, 2048, 1408), dtype=torch.bfloat16, is_leaf=True)  # permute_1672
    buf1291 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1291, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1676
    buf1292 = reader.storage(None, 46137344, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1292, (8, 1408, 2048), dtype=torch.bfloat16, is_leaf=True)  # permute_1680
    buf1293 = reader.storage(None, 1677721600, device=device(type='cuda', index=0), dtype_hint=torch.bfloat16)
    reader.tensor(buf1293, (2, 4096, 102400), dtype=torch.bfloat16, is_leaf=True)  # tangents_1
load_args._version = 0
mod = Repro()
if __name__ == '__main__':
    from torch._dynamo.repro.after_aot import run_repro
    from torch._dynamo.repro.after_aot import setup_fake_process_groups
    setup_fake_process_groups({'0': {'size': 128, 'rank': 0}, '1033': {'size': 8, 'rank': 0}, '1025': {'size': 16, 'rank': 0}})
    with torch.no_grad():
        run_repro(mod, load_args, accuracy=False, command='run', save_dir=None, tracing_mode='symbolic', check_str=None)
        # To run it separately, do 
        # mod, args = run_repro(mod, load_args, accuracy=False, command='get_args', save_dir=None, tracing_mode='symbolic', check_str=None)
        # mod(*args)
    dist.destroy_process_group()

# Helper functions for overlap simulator
def get_pg_config():
    """DSv3 128 GPUs: FSDP=128, TP=1, EP=8."""
    return {'0': {'size': 128, 'rank': 0}, '1025': {'size': 16, 'rank': 0}, '1033': {'size': 8, 'rank': 0}}

def get_colls_estimations_file():
    return "colls16_8.table"

def get_colls_group_mapping():
    # FSDP "0"  internode (table group "0"), all other groups  intranode (table group "1")
    return {'0': '0', '1025': '1', '1033': '1'}
