
import os
os.environ['PYTORCH_KERNEL_CACHE_PATH'] = '/mnt/mffuse/.cache/torch/kernels'
os.environ['TORCH_DISABLE_ADDR2LINE'] = '1'
os.environ['TORCH_TRACE'] = '/mnt/mffuse/outputs/sfsdp-dsv3-16b--tp1-bs2-inductor-128-ivankobzarev-hkpmbjc3/torch_trace/'
os.environ['PYTORCH_CUDA_ALLOC_CONF'] = 'expandable_segments:True'
os.environ['TORCHELASTIC_LOG_LINE_PREFIX_TEMPLATE'] = '[${role_name}${rank}|${local_rank}]:'
os.environ['TORCHELASTIC_MAX_RESTARTS'] = '0'
os.environ['TORCHX_INTERNAL_SESSION_ID'] = '03a200cc-023c-47d4-8372-8d223aedc5c2'
os.environ['TORCHX_RUN_PYTHONPATH'] = ''
os.environ['TORCHELASTIC_ERROR_FILE'] = '/tmp/torchelastic_i226b1gg/sfsdp-dsv3-16b--tp1-bs2-inductor-128-ivankobzarev-hkpmbjc3_ukylfuu9/attempt_0/0/error.json'
os.environ['TORCH_ADDR2LINE_BINARY'] = '/packages/folly.symbolizer/folly-addr2line'
os.environ['TORCHX_JOB_ID'] = 'mast_conda://torchx/sfsdp-dsv3-16b--tp1-bs2-inductor-128-ivankobzarev-hkpmbjc3'
os.environ['TORCH_NCCL_ASYNC_ERROR_HANDLING'] = '3'
os.environ['TORCHELASTIC_SIGNALS_TO_HANDLE'] = 'SIGTERM,SIGINT,SIGHUP,SIGQUIT'
os.environ['TORCHELASTIC_RUN_ID'] = 'sfsdp-dsv3-16b--tp1-bs2-inductor-128-ivankobzarev-hkpmbjc3'
os.environ['TORCH_SHOW_CPP_STACKTRACES'] = '1'
os.environ['TORCHELASTIC_RESTART_COUNT'] = '0'
os.environ['TORCHELASTIC_USE_AGENT_STORE'] = 'False'
os.environ['PYTORCH_DDP_USE_SIDE_STREAM'] = '0'
os.environ['TORCHINDUCTOR_CACHE_DIR'] = '/tmp/torchinductor_root'
os.environ['TORCH_FR_BUFFER_SIZE'] = '20000'
os.environ['TORCH_NCCL_DUMP_ON_TIMEOUT'] = '1'
os.environ['TORCH_FR_DUMP_TEMP_FILE'] = '/mnt/mffuse_nccl_trace/nccl_trace/sfsdp-dsv3-16b--tp1-bs2-inductor-128-ivankobzarev-hkpmbjc3/v_0/attempt_0/nccl_trace_rank_'
os.environ['TRITON_CACHE_DIR'] = '/tmp/torchinductor_root/triton/0'

import torch
from torch import tensor, device
import torch.fx as fx
from torch._dynamo.testing import rand_strided
from math import inf
import torch._inductor.inductor_prims
import torch.distributed as dist
from torch.testing._internal.distributed.fake_pg import FakeStore
import triton
import triton.language as tl

import torch._dynamo.config
import torch._inductor.config
import torch._functorch.config
import torch.fx.experimental._config
torch._dynamo.config.capture_scalar_outputs = True
torch._inductor.config.allow_buffer_reuse = False
torch._inductor.config.reorder_for_compute_comm_overlap = False
torch._inductor.config.reorder_for_peak_memory = False
torch._inductor.config.max_autotune = False
torch._inductor.config.coordinate_descent_tuning = False
torch._inductor.config.deterministic = False
torch._inductor.config.aten_distributed_optimizations.collective_bucketing = True
torch._inductor.config.aten_distributed_optimizations.insert_overlap_deps = True
torch._inductor.config.wrap_inductor_compiled_regions = False
torch._inductor.config.triton.cudagraphs = False
torch._inductor.config.triton.store_cubin = False
torch._inductor.config.test_configs.runtime_triton_dtype_assert = False
torch._functorch.config.functionalize_rng_ops = False
torch._functorch.config.fake_tensor_allow_unsafe_data_ptr_access = True
torch._functorch.config.unlift_effect_tokens = True
torch._functorch.config.selective_decompose = False



isolate_fails_code_str = None





if "__compile_source__" in globals():
    import inspect as __after_aot_inspect
    import linecache as __after_aot_linecache
    __after_aot_filename = __after_aot_inspect.currentframe().f_code.co_filename
    __after_aot_linecache.cache[__after_aot_filename] = (
        len(__compile_source__),
        None,
        __compile_source__.splitlines(True),
        __after_aot_filename,
    )
# torch version: 2.11.0a0+git5ac4d4b
# torch cuda version: 12.4
# torch git version: 5ac4d4bf3f85e15fdd6676f46b090568ea91e47e


# CUDA Info: 
# nvcc not found
# GPU Hardware Info: 
# NVIDIA H100 80GB HBM3 : 8 

torch._higher_order_ops.triton_kernel_wrap.kernel_side_table.reset_table()

@triton.jit
def _fill_indices_kernel_0(
    tokens_per_expert_group_ptr,
    start_index_values_ptr,
    write_offsets_ptr,
    output_ptr,
    experts_per_rank: tl.constexpr,
    num_ranks: tl.constexpr,
    BLOCK_SIZE: tl.constexpr,  # Number of threads per block
):
    pid = tl.program_id(axis=0)
    num_programs = tl.num_programs(axis=0)

    # map programs (blocks) to the experts and loop (grid stride) if needed
    for expert_id in range(pid, experts_per_rank, num_programs):
        # read this experts write offset
        write_offset = tl.load(write_offsets_ptr + expert_id)

        for r in range(num_ranks):
            # index into tokens_per_expert_group array
            i = r * experts_per_rank + expert_id

            # load start index and number of tokens for this expert-rank pair
            start_index = tl.load(start_index_values_ptr + i)
            length = tl.load(tokens_per_expert_group_ptr + i)

            # each thread in block processes tokens in parallel
            offsets = tl.arange(0, BLOCK_SIZE)

            # tokens are processed in chunks of BLOCK_SIZE
            for chunk_start in range(0, length, BLOCK_SIZE):
                chunk_offsets = chunk_start + offsets

                # mask valid indices
                mask = chunk_offsets < length

                values = start_index + chunk_offsets

                # destination
                dest_indices = write_offset + chunk_offsets

                # store
                tl.store(output_ptr + dest_indices, values, mask=mask)

            # update write offset for next rank
            write_offset += length

torch._higher_order_ops.triton_kernel_wrap.kernel_side_table.add_kernel(_fill_indices_kernel_0)
torch._higher_order_ops.triton_kernel_wrap.kernel_side_table.constant_args={0: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 1: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 2: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 3: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 4: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 5: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 6: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 7: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 8: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 9: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 10: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 11: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 12: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 13: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 14: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 15: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 16: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 17: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 18: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 19: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 20: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 21: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 22: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 23: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 24: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}, 25: {'experts_per_rank': 8, 'num_ranks': 8, 'BLOCK_SIZE': 128}}

from torch.nn import *
class Repro(torch.nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.sdpa_score0 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask0 = lambda b, h, m, n, *args: True
        self.sdpa_score1 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask1 = lambda b, h, m, n, *args: True
        self.sdpa_score2 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask2 = lambda b, h, m, n, *args: True
        self.sdpa_score3 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask3 = lambda b, h, m, n, *args: True
        self.sdpa_score4 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask4 = lambda b, h, m, n, *args: True
        self.sdpa_score5 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask5 = lambda b, h, m, n, *args: True
        self.sdpa_score6 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask6 = lambda b, h, m, n, *args: True
        self.sdpa_score7 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask7 = lambda b, h, m, n, *args: True
        self.sdpa_score8 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask8 = lambda b, h, m, n, *args: True
        self.sdpa_score9 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask9 = lambda b, h, m, n, *args: True
        self.sdpa_score10 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask10 = lambda b, h, m, n, *args: True
        self.sdpa_score11 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask11 = lambda b, h, m, n, *args: True
        self.sdpa_score12 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask12 = lambda b, h, m, n, *args: True
        self.sdpa_score13 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask13 = lambda b, h, m, n, *args: True
        self.sdpa_score14 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask14 = lambda b, h, m, n, *args: True
        self.sdpa_score15 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask15 = lambda b, h, m, n, *args: True
        self.sdpa_score16 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask16 = lambda b, h, m, n, *args: True
        self.sdpa_score17 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask17 = lambda b, h, m, n, *args: True
        self.sdpa_score18 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask18 = lambda b, h, m, n, *args: True
        self.sdpa_score19 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask19 = lambda b, h, m, n, *args: True
        self.sdpa_score20 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask20 = lambda b, h, m, n, *args: True
        self.sdpa_score21 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask21 = lambda b, h, m, n, *args: True
        self.sdpa_score22 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask22 = lambda b, h, m, n, *args: True
        self.sdpa_score23 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask23 = lambda b, h, m, n, *args: True
        self.sdpa_score24 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask24 = lambda b, h, m, n, *args: True
        self.sdpa_score25 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask25 = lambda b, h, m, n, *args: True
        self.sdpa_score26 = lambda score, b, h, m, n, *args: score
        self.sdpa_mask26 = lambda b, h, m, n, *args: True



    def forward(self, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_30, primals_31, primals_32, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_46, primals_47, primals_48, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_62, primals_63, primals_64, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_78, primals_79, primals_80, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_94, primals_95, primals_96, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_110, primals_111, primals_112, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_126, primals_127, primals_128, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_142, primals_143, primals_144, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_158, primals_159, primals_160, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_174, primals_175, primals_176, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_190, primals_191, primals_192, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_206, primals_207, primals_208, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_222, primals_223, primals_224, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_238, primals_239, primals_240, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_254, primals_255, primals_256, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_270, primals_271, primals_272, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_286, primals_287, primals_288, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_302, primals_303, primals_304, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_318, primals_319, primals_320, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_334, primals_335, primals_336, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_350, primals_351, primals_352, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_366, primals_367, primals_368, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_382, primals_383, primals_384, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_398, primals_399, primals_400, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_414, primals_415, primals_416, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_430, primals_431, primals_432, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440):
        convert_element_type = torch.ops.prims.convert_element_type.default(primals_1, torch.bfloat16)
        all_gather_into_tensor = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type, 128, '0');  convert_element_type = None
        wait_tensor = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor);  all_gather_into_tensor = None
        embedding = torch.ops.aten.embedding.default(wait_tensor, primals_2);  wait_tensor = None
        convert_element_type_1 = torch.ops.prims.convert_element_type.default(primals_4, torch.bfloat16)
        all_gather_into_tensor_1 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1, 128, '0');  convert_element_type_1 = None
        wait_tensor_1 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_1);  all_gather_into_tensor_1 = None
        convert_element_type_2 = torch.ops.prims.convert_element_type.default(embedding, torch.float32)
        pow_1 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_2, 2)
        mean = torch.ops.aten.mean.dim(pow_1, [2], True);  pow_1 = None
        add = torch.ops.aten.add.Scalar(mean, 1e-05);  mean = None
        rsqrt = torch.ops.aten.rsqrt.default(add);  add = None
        mul = torch.ops.aten.mul.Tensor(convert_element_type_2, rsqrt);  convert_element_type_2 = None
        mul_1 = torch.ops.aten.mul.Tensor(mul, wait_tensor_1);  mul = wait_tensor_1 = None
        convert_element_type_3 = torch.ops.prims.convert_element_type.default(mul_1, torch.bfloat16);  mul_1 = None
        convert_element_type_4 = torch.ops.prims.convert_element_type.default(primals_5, torch.bfloat16)
        all_gather_into_tensor_2 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_4, 128, '0');  convert_element_type_4 = None
        wait_tensor_2 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_2);  all_gather_into_tensor_2 = None
        permute = torch.ops.aten.permute.default(wait_tensor_2, [1, 0]);  wait_tensor_2 = None
        view_3 = torch.ops.aten.view.default(convert_element_type_3, [8192, 2048]);  convert_element_type_3 = None
        mm = torch.ops.aten.mm.default(view_3, permute);  permute = None
        view_4 = torch.ops.aten.view.default(mm, [2, 4096, 3072]);  mm = None
        view_5 = torch.ops.aten.view.default(view_4, [2, 4096, -1, 192]);  view_4 = None
        split_with_sizes = torch.ops.aten.split_with_sizes.default(view_5, [128, 64], -1);  view_5 = None
        getitem = split_with_sizes[0]
        getitem_1 = split_with_sizes[1];  split_with_sizes = None
        convert_element_type_7 = torch.ops.prims.convert_element_type.default(getitem_1, torch.float32);  getitem_1 = None
        view_6 = torch.ops.aten.view.default(convert_element_type_7, [2, 4096, 16, -1, 2]);  convert_element_type_7 = None
        view_as_complex = torch.ops.aten.view_as_complex.default(view_6);  view_6 = None
        view_7 = torch.ops.aten.view.default(primals_3, [1, 4096, 1, 32])
        mul_2 = torch.ops.aten.mul.Tensor(view_as_complex, view_7);  view_as_complex = None
        view_as_real = torch.ops.aten.view_as_real.default(mul_2);  mul_2 = None
        view_8 = torch.ops.aten.view.default(view_as_real, [2, 4096, 16, 64]);  view_as_real = None
        convert_element_type_8 = torch.ops.prims.convert_element_type.default(view_8, torch.bfloat16);  view_8 = None
        cat = torch.ops.aten.cat.default([getitem, convert_element_type_8], -1);  getitem = convert_element_type_8 = None
        convert_element_type_9 = torch.ops.prims.convert_element_type.default(primals_6, torch.bfloat16)
        all_gather_into_tensor_3 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_9, 128, '0');  convert_element_type_9 = None
        wait_tensor_3 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_3);  all_gather_into_tensor_3 = None
        slice_2 = torch.ops.aten.slice.Tensor(wait_tensor_3, 0, 0, 576);  wait_tensor_3 = None
        permute_1 = torch.ops.aten.permute.default(slice_2, [1, 0]);  slice_2 = None
        mm_1 = torch.ops.aten.mm.default(view_3, permute_1);  permute_1 = None
        view_11 = torch.ops.aten.view.default(mm_1, [2, 4096, 576]);  mm_1 = None
        split_with_sizes_1 = torch.ops.aten.split_with_sizes.default(view_11, [512, 64], -1);  view_11 = None
        getitem_2 = split_with_sizes_1[0]
        getitem_3 = split_with_sizes_1[1];  split_with_sizes_1 = None
        unsqueeze = torch.ops.aten.unsqueeze.default(getitem_3, 2);  getitem_3 = None
        convert_element_type_12 = torch.ops.prims.convert_element_type.default(unsqueeze, torch.float32);  unsqueeze = None
        view_12 = torch.ops.aten.view.default(convert_element_type_12, [2, 4096, 1, -1, 2]);  convert_element_type_12 = None
        view_as_complex_1 = torch.ops.aten.view_as_complex.default(view_12);  view_12 = None
        mul_3 = torch.ops.aten.mul.Tensor(view_as_complex_1, view_7);  view_as_complex_1 = None
        view_as_real_1 = torch.ops.aten.view_as_real.default(mul_3);  mul_3 = None
        view_14 = torch.ops.aten.view.default(view_as_real_1, [2, 4096, 1, 64]);  view_as_real_1 = None
        convert_element_type_13 = torch.ops.prims.convert_element_type.default(view_14, torch.bfloat16);  view_14 = None
        convert_element_type_14 = torch.ops.prims.convert_element_type.default(primals_7, torch.bfloat16)
        all_gather_into_tensor_4 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_14, 128, '0');  convert_element_type_14 = None
        wait_tensor_4 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_4);  all_gather_into_tensor_4 = None
        convert_element_type_15 = torch.ops.prims.convert_element_type.default(getitem_2, torch.float32)
        pow_2 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_15, 2)
        mean_1 = torch.ops.aten.mean.dim(pow_2, [2], True);  pow_2 = None
        add_1 = torch.ops.aten.add.Scalar(mean_1, 1e-05);  mean_1 = None
        rsqrt_1 = torch.ops.aten.rsqrt.default(add_1);  add_1 = None
        mul_4 = torch.ops.aten.mul.Tensor(convert_element_type_15, rsqrt_1);  convert_element_type_15 = None
        mul_5 = torch.ops.aten.mul.Tensor(mul_4, wait_tensor_4);  mul_4 = wait_tensor_4 = None
        convert_element_type_16 = torch.ops.prims.convert_element_type.default(mul_5, torch.bfloat16);  mul_5 = None
        convert_element_type_17 = torch.ops.prims.convert_element_type.default(primals_8, torch.bfloat16)
        all_gather_into_tensor_5 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_17, 128, '0');  convert_element_type_17 = None
        wait_tensor_5 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_5);  all_gather_into_tensor_5 = None
        permute_2 = torch.ops.aten.permute.default(wait_tensor_5, [1, 0]);  wait_tensor_5 = None
        view_17 = torch.ops.aten.view.default(convert_element_type_16, [8192, 512]);  convert_element_type_16 = None
        mm_2 = torch.ops.aten.mm.default(view_17, permute_2);  permute_2 = None
        view_18 = torch.ops.aten.view.default(mm_2, [2, 4096, 4096]);  mm_2 = None
        view_19 = torch.ops.aten.view.default(view_18, [2, 4096, -1, 256]);  view_18 = None
        split_with_sizes_2 = torch.ops.aten.split_with_sizes.default(view_19, [128, 128], -1);  view_19 = None
        getitem_4 = split_with_sizes_2[0]
        getitem_5 = split_with_sizes_2[1];  split_with_sizes_2 = None
        expand = torch.ops.aten.expand.default(convert_element_type_13, [-1, -1, 16, -1]);  convert_element_type_13 = None
        cat_1 = torch.ops.aten.cat.default([getitem_4, expand], -1);  getitem_4 = expand = None
        permute_3 = torch.ops.aten.permute.default(cat, [0, 2, 1, 3]);  cat = None
        permute_4 = torch.ops.aten.permute.default(cat_1, [0, 2, 1, 3]);  cat_1 = None
        permute_5 = torch.ops.aten.permute.default(getitem_5, [0, 2, 1, 3]);  getitem_5 = None
        sdpa_score0 = self.sdpa_score0
        sdpa_mask0 = self.sdpa_mask0
        flex_attention = torch.ops.higher_order.flex_attention(permute_3, permute_4, permute_5, sdpa_score0, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask0), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score0 = sdpa_mask0 = None
        getitem_6 = flex_attention[0]
        getitem_7 = flex_attention[1];  flex_attention = None
        permute_6 = torch.ops.aten.permute.default(getitem_6, [0, 2, 1, 3])
        view_20 = torch.ops.aten.view.default(permute_6, [2, 4096, -1]);  permute_6 = None
        convert_element_type_20 = torch.ops.prims.convert_element_type.default(primals_18, torch.bfloat16)
        all_gather_into_tensor_6 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_20, 128, '0');  convert_element_type_20 = None
        wait_tensor_6 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_6);  all_gather_into_tensor_6 = None
        permute_7 = torch.ops.aten.permute.default(wait_tensor_6, [1, 0]);  wait_tensor_6 = None
        view_22 = torch.ops.aten.view.default(view_20, [8192, 2048]);  view_20 = None
        mm_3 = torch.ops.aten.mm.default(view_22, permute_7);  view_22 = permute_7 = None
        view_23 = torch.ops.aten.view.default(mm_3, [2, 4096, 2048])
        add_2 = torch.ops.aten.add.Tensor(embedding, view_23);  view_23 = None
        convert_element_type_23 = torch.ops.prims.convert_element_type.default(primals_19, torch.bfloat16)
        all_gather_into_tensor_7 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_23, 128, '0');  convert_element_type_23 = None
        wait_tensor_7 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_7);  all_gather_into_tensor_7 = None
        convert_element_type_24 = torch.ops.prims.convert_element_type.default(add_2, torch.float32)
        pow_3 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_24, 2)
        mean_2 = torch.ops.aten.mean.dim(pow_3, [2], True);  pow_3 = None
        add_3 = torch.ops.aten.add.Scalar(mean_2, 1e-05);  mean_2 = None
        rsqrt_2 = torch.ops.aten.rsqrt.default(add_3);  add_3 = None
        mul_6 = torch.ops.aten.mul.Tensor(convert_element_type_24, rsqrt_2);  convert_element_type_24 = None
        mul_7 = torch.ops.aten.mul.Tensor(mul_6, wait_tensor_7);  mul_6 = wait_tensor_7 = None
        convert_element_type_25 = torch.ops.prims.convert_element_type.default(mul_7, torch.bfloat16);  mul_7 = None
        convert_element_type_26 = torch.ops.prims.convert_element_type.default(primals_20, torch.bfloat16)
        all_gather_into_tensor_8 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_26, 128, '0');  convert_element_type_26 = None
        wait_tensor_8 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_8);  all_gather_into_tensor_8 = None
        slice_4 = torch.ops.aten.slice.Tensor(wait_tensor_8, 0, 0, 10944);  wait_tensor_8 = None
        permute_8 = torch.ops.aten.permute.default(slice_4, [1, 0]);  slice_4 = None
        view_26 = torch.ops.aten.view.default(convert_element_type_25, [8192, 2048]);  convert_element_type_25 = None
        mm_4 = torch.ops.aten.mm.default(view_26, permute_8);  permute_8 = None
        view_27 = torch.ops.aten.view.default(mm_4, [2, 4096, 10944])
        convert_element_type_29 = torch.ops.prims.convert_element_type.default(view_27, torch.float32);  view_27 = None
        neg = torch.ops.aten.neg.default(convert_element_type_29)
        exp = torch.ops.aten.exp.default(neg);  neg = None
        add_4 = torch.ops.aten.add.Tensor(exp, 1);  exp = None
        div = torch.ops.aten.div.Tensor(convert_element_type_29, add_4);  convert_element_type_29 = add_4 = None
        convert_element_type_30 = torch.ops.prims.convert_element_type.default(div, torch.bfloat16);  div = None
        convert_element_type_31 = torch.ops.prims.convert_element_type.default(primals_21, torch.bfloat16)
        all_gather_into_tensor_9 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_31, 128, '0');  convert_element_type_31 = None
        wait_tensor_9 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_9);  all_gather_into_tensor_9 = None
        slice_5 = torch.ops.aten.slice.Tensor(wait_tensor_9, 0, 0, 10944);  wait_tensor_9 = None
        permute_9 = torch.ops.aten.permute.default(slice_5, [1, 0]);  slice_5 = None
        mm_5 = torch.ops.aten.mm.default(view_26, permute_9);  permute_9 = None
        view_30 = torch.ops.aten.view.default(mm_5, [2, 4096, 10944])
        mul_8 = torch.ops.aten.mul.Tensor(convert_element_type_30, view_30);  convert_element_type_30 = view_30 = None
        convert_element_type_34 = torch.ops.prims.convert_element_type.default(primals_22, torch.bfloat16)
        all_gather_into_tensor_10 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_34, 128, '0');  convert_element_type_34 = None
        wait_tensor_10 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_10);  all_gather_into_tensor_10 = None
        permute_10 = torch.ops.aten.permute.default(wait_tensor_10, [1, 0]);  wait_tensor_10 = None
        view_32 = torch.ops.aten.view.default(mul_8, [8192, 10944]);  mul_8 = None
        mm_6 = torch.ops.aten.mm.default(view_32, permute_10);  permute_10 = None
        view_33 = torch.ops.aten.view.default(mm_6, [2, 4096, 2048]);  mm_6 = None
        add_5 = torch.ops.aten.add.Tensor(add_2, view_33);  add_2 = view_33 = None
        convert_element_type_37 = torch.ops.prims.convert_element_type.default(primals_23, torch.bfloat16)
        all_gather_into_tensor_11 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_37, 128, '0');  convert_element_type_37 = None
        wait_tensor_11 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_11);  all_gather_into_tensor_11 = None
        convert_element_type_38 = torch.ops.prims.convert_element_type.default(add_5, torch.float32)
        pow_4 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_38, 2)
        mean_3 = torch.ops.aten.mean.dim(pow_4, [2], True);  pow_4 = None
        add_6 = torch.ops.aten.add.Scalar(mean_3, 1e-05);  mean_3 = None
        rsqrt_3 = torch.ops.aten.rsqrt.default(add_6);  add_6 = None
        mul_9 = torch.ops.aten.mul.Tensor(convert_element_type_38, rsqrt_3);  convert_element_type_38 = None
        mul_10 = torch.ops.aten.mul.Tensor(mul_9, wait_tensor_11);  mul_9 = wait_tensor_11 = None
        convert_element_type_39 = torch.ops.prims.convert_element_type.default(mul_10, torch.bfloat16);  mul_10 = None
        convert_element_type_40 = torch.ops.prims.convert_element_type.default(primals_24, torch.bfloat16)
        all_gather_into_tensor_12 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_40, 128, '0');  convert_element_type_40 = None
        wait_tensor_12 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_12);  all_gather_into_tensor_12 = None
        permute_11 = torch.ops.aten.permute.default(wait_tensor_12, [1, 0]);  wait_tensor_12 = None
        view_36 = torch.ops.aten.view.default(convert_element_type_39, [8192, 2048]);  convert_element_type_39 = None
        mm_7 = torch.ops.aten.mm.default(view_36, permute_11);  permute_11 = None
        view_37 = torch.ops.aten.view.default(mm_7, [2, 4096, 3072]);  mm_7 = None
        view_38 = torch.ops.aten.view.default(view_37, [2, 4096, -1, 192]);  view_37 = None
        split_with_sizes_3 = torch.ops.aten.split_with_sizes.default(view_38, [128, 64], -1);  view_38 = None
        getitem_9 = split_with_sizes_3[0]
        getitem_10 = split_with_sizes_3[1];  split_with_sizes_3 = None
        convert_element_type_43 = torch.ops.prims.convert_element_type.default(getitem_10, torch.float32);  getitem_10 = None
        view_39 = torch.ops.aten.view.default(convert_element_type_43, [2, 4096, 16, -1, 2]);  convert_element_type_43 = None
        view_as_complex_2 = torch.ops.aten.view_as_complex.default(view_39);  view_39 = None
        mul_11 = torch.ops.aten.mul.Tensor(view_as_complex_2, view_7);  view_as_complex_2 = None
        view_as_real_2 = torch.ops.aten.view_as_real.default(mul_11);  mul_11 = None
        view_41 = torch.ops.aten.view.default(view_as_real_2, [2, 4096, 16, 64]);  view_as_real_2 = None
        convert_element_type_44 = torch.ops.prims.convert_element_type.default(view_41, torch.bfloat16);  view_41 = None
        cat_2 = torch.ops.aten.cat.default([getitem_9, convert_element_type_44], -1);  getitem_9 = convert_element_type_44 = None
        convert_element_type_45 = torch.ops.prims.convert_element_type.default(primals_25, torch.bfloat16)
        all_gather_into_tensor_13 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_45, 128, '0');  convert_element_type_45 = None
        wait_tensor_13 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_13);  all_gather_into_tensor_13 = None
        slice_7 = torch.ops.aten.slice.Tensor(wait_tensor_13, 0, 0, 576);  wait_tensor_13 = None
        permute_12 = torch.ops.aten.permute.default(slice_7, [1, 0]);  slice_7 = None
        mm_8 = torch.ops.aten.mm.default(view_36, permute_12);  permute_12 = None
        view_44 = torch.ops.aten.view.default(mm_8, [2, 4096, 576]);  mm_8 = None
        split_with_sizes_4 = torch.ops.aten.split_with_sizes.default(view_44, [512, 64], -1);  view_44 = None
        getitem_11 = split_with_sizes_4[0]
        getitem_12 = split_with_sizes_4[1];  split_with_sizes_4 = None
        unsqueeze_1 = torch.ops.aten.unsqueeze.default(getitem_12, 2);  getitem_12 = None
        convert_element_type_48 = torch.ops.prims.convert_element_type.default(unsqueeze_1, torch.float32);  unsqueeze_1 = None
        view_45 = torch.ops.aten.view.default(convert_element_type_48, [2, 4096, 1, -1, 2]);  convert_element_type_48 = None
        view_as_complex_3 = torch.ops.aten.view_as_complex.default(view_45);  view_45 = None
        mul_12 = torch.ops.aten.mul.Tensor(view_as_complex_3, view_7);  view_as_complex_3 = None
        view_as_real_3 = torch.ops.aten.view_as_real.default(mul_12);  mul_12 = None
        view_47 = torch.ops.aten.view.default(view_as_real_3, [2, 4096, 1, 64]);  view_as_real_3 = None
        convert_element_type_49 = torch.ops.prims.convert_element_type.default(view_47, torch.bfloat16);  view_47 = None
        convert_element_type_50 = torch.ops.prims.convert_element_type.default(primals_26, torch.bfloat16)
        all_gather_into_tensor_14 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_50, 128, '0');  convert_element_type_50 = None
        wait_tensor_14 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_14);  all_gather_into_tensor_14 = None
        convert_element_type_51 = torch.ops.prims.convert_element_type.default(getitem_11, torch.float32)
        pow_5 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_51, 2)
        mean_4 = torch.ops.aten.mean.dim(pow_5, [2], True);  pow_5 = None
        add_7 = torch.ops.aten.add.Scalar(mean_4, 1e-05);  mean_4 = None
        rsqrt_4 = torch.ops.aten.rsqrt.default(add_7);  add_7 = None
        mul_13 = torch.ops.aten.mul.Tensor(convert_element_type_51, rsqrt_4);  convert_element_type_51 = None
        mul_14 = torch.ops.aten.mul.Tensor(mul_13, wait_tensor_14);  mul_13 = wait_tensor_14 = None
        convert_element_type_52 = torch.ops.prims.convert_element_type.default(mul_14, torch.bfloat16);  mul_14 = None
        convert_element_type_53 = torch.ops.prims.convert_element_type.default(primals_27, torch.bfloat16)
        all_gather_into_tensor_15 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_53, 128, '0');  convert_element_type_53 = None
        wait_tensor_15 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_15);  all_gather_into_tensor_15 = None
        permute_13 = torch.ops.aten.permute.default(wait_tensor_15, [1, 0]);  wait_tensor_15 = None
        view_50 = torch.ops.aten.view.default(convert_element_type_52, [8192, 512]);  convert_element_type_52 = None
        mm_9 = torch.ops.aten.mm.default(view_50, permute_13);  permute_13 = None
        view_51 = torch.ops.aten.view.default(mm_9, [2, 4096, 4096]);  mm_9 = None
        view_52 = torch.ops.aten.view.default(view_51, [2, 4096, -1, 256]);  view_51 = None
        split_with_sizes_5 = torch.ops.aten.split_with_sizes.default(view_52, [128, 128], -1);  view_52 = None
        getitem_13 = split_with_sizes_5[0]
        getitem_14 = split_with_sizes_5[1];  split_with_sizes_5 = None
        expand_1 = torch.ops.aten.expand.default(convert_element_type_49, [-1, -1, 16, -1]);  convert_element_type_49 = None
        cat_3 = torch.ops.aten.cat.default([getitem_13, expand_1], -1);  getitem_13 = expand_1 = None
        permute_14 = torch.ops.aten.permute.default(cat_2, [0, 2, 1, 3]);  cat_2 = None
        permute_15 = torch.ops.aten.permute.default(cat_3, [0, 2, 1, 3]);  cat_3 = None
        permute_16 = torch.ops.aten.permute.default(getitem_14, [0, 2, 1, 3]);  getitem_14 = None
        sdpa_score1 = self.sdpa_score1
        sdpa_mask1 = self.sdpa_mask1
        flex_attention_1 = torch.ops.higher_order.flex_attention(permute_14, permute_15, permute_16, sdpa_score1, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask1), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score1 = sdpa_mask1 = None
        getitem_15 = flex_attention_1[0]
        getitem_16 = flex_attention_1[1];  flex_attention_1 = None
        permute_17 = torch.ops.aten.permute.default(getitem_15, [0, 2, 1, 3])
        view_53 = torch.ops.aten.view.default(permute_17, [2, 4096, -1]);  permute_17 = None
        convert_element_type_56 = torch.ops.prims.convert_element_type.default(primals_28, torch.bfloat16)
        all_gather_into_tensor_16 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_56, 128, '0');  convert_element_type_56 = None
        wait_tensor_16 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_16);  all_gather_into_tensor_16 = None
        permute_18 = torch.ops.aten.permute.default(wait_tensor_16, [1, 0]);  wait_tensor_16 = None
        view_55 = torch.ops.aten.view.default(view_53, [8192, 2048]);  view_53 = None
        mm_10 = torch.ops.aten.mm.default(view_55, permute_18);  view_55 = permute_18 = None
        view_56 = torch.ops.aten.view.default(mm_10, [2, 4096, 2048]);  mm_10 = None
        add_8 = torch.ops.aten.add.Tensor(add_5, view_56);  view_56 = None
        convert_element_type_59 = torch.ops.prims.convert_element_type.default(primals_29, torch.bfloat16)
        all_gather_into_tensor_17 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_59, 128, '0');  convert_element_type_59 = None
        wait_tensor_17 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_17);  all_gather_into_tensor_17 = None
        convert_element_type_60 = torch.ops.prims.convert_element_type.default(add_8, torch.float32)
        pow_6 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_60, 2)
        mean_5 = torch.ops.aten.mean.dim(pow_6, [2], True);  pow_6 = None
        add_9 = torch.ops.aten.add.Scalar(mean_5, 1e-05);  mean_5 = None
        rsqrt_5 = torch.ops.aten.rsqrt.default(add_9);  add_9 = None
        mul_15 = torch.ops.aten.mul.Tensor(convert_element_type_60, rsqrt_5);  convert_element_type_60 = None
        mul_16 = torch.ops.aten.mul.Tensor(mul_15, wait_tensor_17);  mul_15 = wait_tensor_17 = None
        convert_element_type_61 = torch.ops.prims.convert_element_type.default(mul_16, torch.bfloat16);  mul_16 = None
        view_58 = torch.ops.aten.view.default(convert_element_type_61, [-1, 2048]);  convert_element_type_61 = None
        convert_element_type_62 = torch.ops.prims.convert_element_type.default(primals_31, torch.bfloat16)
        all_gather_into_tensor_18 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_62, 128, '0');  convert_element_type_62 = None
        wait_tensor_18 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_18);  all_gather_into_tensor_18 = None
        slice_9 = torch.ops.aten.slice.Tensor(wait_tensor_18, 0, 0, 64);  wait_tensor_18 = None
        permute_19 = torch.ops.aten.permute.default(slice_9, [1, 0]);  slice_9 = None
        mm_11 = torch.ops.aten.mm.default(view_58, permute_19);  permute_19 = None
        convert_element_type_65 = torch.ops.prims.convert_element_type.default(mm_11, torch.float32)
        amax = torch.ops.aten.amax.default(convert_element_type_65, [1], True)
        sub = torch.ops.aten.sub.Tensor(convert_element_type_65, amax);  convert_element_type_65 = None
        exp_1 = torch.ops.aten.exp.default(sub);  sub = None
        sum_1 = torch.ops.aten.sum.dim_IntList(exp_1, [1], True)
        div_1 = torch.ops.aten.div.Tensor(exp_1, sum_1);  exp_1 = None
        add_10 = torch.ops.aten.add.Tensor(div_1, primals_30);  primals_30 = None
        topk = torch.ops.aten.topk.default(add_10, 6, -1, True, False);  add_10 = None
        getitem_19 = topk[1];  topk = None
        gather = torch.ops.aten.gather.default(div_1, 1, getitem_19);  div_1 = None
        mul_17 = torch.ops.aten.mul.Tensor(gather, 1.0);  gather = None
        view_60 = torch.ops.aten.view.default(getitem_19, [-1])
        histc = torch.ops.aten.histc.default(view_60, 64, 0, 64)
        add_11 = torch.ops.aten.add.Tensor(primals_32, histc)
        sort = torch.ops.aten.sort.stable(view_60, stable = True);  view_60 = None
        getitem_21 = sort[1];  sort = None
        div_2 = torch.ops.aten.div.Tensor_mode(getitem_21, 6, rounding_mode = 'floor')
        index = torch.ops.aten.index.Tensor(view_58, [div_2])
        all_to_all_single = torch.ops._c10d_functional.all_to_all_single.default(histc, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_19 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single);  all_to_all_single = None
        wait_tensor_20 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_19);  wait_tensor_19 = None
        view_64 = torch.ops.aten.view.default(histc, [8, -1]);  histc = None
        sum_2 = torch.ops.aten.sum.dim_IntList(view_64, [1]);  view_64 = None
        device_put = torch.ops.prims.device_put.default(sum_2, device(type='cpu'), True);  sum_2 = None
        view_65 = torch.ops.aten.view.default(wait_tensor_20, [8, -1])
        sum_3 = torch.ops.aten.sum.dim_IntList(view_65, [1])
        device_put_1 = torch.ops.prims.device_put.default(sum_3, device(type='cpu'));  sum_3 = None
        select = torch.ops.aten.select.int(device_put, 0, 0)
        _local_scalar_dense = torch.ops.aten._local_scalar_dense.default(select);  select = None
        ge = _local_scalar_dense >= 0
        _assert_scalar = torch.ops.aten._assert_scalar.default(ge, "Runtime assertion failed for expression u0 >= 0 on node 'ge'");  ge = _assert_scalar = None
        select_1 = torch.ops.aten.select.int(device_put, 0, 1)
        _local_scalar_dense_1 = torch.ops.aten._local_scalar_dense.default(select_1);  select_1 = None
        ge_1 = _local_scalar_dense_1 >= 0
        _assert_scalar_1 = torch.ops.aten._assert_scalar.default(ge_1, "Runtime assertion failed for expression u1 >= 0 on node 'ge_1'");  ge_1 = _assert_scalar_1 = None
        select_2 = torch.ops.aten.select.int(device_put, 0, 2)
        _local_scalar_dense_2 = torch.ops.aten._local_scalar_dense.default(select_2);  select_2 = None
        ge_2 = _local_scalar_dense_2 >= 0
        _assert_scalar_2 = torch.ops.aten._assert_scalar.default(ge_2, "Runtime assertion failed for expression u2 >= 0 on node 'ge_2'");  ge_2 = _assert_scalar_2 = None
        select_3 = torch.ops.aten.select.int(device_put, 0, 3)
        _local_scalar_dense_3 = torch.ops.aten._local_scalar_dense.default(select_3);  select_3 = None
        ge_3 = _local_scalar_dense_3 >= 0
        _assert_scalar_3 = torch.ops.aten._assert_scalar.default(ge_3, "Runtime assertion failed for expression u3 >= 0 on node 'ge_3'");  ge_3 = _assert_scalar_3 = None
        select_4 = torch.ops.aten.select.int(device_put, 0, 4)
        _local_scalar_dense_4 = torch.ops.aten._local_scalar_dense.default(select_4);  select_4 = None
        ge_4 = _local_scalar_dense_4 >= 0
        _assert_scalar_4 = torch.ops.aten._assert_scalar.default(ge_4, "Runtime assertion failed for expression u4 >= 0 on node 'ge_4'");  ge_4 = _assert_scalar_4 = None
        select_5 = torch.ops.aten.select.int(device_put, 0, 5)
        _local_scalar_dense_5 = torch.ops.aten._local_scalar_dense.default(select_5);  select_5 = None
        ge_5 = _local_scalar_dense_5 >= 0
        _assert_scalar_5 = torch.ops.aten._assert_scalar.default(ge_5, "Runtime assertion failed for expression u5 >= 0 on node 'ge_5'");  ge_5 = _assert_scalar_5 = None
        select_6 = torch.ops.aten.select.int(device_put, 0, 6)
        _local_scalar_dense_6 = torch.ops.aten._local_scalar_dense.default(select_6);  select_6 = None
        ge_6 = _local_scalar_dense_6 >= 0
        _assert_scalar_6 = torch.ops.aten._assert_scalar.default(ge_6, "Runtime assertion failed for expression u6 >= 0 on node 'ge_6'");  ge_6 = _assert_scalar_6 = None
        select_7 = torch.ops.aten.select.int(device_put, 0, 7);  device_put = None
        _local_scalar_dense_7 = torch.ops.aten._local_scalar_dense.default(select_7);  select_7 = None
        ge_7 = _local_scalar_dense_7 >= 0
        _assert_scalar_7 = torch.ops.aten._assert_scalar.default(ge_7, "Runtime assertion failed for expression u7 >= 0 on node 'ge_7'");  ge_7 = _assert_scalar_7 = None
        select_8 = torch.ops.aten.select.int(device_put_1, 0, 0)
        _local_scalar_dense_8 = torch.ops.aten._local_scalar_dense.default(select_8);  select_8 = None
        ge_8 = _local_scalar_dense_8 >= 0
        _assert_scalar_8 = torch.ops.aten._assert_scalar.default(ge_8, "Runtime assertion failed for expression u8 >= 0 on node 'ge_8'");  ge_8 = _assert_scalar_8 = None
        select_9 = torch.ops.aten.select.int(device_put_1, 0, 1)
        _local_scalar_dense_9 = torch.ops.aten._local_scalar_dense.default(select_9);  select_9 = None
        ge_9 = _local_scalar_dense_9 >= 0
        _assert_scalar_9 = torch.ops.aten._assert_scalar.default(ge_9, "Runtime assertion failed for expression u9 >= 0 on node 'ge_9'");  ge_9 = _assert_scalar_9 = None
        select_10 = torch.ops.aten.select.int(device_put_1, 0, 2)
        _local_scalar_dense_10 = torch.ops.aten._local_scalar_dense.default(select_10);  select_10 = None
        ge_10 = _local_scalar_dense_10 >= 0
        _assert_scalar_10 = torch.ops.aten._assert_scalar.default(ge_10, "Runtime assertion failed for expression u10 >= 0 on node 'ge_10'");  ge_10 = _assert_scalar_10 = None
        select_11 = torch.ops.aten.select.int(device_put_1, 0, 3)
        _local_scalar_dense_11 = torch.ops.aten._local_scalar_dense.default(select_11);  select_11 = None
        ge_11 = _local_scalar_dense_11 >= 0
        _assert_scalar_11 = torch.ops.aten._assert_scalar.default(ge_11, "Runtime assertion failed for expression u11 >= 0 on node 'ge_11'");  ge_11 = _assert_scalar_11 = None
        select_12 = torch.ops.aten.select.int(device_put_1, 0, 4)
        _local_scalar_dense_12 = torch.ops.aten._local_scalar_dense.default(select_12);  select_12 = None
        ge_12 = _local_scalar_dense_12 >= 0
        _assert_scalar_12 = torch.ops.aten._assert_scalar.default(ge_12, "Runtime assertion failed for expression u12 >= 0 on node 'ge_12'");  ge_12 = _assert_scalar_12 = None
        select_13 = torch.ops.aten.select.int(device_put_1, 0, 5)
        _local_scalar_dense_13 = torch.ops.aten._local_scalar_dense.default(select_13);  select_13 = None
        ge_13 = _local_scalar_dense_13 >= 0
        _assert_scalar_13 = torch.ops.aten._assert_scalar.default(ge_13, "Runtime assertion failed for expression u13 >= 0 on node 'ge_13'");  ge_13 = _assert_scalar_13 = None
        select_14 = torch.ops.aten.select.int(device_put_1, 0, 6)
        _local_scalar_dense_14 = torch.ops.aten._local_scalar_dense.default(select_14);  select_14 = None
        ge_14 = _local_scalar_dense_14 >= 0
        _assert_scalar_14 = torch.ops.aten._assert_scalar.default(ge_14, "Runtime assertion failed for expression u14 >= 0 on node 'ge_14'");  ge_14 = _assert_scalar_14 = None
        select_15 = torch.ops.aten.select.int(device_put_1, 0, 7);  device_put_1 = None
        _local_scalar_dense_15 = torch.ops.aten._local_scalar_dense.default(select_15);  select_15 = None
        ge_15 = _local_scalar_dense_15 >= 0
        _assert_scalar_15 = torch.ops.aten._assert_scalar.default(ge_15, "Runtime assertion failed for expression u15 >= 0 on node 'ge_15'");  ge_15 = _assert_scalar_15 = None
        all_to_all_single_1 = torch.ops._c10d_functional.all_to_all_single.default(index, [_local_scalar_dense_8, _local_scalar_dense_9, _local_scalar_dense_10, _local_scalar_dense_11, _local_scalar_dense_12, _local_scalar_dense_13, _local_scalar_dense_14, _local_scalar_dense_15], [_local_scalar_dense, _local_scalar_dense_1, _local_scalar_dense_2, _local_scalar_dense_3, _local_scalar_dense_4, _local_scalar_dense_5, _local_scalar_dense_6, _local_scalar_dense_7], '1033');  index = None
        sym_size_int = torch.ops.aten.sym_size.int(all_to_all_single_1, 0)
        wait_tensor_21 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_1);  all_to_all_single_1 = None
        sym_sum = torch.sym_sum((_local_scalar_dense_10, _local_scalar_dense_11, _local_scalar_dense_12, _local_scalar_dense_13, _local_scalar_dense_14, _local_scalar_dense_15, _local_scalar_dense_8, _local_scalar_dense_9))
        add_18 = sym_sum + 64;  sym_sum = None
        add_19 = add_18 + 8;  add_18 = None
        sub_3 = add_19 - 1;  add_19 = None
        floordiv = sub_3 // 8;  sub_3 = None
        mul_22 = floordiv * 8;  floordiv = None
        cumsum = torch.ops.aten.cumsum.default(wait_tensor_20, 0)
        sub_4 = torch.ops.aten.sub.Tensor(cumsum, wait_tensor_20);  cumsum = None
        sum_4 = torch.ops.aten.sum.dim_IntList(view_65, [0]);  view_65 = None
        clamp_min = torch.ops.aten.clamp_min.default(sum_4, 8);  sum_4 = None
        add_20 = torch.ops.aten.add.Tensor(clamp_min, 8);  clamp_min = None
        sub_5 = torch.ops.aten.sub.Tensor(add_20, 1);  add_20 = None
        div_3 = torch.ops.aten.div.Tensor_mode(sub_5, 8, rounding_mode = 'floor');  sub_5 = None
        mul_23 = torch.ops.aten.mul.Tensor(div_3, 8);  div_3 = None
        convert_element_type_68 = torch.ops.prims.convert_element_type.default(mul_23, torch.int32);  mul_23 = None
        cumsum_1 = torch.ops.aten.cumsum.default(convert_element_type_68, 0)
        sub_6 = torch.ops.aten.sub.Tensor(cumsum_1, convert_element_type_68);  cumsum_1 = None
        full_20 = torch.ops.aten.full.default([mul_22], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_22 = None
        triton_kernel_wrapper_functional_proxy = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 0, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_20, 'start_index_values_ptr': sub_4, 'write_offsets_ptr': sub_6, 'output_ptr': full_20}, tensors_to_clone = ['output_ptr']);  wait_tensor_20 = sub_4 = sub_6 = full_20 = None
        getitem_22 = triton_kernel_wrapper_functional_proxy['output_ptr'];  triton_kernel_wrapper_functional_proxy = None
        full_default = torch.ops.aten.full.default([1, 2048], 0.0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        cat_4 = torch.ops.aten.cat.default([wait_tensor_21, full_default]);  wait_tensor_21 = None
        sym_size_int_1 = torch.ops.aten.sym_size.int(cat_4, 0)
        sym_sum_1 = torch.sym_sum((1, _local_scalar_dense_10, _local_scalar_dense_11, _local_scalar_dense_12, _local_scalar_dense_13, _local_scalar_dense_14, _local_scalar_dense_15, _local_scalar_dense_8, _local_scalar_dense_9))
        index_1 = torch.ops.aten.index.Tensor(cat_4, [getitem_22]);  cat_4 = None
        convert_element_type_70 = torch.ops.prims.convert_element_type.default(primals_33, torch.bfloat16)
        all_gather_into_tensor_19 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_70, 16, '1025');  convert_element_type_70 = None
        wait_tensor_22 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_19);  all_gather_into_tensor_19 = None
        split_1 = torch.ops.aten.split.Tensor(wait_tensor_22, 8);  wait_tensor_22 = None
        getitem_39 = split_1[0]
        getitem_40 = split_1[1]
        getitem_41 = split_1[2]
        getitem_42 = split_1[3]
        getitem_43 = split_1[4]
        getitem_44 = split_1[5]
        getitem_45 = split_1[6]
        getitem_46 = split_1[7]
        getitem_47 = split_1[8]
        getitem_48 = split_1[9]
        getitem_49 = split_1[10]
        getitem_50 = split_1[11]
        getitem_51 = split_1[12]
        getitem_52 = split_1[13]
        getitem_53 = split_1[14]
        getitem_54 = split_1[15];  split_1 = None
        cat_6 = torch.ops.aten.cat.default([getitem_39, getitem_40, getitem_41, getitem_42, getitem_43, getitem_44, getitem_45, getitem_46, getitem_47, getitem_48, getitem_49, getitem_50, getitem_51, getitem_52, getitem_53, getitem_54], 1);  getitem_39 = getitem_40 = getitem_41 = getitem_42 = getitem_43 = getitem_44 = getitem_45 = getitem_46 = getitem_47 = getitem_48 = getitem_49 = getitem_50 = getitem_51 = getitem_52 = getitem_53 = getitem_54 = None
        convert_element_type_72 = torch.ops.prims.convert_element_type.default(primals_34, torch.bfloat16)
        all_gather_into_tensor_21 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_72, 16, '1025');  convert_element_type_72 = None
        wait_tensor_24 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_21);  all_gather_into_tensor_21 = None
        split_2 = torch.ops.aten.split.Tensor(wait_tensor_24, 8);  wait_tensor_24 = None
        getitem_55 = split_2[0]
        getitem_56 = split_2[1]
        getitem_57 = split_2[2]
        getitem_58 = split_2[3]
        getitem_59 = split_2[4]
        getitem_60 = split_2[5]
        getitem_61 = split_2[6]
        getitem_62 = split_2[7]
        getitem_63 = split_2[8]
        getitem_64 = split_2[9]
        getitem_65 = split_2[10]
        getitem_66 = split_2[11]
        getitem_67 = split_2[12]
        getitem_68 = split_2[13]
        getitem_69 = split_2[14]
        getitem_70 = split_2[15];  split_2 = None
        cat_7 = torch.ops.aten.cat.default([getitem_55, getitem_56, getitem_57, getitem_58, getitem_59, getitem_60, getitem_61, getitem_62, getitem_63, getitem_64, getitem_65, getitem_66, getitem_67, getitem_68, getitem_69, getitem_70], 1);  getitem_55 = getitem_56 = getitem_57 = getitem_58 = getitem_59 = getitem_60 = getitem_61 = getitem_62 = getitem_63 = getitem_64 = getitem_65 = getitem_66 = getitem_67 = getitem_68 = getitem_69 = getitem_70 = None
        convert_element_type_73 = torch.ops.prims.convert_element_type.default(primals_35, torch.bfloat16)
        all_gather_into_tensor_22 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_73, 16, '1025');  convert_element_type_73 = None
        wait_tensor_25 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_22);  all_gather_into_tensor_22 = None
        split_3 = torch.ops.aten.split.Tensor(wait_tensor_25, 8);  wait_tensor_25 = None
        getitem_71 = split_3[0]
        getitem_72 = split_3[1]
        getitem_73 = split_3[2]
        getitem_74 = split_3[3]
        getitem_75 = split_3[4]
        getitem_76 = split_3[5]
        getitem_77 = split_3[6]
        getitem_78 = split_3[7]
        getitem_79 = split_3[8]
        getitem_80 = split_3[9]
        getitem_81 = split_3[10]
        getitem_82 = split_3[11]
        getitem_83 = split_3[12]
        getitem_84 = split_3[13]
        getitem_85 = split_3[14]
        getitem_86 = split_3[15];  split_3 = None
        cat_8 = torch.ops.aten.cat.default([getitem_71, getitem_72, getitem_73, getitem_74, getitem_75, getitem_76, getitem_77, getitem_78, getitem_79, getitem_80, getitem_81, getitem_82, getitem_83, getitem_84, getitem_85, getitem_86], 1);  getitem_71 = getitem_72 = getitem_73 = getitem_74 = getitem_75 = getitem_76 = getitem_77 = getitem_78 = getitem_79 = getitem_80 = getitem_81 = getitem_82 = getitem_83 = getitem_84 = getitem_85 = getitem_86 = None
        cumsum_2 = torch.ops.aten.cumsum.default(convert_element_type_68, 0, dtype = torch.int32);  convert_element_type_68 = None
        permute_20 = torch.ops.aten.permute.default(cat_6, [0, 2, 1]);  cat_6 = None
        _grouped_mm = torch.ops.aten._grouped_mm.default(index_1, permute_20, cumsum_2)
        convert_element_type_76 = torch.ops.prims.convert_element_type.default(_grouped_mm, torch.float32)
        neg_1 = torch.ops.aten.neg.default(convert_element_type_76)
        exp_2 = torch.ops.aten.exp.default(neg_1);  neg_1 = None
        add_32 = torch.ops.aten.add.Tensor(exp_2, 1);  exp_2 = None
        div_4 = torch.ops.aten.div.Tensor(convert_element_type_76, add_32);  convert_element_type_76 = add_32 = None
        convert_element_type_77 = torch.ops.prims.convert_element_type.default(div_4, torch.bfloat16);  div_4 = None
        permute_21 = torch.ops.aten.permute.default(cat_8, [0, 2, 1]);  cat_8 = None
        _grouped_mm_1 = torch.ops.aten._grouped_mm.default(index_1, permute_21, cumsum_2)
        mul_35 = torch.ops.aten.mul.Tensor(convert_element_type_77, _grouped_mm_1);  convert_element_type_77 = None
        permute_22 = torch.ops.aten.permute.default(cat_7, [0, 2, 1]);  cat_7 = None
        _grouped_mm_2 = torch.ops.aten._grouped_mm.default(mul_35, permute_22, cumsum_2)
        empty = torch.ops.aten.empty.memory_format([sym_size_int_1, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put = torch.ops.aten.index_put.default(empty, [getitem_22], _grouped_mm_2);  empty = _grouped_mm_2 = None
        slice_11 = torch.ops.aten.slice.Tensor(index_put, 0, 0, -1);  index_put = None
        all_to_all_single_2 = torch.ops._c10d_functional.all_to_all_single.default(slice_11, [_local_scalar_dense, _local_scalar_dense_1, _local_scalar_dense_2, _local_scalar_dense_3, _local_scalar_dense_4, _local_scalar_dense_5, _local_scalar_dense_6, _local_scalar_dense_7], [_local_scalar_dense_8, _local_scalar_dense_9, _local_scalar_dense_10, _local_scalar_dense_11, _local_scalar_dense_12, _local_scalar_dense_13, _local_scalar_dense_14, _local_scalar_dense_15], '1033');  slice_11 = None
        wait_tensor_28 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_2);  all_to_all_single_2 = None
        convert_element_type_78 = torch.ops.prims.convert_element_type.default(primals_36, torch.bfloat16)
        all_gather_into_tensor_25 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_78, 128, '0');  convert_element_type_78 = None
        wait_tensor_29 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_25);  all_gather_into_tensor_25 = None
        permute_23 = torch.ops.aten.permute.default(wait_tensor_29, [1, 0]);  wait_tensor_29 = None
        mm_12 = torch.ops.aten.mm.default(view_58, permute_23);  permute_23 = None
        convert_element_type_81 = torch.ops.prims.convert_element_type.default(mm_12, torch.float32)
        neg_2 = torch.ops.aten.neg.default(convert_element_type_81)
        exp_3 = torch.ops.aten.exp.default(neg_2);  neg_2 = None
        add_68 = torch.ops.aten.add.Tensor(exp_3, 1);  exp_3 = None
        div_5 = torch.ops.aten.div.Tensor(convert_element_type_81, add_68);  convert_element_type_81 = add_68 = None
        convert_element_type_82 = torch.ops.prims.convert_element_type.default(div_5, torch.bfloat16);  div_5 = None
        convert_element_type_83 = torch.ops.prims.convert_element_type.default(primals_37, torch.bfloat16)
        all_gather_into_tensor_26 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_83, 128, '0');  convert_element_type_83 = None
        wait_tensor_30 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_26);  all_gather_into_tensor_26 = None
        permute_24 = torch.ops.aten.permute.default(wait_tensor_30, [1, 0]);  wait_tensor_30 = None
        mm_13 = torch.ops.aten.mm.default(view_58, permute_24);  permute_24 = None
        mul_55 = torch.ops.aten.mul.Tensor(convert_element_type_82, mm_13);  convert_element_type_82 = None
        convert_element_type_86 = torch.ops.prims.convert_element_type.default(primals_38, torch.bfloat16)
        all_gather_into_tensor_27 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_86, 128, '0');  convert_element_type_86 = None
        wait_tensor_31 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_27);  all_gather_into_tensor_27 = None
        permute_25 = torch.ops.aten.permute.default(wait_tensor_31, [1, 0]);  wait_tensor_31 = None
        mm_14 = torch.ops.aten.mm.default(mul_55, permute_25);  permute_25 = None
        full_default_1 = torch.ops.aten.full.default([49152, 2048], 0, dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_1 = torch.ops.aten.index_put.default(full_default_1, [getitem_21], wait_tensor_28);  wait_tensor_28 = None
        view_98 = torch.ops.aten.view.default(mul_17, [-1, 1, 6]);  mul_17 = None
        view_99 = torch.ops.aten.view.default(index_put_1, [-1, 6, 2048]);  index_put_1 = None
        convert_element_type_89 = torch.ops.prims.convert_element_type.default(view_99, torch.float32);  view_99 = None
        bmm = torch.ops.aten.bmm.default(view_98, convert_element_type_89)
        convert_element_type_90 = torch.ops.prims.convert_element_type.default(bmm, torch.bfloat16);  bmm = None
        squeeze = torch.ops.aten.squeeze.dim(convert_element_type_90, 1);  convert_element_type_90 = None
        add_72 = torch.ops.aten.add.Tensor(mm_14, squeeze);  mm_14 = squeeze = None
        view_100 = torch.ops.aten.view.default(add_72, [2, 4096, 2048]);  add_72 = None
        add_73 = torch.ops.aten.add.Tensor(add_8, view_100);  view_100 = None
        convert_element_type_91 = torch.ops.prims.convert_element_type.default(primals_39, torch.bfloat16)
        all_gather_into_tensor_28 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_91, 128, '0');  convert_element_type_91 = None
        wait_tensor_32 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_28);  all_gather_into_tensor_28 = None
        convert_element_type_92 = torch.ops.prims.convert_element_type.default(add_73, torch.float32)
        pow_7 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_92, 2)
        mean_6 = torch.ops.aten.mean.dim(pow_7, [2], True);  pow_7 = None
        add_74 = torch.ops.aten.add.Scalar(mean_6, 1e-05);  mean_6 = None
        rsqrt_6 = torch.ops.aten.rsqrt.default(add_74);  add_74 = None
        mul_58 = torch.ops.aten.mul.Tensor(convert_element_type_92, rsqrt_6);  convert_element_type_92 = None
        mul_59 = torch.ops.aten.mul.Tensor(mul_58, wait_tensor_32);  mul_58 = wait_tensor_32 = None
        convert_element_type_93 = torch.ops.prims.convert_element_type.default(mul_59, torch.bfloat16);  mul_59 = None
        convert_element_type_94 = torch.ops.prims.convert_element_type.default(primals_40, torch.bfloat16)
        all_gather_into_tensor_29 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_94, 128, '0');  convert_element_type_94 = None
        wait_tensor_33 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_29);  all_gather_into_tensor_29 = None
        permute_26 = torch.ops.aten.permute.default(wait_tensor_33, [1, 0]);  wait_tensor_33 = None
        view_103 = torch.ops.aten.view.default(convert_element_type_93, [8192, 2048]);  convert_element_type_93 = None
        mm_15 = torch.ops.aten.mm.default(view_103, permute_26);  permute_26 = None
        view_104 = torch.ops.aten.view.default(mm_15, [2, 4096, 3072]);  mm_15 = None
        view_105 = torch.ops.aten.view.default(view_104, [2, 4096, -1, 192]);  view_104 = None
        split_with_sizes_6 = torch.ops.aten.split_with_sizes.default(view_105, [128, 64], -1);  view_105 = None
        getitem_119 = split_with_sizes_6[0]
        getitem_120 = split_with_sizes_6[1];  split_with_sizes_6 = None
        convert_element_type_97 = torch.ops.prims.convert_element_type.default(getitem_120, torch.float32);  getitem_120 = None
        view_106 = torch.ops.aten.view.default(convert_element_type_97, [2, 4096, 16, -1, 2]);  convert_element_type_97 = None
        view_as_complex_4 = torch.ops.aten.view_as_complex.default(view_106);  view_106 = None
        mul_60 = torch.ops.aten.mul.Tensor(view_as_complex_4, view_7);  view_as_complex_4 = None
        view_as_real_4 = torch.ops.aten.view_as_real.default(mul_60);  mul_60 = None
        view_108 = torch.ops.aten.view.default(view_as_real_4, [2, 4096, 16, 64]);  view_as_real_4 = None
        convert_element_type_98 = torch.ops.prims.convert_element_type.default(view_108, torch.bfloat16);  view_108 = None
        cat_11 = torch.ops.aten.cat.default([getitem_119, convert_element_type_98], -1);  getitem_119 = convert_element_type_98 = None
        convert_element_type_99 = torch.ops.prims.convert_element_type.default(primals_41, torch.bfloat16)
        all_gather_into_tensor_30 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_99, 128, '0');  convert_element_type_99 = None
        wait_tensor_34 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_30);  all_gather_into_tensor_30 = None
        slice_13 = torch.ops.aten.slice.Tensor(wait_tensor_34, 0, 0, 576);  wait_tensor_34 = None
        permute_27 = torch.ops.aten.permute.default(slice_13, [1, 0]);  slice_13 = None
        mm_16 = torch.ops.aten.mm.default(view_103, permute_27);  permute_27 = None
        view_111 = torch.ops.aten.view.default(mm_16, [2, 4096, 576]);  mm_16 = None
        split_with_sizes_7 = torch.ops.aten.split_with_sizes.default(view_111, [512, 64], -1);  view_111 = None
        getitem_121 = split_with_sizes_7[0]
        getitem_122 = split_with_sizes_7[1];  split_with_sizes_7 = None
        unsqueeze_3 = torch.ops.aten.unsqueeze.default(getitem_122, 2);  getitem_122 = None
        convert_element_type_102 = torch.ops.prims.convert_element_type.default(unsqueeze_3, torch.float32);  unsqueeze_3 = None
        view_112 = torch.ops.aten.view.default(convert_element_type_102, [2, 4096, 1, -1, 2]);  convert_element_type_102 = None
        view_as_complex_5 = torch.ops.aten.view_as_complex.default(view_112);  view_112 = None
        mul_61 = torch.ops.aten.mul.Tensor(view_as_complex_5, view_7);  view_as_complex_5 = None
        view_as_real_5 = torch.ops.aten.view_as_real.default(mul_61);  mul_61 = None
        view_114 = torch.ops.aten.view.default(view_as_real_5, [2, 4096, 1, 64]);  view_as_real_5 = None
        convert_element_type_103 = torch.ops.prims.convert_element_type.default(view_114, torch.bfloat16);  view_114 = None
        convert_element_type_104 = torch.ops.prims.convert_element_type.default(primals_42, torch.bfloat16)
        all_gather_into_tensor_31 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_104, 128, '0');  convert_element_type_104 = None
        wait_tensor_35 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_31);  all_gather_into_tensor_31 = None
        convert_element_type_105 = torch.ops.prims.convert_element_type.default(getitem_121, torch.float32)
        pow_8 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_105, 2)
        mean_7 = torch.ops.aten.mean.dim(pow_8, [2], True);  pow_8 = None
        add_75 = torch.ops.aten.add.Scalar(mean_7, 1e-05);  mean_7 = None
        rsqrt_7 = torch.ops.aten.rsqrt.default(add_75);  add_75 = None
        mul_62 = torch.ops.aten.mul.Tensor(convert_element_type_105, rsqrt_7);  convert_element_type_105 = None
        mul_63 = torch.ops.aten.mul.Tensor(mul_62, wait_tensor_35);  mul_62 = wait_tensor_35 = None
        convert_element_type_106 = torch.ops.prims.convert_element_type.default(mul_63, torch.bfloat16);  mul_63 = None
        convert_element_type_107 = torch.ops.prims.convert_element_type.default(primals_43, torch.bfloat16)
        all_gather_into_tensor_32 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_107, 128, '0');  convert_element_type_107 = None
        wait_tensor_36 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_32);  all_gather_into_tensor_32 = None
        permute_28 = torch.ops.aten.permute.default(wait_tensor_36, [1, 0]);  wait_tensor_36 = None
        view_117 = torch.ops.aten.view.default(convert_element_type_106, [8192, 512]);  convert_element_type_106 = None
        mm_17 = torch.ops.aten.mm.default(view_117, permute_28);  permute_28 = None
        view_118 = torch.ops.aten.view.default(mm_17, [2, 4096, 4096]);  mm_17 = None
        view_119 = torch.ops.aten.view.default(view_118, [2, 4096, -1, 256]);  view_118 = None
        split_with_sizes_8 = torch.ops.aten.split_with_sizes.default(view_119, [128, 128], -1);  view_119 = None
        getitem_123 = split_with_sizes_8[0]
        getitem_124 = split_with_sizes_8[1];  split_with_sizes_8 = None
        expand_2 = torch.ops.aten.expand.default(convert_element_type_103, [-1, -1, 16, -1]);  convert_element_type_103 = None
        cat_12 = torch.ops.aten.cat.default([getitem_123, expand_2], -1);  getitem_123 = expand_2 = None
        permute_29 = torch.ops.aten.permute.default(cat_11, [0, 2, 1, 3]);  cat_11 = None
        permute_30 = torch.ops.aten.permute.default(cat_12, [0, 2, 1, 3]);  cat_12 = None
        permute_31 = torch.ops.aten.permute.default(getitem_124, [0, 2, 1, 3]);  getitem_124 = None
        sdpa_score2 = self.sdpa_score2
        sdpa_mask2 = self.sdpa_mask2
        flex_attention_2 = torch.ops.higher_order.flex_attention(permute_29, permute_30, permute_31, sdpa_score2, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask2), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score2 = sdpa_mask2 = None
        getitem_125 = flex_attention_2[0]
        getitem_126 = flex_attention_2[1];  flex_attention_2 = None
        permute_32 = torch.ops.aten.permute.default(getitem_125, [0, 2, 1, 3])
        view_120 = torch.ops.aten.view.default(permute_32, [2, 4096, -1]);  permute_32 = None
        convert_element_type_110 = torch.ops.prims.convert_element_type.default(primals_44, torch.bfloat16)
        all_gather_into_tensor_33 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_110, 128, '0');  convert_element_type_110 = None
        wait_tensor_37 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_33);  all_gather_into_tensor_33 = None
        permute_33 = torch.ops.aten.permute.default(wait_tensor_37, [1, 0]);  wait_tensor_37 = None
        view_122 = torch.ops.aten.view.default(view_120, [8192, 2048]);  view_120 = None
        mm_18 = torch.ops.aten.mm.default(view_122, permute_33);  view_122 = permute_33 = None
        view_123 = torch.ops.aten.view.default(mm_18, [2, 4096, 2048]);  mm_18 = None
        add_76 = torch.ops.aten.add.Tensor(add_73, view_123);  view_123 = None
        convert_element_type_113 = torch.ops.prims.convert_element_type.default(primals_45, torch.bfloat16)
        all_gather_into_tensor_34 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_113, 128, '0');  convert_element_type_113 = None
        wait_tensor_38 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_34);  all_gather_into_tensor_34 = None
        convert_element_type_114 = torch.ops.prims.convert_element_type.default(add_76, torch.float32)
        pow_9 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_114, 2)
        mean_8 = torch.ops.aten.mean.dim(pow_9, [2], True);  pow_9 = None
        add_77 = torch.ops.aten.add.Scalar(mean_8, 1e-05);  mean_8 = None
        rsqrt_8 = torch.ops.aten.rsqrt.default(add_77);  add_77 = None
        mul_64 = torch.ops.aten.mul.Tensor(convert_element_type_114, rsqrt_8);  convert_element_type_114 = None
        mul_65 = torch.ops.aten.mul.Tensor(mul_64, wait_tensor_38);  mul_64 = wait_tensor_38 = None
        convert_element_type_115 = torch.ops.prims.convert_element_type.default(mul_65, torch.bfloat16);  mul_65 = None
        view_125 = torch.ops.aten.view.default(convert_element_type_115, [-1, 2048]);  convert_element_type_115 = None
        convert_element_type_116 = torch.ops.prims.convert_element_type.default(primals_47, torch.bfloat16)
        all_gather_into_tensor_35 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_116, 128, '0');  convert_element_type_116 = None
        wait_tensor_39 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_35);  all_gather_into_tensor_35 = None
        slice_15 = torch.ops.aten.slice.Tensor(wait_tensor_39, 0, 0, 64);  wait_tensor_39 = None
        permute_34 = torch.ops.aten.permute.default(slice_15, [1, 0]);  slice_15 = None
        mm_19 = torch.ops.aten.mm.default(view_125, permute_34);  permute_34 = None
        convert_element_type_119 = torch.ops.prims.convert_element_type.default(mm_19, torch.float32)
        amax_1 = torch.ops.aten.amax.default(convert_element_type_119, [1], True)
        sub_24 = torch.ops.aten.sub.Tensor(convert_element_type_119, amax_1);  convert_element_type_119 = None
        exp_4 = torch.ops.aten.exp.default(sub_24);  sub_24 = None
        sum_5 = torch.ops.aten.sum.dim_IntList(exp_4, [1], True)
        div_6 = torch.ops.aten.div.Tensor(exp_4, sum_5);  exp_4 = None
        add_78 = torch.ops.aten.add.Tensor(div_6, primals_46);  primals_46 = None
        topk_1 = torch.ops.aten.topk.default(add_78, 6, -1, True, False);  add_78 = None
        getitem_129 = topk_1[1];  topk_1 = None
        gather_1 = torch.ops.aten.gather.default(div_6, 1, getitem_129);  div_6 = None
        mul_66 = torch.ops.aten.mul.Tensor(gather_1, 1.0);  gather_1 = None
        view_127 = torch.ops.aten.view.default(getitem_129, [-1])
        histc_2 = torch.ops.aten.histc.default(view_127, 64, 0, 64)
        add_79 = torch.ops.aten.add.Tensor(primals_48, histc_2)
        sort_1 = torch.ops.aten.sort.stable(view_127, stable = True);  view_127 = None
        getitem_131 = sort_1[1];  sort_1 = None
        div_7 = torch.ops.aten.div.Tensor_mode(getitem_131, 6, rounding_mode = 'floor')
        index_2 = torch.ops.aten.index.Tensor(view_125, [div_7])
        all_to_all_single_3 = torch.ops._c10d_functional.all_to_all_single.default(histc_2, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_40 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_3);  all_to_all_single_3 = None
        wait_tensor_41 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_40);  wait_tensor_40 = None
        view_131 = torch.ops.aten.view.default(histc_2, [8, -1]);  histc_2 = None
        sum_6 = torch.ops.aten.sum.dim_IntList(view_131, [1]);  view_131 = None
        device_put_2 = torch.ops.prims.device_put.default(sum_6, device(type='cpu'), True);  sum_6 = None
        view_132 = torch.ops.aten.view.default(wait_tensor_41, [8, -1])
        sum_7 = torch.ops.aten.sum.dim_IntList(view_132, [1])
        device_put_3 = torch.ops.prims.device_put.default(sum_7, device(type='cpu'));  sum_7 = None
        select_16 = torch.ops.aten.select.int(device_put_2, 0, 0)
        _local_scalar_dense_16 = torch.ops.aten._local_scalar_dense.default(select_16);  select_16 = None
        ge_20 = _local_scalar_dense_16 >= 0
        _assert_scalar_16 = torch.ops.aten._assert_scalar.default(ge_20, "Runtime assertion failed for expression u16 >= 0 on node 'ge_16'");  ge_20 = _assert_scalar_16 = None
        select_17 = torch.ops.aten.select.int(device_put_2, 0, 1)
        _local_scalar_dense_17 = torch.ops.aten._local_scalar_dense.default(select_17);  select_17 = None
        ge_21 = _local_scalar_dense_17 >= 0
        _assert_scalar_17 = torch.ops.aten._assert_scalar.default(ge_21, "Runtime assertion failed for expression u17 >= 0 on node 'ge_17'");  ge_21 = _assert_scalar_17 = None
        select_18 = torch.ops.aten.select.int(device_put_2, 0, 2)
        _local_scalar_dense_18 = torch.ops.aten._local_scalar_dense.default(select_18);  select_18 = None
        ge_22 = _local_scalar_dense_18 >= 0
        _assert_scalar_18 = torch.ops.aten._assert_scalar.default(ge_22, "Runtime assertion failed for expression u18 >= 0 on node 'ge_18'");  ge_22 = _assert_scalar_18 = None
        select_19 = torch.ops.aten.select.int(device_put_2, 0, 3)
        _local_scalar_dense_19 = torch.ops.aten._local_scalar_dense.default(select_19);  select_19 = None
        ge_23 = _local_scalar_dense_19 >= 0
        _assert_scalar_19 = torch.ops.aten._assert_scalar.default(ge_23, "Runtime assertion failed for expression u19 >= 0 on node 'ge_19'");  ge_23 = _assert_scalar_19 = None
        select_20 = torch.ops.aten.select.int(device_put_2, 0, 4)
        _local_scalar_dense_20 = torch.ops.aten._local_scalar_dense.default(select_20);  select_20 = None
        ge_24 = _local_scalar_dense_20 >= 0
        _assert_scalar_20 = torch.ops.aten._assert_scalar.default(ge_24, "Runtime assertion failed for expression u20 >= 0 on node 'ge_20'");  ge_24 = _assert_scalar_20 = None
        select_21 = torch.ops.aten.select.int(device_put_2, 0, 5)
        _local_scalar_dense_21 = torch.ops.aten._local_scalar_dense.default(select_21);  select_21 = None
        ge_25 = _local_scalar_dense_21 >= 0
        _assert_scalar_21 = torch.ops.aten._assert_scalar.default(ge_25, "Runtime assertion failed for expression u21 >= 0 on node 'ge_21'");  ge_25 = _assert_scalar_21 = None
        select_22 = torch.ops.aten.select.int(device_put_2, 0, 6)
        _local_scalar_dense_22 = torch.ops.aten._local_scalar_dense.default(select_22);  select_22 = None
        ge_26 = _local_scalar_dense_22 >= 0
        _assert_scalar_22 = torch.ops.aten._assert_scalar.default(ge_26, "Runtime assertion failed for expression u22 >= 0 on node 'ge_22'");  ge_26 = _assert_scalar_22 = None
        select_23 = torch.ops.aten.select.int(device_put_2, 0, 7);  device_put_2 = None
        _local_scalar_dense_23 = torch.ops.aten._local_scalar_dense.default(select_23);  select_23 = None
        ge_27 = _local_scalar_dense_23 >= 0
        _assert_scalar_23 = torch.ops.aten._assert_scalar.default(ge_27, "Runtime assertion failed for expression u23 >= 0 on node 'ge_23'");  ge_27 = _assert_scalar_23 = None
        select_24 = torch.ops.aten.select.int(device_put_3, 0, 0)
        _local_scalar_dense_24 = torch.ops.aten._local_scalar_dense.default(select_24);  select_24 = None
        ge_28 = _local_scalar_dense_24 >= 0
        _assert_scalar_24 = torch.ops.aten._assert_scalar.default(ge_28, "Runtime assertion failed for expression u24 >= 0 on node 'ge_24'");  ge_28 = _assert_scalar_24 = None
        select_25 = torch.ops.aten.select.int(device_put_3, 0, 1)
        _local_scalar_dense_25 = torch.ops.aten._local_scalar_dense.default(select_25);  select_25 = None
        ge_29 = _local_scalar_dense_25 >= 0
        _assert_scalar_25 = torch.ops.aten._assert_scalar.default(ge_29, "Runtime assertion failed for expression u25 >= 0 on node 'ge_25'");  ge_29 = _assert_scalar_25 = None
        select_26 = torch.ops.aten.select.int(device_put_3, 0, 2)
        _local_scalar_dense_26 = torch.ops.aten._local_scalar_dense.default(select_26);  select_26 = None
        ge_30 = _local_scalar_dense_26 >= 0
        _assert_scalar_26 = torch.ops.aten._assert_scalar.default(ge_30, "Runtime assertion failed for expression u26 >= 0 on node 'ge_26'");  ge_30 = _assert_scalar_26 = None
        select_27 = torch.ops.aten.select.int(device_put_3, 0, 3)
        _local_scalar_dense_27 = torch.ops.aten._local_scalar_dense.default(select_27);  select_27 = None
        ge_31 = _local_scalar_dense_27 >= 0
        _assert_scalar_27 = torch.ops.aten._assert_scalar.default(ge_31, "Runtime assertion failed for expression u27 >= 0 on node 'ge_27'");  ge_31 = _assert_scalar_27 = None
        select_28 = torch.ops.aten.select.int(device_put_3, 0, 4)
        _local_scalar_dense_28 = torch.ops.aten._local_scalar_dense.default(select_28);  select_28 = None
        ge_32 = _local_scalar_dense_28 >= 0
        _assert_scalar_28 = torch.ops.aten._assert_scalar.default(ge_32, "Runtime assertion failed for expression u28 >= 0 on node 'ge_28'");  ge_32 = _assert_scalar_28 = None
        select_29 = torch.ops.aten.select.int(device_put_3, 0, 5)
        _local_scalar_dense_29 = torch.ops.aten._local_scalar_dense.default(select_29);  select_29 = None
        ge_33 = _local_scalar_dense_29 >= 0
        _assert_scalar_29 = torch.ops.aten._assert_scalar.default(ge_33, "Runtime assertion failed for expression u29 >= 0 on node 'ge_29'");  ge_33 = _assert_scalar_29 = None
        select_30 = torch.ops.aten.select.int(device_put_3, 0, 6)
        _local_scalar_dense_30 = torch.ops.aten._local_scalar_dense.default(select_30);  select_30 = None
        ge_34 = _local_scalar_dense_30 >= 0
        _assert_scalar_30 = torch.ops.aten._assert_scalar.default(ge_34, "Runtime assertion failed for expression u30 >= 0 on node 'ge_30'");  ge_34 = _assert_scalar_30 = None
        select_31 = torch.ops.aten.select.int(device_put_3, 0, 7);  device_put_3 = None
        _local_scalar_dense_31 = torch.ops.aten._local_scalar_dense.default(select_31);  select_31 = None
        ge_35 = _local_scalar_dense_31 >= 0
        _assert_scalar_31 = torch.ops.aten._assert_scalar.default(ge_35, "Runtime assertion failed for expression u31 >= 0 on node 'ge_31'");  ge_35 = _assert_scalar_31 = None
        all_to_all_single_4 = torch.ops._c10d_functional.all_to_all_single.default(index_2, [_local_scalar_dense_24, _local_scalar_dense_25, _local_scalar_dense_26, _local_scalar_dense_27, _local_scalar_dense_28, _local_scalar_dense_29, _local_scalar_dense_30, _local_scalar_dense_31], [_local_scalar_dense_16, _local_scalar_dense_17, _local_scalar_dense_18, _local_scalar_dense_19, _local_scalar_dense_20, _local_scalar_dense_21, _local_scalar_dense_22, _local_scalar_dense_23], '1033');  index_2 = None
        sym_size_int_4 = torch.ops.aten.sym_size.int(all_to_all_single_4, 0)
        wait_tensor_42 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_4);  all_to_all_single_4 = None
        sym_sum_2 = torch.sym_sum((_local_scalar_dense_24, _local_scalar_dense_25, _local_scalar_dense_26, _local_scalar_dense_27, _local_scalar_dense_28, _local_scalar_dense_29, _local_scalar_dense_30, _local_scalar_dense_31))
        add_86 = sym_sum_2 + 64;  sym_sum_2 = None
        add_87 = add_86 + 8;  add_86 = None
        sub_27 = add_87 - 1;  add_87 = None
        floordiv_1 = sub_27 // 8;  sub_27 = None
        mul_71 = floordiv_1 * 8;  floordiv_1 = None
        cumsum_3 = torch.ops.aten.cumsum.default(wait_tensor_41, 0)
        sub_28 = torch.ops.aten.sub.Tensor(cumsum_3, wait_tensor_41);  cumsum_3 = None
        sum_8 = torch.ops.aten.sum.dim_IntList(view_132, [0]);  view_132 = None
        clamp_min_1 = torch.ops.aten.clamp_min.default(sum_8, 8);  sum_8 = None
        add_88 = torch.ops.aten.add.Tensor(clamp_min_1, 8);  clamp_min_1 = None
        sub_29 = torch.ops.aten.sub.Tensor(add_88, 1);  add_88 = None
        div_8 = torch.ops.aten.div.Tensor_mode(sub_29, 8, rounding_mode = 'floor');  sub_29 = None
        mul_72 = torch.ops.aten.mul.Tensor(div_8, 8);  div_8 = None
        convert_element_type_122 = torch.ops.prims.convert_element_type.default(mul_72, torch.int32);  mul_72 = None
        cumsum_4 = torch.ops.aten.cumsum.default(convert_element_type_122, 0)
        sub_30 = torch.ops.aten.sub.Tensor(cumsum_4, convert_element_type_122);  cumsum_4 = None
        full_33 = torch.ops.aten.full.default([mul_71], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_71 = None
        triton_kernel_wrapper_functional_proxy_1 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 1, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_41, 'start_index_values_ptr': sub_28, 'write_offsets_ptr': sub_30, 'output_ptr': full_33}, tensors_to_clone = ['output_ptr']);  wait_tensor_41 = sub_28 = sub_30 = full_33 = None
        getitem_132 = triton_kernel_wrapper_functional_proxy_1['output_ptr'];  triton_kernel_wrapper_functional_proxy_1 = None
        cat_13 = torch.ops.aten.cat.default([wait_tensor_42, full_default]);  wait_tensor_42 = None
        sym_size_int_5 = torch.ops.aten.sym_size.int(cat_13, 0)
        sym_sum_3 = torch.sym_sum((1, _local_scalar_dense_24, _local_scalar_dense_25, _local_scalar_dense_26, _local_scalar_dense_27, _local_scalar_dense_28, _local_scalar_dense_29, _local_scalar_dense_30, _local_scalar_dense_31))
        index_3 = torch.ops.aten.index.Tensor(cat_13, [getitem_132]);  cat_13 = None
        convert_element_type_124 = torch.ops.prims.convert_element_type.default(primals_49, torch.bfloat16)
        all_gather_into_tensor_36 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_124, 16, '1025');  convert_element_type_124 = None
        wait_tensor_43 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_36);  all_gather_into_tensor_36 = None
        split_7 = torch.ops.aten.split.Tensor(wait_tensor_43, 8);  wait_tensor_43 = None
        getitem_149 = split_7[0]
        getitem_150 = split_7[1]
        getitem_151 = split_7[2]
        getitem_152 = split_7[3]
        getitem_153 = split_7[4]
        getitem_154 = split_7[5]
        getitem_155 = split_7[6]
        getitem_156 = split_7[7]
        getitem_157 = split_7[8]
        getitem_158 = split_7[9]
        getitem_159 = split_7[10]
        getitem_160 = split_7[11]
        getitem_161 = split_7[12]
        getitem_162 = split_7[13]
        getitem_163 = split_7[14]
        getitem_164 = split_7[15];  split_7 = None
        cat_15 = torch.ops.aten.cat.default([getitem_149, getitem_150, getitem_151, getitem_152, getitem_153, getitem_154, getitem_155, getitem_156, getitem_157, getitem_158, getitem_159, getitem_160, getitem_161, getitem_162, getitem_163, getitem_164], 1);  getitem_149 = getitem_150 = getitem_151 = getitem_152 = getitem_153 = getitem_154 = getitem_155 = getitem_156 = getitem_157 = getitem_158 = getitem_159 = getitem_160 = getitem_161 = getitem_162 = getitem_163 = getitem_164 = None
        convert_element_type_126 = torch.ops.prims.convert_element_type.default(primals_50, torch.bfloat16)
        all_gather_into_tensor_38 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_126, 16, '1025');  convert_element_type_126 = None
        wait_tensor_45 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_38);  all_gather_into_tensor_38 = None
        split_8 = torch.ops.aten.split.Tensor(wait_tensor_45, 8);  wait_tensor_45 = None
        getitem_165 = split_8[0]
        getitem_166 = split_8[1]
        getitem_167 = split_8[2]
        getitem_168 = split_8[3]
        getitem_169 = split_8[4]
        getitem_170 = split_8[5]
        getitem_171 = split_8[6]
        getitem_172 = split_8[7]
        getitem_173 = split_8[8]
        getitem_174 = split_8[9]
        getitem_175 = split_8[10]
        getitem_176 = split_8[11]
        getitem_177 = split_8[12]
        getitem_178 = split_8[13]
        getitem_179 = split_8[14]
        getitem_180 = split_8[15];  split_8 = None
        cat_16 = torch.ops.aten.cat.default([getitem_165, getitem_166, getitem_167, getitem_168, getitem_169, getitem_170, getitem_171, getitem_172, getitem_173, getitem_174, getitem_175, getitem_176, getitem_177, getitem_178, getitem_179, getitem_180], 1);  getitem_165 = getitem_166 = getitem_167 = getitem_168 = getitem_169 = getitem_170 = getitem_171 = getitem_172 = getitem_173 = getitem_174 = getitem_175 = getitem_176 = getitem_177 = getitem_178 = getitem_179 = getitem_180 = None
        convert_element_type_127 = torch.ops.prims.convert_element_type.default(primals_51, torch.bfloat16)
        all_gather_into_tensor_39 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_127, 16, '1025');  convert_element_type_127 = None
        wait_tensor_46 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_39);  all_gather_into_tensor_39 = None
        split_9 = torch.ops.aten.split.Tensor(wait_tensor_46, 8);  wait_tensor_46 = None
        getitem_181 = split_9[0]
        getitem_182 = split_9[1]
        getitem_183 = split_9[2]
        getitem_184 = split_9[3]
        getitem_185 = split_9[4]
        getitem_186 = split_9[5]
        getitem_187 = split_9[6]
        getitem_188 = split_9[7]
        getitem_189 = split_9[8]
        getitem_190 = split_9[9]
        getitem_191 = split_9[10]
        getitem_192 = split_9[11]
        getitem_193 = split_9[12]
        getitem_194 = split_9[13]
        getitem_195 = split_9[14]
        getitem_196 = split_9[15];  split_9 = None
        cat_17 = torch.ops.aten.cat.default([getitem_181, getitem_182, getitem_183, getitem_184, getitem_185, getitem_186, getitem_187, getitem_188, getitem_189, getitem_190, getitem_191, getitem_192, getitem_193, getitem_194, getitem_195, getitem_196], 1);  getitem_181 = getitem_182 = getitem_183 = getitem_184 = getitem_185 = getitem_186 = getitem_187 = getitem_188 = getitem_189 = getitem_190 = getitem_191 = getitem_192 = getitem_193 = getitem_194 = getitem_195 = getitem_196 = None
        cumsum_5 = torch.ops.aten.cumsum.default(convert_element_type_122, 0, dtype = torch.int32);  convert_element_type_122 = None
        permute_35 = torch.ops.aten.permute.default(cat_15, [0, 2, 1]);  cat_15 = None
        _grouped_mm_3 = torch.ops.aten._grouped_mm.default(index_3, permute_35, cumsum_5)
        convert_element_type_130 = torch.ops.prims.convert_element_type.default(_grouped_mm_3, torch.float32)
        neg_3 = torch.ops.aten.neg.default(convert_element_type_130)
        exp_5 = torch.ops.aten.exp.default(neg_3);  neg_3 = None
        add_100 = torch.ops.aten.add.Tensor(exp_5, 1);  exp_5 = None
        div_9 = torch.ops.aten.div.Tensor(convert_element_type_130, add_100);  convert_element_type_130 = add_100 = None
        convert_element_type_131 = torch.ops.prims.convert_element_type.default(div_9, torch.bfloat16);  div_9 = None
        permute_36 = torch.ops.aten.permute.default(cat_17, [0, 2, 1]);  cat_17 = None
        _grouped_mm_4 = torch.ops.aten._grouped_mm.default(index_3, permute_36, cumsum_5)
        mul_84 = torch.ops.aten.mul.Tensor(convert_element_type_131, _grouped_mm_4);  convert_element_type_131 = None
        permute_37 = torch.ops.aten.permute.default(cat_16, [0, 2, 1]);  cat_16 = None
        _grouped_mm_5 = torch.ops.aten._grouped_mm.default(mul_84, permute_37, cumsum_5)
        empty_1 = torch.ops.aten.empty.memory_format([sym_size_int_5, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_2 = torch.ops.aten.index_put.default(empty_1, [getitem_132], _grouped_mm_5);  empty_1 = _grouped_mm_5 = None
        slice_17 = torch.ops.aten.slice.Tensor(index_put_2, 0, 0, -1);  index_put_2 = None
        all_to_all_single_5 = torch.ops._c10d_functional.all_to_all_single.default(slice_17, [_local_scalar_dense_16, _local_scalar_dense_17, _local_scalar_dense_18, _local_scalar_dense_19, _local_scalar_dense_20, _local_scalar_dense_21, _local_scalar_dense_22, _local_scalar_dense_23], [_local_scalar_dense_24, _local_scalar_dense_25, _local_scalar_dense_26, _local_scalar_dense_27, _local_scalar_dense_28, _local_scalar_dense_29, _local_scalar_dense_30, _local_scalar_dense_31], '1033');  slice_17 = None
        wait_tensor_49 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_5);  all_to_all_single_5 = None
        convert_element_type_132 = torch.ops.prims.convert_element_type.default(primals_52, torch.bfloat16)
        all_gather_into_tensor_42 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_132, 128, '0');  convert_element_type_132 = None
        wait_tensor_50 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_42);  all_gather_into_tensor_42 = None
        permute_38 = torch.ops.aten.permute.default(wait_tensor_50, [1, 0]);  wait_tensor_50 = None
        mm_20 = torch.ops.aten.mm.default(view_125, permute_38);  permute_38 = None
        convert_element_type_135 = torch.ops.prims.convert_element_type.default(mm_20, torch.float32)
        neg_4 = torch.ops.aten.neg.default(convert_element_type_135)
        exp_6 = torch.ops.aten.exp.default(neg_4);  neg_4 = None
        add_136 = torch.ops.aten.add.Tensor(exp_6, 1);  exp_6 = None
        div_10 = torch.ops.aten.div.Tensor(convert_element_type_135, add_136);  convert_element_type_135 = add_136 = None
        convert_element_type_136 = torch.ops.prims.convert_element_type.default(div_10, torch.bfloat16);  div_10 = None
        convert_element_type_137 = torch.ops.prims.convert_element_type.default(primals_53, torch.bfloat16)
        all_gather_into_tensor_43 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_137, 128, '0');  convert_element_type_137 = None
        wait_tensor_51 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_43);  all_gather_into_tensor_43 = None
        permute_39 = torch.ops.aten.permute.default(wait_tensor_51, [1, 0]);  wait_tensor_51 = None
        mm_21 = torch.ops.aten.mm.default(view_125, permute_39);  permute_39 = None
        mul_104 = torch.ops.aten.mul.Tensor(convert_element_type_136, mm_21);  convert_element_type_136 = None
        convert_element_type_140 = torch.ops.prims.convert_element_type.default(primals_54, torch.bfloat16)
        all_gather_into_tensor_44 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_140, 128, '0');  convert_element_type_140 = None
        wait_tensor_52 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_44);  all_gather_into_tensor_44 = None
        permute_40 = torch.ops.aten.permute.default(wait_tensor_52, [1, 0]);  wait_tensor_52 = None
        mm_22 = torch.ops.aten.mm.default(mul_104, permute_40);  permute_40 = None
        index_put_3 = torch.ops.aten.index_put.default(full_default_1, [getitem_131], wait_tensor_49);  wait_tensor_49 = None
        view_165 = torch.ops.aten.view.default(mul_66, [-1, 1, 6]);  mul_66 = None
        view_166 = torch.ops.aten.view.default(index_put_3, [-1, 6, 2048]);  index_put_3 = None
        convert_element_type_143 = torch.ops.prims.convert_element_type.default(view_166, torch.float32);  view_166 = None
        bmm_1 = torch.ops.aten.bmm.default(view_165, convert_element_type_143)
        convert_element_type_144 = torch.ops.prims.convert_element_type.default(bmm_1, torch.bfloat16);  bmm_1 = None
        squeeze_1 = torch.ops.aten.squeeze.dim(convert_element_type_144, 1);  convert_element_type_144 = None
        add_140 = torch.ops.aten.add.Tensor(mm_22, squeeze_1);  mm_22 = squeeze_1 = None
        view_167 = torch.ops.aten.view.default(add_140, [2, 4096, 2048]);  add_140 = None
        add_141 = torch.ops.aten.add.Tensor(add_76, view_167);  view_167 = None
        convert_element_type_145 = torch.ops.prims.convert_element_type.default(primals_55, torch.bfloat16)
        all_gather_into_tensor_45 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_145, 128, '0');  convert_element_type_145 = None
        wait_tensor_53 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_45);  all_gather_into_tensor_45 = None
        convert_element_type_146 = torch.ops.prims.convert_element_type.default(add_141, torch.float32)
        pow_10 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_146, 2)
        mean_9 = torch.ops.aten.mean.dim(pow_10, [2], True);  pow_10 = None
        add_142 = torch.ops.aten.add.Scalar(mean_9, 1e-05);  mean_9 = None
        rsqrt_9 = torch.ops.aten.rsqrt.default(add_142);  add_142 = None
        mul_107 = torch.ops.aten.mul.Tensor(convert_element_type_146, rsqrt_9);  convert_element_type_146 = None
        mul_108 = torch.ops.aten.mul.Tensor(mul_107, wait_tensor_53);  mul_107 = wait_tensor_53 = None
        convert_element_type_147 = torch.ops.prims.convert_element_type.default(mul_108, torch.bfloat16);  mul_108 = None
        convert_element_type_148 = torch.ops.prims.convert_element_type.default(primals_56, torch.bfloat16)
        all_gather_into_tensor_46 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_148, 128, '0');  convert_element_type_148 = None
        wait_tensor_54 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_46);  all_gather_into_tensor_46 = None
        permute_41 = torch.ops.aten.permute.default(wait_tensor_54, [1, 0]);  wait_tensor_54 = None
        view_170 = torch.ops.aten.view.default(convert_element_type_147, [8192, 2048]);  convert_element_type_147 = None
        mm_23 = torch.ops.aten.mm.default(view_170, permute_41);  permute_41 = None
        view_171 = torch.ops.aten.view.default(mm_23, [2, 4096, 3072]);  mm_23 = None
        view_172 = torch.ops.aten.view.default(view_171, [2, 4096, -1, 192]);  view_171 = None
        split_with_sizes_9 = torch.ops.aten.split_with_sizes.default(view_172, [128, 64], -1);  view_172 = None
        getitem_229 = split_with_sizes_9[0]
        getitem_230 = split_with_sizes_9[1];  split_with_sizes_9 = None
        convert_element_type_151 = torch.ops.prims.convert_element_type.default(getitem_230, torch.float32);  getitem_230 = None
        view_173 = torch.ops.aten.view.default(convert_element_type_151, [2, 4096, 16, -1, 2]);  convert_element_type_151 = None
        view_as_complex_6 = torch.ops.aten.view_as_complex.default(view_173);  view_173 = None
        mul_109 = torch.ops.aten.mul.Tensor(view_as_complex_6, view_7);  view_as_complex_6 = None
        view_as_real_6 = torch.ops.aten.view_as_real.default(mul_109);  mul_109 = None
        view_175 = torch.ops.aten.view.default(view_as_real_6, [2, 4096, 16, 64]);  view_as_real_6 = None
        convert_element_type_152 = torch.ops.prims.convert_element_type.default(view_175, torch.bfloat16);  view_175 = None
        cat_20 = torch.ops.aten.cat.default([getitem_229, convert_element_type_152], -1);  getitem_229 = convert_element_type_152 = None
        convert_element_type_153 = torch.ops.prims.convert_element_type.default(primals_57, torch.bfloat16)
        all_gather_into_tensor_47 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_153, 128, '0');  convert_element_type_153 = None
        wait_tensor_55 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_47);  all_gather_into_tensor_47 = None
        slice_19 = torch.ops.aten.slice.Tensor(wait_tensor_55, 0, 0, 576);  wait_tensor_55 = None
        permute_42 = torch.ops.aten.permute.default(slice_19, [1, 0]);  slice_19 = None
        mm_24 = torch.ops.aten.mm.default(view_170, permute_42);  permute_42 = None
        view_178 = torch.ops.aten.view.default(mm_24, [2, 4096, 576]);  mm_24 = None
        split_with_sizes_10 = torch.ops.aten.split_with_sizes.default(view_178, [512, 64], -1);  view_178 = None
        getitem_231 = split_with_sizes_10[0]
        getitem_232 = split_with_sizes_10[1];  split_with_sizes_10 = None
        unsqueeze_5 = torch.ops.aten.unsqueeze.default(getitem_232, 2);  getitem_232 = None
        convert_element_type_156 = torch.ops.prims.convert_element_type.default(unsqueeze_5, torch.float32);  unsqueeze_5 = None
        view_179 = torch.ops.aten.view.default(convert_element_type_156, [2, 4096, 1, -1, 2]);  convert_element_type_156 = None
        view_as_complex_7 = torch.ops.aten.view_as_complex.default(view_179);  view_179 = None
        mul_110 = torch.ops.aten.mul.Tensor(view_as_complex_7, view_7);  view_as_complex_7 = None
        view_as_real_7 = torch.ops.aten.view_as_real.default(mul_110);  mul_110 = None
        view_181 = torch.ops.aten.view.default(view_as_real_7, [2, 4096, 1, 64]);  view_as_real_7 = None
        convert_element_type_157 = torch.ops.prims.convert_element_type.default(view_181, torch.bfloat16);  view_181 = None
        convert_element_type_158 = torch.ops.prims.convert_element_type.default(primals_58, torch.bfloat16)
        all_gather_into_tensor_48 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_158, 128, '0');  convert_element_type_158 = None
        wait_tensor_56 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_48);  all_gather_into_tensor_48 = None
        convert_element_type_159 = torch.ops.prims.convert_element_type.default(getitem_231, torch.float32)
        pow_11 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_159, 2)
        mean_10 = torch.ops.aten.mean.dim(pow_11, [2], True);  pow_11 = None
        add_143 = torch.ops.aten.add.Scalar(mean_10, 1e-05);  mean_10 = None
        rsqrt_10 = torch.ops.aten.rsqrt.default(add_143);  add_143 = None
        mul_111 = torch.ops.aten.mul.Tensor(convert_element_type_159, rsqrt_10);  convert_element_type_159 = None
        mul_112 = torch.ops.aten.mul.Tensor(mul_111, wait_tensor_56);  mul_111 = wait_tensor_56 = None
        convert_element_type_160 = torch.ops.prims.convert_element_type.default(mul_112, torch.bfloat16);  mul_112 = None
        convert_element_type_161 = torch.ops.prims.convert_element_type.default(primals_59, torch.bfloat16)
        all_gather_into_tensor_49 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_161, 128, '0');  convert_element_type_161 = None
        wait_tensor_57 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_49);  all_gather_into_tensor_49 = None
        permute_43 = torch.ops.aten.permute.default(wait_tensor_57, [1, 0]);  wait_tensor_57 = None
        view_184 = torch.ops.aten.view.default(convert_element_type_160, [8192, 512]);  convert_element_type_160 = None
        mm_25 = torch.ops.aten.mm.default(view_184, permute_43);  permute_43 = None
        view_185 = torch.ops.aten.view.default(mm_25, [2, 4096, 4096]);  mm_25 = None
        view_186 = torch.ops.aten.view.default(view_185, [2, 4096, -1, 256]);  view_185 = None
        split_with_sizes_11 = torch.ops.aten.split_with_sizes.default(view_186, [128, 128], -1);  view_186 = None
        getitem_233 = split_with_sizes_11[0]
        getitem_234 = split_with_sizes_11[1];  split_with_sizes_11 = None
        expand_3 = torch.ops.aten.expand.default(convert_element_type_157, [-1, -1, 16, -1]);  convert_element_type_157 = None
        cat_21 = torch.ops.aten.cat.default([getitem_233, expand_3], -1);  getitem_233 = expand_3 = None
        permute_44 = torch.ops.aten.permute.default(cat_20, [0, 2, 1, 3]);  cat_20 = None
        permute_45 = torch.ops.aten.permute.default(cat_21, [0, 2, 1, 3]);  cat_21 = None
        permute_46 = torch.ops.aten.permute.default(getitem_234, [0, 2, 1, 3]);  getitem_234 = None
        sdpa_score3 = self.sdpa_score3
        sdpa_mask3 = self.sdpa_mask3
        flex_attention_3 = torch.ops.higher_order.flex_attention(permute_44, permute_45, permute_46, sdpa_score3, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask3), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score3 = sdpa_mask3 = None
        getitem_235 = flex_attention_3[0]
        getitem_236 = flex_attention_3[1];  flex_attention_3 = None
        permute_47 = torch.ops.aten.permute.default(getitem_235, [0, 2, 1, 3])
        view_187 = torch.ops.aten.view.default(permute_47, [2, 4096, -1]);  permute_47 = None
        convert_element_type_164 = torch.ops.prims.convert_element_type.default(primals_60, torch.bfloat16)
        all_gather_into_tensor_50 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_164, 128, '0');  convert_element_type_164 = None
        wait_tensor_58 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_50);  all_gather_into_tensor_50 = None
        permute_48 = torch.ops.aten.permute.default(wait_tensor_58, [1, 0]);  wait_tensor_58 = None
        view_189 = torch.ops.aten.view.default(view_187, [8192, 2048]);  view_187 = None
        mm_26 = torch.ops.aten.mm.default(view_189, permute_48);  view_189 = permute_48 = None
        view_190 = torch.ops.aten.view.default(mm_26, [2, 4096, 2048]);  mm_26 = None
        add_144 = torch.ops.aten.add.Tensor(add_141, view_190);  view_190 = None
        convert_element_type_167 = torch.ops.prims.convert_element_type.default(primals_61, torch.bfloat16)
        all_gather_into_tensor_51 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_167, 128, '0');  convert_element_type_167 = None
        wait_tensor_59 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_51);  all_gather_into_tensor_51 = None
        convert_element_type_168 = torch.ops.prims.convert_element_type.default(add_144, torch.float32)
        pow_12 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_168, 2)
        mean_11 = torch.ops.aten.mean.dim(pow_12, [2], True);  pow_12 = None
        add_145 = torch.ops.aten.add.Scalar(mean_11, 1e-05);  mean_11 = None
        rsqrt_11 = torch.ops.aten.rsqrt.default(add_145);  add_145 = None
        mul_113 = torch.ops.aten.mul.Tensor(convert_element_type_168, rsqrt_11);  convert_element_type_168 = None
        mul_114 = torch.ops.aten.mul.Tensor(mul_113, wait_tensor_59);  mul_113 = wait_tensor_59 = None
        convert_element_type_169 = torch.ops.prims.convert_element_type.default(mul_114, torch.bfloat16);  mul_114 = None
        view_192 = torch.ops.aten.view.default(convert_element_type_169, [-1, 2048]);  convert_element_type_169 = None
        convert_element_type_170 = torch.ops.prims.convert_element_type.default(primals_63, torch.bfloat16)
        all_gather_into_tensor_52 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_170, 128, '0');  convert_element_type_170 = None
        wait_tensor_60 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_52);  all_gather_into_tensor_52 = None
        slice_21 = torch.ops.aten.slice.Tensor(wait_tensor_60, 0, 0, 64);  wait_tensor_60 = None
        permute_49 = torch.ops.aten.permute.default(slice_21, [1, 0]);  slice_21 = None
        mm_27 = torch.ops.aten.mm.default(view_192, permute_49);  permute_49 = None
        convert_element_type_173 = torch.ops.prims.convert_element_type.default(mm_27, torch.float32)
        amax_2 = torch.ops.aten.amax.default(convert_element_type_173, [1], True)
        sub_48 = torch.ops.aten.sub.Tensor(convert_element_type_173, amax_2);  convert_element_type_173 = None
        exp_7 = torch.ops.aten.exp.default(sub_48);  sub_48 = None
        sum_9 = torch.ops.aten.sum.dim_IntList(exp_7, [1], True)
        div_11 = torch.ops.aten.div.Tensor(exp_7, sum_9);  exp_7 = None
        add_146 = torch.ops.aten.add.Tensor(div_11, primals_62);  primals_62 = None
        topk_2 = torch.ops.aten.topk.default(add_146, 6, -1, True, False);  add_146 = None
        getitem_239 = topk_2[1];  topk_2 = None
        gather_2 = torch.ops.aten.gather.default(div_11, 1, getitem_239);  div_11 = None
        mul_115 = torch.ops.aten.mul.Tensor(gather_2, 1.0);  gather_2 = None
        view_194 = torch.ops.aten.view.default(getitem_239, [-1])
        histc_4 = torch.ops.aten.histc.default(view_194, 64, 0, 64)
        add_147 = torch.ops.aten.add.Tensor(primals_64, histc_4)
        sort_2 = torch.ops.aten.sort.stable(view_194, stable = True);  view_194 = None
        getitem_241 = sort_2[1];  sort_2 = None
        div_12 = torch.ops.aten.div.Tensor_mode(getitem_241, 6, rounding_mode = 'floor')
        index_4 = torch.ops.aten.index.Tensor(view_192, [div_12])
        all_to_all_single_6 = torch.ops._c10d_functional.all_to_all_single.default(histc_4, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_61 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_6);  all_to_all_single_6 = None
        wait_tensor_62 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_61);  wait_tensor_61 = None
        view_198 = torch.ops.aten.view.default(histc_4, [8, -1]);  histc_4 = None
        sum_10 = torch.ops.aten.sum.dim_IntList(view_198, [1]);  view_198 = None
        device_put_4 = torch.ops.prims.device_put.default(sum_10, device(type='cpu'), True);  sum_10 = None
        view_199 = torch.ops.aten.view.default(wait_tensor_62, [8, -1])
        sum_11 = torch.ops.aten.sum.dim_IntList(view_199, [1])
        device_put_5 = torch.ops.prims.device_put.default(sum_11, device(type='cpu'));  sum_11 = None
        select_32 = torch.ops.aten.select.int(device_put_4, 0, 0)
        _local_scalar_dense_32 = torch.ops.aten._local_scalar_dense.default(select_32);  select_32 = None
        ge_40 = _local_scalar_dense_32 >= 0
        _assert_scalar_32 = torch.ops.aten._assert_scalar.default(ge_40, "Runtime assertion failed for expression u32 >= 0 on node 'ge_32'");  ge_40 = _assert_scalar_32 = None
        select_33 = torch.ops.aten.select.int(device_put_4, 0, 1)
        _local_scalar_dense_33 = torch.ops.aten._local_scalar_dense.default(select_33);  select_33 = None
        ge_41 = _local_scalar_dense_33 >= 0
        _assert_scalar_33 = torch.ops.aten._assert_scalar.default(ge_41, "Runtime assertion failed for expression u33 >= 0 on node 'ge_33'");  ge_41 = _assert_scalar_33 = None
        select_34 = torch.ops.aten.select.int(device_put_4, 0, 2)
        _local_scalar_dense_34 = torch.ops.aten._local_scalar_dense.default(select_34);  select_34 = None
        ge_42 = _local_scalar_dense_34 >= 0
        _assert_scalar_34 = torch.ops.aten._assert_scalar.default(ge_42, "Runtime assertion failed for expression u34 >= 0 on node 'ge_34'");  ge_42 = _assert_scalar_34 = None
        select_35 = torch.ops.aten.select.int(device_put_4, 0, 3)
        _local_scalar_dense_35 = torch.ops.aten._local_scalar_dense.default(select_35);  select_35 = None
        ge_43 = _local_scalar_dense_35 >= 0
        _assert_scalar_35 = torch.ops.aten._assert_scalar.default(ge_43, "Runtime assertion failed for expression u35 >= 0 on node 'ge_35'");  ge_43 = _assert_scalar_35 = None
        select_36 = torch.ops.aten.select.int(device_put_4, 0, 4)
        _local_scalar_dense_36 = torch.ops.aten._local_scalar_dense.default(select_36);  select_36 = None
        ge_44 = _local_scalar_dense_36 >= 0
        _assert_scalar_36 = torch.ops.aten._assert_scalar.default(ge_44, "Runtime assertion failed for expression u36 >= 0 on node 'ge_36'");  ge_44 = _assert_scalar_36 = None
        select_37 = torch.ops.aten.select.int(device_put_4, 0, 5)
        _local_scalar_dense_37 = torch.ops.aten._local_scalar_dense.default(select_37);  select_37 = None
        ge_45 = _local_scalar_dense_37 >= 0
        _assert_scalar_37 = torch.ops.aten._assert_scalar.default(ge_45, "Runtime assertion failed for expression u37 >= 0 on node 'ge_37'");  ge_45 = _assert_scalar_37 = None
        select_38 = torch.ops.aten.select.int(device_put_4, 0, 6)
        _local_scalar_dense_38 = torch.ops.aten._local_scalar_dense.default(select_38);  select_38 = None
        ge_46 = _local_scalar_dense_38 >= 0
        _assert_scalar_38 = torch.ops.aten._assert_scalar.default(ge_46, "Runtime assertion failed for expression u38 >= 0 on node 'ge_38'");  ge_46 = _assert_scalar_38 = None
        select_39 = torch.ops.aten.select.int(device_put_4, 0, 7);  device_put_4 = None
        _local_scalar_dense_39 = torch.ops.aten._local_scalar_dense.default(select_39);  select_39 = None
        ge_47 = _local_scalar_dense_39 >= 0
        _assert_scalar_39 = torch.ops.aten._assert_scalar.default(ge_47, "Runtime assertion failed for expression u39 >= 0 on node 'ge_39'");  ge_47 = _assert_scalar_39 = None
        select_40 = torch.ops.aten.select.int(device_put_5, 0, 0)
        _local_scalar_dense_40 = torch.ops.aten._local_scalar_dense.default(select_40);  select_40 = None
        ge_48 = _local_scalar_dense_40 >= 0
        _assert_scalar_40 = torch.ops.aten._assert_scalar.default(ge_48, "Runtime assertion failed for expression u40 >= 0 on node 'ge_40'");  ge_48 = _assert_scalar_40 = None
        select_41 = torch.ops.aten.select.int(device_put_5, 0, 1)
        _local_scalar_dense_41 = torch.ops.aten._local_scalar_dense.default(select_41);  select_41 = None
        ge_49 = _local_scalar_dense_41 >= 0
        _assert_scalar_41 = torch.ops.aten._assert_scalar.default(ge_49, "Runtime assertion failed for expression u41 >= 0 on node 'ge_41'");  ge_49 = _assert_scalar_41 = None
        select_42 = torch.ops.aten.select.int(device_put_5, 0, 2)
        _local_scalar_dense_42 = torch.ops.aten._local_scalar_dense.default(select_42);  select_42 = None
        ge_50 = _local_scalar_dense_42 >= 0
        _assert_scalar_42 = torch.ops.aten._assert_scalar.default(ge_50, "Runtime assertion failed for expression u42 >= 0 on node 'ge_42'");  ge_50 = _assert_scalar_42 = None
        select_43 = torch.ops.aten.select.int(device_put_5, 0, 3)
        _local_scalar_dense_43 = torch.ops.aten._local_scalar_dense.default(select_43);  select_43 = None
        ge_51 = _local_scalar_dense_43 >= 0
        _assert_scalar_43 = torch.ops.aten._assert_scalar.default(ge_51, "Runtime assertion failed for expression u43 >= 0 on node 'ge_43'");  ge_51 = _assert_scalar_43 = None
        select_44 = torch.ops.aten.select.int(device_put_5, 0, 4)
        _local_scalar_dense_44 = torch.ops.aten._local_scalar_dense.default(select_44);  select_44 = None
        ge_52 = _local_scalar_dense_44 >= 0
        _assert_scalar_44 = torch.ops.aten._assert_scalar.default(ge_52, "Runtime assertion failed for expression u44 >= 0 on node 'ge_44'");  ge_52 = _assert_scalar_44 = None
        select_45 = torch.ops.aten.select.int(device_put_5, 0, 5)
        _local_scalar_dense_45 = torch.ops.aten._local_scalar_dense.default(select_45);  select_45 = None
        ge_53 = _local_scalar_dense_45 >= 0
        _assert_scalar_45 = torch.ops.aten._assert_scalar.default(ge_53, "Runtime assertion failed for expression u45 >= 0 on node 'ge_45'");  ge_53 = _assert_scalar_45 = None
        select_46 = torch.ops.aten.select.int(device_put_5, 0, 6)
        _local_scalar_dense_46 = torch.ops.aten._local_scalar_dense.default(select_46);  select_46 = None
        ge_54 = _local_scalar_dense_46 >= 0
        _assert_scalar_46 = torch.ops.aten._assert_scalar.default(ge_54, "Runtime assertion failed for expression u46 >= 0 on node 'ge_46'");  ge_54 = _assert_scalar_46 = None
        select_47 = torch.ops.aten.select.int(device_put_5, 0, 7);  device_put_5 = None
        _local_scalar_dense_47 = torch.ops.aten._local_scalar_dense.default(select_47);  select_47 = None
        ge_55 = _local_scalar_dense_47 >= 0
        _assert_scalar_47 = torch.ops.aten._assert_scalar.default(ge_55, "Runtime assertion failed for expression u47 >= 0 on node 'ge_47'");  ge_55 = _assert_scalar_47 = None
        all_to_all_single_7 = torch.ops._c10d_functional.all_to_all_single.default(index_4, [_local_scalar_dense_40, _local_scalar_dense_41, _local_scalar_dense_42, _local_scalar_dense_43, _local_scalar_dense_44, _local_scalar_dense_45, _local_scalar_dense_46, _local_scalar_dense_47], [_local_scalar_dense_32, _local_scalar_dense_33, _local_scalar_dense_34, _local_scalar_dense_35, _local_scalar_dense_36, _local_scalar_dense_37, _local_scalar_dense_38, _local_scalar_dense_39], '1033');  index_4 = None
        sym_size_int_8 = torch.ops.aten.sym_size.int(all_to_all_single_7, 0)
        wait_tensor_63 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_7);  all_to_all_single_7 = None
        sym_sum_4 = torch.sym_sum((_local_scalar_dense_40, _local_scalar_dense_41, _local_scalar_dense_42, _local_scalar_dense_43, _local_scalar_dense_44, _local_scalar_dense_45, _local_scalar_dense_46, _local_scalar_dense_47))
        add_154 = sym_sum_4 + 64;  sym_sum_4 = None
        add_155 = add_154 + 8;  add_154 = None
        sub_51 = add_155 - 1;  add_155 = None
        floordiv_2 = sub_51 // 8;  sub_51 = None
        mul_120 = floordiv_2 * 8;  floordiv_2 = None
        cumsum_6 = torch.ops.aten.cumsum.default(wait_tensor_62, 0)
        sub_52 = torch.ops.aten.sub.Tensor(cumsum_6, wait_tensor_62);  cumsum_6 = None
        sum_12 = torch.ops.aten.sum.dim_IntList(view_199, [0]);  view_199 = None
        clamp_min_2 = torch.ops.aten.clamp_min.default(sum_12, 8);  sum_12 = None
        add_156 = torch.ops.aten.add.Tensor(clamp_min_2, 8);  clamp_min_2 = None
        sub_53 = torch.ops.aten.sub.Tensor(add_156, 1);  add_156 = None
        div_13 = torch.ops.aten.div.Tensor_mode(sub_53, 8, rounding_mode = 'floor');  sub_53 = None
        mul_121 = torch.ops.aten.mul.Tensor(div_13, 8);  div_13 = None
        convert_element_type_176 = torch.ops.prims.convert_element_type.default(mul_121, torch.int32);  mul_121 = None
        cumsum_7 = torch.ops.aten.cumsum.default(convert_element_type_176, 0)
        sub_54 = torch.ops.aten.sub.Tensor(cumsum_7, convert_element_type_176);  cumsum_7 = None
        full_46 = torch.ops.aten.full.default([mul_120], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_120 = None
        triton_kernel_wrapper_functional_proxy_2 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 2, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_62, 'start_index_values_ptr': sub_52, 'write_offsets_ptr': sub_54, 'output_ptr': full_46}, tensors_to_clone = ['output_ptr']);  wait_tensor_62 = sub_52 = sub_54 = full_46 = None
        getitem_242 = triton_kernel_wrapper_functional_proxy_2['output_ptr'];  triton_kernel_wrapper_functional_proxy_2 = None
        cat_22 = torch.ops.aten.cat.default([wait_tensor_63, full_default]);  wait_tensor_63 = None
        sym_size_int_9 = torch.ops.aten.sym_size.int(cat_22, 0)
        sym_sum_5 = torch.sym_sum((1, _local_scalar_dense_40, _local_scalar_dense_41, _local_scalar_dense_42, _local_scalar_dense_43, _local_scalar_dense_44, _local_scalar_dense_45, _local_scalar_dense_46, _local_scalar_dense_47))
        index_5 = torch.ops.aten.index.Tensor(cat_22, [getitem_242]);  cat_22 = None
        convert_element_type_178 = torch.ops.prims.convert_element_type.default(primals_65, torch.bfloat16)
        all_gather_into_tensor_53 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_178, 16, '1025');  convert_element_type_178 = None
        wait_tensor_64 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_53);  all_gather_into_tensor_53 = None
        split_13 = torch.ops.aten.split.Tensor(wait_tensor_64, 8);  wait_tensor_64 = None
        getitem_259 = split_13[0]
        getitem_260 = split_13[1]
        getitem_261 = split_13[2]
        getitem_262 = split_13[3]
        getitem_263 = split_13[4]
        getitem_264 = split_13[5]
        getitem_265 = split_13[6]
        getitem_266 = split_13[7]
        getitem_267 = split_13[8]
        getitem_268 = split_13[9]
        getitem_269 = split_13[10]
        getitem_270 = split_13[11]
        getitem_271 = split_13[12]
        getitem_272 = split_13[13]
        getitem_273 = split_13[14]
        getitem_274 = split_13[15];  split_13 = None
        cat_24 = torch.ops.aten.cat.default([getitem_259, getitem_260, getitem_261, getitem_262, getitem_263, getitem_264, getitem_265, getitem_266, getitem_267, getitem_268, getitem_269, getitem_270, getitem_271, getitem_272, getitem_273, getitem_274], 1);  getitem_259 = getitem_260 = getitem_261 = getitem_262 = getitem_263 = getitem_264 = getitem_265 = getitem_266 = getitem_267 = getitem_268 = getitem_269 = getitem_270 = getitem_271 = getitem_272 = getitem_273 = getitem_274 = None
        convert_element_type_180 = torch.ops.prims.convert_element_type.default(primals_66, torch.bfloat16)
        all_gather_into_tensor_55 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_180, 16, '1025');  convert_element_type_180 = None
        wait_tensor_66 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_55);  all_gather_into_tensor_55 = None
        split_14 = torch.ops.aten.split.Tensor(wait_tensor_66, 8);  wait_tensor_66 = None
        getitem_275 = split_14[0]
        getitem_276 = split_14[1]
        getitem_277 = split_14[2]
        getitem_278 = split_14[3]
        getitem_279 = split_14[4]
        getitem_280 = split_14[5]
        getitem_281 = split_14[6]
        getitem_282 = split_14[7]
        getitem_283 = split_14[8]
        getitem_284 = split_14[9]
        getitem_285 = split_14[10]
        getitem_286 = split_14[11]
        getitem_287 = split_14[12]
        getitem_288 = split_14[13]
        getitem_289 = split_14[14]
        getitem_290 = split_14[15];  split_14 = None
        cat_25 = torch.ops.aten.cat.default([getitem_275, getitem_276, getitem_277, getitem_278, getitem_279, getitem_280, getitem_281, getitem_282, getitem_283, getitem_284, getitem_285, getitem_286, getitem_287, getitem_288, getitem_289, getitem_290], 1);  getitem_275 = getitem_276 = getitem_277 = getitem_278 = getitem_279 = getitem_280 = getitem_281 = getitem_282 = getitem_283 = getitem_284 = getitem_285 = getitem_286 = getitem_287 = getitem_288 = getitem_289 = getitem_290 = None
        convert_element_type_181 = torch.ops.prims.convert_element_type.default(primals_67, torch.bfloat16)
        all_gather_into_tensor_56 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_181, 16, '1025');  convert_element_type_181 = None
        wait_tensor_67 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_56);  all_gather_into_tensor_56 = None
        split_15 = torch.ops.aten.split.Tensor(wait_tensor_67, 8);  wait_tensor_67 = None
        getitem_291 = split_15[0]
        getitem_292 = split_15[1]
        getitem_293 = split_15[2]
        getitem_294 = split_15[3]
        getitem_295 = split_15[4]
        getitem_296 = split_15[5]
        getitem_297 = split_15[6]
        getitem_298 = split_15[7]
        getitem_299 = split_15[8]
        getitem_300 = split_15[9]
        getitem_301 = split_15[10]
        getitem_302 = split_15[11]
        getitem_303 = split_15[12]
        getitem_304 = split_15[13]
        getitem_305 = split_15[14]
        getitem_306 = split_15[15];  split_15 = None
        cat_26 = torch.ops.aten.cat.default([getitem_291, getitem_292, getitem_293, getitem_294, getitem_295, getitem_296, getitem_297, getitem_298, getitem_299, getitem_300, getitem_301, getitem_302, getitem_303, getitem_304, getitem_305, getitem_306], 1);  getitem_291 = getitem_292 = getitem_293 = getitem_294 = getitem_295 = getitem_296 = getitem_297 = getitem_298 = getitem_299 = getitem_300 = getitem_301 = getitem_302 = getitem_303 = getitem_304 = getitem_305 = getitem_306 = None
        cumsum_8 = torch.ops.aten.cumsum.default(convert_element_type_176, 0, dtype = torch.int32);  convert_element_type_176 = None
        permute_50 = torch.ops.aten.permute.default(cat_24, [0, 2, 1]);  cat_24 = None
        _grouped_mm_6 = torch.ops.aten._grouped_mm.default(index_5, permute_50, cumsum_8)
        convert_element_type_184 = torch.ops.prims.convert_element_type.default(_grouped_mm_6, torch.float32)
        neg_5 = torch.ops.aten.neg.default(convert_element_type_184)
        exp_8 = torch.ops.aten.exp.default(neg_5);  neg_5 = None
        add_168 = torch.ops.aten.add.Tensor(exp_8, 1);  exp_8 = None
        div_14 = torch.ops.aten.div.Tensor(convert_element_type_184, add_168);  convert_element_type_184 = add_168 = None
        convert_element_type_185 = torch.ops.prims.convert_element_type.default(div_14, torch.bfloat16);  div_14 = None
        permute_51 = torch.ops.aten.permute.default(cat_26, [0, 2, 1]);  cat_26 = None
        _grouped_mm_7 = torch.ops.aten._grouped_mm.default(index_5, permute_51, cumsum_8)
        mul_133 = torch.ops.aten.mul.Tensor(convert_element_type_185, _grouped_mm_7);  convert_element_type_185 = None
        permute_52 = torch.ops.aten.permute.default(cat_25, [0, 2, 1]);  cat_25 = None
        _grouped_mm_8 = torch.ops.aten._grouped_mm.default(mul_133, permute_52, cumsum_8)
        empty_2 = torch.ops.aten.empty.memory_format([sym_size_int_9, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_4 = torch.ops.aten.index_put.default(empty_2, [getitem_242], _grouped_mm_8);  empty_2 = _grouped_mm_8 = None
        slice_23 = torch.ops.aten.slice.Tensor(index_put_4, 0, 0, -1);  index_put_4 = None
        all_to_all_single_8 = torch.ops._c10d_functional.all_to_all_single.default(slice_23, [_local_scalar_dense_32, _local_scalar_dense_33, _local_scalar_dense_34, _local_scalar_dense_35, _local_scalar_dense_36, _local_scalar_dense_37, _local_scalar_dense_38, _local_scalar_dense_39], [_local_scalar_dense_40, _local_scalar_dense_41, _local_scalar_dense_42, _local_scalar_dense_43, _local_scalar_dense_44, _local_scalar_dense_45, _local_scalar_dense_46, _local_scalar_dense_47], '1033');  slice_23 = None
        wait_tensor_70 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_8);  all_to_all_single_8 = None
        convert_element_type_186 = torch.ops.prims.convert_element_type.default(primals_68, torch.bfloat16)
        all_gather_into_tensor_59 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_186, 128, '0');  convert_element_type_186 = None
        wait_tensor_71 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_59);  all_gather_into_tensor_59 = None
        permute_53 = torch.ops.aten.permute.default(wait_tensor_71, [1, 0]);  wait_tensor_71 = None
        mm_28 = torch.ops.aten.mm.default(view_192, permute_53);  permute_53 = None
        convert_element_type_189 = torch.ops.prims.convert_element_type.default(mm_28, torch.float32)
        neg_6 = torch.ops.aten.neg.default(convert_element_type_189)
        exp_9 = torch.ops.aten.exp.default(neg_6);  neg_6 = None
        add_204 = torch.ops.aten.add.Tensor(exp_9, 1);  exp_9 = None
        div_15 = torch.ops.aten.div.Tensor(convert_element_type_189, add_204);  convert_element_type_189 = add_204 = None
        convert_element_type_190 = torch.ops.prims.convert_element_type.default(div_15, torch.bfloat16);  div_15 = None
        convert_element_type_191 = torch.ops.prims.convert_element_type.default(primals_69, torch.bfloat16)
        all_gather_into_tensor_60 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_191, 128, '0');  convert_element_type_191 = None
        wait_tensor_72 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_60);  all_gather_into_tensor_60 = None
        permute_54 = torch.ops.aten.permute.default(wait_tensor_72, [1, 0]);  wait_tensor_72 = None
        mm_29 = torch.ops.aten.mm.default(view_192, permute_54);  permute_54 = None
        mul_153 = torch.ops.aten.mul.Tensor(convert_element_type_190, mm_29);  convert_element_type_190 = None
        convert_element_type_194 = torch.ops.prims.convert_element_type.default(primals_70, torch.bfloat16)
        all_gather_into_tensor_61 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_194, 128, '0');  convert_element_type_194 = None
        wait_tensor_73 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_61);  all_gather_into_tensor_61 = None
        permute_55 = torch.ops.aten.permute.default(wait_tensor_73, [1, 0]);  wait_tensor_73 = None
        mm_30 = torch.ops.aten.mm.default(mul_153, permute_55);  permute_55 = None
        index_put_5 = torch.ops.aten.index_put.default(full_default_1, [getitem_241], wait_tensor_70);  wait_tensor_70 = None
        view_232 = torch.ops.aten.view.default(mul_115, [-1, 1, 6]);  mul_115 = None
        view_233 = torch.ops.aten.view.default(index_put_5, [-1, 6, 2048]);  index_put_5 = None
        convert_element_type_197 = torch.ops.prims.convert_element_type.default(view_233, torch.float32);  view_233 = None
        bmm_2 = torch.ops.aten.bmm.default(view_232, convert_element_type_197)
        convert_element_type_198 = torch.ops.prims.convert_element_type.default(bmm_2, torch.bfloat16);  bmm_2 = None
        squeeze_2 = torch.ops.aten.squeeze.dim(convert_element_type_198, 1);  convert_element_type_198 = None
        add_208 = torch.ops.aten.add.Tensor(mm_30, squeeze_2);  mm_30 = squeeze_2 = None
        view_234 = torch.ops.aten.view.default(add_208, [2, 4096, 2048]);  add_208 = None
        add_209 = torch.ops.aten.add.Tensor(add_144, view_234);  view_234 = None
        convert_element_type_199 = torch.ops.prims.convert_element_type.default(primals_71, torch.bfloat16)
        all_gather_into_tensor_62 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_199, 128, '0');  convert_element_type_199 = None
        wait_tensor_74 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_62);  all_gather_into_tensor_62 = None
        convert_element_type_200 = torch.ops.prims.convert_element_type.default(add_209, torch.float32)
        pow_13 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_200, 2)
        mean_12 = torch.ops.aten.mean.dim(pow_13, [2], True);  pow_13 = None
        add_210 = torch.ops.aten.add.Scalar(mean_12, 1e-05);  mean_12 = None
        rsqrt_12 = torch.ops.aten.rsqrt.default(add_210);  add_210 = None
        mul_156 = torch.ops.aten.mul.Tensor(convert_element_type_200, rsqrt_12);  convert_element_type_200 = None
        mul_157 = torch.ops.aten.mul.Tensor(mul_156, wait_tensor_74);  mul_156 = wait_tensor_74 = None
        convert_element_type_201 = torch.ops.prims.convert_element_type.default(mul_157, torch.bfloat16);  mul_157 = None
        convert_element_type_202 = torch.ops.prims.convert_element_type.default(primals_72, torch.bfloat16)
        all_gather_into_tensor_63 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_202, 128, '0');  convert_element_type_202 = None
        wait_tensor_75 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_63);  all_gather_into_tensor_63 = None
        permute_56 = torch.ops.aten.permute.default(wait_tensor_75, [1, 0]);  wait_tensor_75 = None
        view_237 = torch.ops.aten.view.default(convert_element_type_201, [8192, 2048]);  convert_element_type_201 = None
        mm_31 = torch.ops.aten.mm.default(view_237, permute_56);  permute_56 = None
        view_238 = torch.ops.aten.view.default(mm_31, [2, 4096, 3072]);  mm_31 = None
        view_239 = torch.ops.aten.view.default(view_238, [2, 4096, -1, 192]);  view_238 = None
        split_with_sizes_12 = torch.ops.aten.split_with_sizes.default(view_239, [128, 64], -1);  view_239 = None
        getitem_339 = split_with_sizes_12[0]
        getitem_340 = split_with_sizes_12[1];  split_with_sizes_12 = None
        convert_element_type_205 = torch.ops.prims.convert_element_type.default(getitem_340, torch.float32);  getitem_340 = None
        view_240 = torch.ops.aten.view.default(convert_element_type_205, [2, 4096, 16, -1, 2]);  convert_element_type_205 = None
        view_as_complex_8 = torch.ops.aten.view_as_complex.default(view_240);  view_240 = None
        mul_158 = torch.ops.aten.mul.Tensor(view_as_complex_8, view_7);  view_as_complex_8 = None
        view_as_real_8 = torch.ops.aten.view_as_real.default(mul_158);  mul_158 = None
        view_242 = torch.ops.aten.view.default(view_as_real_8, [2, 4096, 16, 64]);  view_as_real_8 = None
        convert_element_type_206 = torch.ops.prims.convert_element_type.default(view_242, torch.bfloat16);  view_242 = None
        cat_29 = torch.ops.aten.cat.default([getitem_339, convert_element_type_206], -1);  getitem_339 = convert_element_type_206 = None
        convert_element_type_207 = torch.ops.prims.convert_element_type.default(primals_73, torch.bfloat16)
        all_gather_into_tensor_64 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_207, 128, '0');  convert_element_type_207 = None
        wait_tensor_76 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_64);  all_gather_into_tensor_64 = None
        slice_25 = torch.ops.aten.slice.Tensor(wait_tensor_76, 0, 0, 576);  wait_tensor_76 = None
        permute_57 = torch.ops.aten.permute.default(slice_25, [1, 0]);  slice_25 = None
        mm_32 = torch.ops.aten.mm.default(view_237, permute_57);  permute_57 = None
        view_245 = torch.ops.aten.view.default(mm_32, [2, 4096, 576]);  mm_32 = None
        split_with_sizes_13 = torch.ops.aten.split_with_sizes.default(view_245, [512, 64], -1);  view_245 = None
        getitem_341 = split_with_sizes_13[0]
        getitem_342 = split_with_sizes_13[1];  split_with_sizes_13 = None
        unsqueeze_7 = torch.ops.aten.unsqueeze.default(getitem_342, 2);  getitem_342 = None
        convert_element_type_210 = torch.ops.prims.convert_element_type.default(unsqueeze_7, torch.float32);  unsqueeze_7 = None
        view_246 = torch.ops.aten.view.default(convert_element_type_210, [2, 4096, 1, -1, 2]);  convert_element_type_210 = None
        view_as_complex_9 = torch.ops.aten.view_as_complex.default(view_246);  view_246 = None
        mul_159 = torch.ops.aten.mul.Tensor(view_as_complex_9, view_7);  view_as_complex_9 = None
        view_as_real_9 = torch.ops.aten.view_as_real.default(mul_159);  mul_159 = None
        view_248 = torch.ops.aten.view.default(view_as_real_9, [2, 4096, 1, 64]);  view_as_real_9 = None
        convert_element_type_211 = torch.ops.prims.convert_element_type.default(view_248, torch.bfloat16);  view_248 = None
        convert_element_type_212 = torch.ops.prims.convert_element_type.default(primals_74, torch.bfloat16)
        all_gather_into_tensor_65 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_212, 128, '0');  convert_element_type_212 = None
        wait_tensor_77 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_65);  all_gather_into_tensor_65 = None
        convert_element_type_213 = torch.ops.prims.convert_element_type.default(getitem_341, torch.float32)
        pow_14 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_213, 2)
        mean_13 = torch.ops.aten.mean.dim(pow_14, [2], True);  pow_14 = None
        add_211 = torch.ops.aten.add.Scalar(mean_13, 1e-05);  mean_13 = None
        rsqrt_13 = torch.ops.aten.rsqrt.default(add_211);  add_211 = None
        mul_160 = torch.ops.aten.mul.Tensor(convert_element_type_213, rsqrt_13);  convert_element_type_213 = None
        mul_161 = torch.ops.aten.mul.Tensor(mul_160, wait_tensor_77);  mul_160 = wait_tensor_77 = None
        convert_element_type_214 = torch.ops.prims.convert_element_type.default(mul_161, torch.bfloat16);  mul_161 = None
        convert_element_type_215 = torch.ops.prims.convert_element_type.default(primals_75, torch.bfloat16)
        all_gather_into_tensor_66 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_215, 128, '0');  convert_element_type_215 = None
        wait_tensor_78 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_66);  all_gather_into_tensor_66 = None
        permute_58 = torch.ops.aten.permute.default(wait_tensor_78, [1, 0]);  wait_tensor_78 = None
        view_251 = torch.ops.aten.view.default(convert_element_type_214, [8192, 512]);  convert_element_type_214 = None
        mm_33 = torch.ops.aten.mm.default(view_251, permute_58);  permute_58 = None
        view_252 = torch.ops.aten.view.default(mm_33, [2, 4096, 4096]);  mm_33 = None
        view_253 = torch.ops.aten.view.default(view_252, [2, 4096, -1, 256]);  view_252 = None
        split_with_sizes_14 = torch.ops.aten.split_with_sizes.default(view_253, [128, 128], -1);  view_253 = None
        getitem_343 = split_with_sizes_14[0]
        getitem_344 = split_with_sizes_14[1];  split_with_sizes_14 = None
        expand_4 = torch.ops.aten.expand.default(convert_element_type_211, [-1, -1, 16, -1]);  convert_element_type_211 = None
        cat_30 = torch.ops.aten.cat.default([getitem_343, expand_4], -1);  getitem_343 = expand_4 = None
        permute_59 = torch.ops.aten.permute.default(cat_29, [0, 2, 1, 3]);  cat_29 = None
        permute_60 = torch.ops.aten.permute.default(cat_30, [0, 2, 1, 3]);  cat_30 = None
        permute_61 = torch.ops.aten.permute.default(getitem_344, [0, 2, 1, 3]);  getitem_344 = None
        sdpa_score4 = self.sdpa_score4
        sdpa_mask4 = self.sdpa_mask4
        flex_attention_4 = torch.ops.higher_order.flex_attention(permute_59, permute_60, permute_61, sdpa_score4, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask4), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score4 = sdpa_mask4 = None
        getitem_345 = flex_attention_4[0]
        getitem_346 = flex_attention_4[1];  flex_attention_4 = None
        permute_62 = torch.ops.aten.permute.default(getitem_345, [0, 2, 1, 3])
        view_254 = torch.ops.aten.view.default(permute_62, [2, 4096, -1]);  permute_62 = None
        convert_element_type_218 = torch.ops.prims.convert_element_type.default(primals_76, torch.bfloat16)
        all_gather_into_tensor_67 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_218, 128, '0');  convert_element_type_218 = None
        wait_tensor_79 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_67);  all_gather_into_tensor_67 = None
        permute_63 = torch.ops.aten.permute.default(wait_tensor_79, [1, 0]);  wait_tensor_79 = None
        view_256 = torch.ops.aten.view.default(view_254, [8192, 2048]);  view_254 = None
        mm_34 = torch.ops.aten.mm.default(view_256, permute_63);  view_256 = permute_63 = None
        view_257 = torch.ops.aten.view.default(mm_34, [2, 4096, 2048]);  mm_34 = None
        add_212 = torch.ops.aten.add.Tensor(add_209, view_257);  view_257 = None
        convert_element_type_221 = torch.ops.prims.convert_element_type.default(primals_77, torch.bfloat16)
        all_gather_into_tensor_68 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_221, 128, '0');  convert_element_type_221 = None
        wait_tensor_80 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_68);  all_gather_into_tensor_68 = None
        convert_element_type_222 = torch.ops.prims.convert_element_type.default(add_212, torch.float32)
        pow_15 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_222, 2)
        mean_14 = torch.ops.aten.mean.dim(pow_15, [2], True);  pow_15 = None
        add_213 = torch.ops.aten.add.Scalar(mean_14, 1e-05);  mean_14 = None
        rsqrt_14 = torch.ops.aten.rsqrt.default(add_213);  add_213 = None
        mul_162 = torch.ops.aten.mul.Tensor(convert_element_type_222, rsqrt_14);  convert_element_type_222 = None
        mul_163 = torch.ops.aten.mul.Tensor(mul_162, wait_tensor_80);  mul_162 = wait_tensor_80 = None
        convert_element_type_223 = torch.ops.prims.convert_element_type.default(mul_163, torch.bfloat16);  mul_163 = None
        view_259 = torch.ops.aten.view.default(convert_element_type_223, [-1, 2048]);  convert_element_type_223 = None
        convert_element_type_224 = torch.ops.prims.convert_element_type.default(primals_79, torch.bfloat16)
        all_gather_into_tensor_69 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_224, 128, '0');  convert_element_type_224 = None
        wait_tensor_81 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_69);  all_gather_into_tensor_69 = None
        slice_27 = torch.ops.aten.slice.Tensor(wait_tensor_81, 0, 0, 64);  wait_tensor_81 = None
        permute_64 = torch.ops.aten.permute.default(slice_27, [1, 0]);  slice_27 = None
        mm_35 = torch.ops.aten.mm.default(view_259, permute_64);  permute_64 = None
        convert_element_type_227 = torch.ops.prims.convert_element_type.default(mm_35, torch.float32)
        amax_3 = torch.ops.aten.amax.default(convert_element_type_227, [1], True)
        sub_72 = torch.ops.aten.sub.Tensor(convert_element_type_227, amax_3);  convert_element_type_227 = None
        exp_10 = torch.ops.aten.exp.default(sub_72);  sub_72 = None
        sum_13 = torch.ops.aten.sum.dim_IntList(exp_10, [1], True)
        div_16 = torch.ops.aten.div.Tensor(exp_10, sum_13);  exp_10 = None
        add_214 = torch.ops.aten.add.Tensor(div_16, primals_78);  primals_78 = None
        topk_3 = torch.ops.aten.topk.default(add_214, 6, -1, True, False);  add_214 = None
        getitem_349 = topk_3[1];  topk_3 = None
        gather_3 = torch.ops.aten.gather.default(div_16, 1, getitem_349);  div_16 = None
        mul_164 = torch.ops.aten.mul.Tensor(gather_3, 1.0);  gather_3 = None
        view_261 = torch.ops.aten.view.default(getitem_349, [-1])
        histc_6 = torch.ops.aten.histc.default(view_261, 64, 0, 64)
        add_215 = torch.ops.aten.add.Tensor(primals_80, histc_6)
        sort_3 = torch.ops.aten.sort.stable(view_261, stable = True);  view_261 = None
        getitem_351 = sort_3[1];  sort_3 = None
        div_17 = torch.ops.aten.div.Tensor_mode(getitem_351, 6, rounding_mode = 'floor')
        index_6 = torch.ops.aten.index.Tensor(view_259, [div_17])
        all_to_all_single_9 = torch.ops._c10d_functional.all_to_all_single.default(histc_6, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_82 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_9);  all_to_all_single_9 = None
        wait_tensor_83 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_82);  wait_tensor_82 = None
        view_265 = torch.ops.aten.view.default(histc_6, [8, -1]);  histc_6 = None
        sum_14 = torch.ops.aten.sum.dim_IntList(view_265, [1]);  view_265 = None
        device_put_6 = torch.ops.prims.device_put.default(sum_14, device(type='cpu'), True);  sum_14 = None
        view_266 = torch.ops.aten.view.default(wait_tensor_83, [8, -1])
        sum_15 = torch.ops.aten.sum.dim_IntList(view_266, [1])
        device_put_7 = torch.ops.prims.device_put.default(sum_15, device(type='cpu'));  sum_15 = None
        select_48 = torch.ops.aten.select.int(device_put_6, 0, 0)
        _local_scalar_dense_48 = torch.ops.aten._local_scalar_dense.default(select_48);  select_48 = None
        ge_60 = _local_scalar_dense_48 >= 0
        _assert_scalar_48 = torch.ops.aten._assert_scalar.default(ge_60, "Runtime assertion failed for expression u48 >= 0 on node 'ge_48'");  ge_60 = _assert_scalar_48 = None
        select_49 = torch.ops.aten.select.int(device_put_6, 0, 1)
        _local_scalar_dense_49 = torch.ops.aten._local_scalar_dense.default(select_49);  select_49 = None
        ge_61 = _local_scalar_dense_49 >= 0
        _assert_scalar_49 = torch.ops.aten._assert_scalar.default(ge_61, "Runtime assertion failed for expression u49 >= 0 on node 'ge_49'");  ge_61 = _assert_scalar_49 = None
        select_50 = torch.ops.aten.select.int(device_put_6, 0, 2)
        _local_scalar_dense_50 = torch.ops.aten._local_scalar_dense.default(select_50);  select_50 = None
        ge_62 = _local_scalar_dense_50 >= 0
        _assert_scalar_50 = torch.ops.aten._assert_scalar.default(ge_62, "Runtime assertion failed for expression u50 >= 0 on node 'ge_50'");  ge_62 = _assert_scalar_50 = None
        select_51 = torch.ops.aten.select.int(device_put_6, 0, 3)
        _local_scalar_dense_51 = torch.ops.aten._local_scalar_dense.default(select_51);  select_51 = None
        ge_63 = _local_scalar_dense_51 >= 0
        _assert_scalar_51 = torch.ops.aten._assert_scalar.default(ge_63, "Runtime assertion failed for expression u51 >= 0 on node 'ge_51'");  ge_63 = _assert_scalar_51 = None
        select_52 = torch.ops.aten.select.int(device_put_6, 0, 4)
        _local_scalar_dense_52 = torch.ops.aten._local_scalar_dense.default(select_52);  select_52 = None
        ge_64 = _local_scalar_dense_52 >= 0
        _assert_scalar_52 = torch.ops.aten._assert_scalar.default(ge_64, "Runtime assertion failed for expression u52 >= 0 on node 'ge_52'");  ge_64 = _assert_scalar_52 = None
        select_53 = torch.ops.aten.select.int(device_put_6, 0, 5)
        _local_scalar_dense_53 = torch.ops.aten._local_scalar_dense.default(select_53);  select_53 = None
        ge_65 = _local_scalar_dense_53 >= 0
        _assert_scalar_53 = torch.ops.aten._assert_scalar.default(ge_65, "Runtime assertion failed for expression u53 >= 0 on node 'ge_53'");  ge_65 = _assert_scalar_53 = None
        select_54 = torch.ops.aten.select.int(device_put_6, 0, 6)
        _local_scalar_dense_54 = torch.ops.aten._local_scalar_dense.default(select_54);  select_54 = None
        ge_66 = _local_scalar_dense_54 >= 0
        _assert_scalar_54 = torch.ops.aten._assert_scalar.default(ge_66, "Runtime assertion failed for expression u54 >= 0 on node 'ge_54'");  ge_66 = _assert_scalar_54 = None
        select_55 = torch.ops.aten.select.int(device_put_6, 0, 7);  device_put_6 = None
        _local_scalar_dense_55 = torch.ops.aten._local_scalar_dense.default(select_55);  select_55 = None
        ge_67 = _local_scalar_dense_55 >= 0
        _assert_scalar_55 = torch.ops.aten._assert_scalar.default(ge_67, "Runtime assertion failed for expression u55 >= 0 on node 'ge_55'");  ge_67 = _assert_scalar_55 = None
        select_56 = torch.ops.aten.select.int(device_put_7, 0, 0)
        _local_scalar_dense_56 = torch.ops.aten._local_scalar_dense.default(select_56);  select_56 = None
        ge_68 = _local_scalar_dense_56 >= 0
        _assert_scalar_56 = torch.ops.aten._assert_scalar.default(ge_68, "Runtime assertion failed for expression u56 >= 0 on node 'ge_56'");  ge_68 = _assert_scalar_56 = None
        select_57 = torch.ops.aten.select.int(device_put_7, 0, 1)
        _local_scalar_dense_57 = torch.ops.aten._local_scalar_dense.default(select_57);  select_57 = None
        ge_69 = _local_scalar_dense_57 >= 0
        _assert_scalar_57 = torch.ops.aten._assert_scalar.default(ge_69, "Runtime assertion failed for expression u57 >= 0 on node 'ge_57'");  ge_69 = _assert_scalar_57 = None
        select_58 = torch.ops.aten.select.int(device_put_7, 0, 2)
        _local_scalar_dense_58 = torch.ops.aten._local_scalar_dense.default(select_58);  select_58 = None
        ge_70 = _local_scalar_dense_58 >= 0
        _assert_scalar_58 = torch.ops.aten._assert_scalar.default(ge_70, "Runtime assertion failed for expression u58 >= 0 on node 'ge_58'");  ge_70 = _assert_scalar_58 = None
        select_59 = torch.ops.aten.select.int(device_put_7, 0, 3)
        _local_scalar_dense_59 = torch.ops.aten._local_scalar_dense.default(select_59);  select_59 = None
        ge_71 = _local_scalar_dense_59 >= 0
        _assert_scalar_59 = torch.ops.aten._assert_scalar.default(ge_71, "Runtime assertion failed for expression u59 >= 0 on node 'ge_59'");  ge_71 = _assert_scalar_59 = None
        select_60 = torch.ops.aten.select.int(device_put_7, 0, 4)
        _local_scalar_dense_60 = torch.ops.aten._local_scalar_dense.default(select_60);  select_60 = None
        ge_72 = _local_scalar_dense_60 >= 0
        _assert_scalar_60 = torch.ops.aten._assert_scalar.default(ge_72, "Runtime assertion failed for expression u60 >= 0 on node 'ge_60'");  ge_72 = _assert_scalar_60 = None
        select_61 = torch.ops.aten.select.int(device_put_7, 0, 5)
        _local_scalar_dense_61 = torch.ops.aten._local_scalar_dense.default(select_61);  select_61 = None
        ge_73 = _local_scalar_dense_61 >= 0
        _assert_scalar_61 = torch.ops.aten._assert_scalar.default(ge_73, "Runtime assertion failed for expression u61 >= 0 on node 'ge_61'");  ge_73 = _assert_scalar_61 = None
        select_62 = torch.ops.aten.select.int(device_put_7, 0, 6)
        _local_scalar_dense_62 = torch.ops.aten._local_scalar_dense.default(select_62);  select_62 = None
        ge_74 = _local_scalar_dense_62 >= 0
        _assert_scalar_62 = torch.ops.aten._assert_scalar.default(ge_74, "Runtime assertion failed for expression u62 >= 0 on node 'ge_62'");  ge_74 = _assert_scalar_62 = None
        select_63 = torch.ops.aten.select.int(device_put_7, 0, 7);  device_put_7 = None
        _local_scalar_dense_63 = torch.ops.aten._local_scalar_dense.default(select_63);  select_63 = None
        ge_75 = _local_scalar_dense_63 >= 0
        _assert_scalar_63 = torch.ops.aten._assert_scalar.default(ge_75, "Runtime assertion failed for expression u63 >= 0 on node 'ge_63'");  ge_75 = _assert_scalar_63 = None
        all_to_all_single_10 = torch.ops._c10d_functional.all_to_all_single.default(index_6, [_local_scalar_dense_56, _local_scalar_dense_57, _local_scalar_dense_58, _local_scalar_dense_59, _local_scalar_dense_60, _local_scalar_dense_61, _local_scalar_dense_62, _local_scalar_dense_63], [_local_scalar_dense_48, _local_scalar_dense_49, _local_scalar_dense_50, _local_scalar_dense_51, _local_scalar_dense_52, _local_scalar_dense_53, _local_scalar_dense_54, _local_scalar_dense_55], '1033');  index_6 = None
        sym_size_int_12 = torch.ops.aten.sym_size.int(all_to_all_single_10, 0)
        wait_tensor_84 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_10);  all_to_all_single_10 = None
        sym_sum_6 = torch.sym_sum((_local_scalar_dense_56, _local_scalar_dense_57, _local_scalar_dense_58, _local_scalar_dense_59, _local_scalar_dense_60, _local_scalar_dense_61, _local_scalar_dense_62, _local_scalar_dense_63))
        add_222 = sym_sum_6 + 64;  sym_sum_6 = None
        add_223 = add_222 + 8;  add_222 = None
        sub_75 = add_223 - 1;  add_223 = None
        floordiv_3 = sub_75 // 8;  sub_75 = None
        mul_169 = floordiv_3 * 8;  floordiv_3 = None
        cumsum_9 = torch.ops.aten.cumsum.default(wait_tensor_83, 0)
        sub_76 = torch.ops.aten.sub.Tensor(cumsum_9, wait_tensor_83);  cumsum_9 = None
        sum_16 = torch.ops.aten.sum.dim_IntList(view_266, [0]);  view_266 = None
        clamp_min_3 = torch.ops.aten.clamp_min.default(sum_16, 8);  sum_16 = None
        add_224 = torch.ops.aten.add.Tensor(clamp_min_3, 8);  clamp_min_3 = None
        sub_77 = torch.ops.aten.sub.Tensor(add_224, 1);  add_224 = None
        div_18 = torch.ops.aten.div.Tensor_mode(sub_77, 8, rounding_mode = 'floor');  sub_77 = None
        mul_170 = torch.ops.aten.mul.Tensor(div_18, 8);  div_18 = None
        convert_element_type_230 = torch.ops.prims.convert_element_type.default(mul_170, torch.int32);  mul_170 = None
        cumsum_10 = torch.ops.aten.cumsum.default(convert_element_type_230, 0)
        sub_78 = torch.ops.aten.sub.Tensor(cumsum_10, convert_element_type_230);  cumsum_10 = None
        full_59 = torch.ops.aten.full.default([mul_169], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_169 = None
        triton_kernel_wrapper_functional_proxy_3 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 3, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_83, 'start_index_values_ptr': sub_76, 'write_offsets_ptr': sub_78, 'output_ptr': full_59}, tensors_to_clone = ['output_ptr']);  wait_tensor_83 = sub_76 = sub_78 = full_59 = None
        getitem_352 = triton_kernel_wrapper_functional_proxy_3['output_ptr'];  triton_kernel_wrapper_functional_proxy_3 = None
        cat_31 = torch.ops.aten.cat.default([wait_tensor_84, full_default]);  wait_tensor_84 = None
        sym_size_int_13 = torch.ops.aten.sym_size.int(cat_31, 0)
        sym_sum_7 = torch.sym_sum((1, _local_scalar_dense_56, _local_scalar_dense_57, _local_scalar_dense_58, _local_scalar_dense_59, _local_scalar_dense_60, _local_scalar_dense_61, _local_scalar_dense_62, _local_scalar_dense_63))
        index_7 = torch.ops.aten.index.Tensor(cat_31, [getitem_352]);  cat_31 = None
        convert_element_type_232 = torch.ops.prims.convert_element_type.default(primals_81, torch.bfloat16)
        all_gather_into_tensor_70 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_232, 16, '1025');  convert_element_type_232 = None
        wait_tensor_85 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_70);  all_gather_into_tensor_70 = None
        split_19 = torch.ops.aten.split.Tensor(wait_tensor_85, 8);  wait_tensor_85 = None
        getitem_369 = split_19[0]
        getitem_370 = split_19[1]
        getitem_371 = split_19[2]
        getitem_372 = split_19[3]
        getitem_373 = split_19[4]
        getitem_374 = split_19[5]
        getitem_375 = split_19[6]
        getitem_376 = split_19[7]
        getitem_377 = split_19[8]
        getitem_378 = split_19[9]
        getitem_379 = split_19[10]
        getitem_380 = split_19[11]
        getitem_381 = split_19[12]
        getitem_382 = split_19[13]
        getitem_383 = split_19[14]
        getitem_384 = split_19[15];  split_19 = None
        cat_33 = torch.ops.aten.cat.default([getitem_369, getitem_370, getitem_371, getitem_372, getitem_373, getitem_374, getitem_375, getitem_376, getitem_377, getitem_378, getitem_379, getitem_380, getitem_381, getitem_382, getitem_383, getitem_384], 1);  getitem_369 = getitem_370 = getitem_371 = getitem_372 = getitem_373 = getitem_374 = getitem_375 = getitem_376 = getitem_377 = getitem_378 = getitem_379 = getitem_380 = getitem_381 = getitem_382 = getitem_383 = getitem_384 = None
        convert_element_type_234 = torch.ops.prims.convert_element_type.default(primals_82, torch.bfloat16)
        all_gather_into_tensor_72 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_234, 16, '1025');  convert_element_type_234 = None
        wait_tensor_87 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_72);  all_gather_into_tensor_72 = None
        split_20 = torch.ops.aten.split.Tensor(wait_tensor_87, 8);  wait_tensor_87 = None
        getitem_385 = split_20[0]
        getitem_386 = split_20[1]
        getitem_387 = split_20[2]
        getitem_388 = split_20[3]
        getitem_389 = split_20[4]
        getitem_390 = split_20[5]
        getitem_391 = split_20[6]
        getitem_392 = split_20[7]
        getitem_393 = split_20[8]
        getitem_394 = split_20[9]
        getitem_395 = split_20[10]
        getitem_396 = split_20[11]
        getitem_397 = split_20[12]
        getitem_398 = split_20[13]
        getitem_399 = split_20[14]
        getitem_400 = split_20[15];  split_20 = None
        cat_34 = torch.ops.aten.cat.default([getitem_385, getitem_386, getitem_387, getitem_388, getitem_389, getitem_390, getitem_391, getitem_392, getitem_393, getitem_394, getitem_395, getitem_396, getitem_397, getitem_398, getitem_399, getitem_400], 1);  getitem_385 = getitem_386 = getitem_387 = getitem_388 = getitem_389 = getitem_390 = getitem_391 = getitem_392 = getitem_393 = getitem_394 = getitem_395 = getitem_396 = getitem_397 = getitem_398 = getitem_399 = getitem_400 = None
        convert_element_type_235 = torch.ops.prims.convert_element_type.default(primals_83, torch.bfloat16)
        all_gather_into_tensor_73 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_235, 16, '1025');  convert_element_type_235 = None
        wait_tensor_88 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_73);  all_gather_into_tensor_73 = None
        split_21 = torch.ops.aten.split.Tensor(wait_tensor_88, 8);  wait_tensor_88 = None
        getitem_401 = split_21[0]
        getitem_402 = split_21[1]
        getitem_403 = split_21[2]
        getitem_404 = split_21[3]
        getitem_405 = split_21[4]
        getitem_406 = split_21[5]
        getitem_407 = split_21[6]
        getitem_408 = split_21[7]
        getitem_409 = split_21[8]
        getitem_410 = split_21[9]
        getitem_411 = split_21[10]
        getitem_412 = split_21[11]
        getitem_413 = split_21[12]
        getitem_414 = split_21[13]
        getitem_415 = split_21[14]
        getitem_416 = split_21[15];  split_21 = None
        cat_35 = torch.ops.aten.cat.default([getitem_401, getitem_402, getitem_403, getitem_404, getitem_405, getitem_406, getitem_407, getitem_408, getitem_409, getitem_410, getitem_411, getitem_412, getitem_413, getitem_414, getitem_415, getitem_416], 1);  getitem_401 = getitem_402 = getitem_403 = getitem_404 = getitem_405 = getitem_406 = getitem_407 = getitem_408 = getitem_409 = getitem_410 = getitem_411 = getitem_412 = getitem_413 = getitem_414 = getitem_415 = getitem_416 = None
        cumsum_11 = torch.ops.aten.cumsum.default(convert_element_type_230, 0, dtype = torch.int32);  convert_element_type_230 = None
        permute_65 = torch.ops.aten.permute.default(cat_33, [0, 2, 1]);  cat_33 = None
        _grouped_mm_9 = torch.ops.aten._grouped_mm.default(index_7, permute_65, cumsum_11)
        convert_element_type_238 = torch.ops.prims.convert_element_type.default(_grouped_mm_9, torch.float32)
        neg_7 = torch.ops.aten.neg.default(convert_element_type_238)
        exp_11 = torch.ops.aten.exp.default(neg_7);  neg_7 = None
        add_236 = torch.ops.aten.add.Tensor(exp_11, 1);  exp_11 = None
        div_19 = torch.ops.aten.div.Tensor(convert_element_type_238, add_236);  convert_element_type_238 = add_236 = None
        convert_element_type_239 = torch.ops.prims.convert_element_type.default(div_19, torch.bfloat16);  div_19 = None
        permute_66 = torch.ops.aten.permute.default(cat_35, [0, 2, 1]);  cat_35 = None
        _grouped_mm_10 = torch.ops.aten._grouped_mm.default(index_7, permute_66, cumsum_11)
        mul_182 = torch.ops.aten.mul.Tensor(convert_element_type_239, _grouped_mm_10);  convert_element_type_239 = None
        permute_67 = torch.ops.aten.permute.default(cat_34, [0, 2, 1]);  cat_34 = None
        _grouped_mm_11 = torch.ops.aten._grouped_mm.default(mul_182, permute_67, cumsum_11)
        empty_3 = torch.ops.aten.empty.memory_format([sym_size_int_13, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_6 = torch.ops.aten.index_put.default(empty_3, [getitem_352], _grouped_mm_11);  empty_3 = _grouped_mm_11 = None
        slice_29 = torch.ops.aten.slice.Tensor(index_put_6, 0, 0, -1);  index_put_6 = None
        all_to_all_single_11 = torch.ops._c10d_functional.all_to_all_single.default(slice_29, [_local_scalar_dense_48, _local_scalar_dense_49, _local_scalar_dense_50, _local_scalar_dense_51, _local_scalar_dense_52, _local_scalar_dense_53, _local_scalar_dense_54, _local_scalar_dense_55], [_local_scalar_dense_56, _local_scalar_dense_57, _local_scalar_dense_58, _local_scalar_dense_59, _local_scalar_dense_60, _local_scalar_dense_61, _local_scalar_dense_62, _local_scalar_dense_63], '1033');  slice_29 = None
        wait_tensor_91 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_11);  all_to_all_single_11 = None
        convert_element_type_240 = torch.ops.prims.convert_element_type.default(primals_84, torch.bfloat16)
        all_gather_into_tensor_76 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_240, 128, '0');  convert_element_type_240 = None
        wait_tensor_92 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_76);  all_gather_into_tensor_76 = None
        permute_68 = torch.ops.aten.permute.default(wait_tensor_92, [1, 0]);  wait_tensor_92 = None
        mm_36 = torch.ops.aten.mm.default(view_259, permute_68);  permute_68 = None
        convert_element_type_243 = torch.ops.prims.convert_element_type.default(mm_36, torch.float32)
        neg_8 = torch.ops.aten.neg.default(convert_element_type_243)
        exp_12 = torch.ops.aten.exp.default(neg_8);  neg_8 = None
        add_272 = torch.ops.aten.add.Tensor(exp_12, 1);  exp_12 = None
        div_20 = torch.ops.aten.div.Tensor(convert_element_type_243, add_272);  convert_element_type_243 = add_272 = None
        convert_element_type_244 = torch.ops.prims.convert_element_type.default(div_20, torch.bfloat16);  div_20 = None
        convert_element_type_245 = torch.ops.prims.convert_element_type.default(primals_85, torch.bfloat16)
        all_gather_into_tensor_77 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_245, 128, '0');  convert_element_type_245 = None
        wait_tensor_93 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_77);  all_gather_into_tensor_77 = None
        permute_69 = torch.ops.aten.permute.default(wait_tensor_93, [1, 0]);  wait_tensor_93 = None
        mm_37 = torch.ops.aten.mm.default(view_259, permute_69);  permute_69 = None
        mul_202 = torch.ops.aten.mul.Tensor(convert_element_type_244, mm_37);  convert_element_type_244 = None
        convert_element_type_248 = torch.ops.prims.convert_element_type.default(primals_86, torch.bfloat16)
        all_gather_into_tensor_78 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_248, 128, '0');  convert_element_type_248 = None
        wait_tensor_94 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_78);  all_gather_into_tensor_78 = None
        permute_70 = torch.ops.aten.permute.default(wait_tensor_94, [1, 0]);  wait_tensor_94 = None
        mm_38 = torch.ops.aten.mm.default(mul_202, permute_70);  permute_70 = None
        index_put_7 = torch.ops.aten.index_put.default(full_default_1, [getitem_351], wait_tensor_91);  wait_tensor_91 = None
        view_299 = torch.ops.aten.view.default(mul_164, [-1, 1, 6]);  mul_164 = None
        view_300 = torch.ops.aten.view.default(index_put_7, [-1, 6, 2048]);  index_put_7 = None
        convert_element_type_251 = torch.ops.prims.convert_element_type.default(view_300, torch.float32);  view_300 = None
        bmm_3 = torch.ops.aten.bmm.default(view_299, convert_element_type_251)
        convert_element_type_252 = torch.ops.prims.convert_element_type.default(bmm_3, torch.bfloat16);  bmm_3 = None
        squeeze_3 = torch.ops.aten.squeeze.dim(convert_element_type_252, 1);  convert_element_type_252 = None
        add_276 = torch.ops.aten.add.Tensor(mm_38, squeeze_3);  mm_38 = squeeze_3 = None
        view_301 = torch.ops.aten.view.default(add_276, [2, 4096, 2048]);  add_276 = None
        add_277 = torch.ops.aten.add.Tensor(add_212, view_301);  view_301 = None
        convert_element_type_253 = torch.ops.prims.convert_element_type.default(primals_87, torch.bfloat16)
        all_gather_into_tensor_79 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_253, 128, '0');  convert_element_type_253 = None
        wait_tensor_95 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_79);  all_gather_into_tensor_79 = None
        convert_element_type_254 = torch.ops.prims.convert_element_type.default(add_277, torch.float32)
        pow_16 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_254, 2)
        mean_15 = torch.ops.aten.mean.dim(pow_16, [2], True);  pow_16 = None
        add_278 = torch.ops.aten.add.Scalar(mean_15, 1e-05);  mean_15 = None
        rsqrt_15 = torch.ops.aten.rsqrt.default(add_278);  add_278 = None
        mul_205 = torch.ops.aten.mul.Tensor(convert_element_type_254, rsqrt_15);  convert_element_type_254 = None
        mul_206 = torch.ops.aten.mul.Tensor(mul_205, wait_tensor_95);  mul_205 = wait_tensor_95 = None
        convert_element_type_255 = torch.ops.prims.convert_element_type.default(mul_206, torch.bfloat16);  mul_206 = None
        convert_element_type_256 = torch.ops.prims.convert_element_type.default(primals_88, torch.bfloat16)
        all_gather_into_tensor_80 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_256, 128, '0');  convert_element_type_256 = None
        wait_tensor_96 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_80);  all_gather_into_tensor_80 = None
        permute_71 = torch.ops.aten.permute.default(wait_tensor_96, [1, 0]);  wait_tensor_96 = None
        view_304 = torch.ops.aten.view.default(convert_element_type_255, [8192, 2048]);  convert_element_type_255 = None
        mm_39 = torch.ops.aten.mm.default(view_304, permute_71);  permute_71 = None
        view_305 = torch.ops.aten.view.default(mm_39, [2, 4096, 3072]);  mm_39 = None
        view_306 = torch.ops.aten.view.default(view_305, [2, 4096, -1, 192]);  view_305 = None
        split_with_sizes_15 = torch.ops.aten.split_with_sizes.default(view_306, [128, 64], -1);  view_306 = None
        getitem_449 = split_with_sizes_15[0]
        getitem_450 = split_with_sizes_15[1];  split_with_sizes_15 = None
        convert_element_type_259 = torch.ops.prims.convert_element_type.default(getitem_450, torch.float32);  getitem_450 = None
        view_307 = torch.ops.aten.view.default(convert_element_type_259, [2, 4096, 16, -1, 2]);  convert_element_type_259 = None
        view_as_complex_10 = torch.ops.aten.view_as_complex.default(view_307);  view_307 = None
        mul_207 = torch.ops.aten.mul.Tensor(view_as_complex_10, view_7);  view_as_complex_10 = None
        view_as_real_10 = torch.ops.aten.view_as_real.default(mul_207);  mul_207 = None
        view_309 = torch.ops.aten.view.default(view_as_real_10, [2, 4096, 16, 64]);  view_as_real_10 = None
        convert_element_type_260 = torch.ops.prims.convert_element_type.default(view_309, torch.bfloat16);  view_309 = None
        cat_38 = torch.ops.aten.cat.default([getitem_449, convert_element_type_260], -1);  getitem_449 = convert_element_type_260 = None
        convert_element_type_261 = torch.ops.prims.convert_element_type.default(primals_89, torch.bfloat16)
        all_gather_into_tensor_81 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_261, 128, '0');  convert_element_type_261 = None
        wait_tensor_97 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_81);  all_gather_into_tensor_81 = None
        slice_31 = torch.ops.aten.slice.Tensor(wait_tensor_97, 0, 0, 576);  wait_tensor_97 = None
        permute_72 = torch.ops.aten.permute.default(slice_31, [1, 0]);  slice_31 = None
        mm_40 = torch.ops.aten.mm.default(view_304, permute_72);  permute_72 = None
        view_312 = torch.ops.aten.view.default(mm_40, [2, 4096, 576]);  mm_40 = None
        split_with_sizes_16 = torch.ops.aten.split_with_sizes.default(view_312, [512, 64], -1);  view_312 = None
        getitem_451 = split_with_sizes_16[0]
        getitem_452 = split_with_sizes_16[1];  split_with_sizes_16 = None
        unsqueeze_9 = torch.ops.aten.unsqueeze.default(getitem_452, 2);  getitem_452 = None
        convert_element_type_264 = torch.ops.prims.convert_element_type.default(unsqueeze_9, torch.float32);  unsqueeze_9 = None
        view_313 = torch.ops.aten.view.default(convert_element_type_264, [2, 4096, 1, -1, 2]);  convert_element_type_264 = None
        view_as_complex_11 = torch.ops.aten.view_as_complex.default(view_313);  view_313 = None
        mul_208 = torch.ops.aten.mul.Tensor(view_as_complex_11, view_7);  view_as_complex_11 = None
        view_as_real_11 = torch.ops.aten.view_as_real.default(mul_208);  mul_208 = None
        view_315 = torch.ops.aten.view.default(view_as_real_11, [2, 4096, 1, 64]);  view_as_real_11 = None
        convert_element_type_265 = torch.ops.prims.convert_element_type.default(view_315, torch.bfloat16);  view_315 = None
        convert_element_type_266 = torch.ops.prims.convert_element_type.default(primals_90, torch.bfloat16)
        all_gather_into_tensor_82 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_266, 128, '0');  convert_element_type_266 = None
        wait_tensor_98 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_82);  all_gather_into_tensor_82 = None
        convert_element_type_267 = torch.ops.prims.convert_element_type.default(getitem_451, torch.float32)
        pow_17 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_267, 2)
        mean_16 = torch.ops.aten.mean.dim(pow_17, [2], True);  pow_17 = None
        add_279 = torch.ops.aten.add.Scalar(mean_16, 1e-05);  mean_16 = None
        rsqrt_16 = torch.ops.aten.rsqrt.default(add_279);  add_279 = None
        mul_209 = torch.ops.aten.mul.Tensor(convert_element_type_267, rsqrt_16);  convert_element_type_267 = None
        mul_210 = torch.ops.aten.mul.Tensor(mul_209, wait_tensor_98);  mul_209 = wait_tensor_98 = None
        convert_element_type_268 = torch.ops.prims.convert_element_type.default(mul_210, torch.bfloat16);  mul_210 = None
        convert_element_type_269 = torch.ops.prims.convert_element_type.default(primals_91, torch.bfloat16)
        all_gather_into_tensor_83 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_269, 128, '0');  convert_element_type_269 = None
        wait_tensor_99 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_83);  all_gather_into_tensor_83 = None
        permute_73 = torch.ops.aten.permute.default(wait_tensor_99, [1, 0]);  wait_tensor_99 = None
        view_318 = torch.ops.aten.view.default(convert_element_type_268, [8192, 512]);  convert_element_type_268 = None
        mm_41 = torch.ops.aten.mm.default(view_318, permute_73);  permute_73 = None
        view_319 = torch.ops.aten.view.default(mm_41, [2, 4096, 4096]);  mm_41 = None
        view_320 = torch.ops.aten.view.default(view_319, [2, 4096, -1, 256]);  view_319 = None
        split_with_sizes_17 = torch.ops.aten.split_with_sizes.default(view_320, [128, 128], -1);  view_320 = None
        getitem_453 = split_with_sizes_17[0]
        getitem_454 = split_with_sizes_17[1];  split_with_sizes_17 = None
        expand_5 = torch.ops.aten.expand.default(convert_element_type_265, [-1, -1, 16, -1]);  convert_element_type_265 = None
        cat_39 = torch.ops.aten.cat.default([getitem_453, expand_5], -1);  getitem_453 = expand_5 = None
        permute_74 = torch.ops.aten.permute.default(cat_38, [0, 2, 1, 3]);  cat_38 = None
        permute_75 = torch.ops.aten.permute.default(cat_39, [0, 2, 1, 3]);  cat_39 = None
        permute_76 = torch.ops.aten.permute.default(getitem_454, [0, 2, 1, 3]);  getitem_454 = None
        sdpa_score5 = self.sdpa_score5
        sdpa_mask5 = self.sdpa_mask5
        flex_attention_5 = torch.ops.higher_order.flex_attention(permute_74, permute_75, permute_76, sdpa_score5, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask5), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score5 = sdpa_mask5 = None
        getitem_455 = flex_attention_5[0]
        getitem_456 = flex_attention_5[1];  flex_attention_5 = None
        permute_77 = torch.ops.aten.permute.default(getitem_455, [0, 2, 1, 3])
        view_321 = torch.ops.aten.view.default(permute_77, [2, 4096, -1]);  permute_77 = None
        convert_element_type_272 = torch.ops.prims.convert_element_type.default(primals_92, torch.bfloat16)
        all_gather_into_tensor_84 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_272, 128, '0');  convert_element_type_272 = None
        wait_tensor_100 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_84);  all_gather_into_tensor_84 = None
        permute_78 = torch.ops.aten.permute.default(wait_tensor_100, [1, 0]);  wait_tensor_100 = None
        view_323 = torch.ops.aten.view.default(view_321, [8192, 2048]);  view_321 = None
        mm_42 = torch.ops.aten.mm.default(view_323, permute_78);  view_323 = permute_78 = None
        view_324 = torch.ops.aten.view.default(mm_42, [2, 4096, 2048]);  mm_42 = None
        add_280 = torch.ops.aten.add.Tensor(add_277, view_324);  view_324 = None
        convert_element_type_275 = torch.ops.prims.convert_element_type.default(primals_93, torch.bfloat16)
        all_gather_into_tensor_85 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_275, 128, '0');  convert_element_type_275 = None
        wait_tensor_101 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_85);  all_gather_into_tensor_85 = None
        convert_element_type_276 = torch.ops.prims.convert_element_type.default(add_280, torch.float32)
        pow_18 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_276, 2)
        mean_17 = torch.ops.aten.mean.dim(pow_18, [2], True);  pow_18 = None
        add_281 = torch.ops.aten.add.Scalar(mean_17, 1e-05);  mean_17 = None
        rsqrt_17 = torch.ops.aten.rsqrt.default(add_281);  add_281 = None
        mul_211 = torch.ops.aten.mul.Tensor(convert_element_type_276, rsqrt_17);  convert_element_type_276 = None
        mul_212 = torch.ops.aten.mul.Tensor(mul_211, wait_tensor_101);  mul_211 = wait_tensor_101 = None
        convert_element_type_277 = torch.ops.prims.convert_element_type.default(mul_212, torch.bfloat16);  mul_212 = None
        view_326 = torch.ops.aten.view.default(convert_element_type_277, [-1, 2048]);  convert_element_type_277 = None
        convert_element_type_278 = torch.ops.prims.convert_element_type.default(primals_95, torch.bfloat16)
        all_gather_into_tensor_86 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_278, 128, '0');  convert_element_type_278 = None
        wait_tensor_102 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_86);  all_gather_into_tensor_86 = None
        slice_33 = torch.ops.aten.slice.Tensor(wait_tensor_102, 0, 0, 64);  wait_tensor_102 = None
        permute_79 = torch.ops.aten.permute.default(slice_33, [1, 0]);  slice_33 = None
        mm_43 = torch.ops.aten.mm.default(view_326, permute_79);  permute_79 = None
        convert_element_type_281 = torch.ops.prims.convert_element_type.default(mm_43, torch.float32)
        amax_4 = torch.ops.aten.amax.default(convert_element_type_281, [1], True)
        sub_96 = torch.ops.aten.sub.Tensor(convert_element_type_281, amax_4);  convert_element_type_281 = None
        exp_13 = torch.ops.aten.exp.default(sub_96);  sub_96 = None
        sum_17 = torch.ops.aten.sum.dim_IntList(exp_13, [1], True)
        div_21 = torch.ops.aten.div.Tensor(exp_13, sum_17);  exp_13 = None
        add_282 = torch.ops.aten.add.Tensor(div_21, primals_94);  primals_94 = None
        topk_4 = torch.ops.aten.topk.default(add_282, 6, -1, True, False);  add_282 = None
        getitem_459 = topk_4[1];  topk_4 = None
        gather_4 = torch.ops.aten.gather.default(div_21, 1, getitem_459);  div_21 = None
        mul_213 = torch.ops.aten.mul.Tensor(gather_4, 1.0);  gather_4 = None
        view_328 = torch.ops.aten.view.default(getitem_459, [-1])
        histc_8 = torch.ops.aten.histc.default(view_328, 64, 0, 64)
        add_283 = torch.ops.aten.add.Tensor(primals_96, histc_8)
        sort_4 = torch.ops.aten.sort.stable(view_328, stable = True);  view_328 = None
        getitem_461 = sort_4[1];  sort_4 = None
        div_22 = torch.ops.aten.div.Tensor_mode(getitem_461, 6, rounding_mode = 'floor')
        index_8 = torch.ops.aten.index.Tensor(view_326, [div_22])
        all_to_all_single_12 = torch.ops._c10d_functional.all_to_all_single.default(histc_8, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_103 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_12);  all_to_all_single_12 = None
        wait_tensor_104 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_103);  wait_tensor_103 = None
        view_332 = torch.ops.aten.view.default(histc_8, [8, -1]);  histc_8 = None
        sum_18 = torch.ops.aten.sum.dim_IntList(view_332, [1]);  view_332 = None
        device_put_8 = torch.ops.prims.device_put.default(sum_18, device(type='cpu'), True);  sum_18 = None
        view_333 = torch.ops.aten.view.default(wait_tensor_104, [8, -1])
        sum_19 = torch.ops.aten.sum.dim_IntList(view_333, [1])
        device_put_9 = torch.ops.prims.device_put.default(sum_19, device(type='cpu'));  sum_19 = None
        select_64 = torch.ops.aten.select.int(device_put_8, 0, 0)
        _local_scalar_dense_64 = torch.ops.aten._local_scalar_dense.default(select_64);  select_64 = None
        ge_80 = _local_scalar_dense_64 >= 0
        _assert_scalar_64 = torch.ops.aten._assert_scalar.default(ge_80, "Runtime assertion failed for expression u64 >= 0 on node 'ge_64'");  ge_80 = _assert_scalar_64 = None
        select_65 = torch.ops.aten.select.int(device_put_8, 0, 1)
        _local_scalar_dense_65 = torch.ops.aten._local_scalar_dense.default(select_65);  select_65 = None
        ge_81 = _local_scalar_dense_65 >= 0
        _assert_scalar_65 = torch.ops.aten._assert_scalar.default(ge_81, "Runtime assertion failed for expression u65 >= 0 on node 'ge_65'");  ge_81 = _assert_scalar_65 = None
        select_66 = torch.ops.aten.select.int(device_put_8, 0, 2)
        _local_scalar_dense_66 = torch.ops.aten._local_scalar_dense.default(select_66);  select_66 = None
        ge_82 = _local_scalar_dense_66 >= 0
        _assert_scalar_66 = torch.ops.aten._assert_scalar.default(ge_82, "Runtime assertion failed for expression u66 >= 0 on node 'ge_66'");  ge_82 = _assert_scalar_66 = None
        select_67 = torch.ops.aten.select.int(device_put_8, 0, 3)
        _local_scalar_dense_67 = torch.ops.aten._local_scalar_dense.default(select_67);  select_67 = None
        ge_83 = _local_scalar_dense_67 >= 0
        _assert_scalar_67 = torch.ops.aten._assert_scalar.default(ge_83, "Runtime assertion failed for expression u67 >= 0 on node 'ge_67'");  ge_83 = _assert_scalar_67 = None
        select_68 = torch.ops.aten.select.int(device_put_8, 0, 4)
        _local_scalar_dense_68 = torch.ops.aten._local_scalar_dense.default(select_68);  select_68 = None
        ge_84 = _local_scalar_dense_68 >= 0
        _assert_scalar_68 = torch.ops.aten._assert_scalar.default(ge_84, "Runtime assertion failed for expression u68 >= 0 on node 'ge_68'");  ge_84 = _assert_scalar_68 = None
        select_69 = torch.ops.aten.select.int(device_put_8, 0, 5)
        _local_scalar_dense_69 = torch.ops.aten._local_scalar_dense.default(select_69);  select_69 = None
        ge_85 = _local_scalar_dense_69 >= 0
        _assert_scalar_69 = torch.ops.aten._assert_scalar.default(ge_85, "Runtime assertion failed for expression u69 >= 0 on node 'ge_69'");  ge_85 = _assert_scalar_69 = None
        select_70 = torch.ops.aten.select.int(device_put_8, 0, 6)
        _local_scalar_dense_70 = torch.ops.aten._local_scalar_dense.default(select_70);  select_70 = None
        ge_86 = _local_scalar_dense_70 >= 0
        _assert_scalar_70 = torch.ops.aten._assert_scalar.default(ge_86, "Runtime assertion failed for expression u70 >= 0 on node 'ge_70'");  ge_86 = _assert_scalar_70 = None
        select_71 = torch.ops.aten.select.int(device_put_8, 0, 7);  device_put_8 = None
        _local_scalar_dense_71 = torch.ops.aten._local_scalar_dense.default(select_71);  select_71 = None
        ge_87 = _local_scalar_dense_71 >= 0
        _assert_scalar_71 = torch.ops.aten._assert_scalar.default(ge_87, "Runtime assertion failed for expression u71 >= 0 on node 'ge_71'");  ge_87 = _assert_scalar_71 = None
        select_72 = torch.ops.aten.select.int(device_put_9, 0, 0)
        _local_scalar_dense_72 = torch.ops.aten._local_scalar_dense.default(select_72);  select_72 = None
        ge_88 = _local_scalar_dense_72 >= 0
        _assert_scalar_72 = torch.ops.aten._assert_scalar.default(ge_88, "Runtime assertion failed for expression u72 >= 0 on node 'ge_72'");  ge_88 = _assert_scalar_72 = None
        select_73 = torch.ops.aten.select.int(device_put_9, 0, 1)
        _local_scalar_dense_73 = torch.ops.aten._local_scalar_dense.default(select_73);  select_73 = None
        ge_89 = _local_scalar_dense_73 >= 0
        _assert_scalar_73 = torch.ops.aten._assert_scalar.default(ge_89, "Runtime assertion failed for expression u73 >= 0 on node 'ge_73'");  ge_89 = _assert_scalar_73 = None
        select_74 = torch.ops.aten.select.int(device_put_9, 0, 2)
        _local_scalar_dense_74 = torch.ops.aten._local_scalar_dense.default(select_74);  select_74 = None
        ge_90 = _local_scalar_dense_74 >= 0
        _assert_scalar_74 = torch.ops.aten._assert_scalar.default(ge_90, "Runtime assertion failed for expression u74 >= 0 on node 'ge_74'");  ge_90 = _assert_scalar_74 = None
        select_75 = torch.ops.aten.select.int(device_put_9, 0, 3)
        _local_scalar_dense_75 = torch.ops.aten._local_scalar_dense.default(select_75);  select_75 = None
        ge_91 = _local_scalar_dense_75 >= 0
        _assert_scalar_75 = torch.ops.aten._assert_scalar.default(ge_91, "Runtime assertion failed for expression u75 >= 0 on node 'ge_75'");  ge_91 = _assert_scalar_75 = None
        select_76 = torch.ops.aten.select.int(device_put_9, 0, 4)
        _local_scalar_dense_76 = torch.ops.aten._local_scalar_dense.default(select_76);  select_76 = None
        ge_92 = _local_scalar_dense_76 >= 0
        _assert_scalar_76 = torch.ops.aten._assert_scalar.default(ge_92, "Runtime assertion failed for expression u76 >= 0 on node 'ge_76'");  ge_92 = _assert_scalar_76 = None
        select_77 = torch.ops.aten.select.int(device_put_9, 0, 5)
        _local_scalar_dense_77 = torch.ops.aten._local_scalar_dense.default(select_77);  select_77 = None
        ge_93 = _local_scalar_dense_77 >= 0
        _assert_scalar_77 = torch.ops.aten._assert_scalar.default(ge_93, "Runtime assertion failed for expression u77 >= 0 on node 'ge_77'");  ge_93 = _assert_scalar_77 = None
        select_78 = torch.ops.aten.select.int(device_put_9, 0, 6)
        _local_scalar_dense_78 = torch.ops.aten._local_scalar_dense.default(select_78);  select_78 = None
        ge_94 = _local_scalar_dense_78 >= 0
        _assert_scalar_78 = torch.ops.aten._assert_scalar.default(ge_94, "Runtime assertion failed for expression u78 >= 0 on node 'ge_78'");  ge_94 = _assert_scalar_78 = None
        select_79 = torch.ops.aten.select.int(device_put_9, 0, 7);  device_put_9 = None
        _local_scalar_dense_79 = torch.ops.aten._local_scalar_dense.default(select_79);  select_79 = None
        ge_95 = _local_scalar_dense_79 >= 0
        _assert_scalar_79 = torch.ops.aten._assert_scalar.default(ge_95, "Runtime assertion failed for expression u79 >= 0 on node 'ge_79'");  ge_95 = _assert_scalar_79 = None
        all_to_all_single_13 = torch.ops._c10d_functional.all_to_all_single.default(index_8, [_local_scalar_dense_72, _local_scalar_dense_73, _local_scalar_dense_74, _local_scalar_dense_75, _local_scalar_dense_76, _local_scalar_dense_77, _local_scalar_dense_78, _local_scalar_dense_79], [_local_scalar_dense_64, _local_scalar_dense_65, _local_scalar_dense_66, _local_scalar_dense_67, _local_scalar_dense_68, _local_scalar_dense_69, _local_scalar_dense_70, _local_scalar_dense_71], '1033');  index_8 = None
        sym_size_int_16 = torch.ops.aten.sym_size.int(all_to_all_single_13, 0)
        wait_tensor_105 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_13);  all_to_all_single_13 = None
        sym_sum_8 = torch.sym_sum((_local_scalar_dense_72, _local_scalar_dense_73, _local_scalar_dense_74, _local_scalar_dense_75, _local_scalar_dense_76, _local_scalar_dense_77, _local_scalar_dense_78, _local_scalar_dense_79))
        add_290 = sym_sum_8 + 64;  sym_sum_8 = None
        add_291 = add_290 + 8;  add_290 = None
        sub_99 = add_291 - 1;  add_291 = None
        floordiv_4 = sub_99 // 8;  sub_99 = None
        mul_218 = floordiv_4 * 8;  floordiv_4 = None
        cumsum_12 = torch.ops.aten.cumsum.default(wait_tensor_104, 0)
        sub_100 = torch.ops.aten.sub.Tensor(cumsum_12, wait_tensor_104);  cumsum_12 = None
        sum_20 = torch.ops.aten.sum.dim_IntList(view_333, [0]);  view_333 = None
        clamp_min_4 = torch.ops.aten.clamp_min.default(sum_20, 8);  sum_20 = None
        add_292 = torch.ops.aten.add.Tensor(clamp_min_4, 8);  clamp_min_4 = None
        sub_101 = torch.ops.aten.sub.Tensor(add_292, 1);  add_292 = None
        div_23 = torch.ops.aten.div.Tensor_mode(sub_101, 8, rounding_mode = 'floor');  sub_101 = None
        mul_219 = torch.ops.aten.mul.Tensor(div_23, 8);  div_23 = None
        convert_element_type_284 = torch.ops.prims.convert_element_type.default(mul_219, torch.int32);  mul_219 = None
        cumsum_13 = torch.ops.aten.cumsum.default(convert_element_type_284, 0)
        sub_102 = torch.ops.aten.sub.Tensor(cumsum_13, convert_element_type_284);  cumsum_13 = None
        full_72 = torch.ops.aten.full.default([mul_218], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_218 = None
        triton_kernel_wrapper_functional_proxy_4 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 4, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_104, 'start_index_values_ptr': sub_100, 'write_offsets_ptr': sub_102, 'output_ptr': full_72}, tensors_to_clone = ['output_ptr']);  wait_tensor_104 = sub_100 = sub_102 = full_72 = None
        getitem_462 = triton_kernel_wrapper_functional_proxy_4['output_ptr'];  triton_kernel_wrapper_functional_proxy_4 = None
        cat_40 = torch.ops.aten.cat.default([wait_tensor_105, full_default]);  wait_tensor_105 = None
        sym_size_int_17 = torch.ops.aten.sym_size.int(cat_40, 0)
        sym_sum_9 = torch.sym_sum((1, _local_scalar_dense_72, _local_scalar_dense_73, _local_scalar_dense_74, _local_scalar_dense_75, _local_scalar_dense_76, _local_scalar_dense_77, _local_scalar_dense_78, _local_scalar_dense_79))
        index_9 = torch.ops.aten.index.Tensor(cat_40, [getitem_462]);  cat_40 = None
        convert_element_type_286 = torch.ops.prims.convert_element_type.default(primals_97, torch.bfloat16)
        all_gather_into_tensor_87 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_286, 16, '1025');  convert_element_type_286 = None
        wait_tensor_106 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_87);  all_gather_into_tensor_87 = None
        split_25 = torch.ops.aten.split.Tensor(wait_tensor_106, 8);  wait_tensor_106 = None
        getitem_479 = split_25[0]
        getitem_480 = split_25[1]
        getitem_481 = split_25[2]
        getitem_482 = split_25[3]
        getitem_483 = split_25[4]
        getitem_484 = split_25[5]
        getitem_485 = split_25[6]
        getitem_486 = split_25[7]
        getitem_487 = split_25[8]
        getitem_488 = split_25[9]
        getitem_489 = split_25[10]
        getitem_490 = split_25[11]
        getitem_491 = split_25[12]
        getitem_492 = split_25[13]
        getitem_493 = split_25[14]
        getitem_494 = split_25[15];  split_25 = None
        cat_42 = torch.ops.aten.cat.default([getitem_479, getitem_480, getitem_481, getitem_482, getitem_483, getitem_484, getitem_485, getitem_486, getitem_487, getitem_488, getitem_489, getitem_490, getitem_491, getitem_492, getitem_493, getitem_494], 1);  getitem_479 = getitem_480 = getitem_481 = getitem_482 = getitem_483 = getitem_484 = getitem_485 = getitem_486 = getitem_487 = getitem_488 = getitem_489 = getitem_490 = getitem_491 = getitem_492 = getitem_493 = getitem_494 = None
        convert_element_type_288 = torch.ops.prims.convert_element_type.default(primals_98, torch.bfloat16)
        all_gather_into_tensor_89 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_288, 16, '1025');  convert_element_type_288 = None
        wait_tensor_108 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_89);  all_gather_into_tensor_89 = None
        split_26 = torch.ops.aten.split.Tensor(wait_tensor_108, 8);  wait_tensor_108 = None
        getitem_495 = split_26[0]
        getitem_496 = split_26[1]
        getitem_497 = split_26[2]
        getitem_498 = split_26[3]
        getitem_499 = split_26[4]
        getitem_500 = split_26[5]
        getitem_501 = split_26[6]
        getitem_502 = split_26[7]
        getitem_503 = split_26[8]
        getitem_504 = split_26[9]
        getitem_505 = split_26[10]
        getitem_506 = split_26[11]
        getitem_507 = split_26[12]
        getitem_508 = split_26[13]
        getitem_509 = split_26[14]
        getitem_510 = split_26[15];  split_26 = None
        cat_43 = torch.ops.aten.cat.default([getitem_495, getitem_496, getitem_497, getitem_498, getitem_499, getitem_500, getitem_501, getitem_502, getitem_503, getitem_504, getitem_505, getitem_506, getitem_507, getitem_508, getitem_509, getitem_510], 1);  getitem_495 = getitem_496 = getitem_497 = getitem_498 = getitem_499 = getitem_500 = getitem_501 = getitem_502 = getitem_503 = getitem_504 = getitem_505 = getitem_506 = getitem_507 = getitem_508 = getitem_509 = getitem_510 = None
        convert_element_type_289 = torch.ops.prims.convert_element_type.default(primals_99, torch.bfloat16)
        all_gather_into_tensor_90 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_289, 16, '1025');  convert_element_type_289 = None
        wait_tensor_109 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_90);  all_gather_into_tensor_90 = None
        split_27 = torch.ops.aten.split.Tensor(wait_tensor_109, 8);  wait_tensor_109 = None
        getitem_511 = split_27[0]
        getitem_512 = split_27[1]
        getitem_513 = split_27[2]
        getitem_514 = split_27[3]
        getitem_515 = split_27[4]
        getitem_516 = split_27[5]
        getitem_517 = split_27[6]
        getitem_518 = split_27[7]
        getitem_519 = split_27[8]
        getitem_520 = split_27[9]
        getitem_521 = split_27[10]
        getitem_522 = split_27[11]
        getitem_523 = split_27[12]
        getitem_524 = split_27[13]
        getitem_525 = split_27[14]
        getitem_526 = split_27[15];  split_27 = None
        cat_44 = torch.ops.aten.cat.default([getitem_511, getitem_512, getitem_513, getitem_514, getitem_515, getitem_516, getitem_517, getitem_518, getitem_519, getitem_520, getitem_521, getitem_522, getitem_523, getitem_524, getitem_525, getitem_526], 1);  getitem_511 = getitem_512 = getitem_513 = getitem_514 = getitem_515 = getitem_516 = getitem_517 = getitem_518 = getitem_519 = getitem_520 = getitem_521 = getitem_522 = getitem_523 = getitem_524 = getitem_525 = getitem_526 = None
        cumsum_14 = torch.ops.aten.cumsum.default(convert_element_type_284, 0, dtype = torch.int32);  convert_element_type_284 = None
        permute_80 = torch.ops.aten.permute.default(cat_42, [0, 2, 1]);  cat_42 = None
        _grouped_mm_12 = torch.ops.aten._grouped_mm.default(index_9, permute_80, cumsum_14)
        convert_element_type_292 = torch.ops.prims.convert_element_type.default(_grouped_mm_12, torch.float32)
        neg_9 = torch.ops.aten.neg.default(convert_element_type_292)
        exp_14 = torch.ops.aten.exp.default(neg_9);  neg_9 = None
        add_304 = torch.ops.aten.add.Tensor(exp_14, 1);  exp_14 = None
        div_24 = torch.ops.aten.div.Tensor(convert_element_type_292, add_304);  convert_element_type_292 = add_304 = None
        convert_element_type_293 = torch.ops.prims.convert_element_type.default(div_24, torch.bfloat16);  div_24 = None
        permute_81 = torch.ops.aten.permute.default(cat_44, [0, 2, 1]);  cat_44 = None
        _grouped_mm_13 = torch.ops.aten._grouped_mm.default(index_9, permute_81, cumsum_14)
        mul_231 = torch.ops.aten.mul.Tensor(convert_element_type_293, _grouped_mm_13);  convert_element_type_293 = None
        permute_82 = torch.ops.aten.permute.default(cat_43, [0, 2, 1]);  cat_43 = None
        _grouped_mm_14 = torch.ops.aten._grouped_mm.default(mul_231, permute_82, cumsum_14)
        empty_4 = torch.ops.aten.empty.memory_format([sym_size_int_17, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_8 = torch.ops.aten.index_put.default(empty_4, [getitem_462], _grouped_mm_14);  empty_4 = _grouped_mm_14 = None
        slice_35 = torch.ops.aten.slice.Tensor(index_put_8, 0, 0, -1);  index_put_8 = None
        all_to_all_single_14 = torch.ops._c10d_functional.all_to_all_single.default(slice_35, [_local_scalar_dense_64, _local_scalar_dense_65, _local_scalar_dense_66, _local_scalar_dense_67, _local_scalar_dense_68, _local_scalar_dense_69, _local_scalar_dense_70, _local_scalar_dense_71], [_local_scalar_dense_72, _local_scalar_dense_73, _local_scalar_dense_74, _local_scalar_dense_75, _local_scalar_dense_76, _local_scalar_dense_77, _local_scalar_dense_78, _local_scalar_dense_79], '1033');  slice_35 = None
        wait_tensor_112 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_14);  all_to_all_single_14 = None
        convert_element_type_294 = torch.ops.prims.convert_element_type.default(primals_100, torch.bfloat16)
        all_gather_into_tensor_93 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_294, 128, '0');  convert_element_type_294 = None
        wait_tensor_113 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_93);  all_gather_into_tensor_93 = None
        permute_83 = torch.ops.aten.permute.default(wait_tensor_113, [1, 0]);  wait_tensor_113 = None
        mm_44 = torch.ops.aten.mm.default(view_326, permute_83);  permute_83 = None
        convert_element_type_297 = torch.ops.prims.convert_element_type.default(mm_44, torch.float32)
        neg_10 = torch.ops.aten.neg.default(convert_element_type_297)
        exp_15 = torch.ops.aten.exp.default(neg_10);  neg_10 = None
        add_340 = torch.ops.aten.add.Tensor(exp_15, 1);  exp_15 = None
        div_25 = torch.ops.aten.div.Tensor(convert_element_type_297, add_340);  convert_element_type_297 = add_340 = None
        convert_element_type_298 = torch.ops.prims.convert_element_type.default(div_25, torch.bfloat16);  div_25 = None
        convert_element_type_299 = torch.ops.prims.convert_element_type.default(primals_101, torch.bfloat16)
        all_gather_into_tensor_94 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_299, 128, '0');  convert_element_type_299 = None
        wait_tensor_114 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_94);  all_gather_into_tensor_94 = None
        permute_84 = torch.ops.aten.permute.default(wait_tensor_114, [1, 0]);  wait_tensor_114 = None
        mm_45 = torch.ops.aten.mm.default(view_326, permute_84);  permute_84 = None
        mul_251 = torch.ops.aten.mul.Tensor(convert_element_type_298, mm_45);  convert_element_type_298 = None
        convert_element_type_302 = torch.ops.prims.convert_element_type.default(primals_102, torch.bfloat16)
        all_gather_into_tensor_95 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_302, 128, '0');  convert_element_type_302 = None
        wait_tensor_115 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_95);  all_gather_into_tensor_95 = None
        permute_85 = torch.ops.aten.permute.default(wait_tensor_115, [1, 0]);  wait_tensor_115 = None
        mm_46 = torch.ops.aten.mm.default(mul_251, permute_85);  permute_85 = None
        index_put_9 = torch.ops.aten.index_put.default(full_default_1, [getitem_461], wait_tensor_112);  wait_tensor_112 = None
        view_366 = torch.ops.aten.view.default(mul_213, [-1, 1, 6]);  mul_213 = None
        view_367 = torch.ops.aten.view.default(index_put_9, [-1, 6, 2048]);  index_put_9 = None
        convert_element_type_305 = torch.ops.prims.convert_element_type.default(view_367, torch.float32);  view_367 = None
        bmm_4 = torch.ops.aten.bmm.default(view_366, convert_element_type_305)
        convert_element_type_306 = torch.ops.prims.convert_element_type.default(bmm_4, torch.bfloat16);  bmm_4 = None
        squeeze_4 = torch.ops.aten.squeeze.dim(convert_element_type_306, 1);  convert_element_type_306 = None
        add_344 = torch.ops.aten.add.Tensor(mm_46, squeeze_4);  mm_46 = squeeze_4 = None
        view_368 = torch.ops.aten.view.default(add_344, [2, 4096, 2048]);  add_344 = None
        add_345 = torch.ops.aten.add.Tensor(add_280, view_368);  view_368 = None
        convert_element_type_307 = torch.ops.prims.convert_element_type.default(primals_103, torch.bfloat16)
        all_gather_into_tensor_96 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_307, 128, '0');  convert_element_type_307 = None
        wait_tensor_116 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_96);  all_gather_into_tensor_96 = None
        convert_element_type_308 = torch.ops.prims.convert_element_type.default(add_345, torch.float32)
        pow_19 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_308, 2)
        mean_18 = torch.ops.aten.mean.dim(pow_19, [2], True);  pow_19 = None
        add_346 = torch.ops.aten.add.Scalar(mean_18, 1e-05);  mean_18 = None
        rsqrt_18 = torch.ops.aten.rsqrt.default(add_346);  add_346 = None
        mul_254 = torch.ops.aten.mul.Tensor(convert_element_type_308, rsqrt_18);  convert_element_type_308 = None
        mul_255 = torch.ops.aten.mul.Tensor(mul_254, wait_tensor_116);  mul_254 = wait_tensor_116 = None
        convert_element_type_309 = torch.ops.prims.convert_element_type.default(mul_255, torch.bfloat16);  mul_255 = None
        convert_element_type_310 = torch.ops.prims.convert_element_type.default(primals_104, torch.bfloat16)
        all_gather_into_tensor_97 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_310, 128, '0');  convert_element_type_310 = None
        wait_tensor_117 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_97);  all_gather_into_tensor_97 = None
        permute_86 = torch.ops.aten.permute.default(wait_tensor_117, [1, 0]);  wait_tensor_117 = None
        view_371 = torch.ops.aten.view.default(convert_element_type_309, [8192, 2048]);  convert_element_type_309 = None
        mm_47 = torch.ops.aten.mm.default(view_371, permute_86);  permute_86 = None
        view_372 = torch.ops.aten.view.default(mm_47, [2, 4096, 3072]);  mm_47 = None
        view_373 = torch.ops.aten.view.default(view_372, [2, 4096, -1, 192]);  view_372 = None
        split_with_sizes_18 = torch.ops.aten.split_with_sizes.default(view_373, [128, 64], -1);  view_373 = None
        getitem_559 = split_with_sizes_18[0]
        getitem_560 = split_with_sizes_18[1];  split_with_sizes_18 = None
        convert_element_type_313 = torch.ops.prims.convert_element_type.default(getitem_560, torch.float32);  getitem_560 = None
        view_374 = torch.ops.aten.view.default(convert_element_type_313, [2, 4096, 16, -1, 2]);  convert_element_type_313 = None
        view_as_complex_12 = torch.ops.aten.view_as_complex.default(view_374);  view_374 = None
        mul_256 = torch.ops.aten.mul.Tensor(view_as_complex_12, view_7);  view_as_complex_12 = None
        view_as_real_12 = torch.ops.aten.view_as_real.default(mul_256);  mul_256 = None
        view_376 = torch.ops.aten.view.default(view_as_real_12, [2, 4096, 16, 64]);  view_as_real_12 = None
        convert_element_type_314 = torch.ops.prims.convert_element_type.default(view_376, torch.bfloat16);  view_376 = None
        cat_47 = torch.ops.aten.cat.default([getitem_559, convert_element_type_314], -1);  getitem_559 = convert_element_type_314 = None
        convert_element_type_315 = torch.ops.prims.convert_element_type.default(primals_105, torch.bfloat16)
        all_gather_into_tensor_98 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_315, 128, '0');  convert_element_type_315 = None
        wait_tensor_118 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_98);  all_gather_into_tensor_98 = None
        slice_37 = torch.ops.aten.slice.Tensor(wait_tensor_118, 0, 0, 576);  wait_tensor_118 = None
        permute_87 = torch.ops.aten.permute.default(slice_37, [1, 0]);  slice_37 = None
        mm_48 = torch.ops.aten.mm.default(view_371, permute_87);  permute_87 = None
        view_379 = torch.ops.aten.view.default(mm_48, [2, 4096, 576]);  mm_48 = None
        split_with_sizes_19 = torch.ops.aten.split_with_sizes.default(view_379, [512, 64], -1);  view_379 = None
        getitem_561 = split_with_sizes_19[0]
        getitem_562 = split_with_sizes_19[1];  split_with_sizes_19 = None
        unsqueeze_11 = torch.ops.aten.unsqueeze.default(getitem_562, 2);  getitem_562 = None
        convert_element_type_318 = torch.ops.prims.convert_element_type.default(unsqueeze_11, torch.float32);  unsqueeze_11 = None
        view_380 = torch.ops.aten.view.default(convert_element_type_318, [2, 4096, 1, -1, 2]);  convert_element_type_318 = None
        view_as_complex_13 = torch.ops.aten.view_as_complex.default(view_380);  view_380 = None
        mul_257 = torch.ops.aten.mul.Tensor(view_as_complex_13, view_7);  view_as_complex_13 = None
        view_as_real_13 = torch.ops.aten.view_as_real.default(mul_257);  mul_257 = None
        view_382 = torch.ops.aten.view.default(view_as_real_13, [2, 4096, 1, 64]);  view_as_real_13 = None
        convert_element_type_319 = torch.ops.prims.convert_element_type.default(view_382, torch.bfloat16);  view_382 = None
        convert_element_type_320 = torch.ops.prims.convert_element_type.default(primals_106, torch.bfloat16)
        all_gather_into_tensor_99 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_320, 128, '0');  convert_element_type_320 = None
        wait_tensor_119 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_99);  all_gather_into_tensor_99 = None
        convert_element_type_321 = torch.ops.prims.convert_element_type.default(getitem_561, torch.float32)
        pow_20 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_321, 2)
        mean_19 = torch.ops.aten.mean.dim(pow_20, [2], True);  pow_20 = None
        add_347 = torch.ops.aten.add.Scalar(mean_19, 1e-05);  mean_19 = None
        rsqrt_19 = torch.ops.aten.rsqrt.default(add_347);  add_347 = None
        mul_258 = torch.ops.aten.mul.Tensor(convert_element_type_321, rsqrt_19);  convert_element_type_321 = None
        mul_259 = torch.ops.aten.mul.Tensor(mul_258, wait_tensor_119);  mul_258 = wait_tensor_119 = None
        convert_element_type_322 = torch.ops.prims.convert_element_type.default(mul_259, torch.bfloat16);  mul_259 = None
        convert_element_type_323 = torch.ops.prims.convert_element_type.default(primals_107, torch.bfloat16)
        all_gather_into_tensor_100 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_323, 128, '0');  convert_element_type_323 = None
        wait_tensor_120 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_100);  all_gather_into_tensor_100 = None
        permute_88 = torch.ops.aten.permute.default(wait_tensor_120, [1, 0]);  wait_tensor_120 = None
        view_385 = torch.ops.aten.view.default(convert_element_type_322, [8192, 512]);  convert_element_type_322 = None
        mm_49 = torch.ops.aten.mm.default(view_385, permute_88);  permute_88 = None
        view_386 = torch.ops.aten.view.default(mm_49, [2, 4096, 4096]);  mm_49 = None
        view_387 = torch.ops.aten.view.default(view_386, [2, 4096, -1, 256]);  view_386 = None
        split_with_sizes_20 = torch.ops.aten.split_with_sizes.default(view_387, [128, 128], -1);  view_387 = None
        getitem_563 = split_with_sizes_20[0]
        getitem_564 = split_with_sizes_20[1];  split_with_sizes_20 = None
        expand_6 = torch.ops.aten.expand.default(convert_element_type_319, [-1, -1, 16, -1]);  convert_element_type_319 = None
        cat_48 = torch.ops.aten.cat.default([getitem_563, expand_6], -1);  getitem_563 = expand_6 = None
        permute_89 = torch.ops.aten.permute.default(cat_47, [0, 2, 1, 3]);  cat_47 = None
        permute_90 = torch.ops.aten.permute.default(cat_48, [0, 2, 1, 3]);  cat_48 = None
        permute_91 = torch.ops.aten.permute.default(getitem_564, [0, 2, 1, 3]);  getitem_564 = None
        sdpa_score6 = self.sdpa_score6
        sdpa_mask6 = self.sdpa_mask6
        flex_attention_6 = torch.ops.higher_order.flex_attention(permute_89, permute_90, permute_91, sdpa_score6, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask6), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score6 = sdpa_mask6 = None
        getitem_565 = flex_attention_6[0]
        getitem_566 = flex_attention_6[1];  flex_attention_6 = None
        permute_92 = torch.ops.aten.permute.default(getitem_565, [0, 2, 1, 3])
        view_388 = torch.ops.aten.view.default(permute_92, [2, 4096, -1]);  permute_92 = None
        convert_element_type_326 = torch.ops.prims.convert_element_type.default(primals_108, torch.bfloat16)
        all_gather_into_tensor_101 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_326, 128, '0');  convert_element_type_326 = None
        wait_tensor_121 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_101);  all_gather_into_tensor_101 = None
        permute_93 = torch.ops.aten.permute.default(wait_tensor_121, [1, 0]);  wait_tensor_121 = None
        view_390 = torch.ops.aten.view.default(view_388, [8192, 2048]);  view_388 = None
        mm_50 = torch.ops.aten.mm.default(view_390, permute_93);  view_390 = permute_93 = None
        view_391 = torch.ops.aten.view.default(mm_50, [2, 4096, 2048]);  mm_50 = None
        add_348 = torch.ops.aten.add.Tensor(add_345, view_391);  view_391 = None
        convert_element_type_329 = torch.ops.prims.convert_element_type.default(primals_109, torch.bfloat16)
        all_gather_into_tensor_102 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_329, 128, '0');  convert_element_type_329 = None
        wait_tensor_122 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_102);  all_gather_into_tensor_102 = None
        convert_element_type_330 = torch.ops.prims.convert_element_type.default(add_348, torch.float32)
        pow_21 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_330, 2)
        mean_20 = torch.ops.aten.mean.dim(pow_21, [2], True);  pow_21 = None
        add_349 = torch.ops.aten.add.Scalar(mean_20, 1e-05);  mean_20 = None
        rsqrt_20 = torch.ops.aten.rsqrt.default(add_349);  add_349 = None
        mul_260 = torch.ops.aten.mul.Tensor(convert_element_type_330, rsqrt_20);  convert_element_type_330 = None
        mul_261 = torch.ops.aten.mul.Tensor(mul_260, wait_tensor_122);  mul_260 = wait_tensor_122 = None
        convert_element_type_331 = torch.ops.prims.convert_element_type.default(mul_261, torch.bfloat16);  mul_261 = None
        view_393 = torch.ops.aten.view.default(convert_element_type_331, [-1, 2048]);  convert_element_type_331 = None
        convert_element_type_332 = torch.ops.prims.convert_element_type.default(primals_111, torch.bfloat16)
        all_gather_into_tensor_103 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_332, 128, '0');  convert_element_type_332 = None
        wait_tensor_123 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_103);  all_gather_into_tensor_103 = None
        slice_39 = torch.ops.aten.slice.Tensor(wait_tensor_123, 0, 0, 64);  wait_tensor_123 = None
        permute_94 = torch.ops.aten.permute.default(slice_39, [1, 0]);  slice_39 = None
        mm_51 = torch.ops.aten.mm.default(view_393, permute_94);  permute_94 = None
        convert_element_type_335 = torch.ops.prims.convert_element_type.default(mm_51, torch.float32)
        amax_5 = torch.ops.aten.amax.default(convert_element_type_335, [1], True)
        sub_120 = torch.ops.aten.sub.Tensor(convert_element_type_335, amax_5);  convert_element_type_335 = None
        exp_16 = torch.ops.aten.exp.default(sub_120);  sub_120 = None
        sum_21 = torch.ops.aten.sum.dim_IntList(exp_16, [1], True)
        div_26 = torch.ops.aten.div.Tensor(exp_16, sum_21);  exp_16 = None
        add_350 = torch.ops.aten.add.Tensor(div_26, primals_110);  primals_110 = None
        topk_5 = torch.ops.aten.topk.default(add_350, 6, -1, True, False);  add_350 = None
        getitem_569 = topk_5[1];  topk_5 = None
        gather_5 = torch.ops.aten.gather.default(div_26, 1, getitem_569);  div_26 = None
        mul_262 = torch.ops.aten.mul.Tensor(gather_5, 1.0);  gather_5 = None
        view_395 = torch.ops.aten.view.default(getitem_569, [-1])
        histc_10 = torch.ops.aten.histc.default(view_395, 64, 0, 64)
        add_351 = torch.ops.aten.add.Tensor(primals_112, histc_10)
        sort_5 = torch.ops.aten.sort.stable(view_395, stable = True);  view_395 = None
        getitem_571 = sort_5[1];  sort_5 = None
        div_27 = torch.ops.aten.div.Tensor_mode(getitem_571, 6, rounding_mode = 'floor')
        index_10 = torch.ops.aten.index.Tensor(view_393, [div_27])
        all_to_all_single_15 = torch.ops._c10d_functional.all_to_all_single.default(histc_10, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_124 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_15);  all_to_all_single_15 = None
        wait_tensor_125 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_124);  wait_tensor_124 = None
        view_399 = torch.ops.aten.view.default(histc_10, [8, -1]);  histc_10 = None
        sum_22 = torch.ops.aten.sum.dim_IntList(view_399, [1]);  view_399 = None
        device_put_10 = torch.ops.prims.device_put.default(sum_22, device(type='cpu'), True);  sum_22 = None
        view_400 = torch.ops.aten.view.default(wait_tensor_125, [8, -1])
        sum_23 = torch.ops.aten.sum.dim_IntList(view_400, [1])
        device_put_11 = torch.ops.prims.device_put.default(sum_23, device(type='cpu'));  sum_23 = None
        select_80 = torch.ops.aten.select.int(device_put_10, 0, 0)
        _local_scalar_dense_80 = torch.ops.aten._local_scalar_dense.default(select_80);  select_80 = None
        ge_100 = _local_scalar_dense_80 >= 0
        _assert_scalar_80 = torch.ops.aten._assert_scalar.default(ge_100, "Runtime assertion failed for expression u80 >= 0 on node 'ge_80'");  ge_100 = _assert_scalar_80 = None
        select_81 = torch.ops.aten.select.int(device_put_10, 0, 1)
        _local_scalar_dense_81 = torch.ops.aten._local_scalar_dense.default(select_81);  select_81 = None
        ge_101 = _local_scalar_dense_81 >= 0
        _assert_scalar_81 = torch.ops.aten._assert_scalar.default(ge_101, "Runtime assertion failed for expression u81 >= 0 on node 'ge_81'");  ge_101 = _assert_scalar_81 = None
        select_82 = torch.ops.aten.select.int(device_put_10, 0, 2)
        _local_scalar_dense_82 = torch.ops.aten._local_scalar_dense.default(select_82);  select_82 = None
        ge_102 = _local_scalar_dense_82 >= 0
        _assert_scalar_82 = torch.ops.aten._assert_scalar.default(ge_102, "Runtime assertion failed for expression u82 >= 0 on node 'ge_82'");  ge_102 = _assert_scalar_82 = None
        select_83 = torch.ops.aten.select.int(device_put_10, 0, 3)
        _local_scalar_dense_83 = torch.ops.aten._local_scalar_dense.default(select_83);  select_83 = None
        ge_103 = _local_scalar_dense_83 >= 0
        _assert_scalar_83 = torch.ops.aten._assert_scalar.default(ge_103, "Runtime assertion failed for expression u83 >= 0 on node 'ge_83'");  ge_103 = _assert_scalar_83 = None
        select_84 = torch.ops.aten.select.int(device_put_10, 0, 4)
        _local_scalar_dense_84 = torch.ops.aten._local_scalar_dense.default(select_84);  select_84 = None
        ge_104 = _local_scalar_dense_84 >= 0
        _assert_scalar_84 = torch.ops.aten._assert_scalar.default(ge_104, "Runtime assertion failed for expression u84 >= 0 on node 'ge_84'");  ge_104 = _assert_scalar_84 = None
        select_85 = torch.ops.aten.select.int(device_put_10, 0, 5)
        _local_scalar_dense_85 = torch.ops.aten._local_scalar_dense.default(select_85);  select_85 = None
        ge_105 = _local_scalar_dense_85 >= 0
        _assert_scalar_85 = torch.ops.aten._assert_scalar.default(ge_105, "Runtime assertion failed for expression u85 >= 0 on node 'ge_85'");  ge_105 = _assert_scalar_85 = None
        select_86 = torch.ops.aten.select.int(device_put_10, 0, 6)
        _local_scalar_dense_86 = torch.ops.aten._local_scalar_dense.default(select_86);  select_86 = None
        ge_106 = _local_scalar_dense_86 >= 0
        _assert_scalar_86 = torch.ops.aten._assert_scalar.default(ge_106, "Runtime assertion failed for expression u86 >= 0 on node 'ge_86'");  ge_106 = _assert_scalar_86 = None
        select_87 = torch.ops.aten.select.int(device_put_10, 0, 7);  device_put_10 = None
        _local_scalar_dense_87 = torch.ops.aten._local_scalar_dense.default(select_87);  select_87 = None
        ge_107 = _local_scalar_dense_87 >= 0
        _assert_scalar_87 = torch.ops.aten._assert_scalar.default(ge_107, "Runtime assertion failed for expression u87 >= 0 on node 'ge_87'");  ge_107 = _assert_scalar_87 = None
        select_88 = torch.ops.aten.select.int(device_put_11, 0, 0)
        _local_scalar_dense_88 = torch.ops.aten._local_scalar_dense.default(select_88);  select_88 = None
        ge_108 = _local_scalar_dense_88 >= 0
        _assert_scalar_88 = torch.ops.aten._assert_scalar.default(ge_108, "Runtime assertion failed for expression u88 >= 0 on node 'ge_88'");  ge_108 = _assert_scalar_88 = None
        select_89 = torch.ops.aten.select.int(device_put_11, 0, 1)
        _local_scalar_dense_89 = torch.ops.aten._local_scalar_dense.default(select_89);  select_89 = None
        ge_109 = _local_scalar_dense_89 >= 0
        _assert_scalar_89 = torch.ops.aten._assert_scalar.default(ge_109, "Runtime assertion failed for expression u89 >= 0 on node 'ge_89'");  ge_109 = _assert_scalar_89 = None
        select_90 = torch.ops.aten.select.int(device_put_11, 0, 2)
        _local_scalar_dense_90 = torch.ops.aten._local_scalar_dense.default(select_90);  select_90 = None
        ge_110 = _local_scalar_dense_90 >= 0
        _assert_scalar_90 = torch.ops.aten._assert_scalar.default(ge_110, "Runtime assertion failed for expression u90 >= 0 on node 'ge_90'");  ge_110 = _assert_scalar_90 = None
        select_91 = torch.ops.aten.select.int(device_put_11, 0, 3)
        _local_scalar_dense_91 = torch.ops.aten._local_scalar_dense.default(select_91);  select_91 = None
        ge_111 = _local_scalar_dense_91 >= 0
        _assert_scalar_91 = torch.ops.aten._assert_scalar.default(ge_111, "Runtime assertion failed for expression u91 >= 0 on node 'ge_91'");  ge_111 = _assert_scalar_91 = None
        select_92 = torch.ops.aten.select.int(device_put_11, 0, 4)
        _local_scalar_dense_92 = torch.ops.aten._local_scalar_dense.default(select_92);  select_92 = None
        ge_112 = _local_scalar_dense_92 >= 0
        _assert_scalar_92 = torch.ops.aten._assert_scalar.default(ge_112, "Runtime assertion failed for expression u92 >= 0 on node 'ge_92'");  ge_112 = _assert_scalar_92 = None
        select_93 = torch.ops.aten.select.int(device_put_11, 0, 5)
        _local_scalar_dense_93 = torch.ops.aten._local_scalar_dense.default(select_93);  select_93 = None
        ge_113 = _local_scalar_dense_93 >= 0
        _assert_scalar_93 = torch.ops.aten._assert_scalar.default(ge_113, "Runtime assertion failed for expression u93 >= 0 on node 'ge_93'");  ge_113 = _assert_scalar_93 = None
        select_94 = torch.ops.aten.select.int(device_put_11, 0, 6)
        _local_scalar_dense_94 = torch.ops.aten._local_scalar_dense.default(select_94);  select_94 = None
        ge_114 = _local_scalar_dense_94 >= 0
        _assert_scalar_94 = torch.ops.aten._assert_scalar.default(ge_114, "Runtime assertion failed for expression u94 >= 0 on node 'ge_94'");  ge_114 = _assert_scalar_94 = None
        select_95 = torch.ops.aten.select.int(device_put_11, 0, 7);  device_put_11 = None
        _local_scalar_dense_95 = torch.ops.aten._local_scalar_dense.default(select_95);  select_95 = None
        ge_115 = _local_scalar_dense_95 >= 0
        _assert_scalar_95 = torch.ops.aten._assert_scalar.default(ge_115, "Runtime assertion failed for expression u95 >= 0 on node 'ge_95'");  ge_115 = _assert_scalar_95 = None
        all_to_all_single_16 = torch.ops._c10d_functional.all_to_all_single.default(index_10, [_local_scalar_dense_88, _local_scalar_dense_89, _local_scalar_dense_90, _local_scalar_dense_91, _local_scalar_dense_92, _local_scalar_dense_93, _local_scalar_dense_94, _local_scalar_dense_95], [_local_scalar_dense_80, _local_scalar_dense_81, _local_scalar_dense_82, _local_scalar_dense_83, _local_scalar_dense_84, _local_scalar_dense_85, _local_scalar_dense_86, _local_scalar_dense_87], '1033');  index_10 = None
        sym_size_int_20 = torch.ops.aten.sym_size.int(all_to_all_single_16, 0)
        wait_tensor_126 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_16);  all_to_all_single_16 = None
        sym_sum_10 = torch.sym_sum((_local_scalar_dense_88, _local_scalar_dense_89, _local_scalar_dense_90, _local_scalar_dense_91, _local_scalar_dense_92, _local_scalar_dense_93, _local_scalar_dense_94, _local_scalar_dense_95))
        add_358 = sym_sum_10 + 64;  sym_sum_10 = None
        add_359 = add_358 + 8;  add_358 = None
        sub_123 = add_359 - 1;  add_359 = None
        floordiv_5 = sub_123 // 8;  sub_123 = None
        mul_267 = floordiv_5 * 8;  floordiv_5 = None
        cumsum_15 = torch.ops.aten.cumsum.default(wait_tensor_125, 0)
        sub_124 = torch.ops.aten.sub.Tensor(cumsum_15, wait_tensor_125);  cumsum_15 = None
        sum_24 = torch.ops.aten.sum.dim_IntList(view_400, [0]);  view_400 = None
        clamp_min_5 = torch.ops.aten.clamp_min.default(sum_24, 8);  sum_24 = None
        add_360 = torch.ops.aten.add.Tensor(clamp_min_5, 8);  clamp_min_5 = None
        sub_125 = torch.ops.aten.sub.Tensor(add_360, 1);  add_360 = None
        div_28 = torch.ops.aten.div.Tensor_mode(sub_125, 8, rounding_mode = 'floor');  sub_125 = None
        mul_268 = torch.ops.aten.mul.Tensor(div_28, 8);  div_28 = None
        convert_element_type_338 = torch.ops.prims.convert_element_type.default(mul_268, torch.int32);  mul_268 = None
        cumsum_16 = torch.ops.aten.cumsum.default(convert_element_type_338, 0)
        sub_126 = torch.ops.aten.sub.Tensor(cumsum_16, convert_element_type_338);  cumsum_16 = None
        full_85 = torch.ops.aten.full.default([mul_267], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_267 = None
        triton_kernel_wrapper_functional_proxy_5 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 5, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_125, 'start_index_values_ptr': sub_124, 'write_offsets_ptr': sub_126, 'output_ptr': full_85}, tensors_to_clone = ['output_ptr']);  wait_tensor_125 = sub_124 = sub_126 = full_85 = None
        getitem_572 = triton_kernel_wrapper_functional_proxy_5['output_ptr'];  triton_kernel_wrapper_functional_proxy_5 = None
        cat_49 = torch.ops.aten.cat.default([wait_tensor_126, full_default]);  wait_tensor_126 = None
        sym_size_int_21 = torch.ops.aten.sym_size.int(cat_49, 0)
        sym_sum_11 = torch.sym_sum((1, _local_scalar_dense_88, _local_scalar_dense_89, _local_scalar_dense_90, _local_scalar_dense_91, _local_scalar_dense_92, _local_scalar_dense_93, _local_scalar_dense_94, _local_scalar_dense_95))
        index_11 = torch.ops.aten.index.Tensor(cat_49, [getitem_572]);  cat_49 = None
        convert_element_type_340 = torch.ops.prims.convert_element_type.default(primals_113, torch.bfloat16)
        all_gather_into_tensor_104 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_340, 16, '1025');  convert_element_type_340 = None
        wait_tensor_127 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_104);  all_gather_into_tensor_104 = None
        split_31 = torch.ops.aten.split.Tensor(wait_tensor_127, 8);  wait_tensor_127 = None
        getitem_589 = split_31[0]
        getitem_590 = split_31[1]
        getitem_591 = split_31[2]
        getitem_592 = split_31[3]
        getitem_593 = split_31[4]
        getitem_594 = split_31[5]
        getitem_595 = split_31[6]
        getitem_596 = split_31[7]
        getitem_597 = split_31[8]
        getitem_598 = split_31[9]
        getitem_599 = split_31[10]
        getitem_600 = split_31[11]
        getitem_601 = split_31[12]
        getitem_602 = split_31[13]
        getitem_603 = split_31[14]
        getitem_604 = split_31[15];  split_31 = None
        cat_51 = torch.ops.aten.cat.default([getitem_589, getitem_590, getitem_591, getitem_592, getitem_593, getitem_594, getitem_595, getitem_596, getitem_597, getitem_598, getitem_599, getitem_600, getitem_601, getitem_602, getitem_603, getitem_604], 1);  getitem_589 = getitem_590 = getitem_591 = getitem_592 = getitem_593 = getitem_594 = getitem_595 = getitem_596 = getitem_597 = getitem_598 = getitem_599 = getitem_600 = getitem_601 = getitem_602 = getitem_603 = getitem_604 = None
        convert_element_type_342 = torch.ops.prims.convert_element_type.default(primals_114, torch.bfloat16)
        all_gather_into_tensor_106 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_342, 16, '1025');  convert_element_type_342 = None
        wait_tensor_129 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_106);  all_gather_into_tensor_106 = None
        split_32 = torch.ops.aten.split.Tensor(wait_tensor_129, 8);  wait_tensor_129 = None
        getitem_605 = split_32[0]
        getitem_606 = split_32[1]
        getitem_607 = split_32[2]
        getitem_608 = split_32[3]
        getitem_609 = split_32[4]
        getitem_610 = split_32[5]
        getitem_611 = split_32[6]
        getitem_612 = split_32[7]
        getitem_613 = split_32[8]
        getitem_614 = split_32[9]
        getitem_615 = split_32[10]
        getitem_616 = split_32[11]
        getitem_617 = split_32[12]
        getitem_618 = split_32[13]
        getitem_619 = split_32[14]
        getitem_620 = split_32[15];  split_32 = None
        cat_52 = torch.ops.aten.cat.default([getitem_605, getitem_606, getitem_607, getitem_608, getitem_609, getitem_610, getitem_611, getitem_612, getitem_613, getitem_614, getitem_615, getitem_616, getitem_617, getitem_618, getitem_619, getitem_620], 1);  getitem_605 = getitem_606 = getitem_607 = getitem_608 = getitem_609 = getitem_610 = getitem_611 = getitem_612 = getitem_613 = getitem_614 = getitem_615 = getitem_616 = getitem_617 = getitem_618 = getitem_619 = getitem_620 = None
        convert_element_type_343 = torch.ops.prims.convert_element_type.default(primals_115, torch.bfloat16)
        all_gather_into_tensor_107 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_343, 16, '1025');  convert_element_type_343 = None
        wait_tensor_130 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_107);  all_gather_into_tensor_107 = None
        split_33 = torch.ops.aten.split.Tensor(wait_tensor_130, 8);  wait_tensor_130 = None
        getitem_621 = split_33[0]
        getitem_622 = split_33[1]
        getitem_623 = split_33[2]
        getitem_624 = split_33[3]
        getitem_625 = split_33[4]
        getitem_626 = split_33[5]
        getitem_627 = split_33[6]
        getitem_628 = split_33[7]
        getitem_629 = split_33[8]
        getitem_630 = split_33[9]
        getitem_631 = split_33[10]
        getitem_632 = split_33[11]
        getitem_633 = split_33[12]
        getitem_634 = split_33[13]
        getitem_635 = split_33[14]
        getitem_636 = split_33[15];  split_33 = None
        cat_53 = torch.ops.aten.cat.default([getitem_621, getitem_622, getitem_623, getitem_624, getitem_625, getitem_626, getitem_627, getitem_628, getitem_629, getitem_630, getitem_631, getitem_632, getitem_633, getitem_634, getitem_635, getitem_636], 1);  getitem_621 = getitem_622 = getitem_623 = getitem_624 = getitem_625 = getitem_626 = getitem_627 = getitem_628 = getitem_629 = getitem_630 = getitem_631 = getitem_632 = getitem_633 = getitem_634 = getitem_635 = getitem_636 = None
        cumsum_17 = torch.ops.aten.cumsum.default(convert_element_type_338, 0, dtype = torch.int32);  convert_element_type_338 = None
        permute_95 = torch.ops.aten.permute.default(cat_51, [0, 2, 1]);  cat_51 = None
        _grouped_mm_15 = torch.ops.aten._grouped_mm.default(index_11, permute_95, cumsum_17)
        convert_element_type_346 = torch.ops.prims.convert_element_type.default(_grouped_mm_15, torch.float32)
        neg_11 = torch.ops.aten.neg.default(convert_element_type_346)
        exp_17 = torch.ops.aten.exp.default(neg_11);  neg_11 = None
        add_372 = torch.ops.aten.add.Tensor(exp_17, 1);  exp_17 = None
        div_29 = torch.ops.aten.div.Tensor(convert_element_type_346, add_372);  convert_element_type_346 = add_372 = None
        convert_element_type_347 = torch.ops.prims.convert_element_type.default(div_29, torch.bfloat16);  div_29 = None
        permute_96 = torch.ops.aten.permute.default(cat_53, [0, 2, 1]);  cat_53 = None
        _grouped_mm_16 = torch.ops.aten._grouped_mm.default(index_11, permute_96, cumsum_17)
        mul_280 = torch.ops.aten.mul.Tensor(convert_element_type_347, _grouped_mm_16);  convert_element_type_347 = None
        permute_97 = torch.ops.aten.permute.default(cat_52, [0, 2, 1]);  cat_52 = None
        _grouped_mm_17 = torch.ops.aten._grouped_mm.default(mul_280, permute_97, cumsum_17)
        empty_5 = torch.ops.aten.empty.memory_format([sym_size_int_21, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_10 = torch.ops.aten.index_put.default(empty_5, [getitem_572], _grouped_mm_17);  empty_5 = _grouped_mm_17 = None
        slice_41 = torch.ops.aten.slice.Tensor(index_put_10, 0, 0, -1);  index_put_10 = None
        all_to_all_single_17 = torch.ops._c10d_functional.all_to_all_single.default(slice_41, [_local_scalar_dense_80, _local_scalar_dense_81, _local_scalar_dense_82, _local_scalar_dense_83, _local_scalar_dense_84, _local_scalar_dense_85, _local_scalar_dense_86, _local_scalar_dense_87], [_local_scalar_dense_88, _local_scalar_dense_89, _local_scalar_dense_90, _local_scalar_dense_91, _local_scalar_dense_92, _local_scalar_dense_93, _local_scalar_dense_94, _local_scalar_dense_95], '1033');  slice_41 = None
        wait_tensor_133 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_17);  all_to_all_single_17 = None
        convert_element_type_348 = torch.ops.prims.convert_element_type.default(primals_116, torch.bfloat16)
        all_gather_into_tensor_110 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_348, 128, '0');  convert_element_type_348 = None
        wait_tensor_134 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_110);  all_gather_into_tensor_110 = None
        permute_98 = torch.ops.aten.permute.default(wait_tensor_134, [1, 0]);  wait_tensor_134 = None
        mm_52 = torch.ops.aten.mm.default(view_393, permute_98);  permute_98 = None
        convert_element_type_351 = torch.ops.prims.convert_element_type.default(mm_52, torch.float32)
        neg_12 = torch.ops.aten.neg.default(convert_element_type_351)
        exp_18 = torch.ops.aten.exp.default(neg_12);  neg_12 = None
        add_408 = torch.ops.aten.add.Tensor(exp_18, 1);  exp_18 = None
        div_30 = torch.ops.aten.div.Tensor(convert_element_type_351, add_408);  convert_element_type_351 = add_408 = None
        convert_element_type_352 = torch.ops.prims.convert_element_type.default(div_30, torch.bfloat16);  div_30 = None
        convert_element_type_353 = torch.ops.prims.convert_element_type.default(primals_117, torch.bfloat16)
        all_gather_into_tensor_111 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_353, 128, '0');  convert_element_type_353 = None
        wait_tensor_135 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_111);  all_gather_into_tensor_111 = None
        permute_99 = torch.ops.aten.permute.default(wait_tensor_135, [1, 0]);  wait_tensor_135 = None
        mm_53 = torch.ops.aten.mm.default(view_393, permute_99);  permute_99 = None
        mul_300 = torch.ops.aten.mul.Tensor(convert_element_type_352, mm_53);  convert_element_type_352 = None
        convert_element_type_356 = torch.ops.prims.convert_element_type.default(primals_118, torch.bfloat16)
        all_gather_into_tensor_112 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_356, 128, '0');  convert_element_type_356 = None
        wait_tensor_136 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_112);  all_gather_into_tensor_112 = None
        permute_100 = torch.ops.aten.permute.default(wait_tensor_136, [1, 0]);  wait_tensor_136 = None
        mm_54 = torch.ops.aten.mm.default(mul_300, permute_100);  permute_100 = None
        index_put_11 = torch.ops.aten.index_put.default(full_default_1, [getitem_571], wait_tensor_133);  wait_tensor_133 = None
        view_433 = torch.ops.aten.view.default(mul_262, [-1, 1, 6]);  mul_262 = None
        view_434 = torch.ops.aten.view.default(index_put_11, [-1, 6, 2048]);  index_put_11 = None
        convert_element_type_359 = torch.ops.prims.convert_element_type.default(view_434, torch.float32);  view_434 = None
        bmm_5 = torch.ops.aten.bmm.default(view_433, convert_element_type_359)
        convert_element_type_360 = torch.ops.prims.convert_element_type.default(bmm_5, torch.bfloat16);  bmm_5 = None
        squeeze_5 = torch.ops.aten.squeeze.dim(convert_element_type_360, 1);  convert_element_type_360 = None
        add_412 = torch.ops.aten.add.Tensor(mm_54, squeeze_5);  mm_54 = squeeze_5 = None
        view_435 = torch.ops.aten.view.default(add_412, [2, 4096, 2048]);  add_412 = None
        add_413 = torch.ops.aten.add.Tensor(add_348, view_435);  view_435 = None
        convert_element_type_361 = torch.ops.prims.convert_element_type.default(primals_119, torch.bfloat16)
        all_gather_into_tensor_113 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_361, 128, '0');  convert_element_type_361 = None
        wait_tensor_137 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_113);  all_gather_into_tensor_113 = None
        convert_element_type_362 = torch.ops.prims.convert_element_type.default(add_413, torch.float32)
        pow_22 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_362, 2)
        mean_21 = torch.ops.aten.mean.dim(pow_22, [2], True);  pow_22 = None
        add_414 = torch.ops.aten.add.Scalar(mean_21, 1e-05);  mean_21 = None
        rsqrt_21 = torch.ops.aten.rsqrt.default(add_414);  add_414 = None
        mul_303 = torch.ops.aten.mul.Tensor(convert_element_type_362, rsqrt_21);  convert_element_type_362 = None
        mul_304 = torch.ops.aten.mul.Tensor(mul_303, wait_tensor_137);  mul_303 = wait_tensor_137 = None
        convert_element_type_363 = torch.ops.prims.convert_element_type.default(mul_304, torch.bfloat16);  mul_304 = None
        convert_element_type_364 = torch.ops.prims.convert_element_type.default(primals_120, torch.bfloat16)
        all_gather_into_tensor_114 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_364, 128, '0');  convert_element_type_364 = None
        wait_tensor_138 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_114);  all_gather_into_tensor_114 = None
        permute_101 = torch.ops.aten.permute.default(wait_tensor_138, [1, 0]);  wait_tensor_138 = None
        view_438 = torch.ops.aten.view.default(convert_element_type_363, [8192, 2048]);  convert_element_type_363 = None
        mm_55 = torch.ops.aten.mm.default(view_438, permute_101);  permute_101 = None
        view_439 = torch.ops.aten.view.default(mm_55, [2, 4096, 3072]);  mm_55 = None
        view_440 = torch.ops.aten.view.default(view_439, [2, 4096, -1, 192]);  view_439 = None
        split_with_sizes_21 = torch.ops.aten.split_with_sizes.default(view_440, [128, 64], -1);  view_440 = None
        getitem_669 = split_with_sizes_21[0]
        getitem_670 = split_with_sizes_21[1];  split_with_sizes_21 = None
        convert_element_type_367 = torch.ops.prims.convert_element_type.default(getitem_670, torch.float32);  getitem_670 = None
        view_441 = torch.ops.aten.view.default(convert_element_type_367, [2, 4096, 16, -1, 2]);  convert_element_type_367 = None
        view_as_complex_14 = torch.ops.aten.view_as_complex.default(view_441);  view_441 = None
        mul_305 = torch.ops.aten.mul.Tensor(view_as_complex_14, view_7);  view_as_complex_14 = None
        view_as_real_14 = torch.ops.aten.view_as_real.default(mul_305);  mul_305 = None
        view_443 = torch.ops.aten.view.default(view_as_real_14, [2, 4096, 16, 64]);  view_as_real_14 = None
        convert_element_type_368 = torch.ops.prims.convert_element_type.default(view_443, torch.bfloat16);  view_443 = None
        cat_56 = torch.ops.aten.cat.default([getitem_669, convert_element_type_368], -1);  getitem_669 = convert_element_type_368 = None
        convert_element_type_369 = torch.ops.prims.convert_element_type.default(primals_121, torch.bfloat16)
        all_gather_into_tensor_115 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_369, 128, '0');  convert_element_type_369 = None
        wait_tensor_139 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_115);  all_gather_into_tensor_115 = None
        slice_43 = torch.ops.aten.slice.Tensor(wait_tensor_139, 0, 0, 576);  wait_tensor_139 = None
        permute_102 = torch.ops.aten.permute.default(slice_43, [1, 0]);  slice_43 = None
        mm_56 = torch.ops.aten.mm.default(view_438, permute_102);  permute_102 = None
        view_446 = torch.ops.aten.view.default(mm_56, [2, 4096, 576]);  mm_56 = None
        split_with_sizes_22 = torch.ops.aten.split_with_sizes.default(view_446, [512, 64], -1);  view_446 = None
        getitem_671 = split_with_sizes_22[0]
        getitem_672 = split_with_sizes_22[1];  split_with_sizes_22 = None
        unsqueeze_13 = torch.ops.aten.unsqueeze.default(getitem_672, 2);  getitem_672 = None
        convert_element_type_372 = torch.ops.prims.convert_element_type.default(unsqueeze_13, torch.float32);  unsqueeze_13 = None
        view_447 = torch.ops.aten.view.default(convert_element_type_372, [2, 4096, 1, -1, 2]);  convert_element_type_372 = None
        view_as_complex_15 = torch.ops.aten.view_as_complex.default(view_447);  view_447 = None
        mul_306 = torch.ops.aten.mul.Tensor(view_as_complex_15, view_7);  view_as_complex_15 = None
        view_as_real_15 = torch.ops.aten.view_as_real.default(mul_306);  mul_306 = None
        view_449 = torch.ops.aten.view.default(view_as_real_15, [2, 4096, 1, 64]);  view_as_real_15 = None
        convert_element_type_373 = torch.ops.prims.convert_element_type.default(view_449, torch.bfloat16);  view_449 = None
        convert_element_type_374 = torch.ops.prims.convert_element_type.default(primals_122, torch.bfloat16)
        all_gather_into_tensor_116 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_374, 128, '0');  convert_element_type_374 = None
        wait_tensor_140 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_116);  all_gather_into_tensor_116 = None
        convert_element_type_375 = torch.ops.prims.convert_element_type.default(getitem_671, torch.float32)
        pow_23 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_375, 2)
        mean_22 = torch.ops.aten.mean.dim(pow_23, [2], True);  pow_23 = None
        add_415 = torch.ops.aten.add.Scalar(mean_22, 1e-05);  mean_22 = None
        rsqrt_22 = torch.ops.aten.rsqrt.default(add_415);  add_415 = None
        mul_307 = torch.ops.aten.mul.Tensor(convert_element_type_375, rsqrt_22);  convert_element_type_375 = None
        mul_308 = torch.ops.aten.mul.Tensor(mul_307, wait_tensor_140);  mul_307 = wait_tensor_140 = None
        convert_element_type_376 = torch.ops.prims.convert_element_type.default(mul_308, torch.bfloat16);  mul_308 = None
        convert_element_type_377 = torch.ops.prims.convert_element_type.default(primals_123, torch.bfloat16)
        all_gather_into_tensor_117 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_377, 128, '0');  convert_element_type_377 = None
        wait_tensor_141 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_117);  all_gather_into_tensor_117 = None
        permute_103 = torch.ops.aten.permute.default(wait_tensor_141, [1, 0]);  wait_tensor_141 = None
        view_452 = torch.ops.aten.view.default(convert_element_type_376, [8192, 512]);  convert_element_type_376 = None
        mm_57 = torch.ops.aten.mm.default(view_452, permute_103);  permute_103 = None
        view_453 = torch.ops.aten.view.default(mm_57, [2, 4096, 4096]);  mm_57 = None
        view_454 = torch.ops.aten.view.default(view_453, [2, 4096, -1, 256]);  view_453 = None
        split_with_sizes_23 = torch.ops.aten.split_with_sizes.default(view_454, [128, 128], -1);  view_454 = None
        getitem_673 = split_with_sizes_23[0]
        getitem_674 = split_with_sizes_23[1];  split_with_sizes_23 = None
        expand_7 = torch.ops.aten.expand.default(convert_element_type_373, [-1, -1, 16, -1]);  convert_element_type_373 = None
        cat_57 = torch.ops.aten.cat.default([getitem_673, expand_7], -1);  getitem_673 = expand_7 = None
        permute_104 = torch.ops.aten.permute.default(cat_56, [0, 2, 1, 3]);  cat_56 = None
        permute_105 = torch.ops.aten.permute.default(cat_57, [0, 2, 1, 3]);  cat_57 = None
        permute_106 = torch.ops.aten.permute.default(getitem_674, [0, 2, 1, 3]);  getitem_674 = None
        sdpa_score7 = self.sdpa_score7
        sdpa_mask7 = self.sdpa_mask7
        flex_attention_7 = torch.ops.higher_order.flex_attention(permute_104, permute_105, permute_106, sdpa_score7, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask7), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score7 = sdpa_mask7 = None
        getitem_675 = flex_attention_7[0]
        getitem_676 = flex_attention_7[1];  flex_attention_7 = None
        permute_107 = torch.ops.aten.permute.default(getitem_675, [0, 2, 1, 3])
        view_455 = torch.ops.aten.view.default(permute_107, [2, 4096, -1]);  permute_107 = None
        convert_element_type_380 = torch.ops.prims.convert_element_type.default(primals_124, torch.bfloat16)
        all_gather_into_tensor_118 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_380, 128, '0');  convert_element_type_380 = None
        wait_tensor_142 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_118);  all_gather_into_tensor_118 = None
        permute_108 = torch.ops.aten.permute.default(wait_tensor_142, [1, 0]);  wait_tensor_142 = None
        view_457 = torch.ops.aten.view.default(view_455, [8192, 2048]);  view_455 = None
        mm_58 = torch.ops.aten.mm.default(view_457, permute_108);  view_457 = permute_108 = None
        view_458 = torch.ops.aten.view.default(mm_58, [2, 4096, 2048]);  mm_58 = None
        add_416 = torch.ops.aten.add.Tensor(add_413, view_458);  view_458 = None
        convert_element_type_383 = torch.ops.prims.convert_element_type.default(primals_125, torch.bfloat16)
        all_gather_into_tensor_119 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_383, 128, '0');  convert_element_type_383 = None
        wait_tensor_143 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_119);  all_gather_into_tensor_119 = None
        convert_element_type_384 = torch.ops.prims.convert_element_type.default(add_416, torch.float32)
        pow_24 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_384, 2)
        mean_23 = torch.ops.aten.mean.dim(pow_24, [2], True);  pow_24 = None
        add_417 = torch.ops.aten.add.Scalar(mean_23, 1e-05);  mean_23 = None
        rsqrt_23 = torch.ops.aten.rsqrt.default(add_417);  add_417 = None
        mul_309 = torch.ops.aten.mul.Tensor(convert_element_type_384, rsqrt_23);  convert_element_type_384 = None
        mul_310 = torch.ops.aten.mul.Tensor(mul_309, wait_tensor_143);  mul_309 = wait_tensor_143 = None
        convert_element_type_385 = torch.ops.prims.convert_element_type.default(mul_310, torch.bfloat16);  mul_310 = None
        view_460 = torch.ops.aten.view.default(convert_element_type_385, [-1, 2048]);  convert_element_type_385 = None
        convert_element_type_386 = torch.ops.prims.convert_element_type.default(primals_127, torch.bfloat16)
        all_gather_into_tensor_120 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_386, 128, '0');  convert_element_type_386 = None
        wait_tensor_144 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_120);  all_gather_into_tensor_120 = None
        slice_45 = torch.ops.aten.slice.Tensor(wait_tensor_144, 0, 0, 64);  wait_tensor_144 = None
        permute_109 = torch.ops.aten.permute.default(slice_45, [1, 0]);  slice_45 = None
        mm_59 = torch.ops.aten.mm.default(view_460, permute_109);  permute_109 = None
        convert_element_type_389 = torch.ops.prims.convert_element_type.default(mm_59, torch.float32)
        amax_6 = torch.ops.aten.amax.default(convert_element_type_389, [1], True)
        sub_144 = torch.ops.aten.sub.Tensor(convert_element_type_389, amax_6);  convert_element_type_389 = None
        exp_19 = torch.ops.aten.exp.default(sub_144);  sub_144 = None
        sum_25 = torch.ops.aten.sum.dim_IntList(exp_19, [1], True)
        div_31 = torch.ops.aten.div.Tensor(exp_19, sum_25);  exp_19 = None
        add_418 = torch.ops.aten.add.Tensor(div_31, primals_126);  primals_126 = None
        topk_6 = torch.ops.aten.topk.default(add_418, 6, -1, True, False);  add_418 = None
        getitem_679 = topk_6[1];  topk_6 = None
        gather_6 = torch.ops.aten.gather.default(div_31, 1, getitem_679);  div_31 = None
        mul_311 = torch.ops.aten.mul.Tensor(gather_6, 1.0);  gather_6 = None
        view_462 = torch.ops.aten.view.default(getitem_679, [-1])
        histc_12 = torch.ops.aten.histc.default(view_462, 64, 0, 64)
        add_419 = torch.ops.aten.add.Tensor(primals_128, histc_12)
        sort_6 = torch.ops.aten.sort.stable(view_462, stable = True);  view_462 = None
        getitem_681 = sort_6[1];  sort_6 = None
        div_32 = torch.ops.aten.div.Tensor_mode(getitem_681, 6, rounding_mode = 'floor')
        index_12 = torch.ops.aten.index.Tensor(view_460, [div_32])
        all_to_all_single_18 = torch.ops._c10d_functional.all_to_all_single.default(histc_12, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_145 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_18);  all_to_all_single_18 = None
        wait_tensor_146 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_145);  wait_tensor_145 = None
        view_466 = torch.ops.aten.view.default(histc_12, [8, -1]);  histc_12 = None
        sum_26 = torch.ops.aten.sum.dim_IntList(view_466, [1]);  view_466 = None
        device_put_12 = torch.ops.prims.device_put.default(sum_26, device(type='cpu'), True);  sum_26 = None
        view_467 = torch.ops.aten.view.default(wait_tensor_146, [8, -1])
        sum_27 = torch.ops.aten.sum.dim_IntList(view_467, [1])
        device_put_13 = torch.ops.prims.device_put.default(sum_27, device(type='cpu'));  sum_27 = None
        select_96 = torch.ops.aten.select.int(device_put_12, 0, 0)
        _local_scalar_dense_96 = torch.ops.aten._local_scalar_dense.default(select_96);  select_96 = None
        ge_120 = _local_scalar_dense_96 >= 0
        _assert_scalar_96 = torch.ops.aten._assert_scalar.default(ge_120, "Runtime assertion failed for expression u96 >= 0 on node 'ge_96'");  ge_120 = _assert_scalar_96 = None
        select_97 = torch.ops.aten.select.int(device_put_12, 0, 1)
        _local_scalar_dense_97 = torch.ops.aten._local_scalar_dense.default(select_97);  select_97 = None
        ge_121 = _local_scalar_dense_97 >= 0
        _assert_scalar_97 = torch.ops.aten._assert_scalar.default(ge_121, "Runtime assertion failed for expression u97 >= 0 on node 'ge_97'");  ge_121 = _assert_scalar_97 = None
        select_98 = torch.ops.aten.select.int(device_put_12, 0, 2)
        _local_scalar_dense_98 = torch.ops.aten._local_scalar_dense.default(select_98);  select_98 = None
        ge_122 = _local_scalar_dense_98 >= 0
        _assert_scalar_98 = torch.ops.aten._assert_scalar.default(ge_122, "Runtime assertion failed for expression u98 >= 0 on node 'ge_98'");  ge_122 = _assert_scalar_98 = None
        select_99 = torch.ops.aten.select.int(device_put_12, 0, 3)
        _local_scalar_dense_99 = torch.ops.aten._local_scalar_dense.default(select_99);  select_99 = None
        ge_123 = _local_scalar_dense_99 >= 0
        _assert_scalar_99 = torch.ops.aten._assert_scalar.default(ge_123, "Runtime assertion failed for expression u99 >= 0 on node 'ge_99'");  ge_123 = _assert_scalar_99 = None
        select_100 = torch.ops.aten.select.int(device_put_12, 0, 4)
        _local_scalar_dense_100 = torch.ops.aten._local_scalar_dense.default(select_100);  select_100 = None
        ge_124 = _local_scalar_dense_100 >= 0
        _assert_scalar_100 = torch.ops.aten._assert_scalar.default(ge_124, "Runtime assertion failed for expression u100 >= 0 on node 'ge_100'");  ge_124 = _assert_scalar_100 = None
        select_101 = torch.ops.aten.select.int(device_put_12, 0, 5)
        _local_scalar_dense_101 = torch.ops.aten._local_scalar_dense.default(select_101);  select_101 = None
        ge_125 = _local_scalar_dense_101 >= 0
        _assert_scalar_101 = torch.ops.aten._assert_scalar.default(ge_125, "Runtime assertion failed for expression u101 >= 0 on node 'ge_101'");  ge_125 = _assert_scalar_101 = None
        select_102 = torch.ops.aten.select.int(device_put_12, 0, 6)
        _local_scalar_dense_102 = torch.ops.aten._local_scalar_dense.default(select_102);  select_102 = None
        ge_126 = _local_scalar_dense_102 >= 0
        _assert_scalar_102 = torch.ops.aten._assert_scalar.default(ge_126, "Runtime assertion failed for expression u102 >= 0 on node 'ge_102'");  ge_126 = _assert_scalar_102 = None
        select_103 = torch.ops.aten.select.int(device_put_12, 0, 7);  device_put_12 = None
        _local_scalar_dense_103 = torch.ops.aten._local_scalar_dense.default(select_103);  select_103 = None
        ge_127 = _local_scalar_dense_103 >= 0
        _assert_scalar_103 = torch.ops.aten._assert_scalar.default(ge_127, "Runtime assertion failed for expression u103 >= 0 on node 'ge_103'");  ge_127 = _assert_scalar_103 = None
        select_104 = torch.ops.aten.select.int(device_put_13, 0, 0)
        _local_scalar_dense_104 = torch.ops.aten._local_scalar_dense.default(select_104);  select_104 = None
        ge_128 = _local_scalar_dense_104 >= 0
        _assert_scalar_104 = torch.ops.aten._assert_scalar.default(ge_128, "Runtime assertion failed for expression u104 >= 0 on node 'ge_104'");  ge_128 = _assert_scalar_104 = None
        select_105 = torch.ops.aten.select.int(device_put_13, 0, 1)
        _local_scalar_dense_105 = torch.ops.aten._local_scalar_dense.default(select_105);  select_105 = None
        ge_129 = _local_scalar_dense_105 >= 0
        _assert_scalar_105 = torch.ops.aten._assert_scalar.default(ge_129, "Runtime assertion failed for expression u105 >= 0 on node 'ge_105'");  ge_129 = _assert_scalar_105 = None
        select_106 = torch.ops.aten.select.int(device_put_13, 0, 2)
        _local_scalar_dense_106 = torch.ops.aten._local_scalar_dense.default(select_106);  select_106 = None
        ge_130 = _local_scalar_dense_106 >= 0
        _assert_scalar_106 = torch.ops.aten._assert_scalar.default(ge_130, "Runtime assertion failed for expression u106 >= 0 on node 'ge_106'");  ge_130 = _assert_scalar_106 = None
        select_107 = torch.ops.aten.select.int(device_put_13, 0, 3)
        _local_scalar_dense_107 = torch.ops.aten._local_scalar_dense.default(select_107);  select_107 = None
        ge_131 = _local_scalar_dense_107 >= 0
        _assert_scalar_107 = torch.ops.aten._assert_scalar.default(ge_131, "Runtime assertion failed for expression u107 >= 0 on node 'ge_107'");  ge_131 = _assert_scalar_107 = None
        select_108 = torch.ops.aten.select.int(device_put_13, 0, 4)
        _local_scalar_dense_108 = torch.ops.aten._local_scalar_dense.default(select_108);  select_108 = None
        ge_132 = _local_scalar_dense_108 >= 0
        _assert_scalar_108 = torch.ops.aten._assert_scalar.default(ge_132, "Runtime assertion failed for expression u108 >= 0 on node 'ge_108'");  ge_132 = _assert_scalar_108 = None
        select_109 = torch.ops.aten.select.int(device_put_13, 0, 5)
        _local_scalar_dense_109 = torch.ops.aten._local_scalar_dense.default(select_109);  select_109 = None
        ge_133 = _local_scalar_dense_109 >= 0
        _assert_scalar_109 = torch.ops.aten._assert_scalar.default(ge_133, "Runtime assertion failed for expression u109 >= 0 on node 'ge_109'");  ge_133 = _assert_scalar_109 = None
        select_110 = torch.ops.aten.select.int(device_put_13, 0, 6)
        _local_scalar_dense_110 = torch.ops.aten._local_scalar_dense.default(select_110);  select_110 = None
        ge_134 = _local_scalar_dense_110 >= 0
        _assert_scalar_110 = torch.ops.aten._assert_scalar.default(ge_134, "Runtime assertion failed for expression u110 >= 0 on node 'ge_110'");  ge_134 = _assert_scalar_110 = None
        select_111 = torch.ops.aten.select.int(device_put_13, 0, 7);  device_put_13 = None
        _local_scalar_dense_111 = torch.ops.aten._local_scalar_dense.default(select_111);  select_111 = None
        ge_135 = _local_scalar_dense_111 >= 0
        _assert_scalar_111 = torch.ops.aten._assert_scalar.default(ge_135, "Runtime assertion failed for expression u111 >= 0 on node 'ge_111'");  ge_135 = _assert_scalar_111 = None
        all_to_all_single_19 = torch.ops._c10d_functional.all_to_all_single.default(index_12, [_local_scalar_dense_104, _local_scalar_dense_105, _local_scalar_dense_106, _local_scalar_dense_107, _local_scalar_dense_108, _local_scalar_dense_109, _local_scalar_dense_110, _local_scalar_dense_111], [_local_scalar_dense_96, _local_scalar_dense_97, _local_scalar_dense_98, _local_scalar_dense_99, _local_scalar_dense_100, _local_scalar_dense_101, _local_scalar_dense_102, _local_scalar_dense_103], '1033');  index_12 = None
        sym_size_int_24 = torch.ops.aten.sym_size.int(all_to_all_single_19, 0)
        wait_tensor_147 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_19);  all_to_all_single_19 = None
        sym_sum_12 = torch.sym_sum((_local_scalar_dense_104, _local_scalar_dense_105, _local_scalar_dense_106, _local_scalar_dense_107, _local_scalar_dense_108, _local_scalar_dense_109, _local_scalar_dense_110, _local_scalar_dense_111))
        add_426 = sym_sum_12 + 64;  sym_sum_12 = None
        add_427 = add_426 + 8;  add_426 = None
        sub_147 = add_427 - 1;  add_427 = None
        floordiv_6 = sub_147 // 8;  sub_147 = None
        mul_316 = floordiv_6 * 8;  floordiv_6 = None
        cumsum_18 = torch.ops.aten.cumsum.default(wait_tensor_146, 0)
        sub_148 = torch.ops.aten.sub.Tensor(cumsum_18, wait_tensor_146);  cumsum_18 = None
        sum_28 = torch.ops.aten.sum.dim_IntList(view_467, [0]);  view_467 = None
        clamp_min_6 = torch.ops.aten.clamp_min.default(sum_28, 8);  sum_28 = None
        add_428 = torch.ops.aten.add.Tensor(clamp_min_6, 8);  clamp_min_6 = None
        sub_149 = torch.ops.aten.sub.Tensor(add_428, 1);  add_428 = None
        div_33 = torch.ops.aten.div.Tensor_mode(sub_149, 8, rounding_mode = 'floor');  sub_149 = None
        mul_317 = torch.ops.aten.mul.Tensor(div_33, 8);  div_33 = None
        convert_element_type_392 = torch.ops.prims.convert_element_type.default(mul_317, torch.int32);  mul_317 = None
        cumsum_19 = torch.ops.aten.cumsum.default(convert_element_type_392, 0)
        sub_150 = torch.ops.aten.sub.Tensor(cumsum_19, convert_element_type_392);  cumsum_19 = None
        full_98 = torch.ops.aten.full.default([mul_316], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_316 = None
        triton_kernel_wrapper_functional_proxy_6 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 6, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_146, 'start_index_values_ptr': sub_148, 'write_offsets_ptr': sub_150, 'output_ptr': full_98}, tensors_to_clone = ['output_ptr']);  wait_tensor_146 = sub_148 = sub_150 = full_98 = None
        getitem_682 = triton_kernel_wrapper_functional_proxy_6['output_ptr'];  triton_kernel_wrapper_functional_proxy_6 = None
        cat_58 = torch.ops.aten.cat.default([wait_tensor_147, full_default]);  wait_tensor_147 = None
        sym_size_int_25 = torch.ops.aten.sym_size.int(cat_58, 0)
        sym_sum_13 = torch.sym_sum((1, _local_scalar_dense_104, _local_scalar_dense_105, _local_scalar_dense_106, _local_scalar_dense_107, _local_scalar_dense_108, _local_scalar_dense_109, _local_scalar_dense_110, _local_scalar_dense_111))
        index_13 = torch.ops.aten.index.Tensor(cat_58, [getitem_682]);  cat_58 = None
        convert_element_type_394 = torch.ops.prims.convert_element_type.default(primals_129, torch.bfloat16)
        all_gather_into_tensor_121 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_394, 16, '1025');  convert_element_type_394 = None
        wait_tensor_148 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_121);  all_gather_into_tensor_121 = None
        split_37 = torch.ops.aten.split.Tensor(wait_tensor_148, 8);  wait_tensor_148 = None
        getitem_699 = split_37[0]
        getitem_700 = split_37[1]
        getitem_701 = split_37[2]
        getitem_702 = split_37[3]
        getitem_703 = split_37[4]
        getitem_704 = split_37[5]
        getitem_705 = split_37[6]
        getitem_706 = split_37[7]
        getitem_707 = split_37[8]
        getitem_708 = split_37[9]
        getitem_709 = split_37[10]
        getitem_710 = split_37[11]
        getitem_711 = split_37[12]
        getitem_712 = split_37[13]
        getitem_713 = split_37[14]
        getitem_714 = split_37[15];  split_37 = None
        cat_60 = torch.ops.aten.cat.default([getitem_699, getitem_700, getitem_701, getitem_702, getitem_703, getitem_704, getitem_705, getitem_706, getitem_707, getitem_708, getitem_709, getitem_710, getitem_711, getitem_712, getitem_713, getitem_714], 1);  getitem_699 = getitem_700 = getitem_701 = getitem_702 = getitem_703 = getitem_704 = getitem_705 = getitem_706 = getitem_707 = getitem_708 = getitem_709 = getitem_710 = getitem_711 = getitem_712 = getitem_713 = getitem_714 = None
        convert_element_type_396 = torch.ops.prims.convert_element_type.default(primals_130, torch.bfloat16)
        all_gather_into_tensor_123 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_396, 16, '1025');  convert_element_type_396 = None
        wait_tensor_150 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_123);  all_gather_into_tensor_123 = None
        split_38 = torch.ops.aten.split.Tensor(wait_tensor_150, 8);  wait_tensor_150 = None
        getitem_715 = split_38[0]
        getitem_716 = split_38[1]
        getitem_717 = split_38[2]
        getitem_718 = split_38[3]
        getitem_719 = split_38[4]
        getitem_720 = split_38[5]
        getitem_721 = split_38[6]
        getitem_722 = split_38[7]
        getitem_723 = split_38[8]
        getitem_724 = split_38[9]
        getitem_725 = split_38[10]
        getitem_726 = split_38[11]
        getitem_727 = split_38[12]
        getitem_728 = split_38[13]
        getitem_729 = split_38[14]
        getitem_730 = split_38[15];  split_38 = None
        cat_61 = torch.ops.aten.cat.default([getitem_715, getitem_716, getitem_717, getitem_718, getitem_719, getitem_720, getitem_721, getitem_722, getitem_723, getitem_724, getitem_725, getitem_726, getitem_727, getitem_728, getitem_729, getitem_730], 1);  getitem_715 = getitem_716 = getitem_717 = getitem_718 = getitem_719 = getitem_720 = getitem_721 = getitem_722 = getitem_723 = getitem_724 = getitem_725 = getitem_726 = getitem_727 = getitem_728 = getitem_729 = getitem_730 = None
        convert_element_type_397 = torch.ops.prims.convert_element_type.default(primals_131, torch.bfloat16)
        all_gather_into_tensor_124 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_397, 16, '1025');  convert_element_type_397 = None
        wait_tensor_151 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_124);  all_gather_into_tensor_124 = None
        split_39 = torch.ops.aten.split.Tensor(wait_tensor_151, 8);  wait_tensor_151 = None
        getitem_731 = split_39[0]
        getitem_732 = split_39[1]
        getitem_733 = split_39[2]
        getitem_734 = split_39[3]
        getitem_735 = split_39[4]
        getitem_736 = split_39[5]
        getitem_737 = split_39[6]
        getitem_738 = split_39[7]
        getitem_739 = split_39[8]
        getitem_740 = split_39[9]
        getitem_741 = split_39[10]
        getitem_742 = split_39[11]
        getitem_743 = split_39[12]
        getitem_744 = split_39[13]
        getitem_745 = split_39[14]
        getitem_746 = split_39[15];  split_39 = None
        cat_62 = torch.ops.aten.cat.default([getitem_731, getitem_732, getitem_733, getitem_734, getitem_735, getitem_736, getitem_737, getitem_738, getitem_739, getitem_740, getitem_741, getitem_742, getitem_743, getitem_744, getitem_745, getitem_746], 1);  getitem_731 = getitem_732 = getitem_733 = getitem_734 = getitem_735 = getitem_736 = getitem_737 = getitem_738 = getitem_739 = getitem_740 = getitem_741 = getitem_742 = getitem_743 = getitem_744 = getitem_745 = getitem_746 = None
        cumsum_20 = torch.ops.aten.cumsum.default(convert_element_type_392, 0, dtype = torch.int32);  convert_element_type_392 = None
        permute_110 = torch.ops.aten.permute.default(cat_60, [0, 2, 1]);  cat_60 = None
        _grouped_mm_18 = torch.ops.aten._grouped_mm.default(index_13, permute_110, cumsum_20)
        convert_element_type_400 = torch.ops.prims.convert_element_type.default(_grouped_mm_18, torch.float32)
        neg_13 = torch.ops.aten.neg.default(convert_element_type_400)
        exp_20 = torch.ops.aten.exp.default(neg_13);  neg_13 = None
        add_440 = torch.ops.aten.add.Tensor(exp_20, 1);  exp_20 = None
        div_34 = torch.ops.aten.div.Tensor(convert_element_type_400, add_440);  convert_element_type_400 = add_440 = None
        convert_element_type_401 = torch.ops.prims.convert_element_type.default(div_34, torch.bfloat16);  div_34 = None
        permute_111 = torch.ops.aten.permute.default(cat_62, [0, 2, 1]);  cat_62 = None
        _grouped_mm_19 = torch.ops.aten._grouped_mm.default(index_13, permute_111, cumsum_20)
        mul_329 = torch.ops.aten.mul.Tensor(convert_element_type_401, _grouped_mm_19);  convert_element_type_401 = None
        permute_112 = torch.ops.aten.permute.default(cat_61, [0, 2, 1]);  cat_61 = None
        _grouped_mm_20 = torch.ops.aten._grouped_mm.default(mul_329, permute_112, cumsum_20)
        empty_6 = torch.ops.aten.empty.memory_format([sym_size_int_25, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_12 = torch.ops.aten.index_put.default(empty_6, [getitem_682], _grouped_mm_20);  empty_6 = _grouped_mm_20 = None
        slice_47 = torch.ops.aten.slice.Tensor(index_put_12, 0, 0, -1);  index_put_12 = None
        all_to_all_single_20 = torch.ops._c10d_functional.all_to_all_single.default(slice_47, [_local_scalar_dense_96, _local_scalar_dense_97, _local_scalar_dense_98, _local_scalar_dense_99, _local_scalar_dense_100, _local_scalar_dense_101, _local_scalar_dense_102, _local_scalar_dense_103], [_local_scalar_dense_104, _local_scalar_dense_105, _local_scalar_dense_106, _local_scalar_dense_107, _local_scalar_dense_108, _local_scalar_dense_109, _local_scalar_dense_110, _local_scalar_dense_111], '1033');  slice_47 = None
        wait_tensor_154 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_20);  all_to_all_single_20 = None
        convert_element_type_402 = torch.ops.prims.convert_element_type.default(primals_132, torch.bfloat16)
        all_gather_into_tensor_127 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_402, 128, '0');  convert_element_type_402 = None
        wait_tensor_155 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_127);  all_gather_into_tensor_127 = None
        permute_113 = torch.ops.aten.permute.default(wait_tensor_155, [1, 0]);  wait_tensor_155 = None
        mm_60 = torch.ops.aten.mm.default(view_460, permute_113);  permute_113 = None
        convert_element_type_405 = torch.ops.prims.convert_element_type.default(mm_60, torch.float32)
        neg_14 = torch.ops.aten.neg.default(convert_element_type_405)
        exp_21 = torch.ops.aten.exp.default(neg_14);  neg_14 = None
        add_476 = torch.ops.aten.add.Tensor(exp_21, 1);  exp_21 = None
        div_35 = torch.ops.aten.div.Tensor(convert_element_type_405, add_476);  convert_element_type_405 = add_476 = None
        convert_element_type_406 = torch.ops.prims.convert_element_type.default(div_35, torch.bfloat16);  div_35 = None
        convert_element_type_407 = torch.ops.prims.convert_element_type.default(primals_133, torch.bfloat16)
        all_gather_into_tensor_128 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_407, 128, '0');  convert_element_type_407 = None
        wait_tensor_156 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_128);  all_gather_into_tensor_128 = None
        permute_114 = torch.ops.aten.permute.default(wait_tensor_156, [1, 0]);  wait_tensor_156 = None
        mm_61 = torch.ops.aten.mm.default(view_460, permute_114);  permute_114 = None
        mul_349 = torch.ops.aten.mul.Tensor(convert_element_type_406, mm_61);  convert_element_type_406 = None
        convert_element_type_410 = torch.ops.prims.convert_element_type.default(primals_134, torch.bfloat16)
        all_gather_into_tensor_129 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_410, 128, '0');  convert_element_type_410 = None
        wait_tensor_157 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_129);  all_gather_into_tensor_129 = None
        permute_115 = torch.ops.aten.permute.default(wait_tensor_157, [1, 0]);  wait_tensor_157 = None
        mm_62 = torch.ops.aten.mm.default(mul_349, permute_115);  permute_115 = None
        index_put_13 = torch.ops.aten.index_put.default(full_default_1, [getitem_681], wait_tensor_154);  wait_tensor_154 = None
        view_500 = torch.ops.aten.view.default(mul_311, [-1, 1, 6]);  mul_311 = None
        view_501 = torch.ops.aten.view.default(index_put_13, [-1, 6, 2048]);  index_put_13 = None
        convert_element_type_413 = torch.ops.prims.convert_element_type.default(view_501, torch.float32);  view_501 = None
        bmm_6 = torch.ops.aten.bmm.default(view_500, convert_element_type_413)
        convert_element_type_414 = torch.ops.prims.convert_element_type.default(bmm_6, torch.bfloat16);  bmm_6 = None
        squeeze_6 = torch.ops.aten.squeeze.dim(convert_element_type_414, 1);  convert_element_type_414 = None
        add_480 = torch.ops.aten.add.Tensor(mm_62, squeeze_6);  mm_62 = squeeze_6 = None
        view_502 = torch.ops.aten.view.default(add_480, [2, 4096, 2048]);  add_480 = None
        add_481 = torch.ops.aten.add.Tensor(add_416, view_502);  view_502 = None
        convert_element_type_415 = torch.ops.prims.convert_element_type.default(primals_135, torch.bfloat16)
        all_gather_into_tensor_130 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_415, 128, '0');  convert_element_type_415 = None
        wait_tensor_158 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_130);  all_gather_into_tensor_130 = None
        convert_element_type_416 = torch.ops.prims.convert_element_type.default(add_481, torch.float32)
        pow_25 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_416, 2)
        mean_24 = torch.ops.aten.mean.dim(pow_25, [2], True);  pow_25 = None
        add_482 = torch.ops.aten.add.Scalar(mean_24, 1e-05);  mean_24 = None
        rsqrt_24 = torch.ops.aten.rsqrt.default(add_482);  add_482 = None
        mul_352 = torch.ops.aten.mul.Tensor(convert_element_type_416, rsqrt_24);  convert_element_type_416 = None
        mul_353 = torch.ops.aten.mul.Tensor(mul_352, wait_tensor_158);  mul_352 = wait_tensor_158 = None
        convert_element_type_417 = torch.ops.prims.convert_element_type.default(mul_353, torch.bfloat16);  mul_353 = None
        convert_element_type_418 = torch.ops.prims.convert_element_type.default(primals_136, torch.bfloat16)
        all_gather_into_tensor_131 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_418, 128, '0');  convert_element_type_418 = None
        wait_tensor_159 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_131);  all_gather_into_tensor_131 = None
        permute_116 = torch.ops.aten.permute.default(wait_tensor_159, [1, 0]);  wait_tensor_159 = None
        view_505 = torch.ops.aten.view.default(convert_element_type_417, [8192, 2048]);  convert_element_type_417 = None
        mm_63 = torch.ops.aten.mm.default(view_505, permute_116);  permute_116 = None
        view_506 = torch.ops.aten.view.default(mm_63, [2, 4096, 3072]);  mm_63 = None
        view_507 = torch.ops.aten.view.default(view_506, [2, 4096, -1, 192]);  view_506 = None
        split_with_sizes_24 = torch.ops.aten.split_with_sizes.default(view_507, [128, 64], -1);  view_507 = None
        getitem_779 = split_with_sizes_24[0]
        getitem_780 = split_with_sizes_24[1];  split_with_sizes_24 = None
        convert_element_type_421 = torch.ops.prims.convert_element_type.default(getitem_780, torch.float32);  getitem_780 = None
        view_508 = torch.ops.aten.view.default(convert_element_type_421, [2, 4096, 16, -1, 2]);  convert_element_type_421 = None
        view_as_complex_16 = torch.ops.aten.view_as_complex.default(view_508);  view_508 = None
        mul_354 = torch.ops.aten.mul.Tensor(view_as_complex_16, view_7);  view_as_complex_16 = None
        view_as_real_16 = torch.ops.aten.view_as_real.default(mul_354);  mul_354 = None
        view_510 = torch.ops.aten.view.default(view_as_real_16, [2, 4096, 16, 64]);  view_as_real_16 = None
        convert_element_type_422 = torch.ops.prims.convert_element_type.default(view_510, torch.bfloat16);  view_510 = None
        cat_65 = torch.ops.aten.cat.default([getitem_779, convert_element_type_422], -1);  getitem_779 = convert_element_type_422 = None
        convert_element_type_423 = torch.ops.prims.convert_element_type.default(primals_137, torch.bfloat16)
        all_gather_into_tensor_132 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_423, 128, '0');  convert_element_type_423 = None
        wait_tensor_160 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_132);  all_gather_into_tensor_132 = None
        slice_49 = torch.ops.aten.slice.Tensor(wait_tensor_160, 0, 0, 576);  wait_tensor_160 = None
        permute_117 = torch.ops.aten.permute.default(slice_49, [1, 0]);  slice_49 = None
        mm_64 = torch.ops.aten.mm.default(view_505, permute_117);  permute_117 = None
        view_513 = torch.ops.aten.view.default(mm_64, [2, 4096, 576]);  mm_64 = None
        split_with_sizes_25 = torch.ops.aten.split_with_sizes.default(view_513, [512, 64], -1);  view_513 = None
        getitem_781 = split_with_sizes_25[0]
        getitem_782 = split_with_sizes_25[1];  split_with_sizes_25 = None
        unsqueeze_15 = torch.ops.aten.unsqueeze.default(getitem_782, 2);  getitem_782 = None
        convert_element_type_426 = torch.ops.prims.convert_element_type.default(unsqueeze_15, torch.float32);  unsqueeze_15 = None
        view_514 = torch.ops.aten.view.default(convert_element_type_426, [2, 4096, 1, -1, 2]);  convert_element_type_426 = None
        view_as_complex_17 = torch.ops.aten.view_as_complex.default(view_514);  view_514 = None
        mul_355 = torch.ops.aten.mul.Tensor(view_as_complex_17, view_7);  view_as_complex_17 = None
        view_as_real_17 = torch.ops.aten.view_as_real.default(mul_355);  mul_355 = None
        view_516 = torch.ops.aten.view.default(view_as_real_17, [2, 4096, 1, 64]);  view_as_real_17 = None
        convert_element_type_427 = torch.ops.prims.convert_element_type.default(view_516, torch.bfloat16);  view_516 = None
        convert_element_type_428 = torch.ops.prims.convert_element_type.default(primals_138, torch.bfloat16)
        all_gather_into_tensor_133 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_428, 128, '0');  convert_element_type_428 = None
        wait_tensor_161 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_133);  all_gather_into_tensor_133 = None
        convert_element_type_429 = torch.ops.prims.convert_element_type.default(getitem_781, torch.float32)
        pow_26 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_429, 2)
        mean_25 = torch.ops.aten.mean.dim(pow_26, [2], True);  pow_26 = None
        add_483 = torch.ops.aten.add.Scalar(mean_25, 1e-05);  mean_25 = None
        rsqrt_25 = torch.ops.aten.rsqrt.default(add_483);  add_483 = None
        mul_356 = torch.ops.aten.mul.Tensor(convert_element_type_429, rsqrt_25);  convert_element_type_429 = None
        mul_357 = torch.ops.aten.mul.Tensor(mul_356, wait_tensor_161);  mul_356 = wait_tensor_161 = None
        convert_element_type_430 = torch.ops.prims.convert_element_type.default(mul_357, torch.bfloat16);  mul_357 = None
        convert_element_type_431 = torch.ops.prims.convert_element_type.default(primals_139, torch.bfloat16)
        all_gather_into_tensor_134 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_431, 128, '0');  convert_element_type_431 = None
        wait_tensor_162 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_134);  all_gather_into_tensor_134 = None
        permute_118 = torch.ops.aten.permute.default(wait_tensor_162, [1, 0]);  wait_tensor_162 = None
        view_519 = torch.ops.aten.view.default(convert_element_type_430, [8192, 512]);  convert_element_type_430 = None
        mm_65 = torch.ops.aten.mm.default(view_519, permute_118);  permute_118 = None
        view_520 = torch.ops.aten.view.default(mm_65, [2, 4096, 4096]);  mm_65 = None
        view_521 = torch.ops.aten.view.default(view_520, [2, 4096, -1, 256]);  view_520 = None
        split_with_sizes_26 = torch.ops.aten.split_with_sizes.default(view_521, [128, 128], -1);  view_521 = None
        getitem_783 = split_with_sizes_26[0]
        getitem_784 = split_with_sizes_26[1];  split_with_sizes_26 = None
        expand_8 = torch.ops.aten.expand.default(convert_element_type_427, [-1, -1, 16, -1]);  convert_element_type_427 = None
        cat_66 = torch.ops.aten.cat.default([getitem_783, expand_8], -1);  getitem_783 = expand_8 = None
        permute_119 = torch.ops.aten.permute.default(cat_65, [0, 2, 1, 3]);  cat_65 = None
        permute_120 = torch.ops.aten.permute.default(cat_66, [0, 2, 1, 3]);  cat_66 = None
        permute_121 = torch.ops.aten.permute.default(getitem_784, [0, 2, 1, 3]);  getitem_784 = None
        sdpa_score8 = self.sdpa_score8
        sdpa_mask8 = self.sdpa_mask8
        flex_attention_8 = torch.ops.higher_order.flex_attention(permute_119, permute_120, permute_121, sdpa_score8, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask8), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score8 = sdpa_mask8 = None
        getitem_785 = flex_attention_8[0]
        getitem_786 = flex_attention_8[1];  flex_attention_8 = None
        permute_122 = torch.ops.aten.permute.default(getitem_785, [0, 2, 1, 3])
        view_522 = torch.ops.aten.view.default(permute_122, [2, 4096, -1]);  permute_122 = None
        convert_element_type_434 = torch.ops.prims.convert_element_type.default(primals_140, torch.bfloat16)
        all_gather_into_tensor_135 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_434, 128, '0');  convert_element_type_434 = None
        wait_tensor_163 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_135);  all_gather_into_tensor_135 = None
        permute_123 = torch.ops.aten.permute.default(wait_tensor_163, [1, 0]);  wait_tensor_163 = None
        view_524 = torch.ops.aten.view.default(view_522, [8192, 2048]);  view_522 = None
        mm_66 = torch.ops.aten.mm.default(view_524, permute_123);  view_524 = permute_123 = None
        view_525 = torch.ops.aten.view.default(mm_66, [2, 4096, 2048]);  mm_66 = None
        add_484 = torch.ops.aten.add.Tensor(add_481, view_525);  view_525 = None
        convert_element_type_437 = torch.ops.prims.convert_element_type.default(primals_141, torch.bfloat16)
        all_gather_into_tensor_136 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_437, 128, '0');  convert_element_type_437 = None
        wait_tensor_164 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_136);  all_gather_into_tensor_136 = None
        convert_element_type_438 = torch.ops.prims.convert_element_type.default(add_484, torch.float32)
        pow_27 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_438, 2)
        mean_26 = torch.ops.aten.mean.dim(pow_27, [2], True);  pow_27 = None
        add_485 = torch.ops.aten.add.Scalar(mean_26, 1e-05);  mean_26 = None
        rsqrt_26 = torch.ops.aten.rsqrt.default(add_485);  add_485 = None
        mul_358 = torch.ops.aten.mul.Tensor(convert_element_type_438, rsqrt_26);  convert_element_type_438 = None
        mul_359 = torch.ops.aten.mul.Tensor(mul_358, wait_tensor_164);  mul_358 = wait_tensor_164 = None
        convert_element_type_439 = torch.ops.prims.convert_element_type.default(mul_359, torch.bfloat16);  mul_359 = None
        view_527 = torch.ops.aten.view.default(convert_element_type_439, [-1, 2048]);  convert_element_type_439 = None
        convert_element_type_440 = torch.ops.prims.convert_element_type.default(primals_143, torch.bfloat16)
        all_gather_into_tensor_137 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_440, 128, '0');  convert_element_type_440 = None
        wait_tensor_165 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_137);  all_gather_into_tensor_137 = None
        slice_51 = torch.ops.aten.slice.Tensor(wait_tensor_165, 0, 0, 64);  wait_tensor_165 = None
        permute_124 = torch.ops.aten.permute.default(slice_51, [1, 0]);  slice_51 = None
        mm_67 = torch.ops.aten.mm.default(view_527, permute_124);  permute_124 = None
        convert_element_type_443 = torch.ops.prims.convert_element_type.default(mm_67, torch.float32)
        amax_7 = torch.ops.aten.amax.default(convert_element_type_443, [1], True)
        sub_168 = torch.ops.aten.sub.Tensor(convert_element_type_443, amax_7);  convert_element_type_443 = None
        exp_22 = torch.ops.aten.exp.default(sub_168);  sub_168 = None
        sum_29 = torch.ops.aten.sum.dim_IntList(exp_22, [1], True)
        div_36 = torch.ops.aten.div.Tensor(exp_22, sum_29);  exp_22 = None
        add_486 = torch.ops.aten.add.Tensor(div_36, primals_142);  primals_142 = None
        topk_7 = torch.ops.aten.topk.default(add_486, 6, -1, True, False);  add_486 = None
        getitem_789 = topk_7[1];  topk_7 = None
        gather_7 = torch.ops.aten.gather.default(div_36, 1, getitem_789);  div_36 = None
        mul_360 = torch.ops.aten.mul.Tensor(gather_7, 1.0);  gather_7 = None
        view_529 = torch.ops.aten.view.default(getitem_789, [-1])
        histc_14 = torch.ops.aten.histc.default(view_529, 64, 0, 64)
        add_487 = torch.ops.aten.add.Tensor(primals_144, histc_14)
        sort_7 = torch.ops.aten.sort.stable(view_529, stable = True);  view_529 = None
        getitem_791 = sort_7[1];  sort_7 = None
        div_37 = torch.ops.aten.div.Tensor_mode(getitem_791, 6, rounding_mode = 'floor')
        index_14 = torch.ops.aten.index.Tensor(view_527, [div_37])
        all_to_all_single_21 = torch.ops._c10d_functional.all_to_all_single.default(histc_14, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_166 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_21);  all_to_all_single_21 = None
        wait_tensor_167 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_166);  wait_tensor_166 = None
        view_533 = torch.ops.aten.view.default(histc_14, [8, -1]);  histc_14 = None
        sum_30 = torch.ops.aten.sum.dim_IntList(view_533, [1]);  view_533 = None
        device_put_14 = torch.ops.prims.device_put.default(sum_30, device(type='cpu'), True);  sum_30 = None
        view_534 = torch.ops.aten.view.default(wait_tensor_167, [8, -1])
        sum_31 = torch.ops.aten.sum.dim_IntList(view_534, [1])
        device_put_15 = torch.ops.prims.device_put.default(sum_31, device(type='cpu'));  sum_31 = None
        select_112 = torch.ops.aten.select.int(device_put_14, 0, 0)
        _local_scalar_dense_112 = torch.ops.aten._local_scalar_dense.default(select_112);  select_112 = None
        ge_140 = _local_scalar_dense_112 >= 0
        _assert_scalar_112 = torch.ops.aten._assert_scalar.default(ge_140, "Runtime assertion failed for expression u112 >= 0 on node 'ge_112'");  ge_140 = _assert_scalar_112 = None
        select_113 = torch.ops.aten.select.int(device_put_14, 0, 1)
        _local_scalar_dense_113 = torch.ops.aten._local_scalar_dense.default(select_113);  select_113 = None
        ge_141 = _local_scalar_dense_113 >= 0
        _assert_scalar_113 = torch.ops.aten._assert_scalar.default(ge_141, "Runtime assertion failed for expression u113 >= 0 on node 'ge_113'");  ge_141 = _assert_scalar_113 = None
        select_114 = torch.ops.aten.select.int(device_put_14, 0, 2)
        _local_scalar_dense_114 = torch.ops.aten._local_scalar_dense.default(select_114);  select_114 = None
        ge_142 = _local_scalar_dense_114 >= 0
        _assert_scalar_114 = torch.ops.aten._assert_scalar.default(ge_142, "Runtime assertion failed for expression u114 >= 0 on node 'ge_114'");  ge_142 = _assert_scalar_114 = None
        select_115 = torch.ops.aten.select.int(device_put_14, 0, 3)
        _local_scalar_dense_115 = torch.ops.aten._local_scalar_dense.default(select_115);  select_115 = None
        ge_143 = _local_scalar_dense_115 >= 0
        _assert_scalar_115 = torch.ops.aten._assert_scalar.default(ge_143, "Runtime assertion failed for expression u115 >= 0 on node 'ge_115'");  ge_143 = _assert_scalar_115 = None
        select_116 = torch.ops.aten.select.int(device_put_14, 0, 4)
        _local_scalar_dense_116 = torch.ops.aten._local_scalar_dense.default(select_116);  select_116 = None
        ge_144 = _local_scalar_dense_116 >= 0
        _assert_scalar_116 = torch.ops.aten._assert_scalar.default(ge_144, "Runtime assertion failed for expression u116 >= 0 on node 'ge_116'");  ge_144 = _assert_scalar_116 = None
        select_117 = torch.ops.aten.select.int(device_put_14, 0, 5)
        _local_scalar_dense_117 = torch.ops.aten._local_scalar_dense.default(select_117);  select_117 = None
        ge_145 = _local_scalar_dense_117 >= 0
        _assert_scalar_117 = torch.ops.aten._assert_scalar.default(ge_145, "Runtime assertion failed for expression u117 >= 0 on node 'ge_117'");  ge_145 = _assert_scalar_117 = None
        select_118 = torch.ops.aten.select.int(device_put_14, 0, 6)
        _local_scalar_dense_118 = torch.ops.aten._local_scalar_dense.default(select_118);  select_118 = None
        ge_146 = _local_scalar_dense_118 >= 0
        _assert_scalar_118 = torch.ops.aten._assert_scalar.default(ge_146, "Runtime assertion failed for expression u118 >= 0 on node 'ge_118'");  ge_146 = _assert_scalar_118 = None
        select_119 = torch.ops.aten.select.int(device_put_14, 0, 7);  device_put_14 = None
        _local_scalar_dense_119 = torch.ops.aten._local_scalar_dense.default(select_119);  select_119 = None
        ge_147 = _local_scalar_dense_119 >= 0
        _assert_scalar_119 = torch.ops.aten._assert_scalar.default(ge_147, "Runtime assertion failed for expression u119 >= 0 on node 'ge_119'");  ge_147 = _assert_scalar_119 = None
        select_120 = torch.ops.aten.select.int(device_put_15, 0, 0)
        _local_scalar_dense_120 = torch.ops.aten._local_scalar_dense.default(select_120);  select_120 = None
        ge_148 = _local_scalar_dense_120 >= 0
        _assert_scalar_120 = torch.ops.aten._assert_scalar.default(ge_148, "Runtime assertion failed for expression u120 >= 0 on node 'ge_120'");  ge_148 = _assert_scalar_120 = None
        select_121 = torch.ops.aten.select.int(device_put_15, 0, 1)
        _local_scalar_dense_121 = torch.ops.aten._local_scalar_dense.default(select_121);  select_121 = None
        ge_149 = _local_scalar_dense_121 >= 0
        _assert_scalar_121 = torch.ops.aten._assert_scalar.default(ge_149, "Runtime assertion failed for expression u121 >= 0 on node 'ge_121'");  ge_149 = _assert_scalar_121 = None
        select_122 = torch.ops.aten.select.int(device_put_15, 0, 2)
        _local_scalar_dense_122 = torch.ops.aten._local_scalar_dense.default(select_122);  select_122 = None
        ge_150 = _local_scalar_dense_122 >= 0
        _assert_scalar_122 = torch.ops.aten._assert_scalar.default(ge_150, "Runtime assertion failed for expression u122 >= 0 on node 'ge_122'");  ge_150 = _assert_scalar_122 = None
        select_123 = torch.ops.aten.select.int(device_put_15, 0, 3)
        _local_scalar_dense_123 = torch.ops.aten._local_scalar_dense.default(select_123);  select_123 = None
        ge_151 = _local_scalar_dense_123 >= 0
        _assert_scalar_123 = torch.ops.aten._assert_scalar.default(ge_151, "Runtime assertion failed for expression u123 >= 0 on node 'ge_123'");  ge_151 = _assert_scalar_123 = None
        select_124 = torch.ops.aten.select.int(device_put_15, 0, 4)
        _local_scalar_dense_124 = torch.ops.aten._local_scalar_dense.default(select_124);  select_124 = None
        ge_152 = _local_scalar_dense_124 >= 0
        _assert_scalar_124 = torch.ops.aten._assert_scalar.default(ge_152, "Runtime assertion failed for expression u124 >= 0 on node 'ge_124'");  ge_152 = _assert_scalar_124 = None
        select_125 = torch.ops.aten.select.int(device_put_15, 0, 5)
        _local_scalar_dense_125 = torch.ops.aten._local_scalar_dense.default(select_125);  select_125 = None
        ge_153 = _local_scalar_dense_125 >= 0
        _assert_scalar_125 = torch.ops.aten._assert_scalar.default(ge_153, "Runtime assertion failed for expression u125 >= 0 on node 'ge_125'");  ge_153 = _assert_scalar_125 = None
        select_126 = torch.ops.aten.select.int(device_put_15, 0, 6)
        _local_scalar_dense_126 = torch.ops.aten._local_scalar_dense.default(select_126);  select_126 = None
        ge_154 = _local_scalar_dense_126 >= 0
        _assert_scalar_126 = torch.ops.aten._assert_scalar.default(ge_154, "Runtime assertion failed for expression u126 >= 0 on node 'ge_126'");  ge_154 = _assert_scalar_126 = None
        select_127 = torch.ops.aten.select.int(device_put_15, 0, 7);  device_put_15 = None
        _local_scalar_dense_127 = torch.ops.aten._local_scalar_dense.default(select_127);  select_127 = None
        ge_155 = _local_scalar_dense_127 >= 0
        _assert_scalar_127 = torch.ops.aten._assert_scalar.default(ge_155, "Runtime assertion failed for expression u127 >= 0 on node 'ge_127'");  ge_155 = _assert_scalar_127 = None
        all_to_all_single_22 = torch.ops._c10d_functional.all_to_all_single.default(index_14, [_local_scalar_dense_120, _local_scalar_dense_121, _local_scalar_dense_122, _local_scalar_dense_123, _local_scalar_dense_124, _local_scalar_dense_125, _local_scalar_dense_126, _local_scalar_dense_127], [_local_scalar_dense_112, _local_scalar_dense_113, _local_scalar_dense_114, _local_scalar_dense_115, _local_scalar_dense_116, _local_scalar_dense_117, _local_scalar_dense_118, _local_scalar_dense_119], '1033');  index_14 = None
        sym_size_int_28 = torch.ops.aten.sym_size.int(all_to_all_single_22, 0)
        wait_tensor_168 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_22);  all_to_all_single_22 = None
        sym_sum_14 = torch.sym_sum((_local_scalar_dense_120, _local_scalar_dense_121, _local_scalar_dense_122, _local_scalar_dense_123, _local_scalar_dense_124, _local_scalar_dense_125, _local_scalar_dense_126, _local_scalar_dense_127))
        add_494 = sym_sum_14 + 64;  sym_sum_14 = None
        add_495 = add_494 + 8;  add_494 = None
        sub_171 = add_495 - 1;  add_495 = None
        floordiv_7 = sub_171 // 8;  sub_171 = None
        mul_365 = floordiv_7 * 8;  floordiv_7 = None
        cumsum_21 = torch.ops.aten.cumsum.default(wait_tensor_167, 0)
        sub_172 = torch.ops.aten.sub.Tensor(cumsum_21, wait_tensor_167);  cumsum_21 = None
        sum_32 = torch.ops.aten.sum.dim_IntList(view_534, [0]);  view_534 = None
        clamp_min_7 = torch.ops.aten.clamp_min.default(sum_32, 8);  sum_32 = None
        add_496 = torch.ops.aten.add.Tensor(clamp_min_7, 8);  clamp_min_7 = None
        sub_173 = torch.ops.aten.sub.Tensor(add_496, 1);  add_496 = None
        div_38 = torch.ops.aten.div.Tensor_mode(sub_173, 8, rounding_mode = 'floor');  sub_173 = None
        mul_366 = torch.ops.aten.mul.Tensor(div_38, 8);  div_38 = None
        convert_element_type_446 = torch.ops.prims.convert_element_type.default(mul_366, torch.int32);  mul_366 = None
        cumsum_22 = torch.ops.aten.cumsum.default(convert_element_type_446, 0)
        sub_174 = torch.ops.aten.sub.Tensor(cumsum_22, convert_element_type_446);  cumsum_22 = None
        full_111 = torch.ops.aten.full.default([mul_365], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_365 = None
        triton_kernel_wrapper_functional_proxy_7 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 7, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_167, 'start_index_values_ptr': sub_172, 'write_offsets_ptr': sub_174, 'output_ptr': full_111}, tensors_to_clone = ['output_ptr']);  wait_tensor_167 = sub_172 = sub_174 = full_111 = None
        getitem_792 = triton_kernel_wrapper_functional_proxy_7['output_ptr'];  triton_kernel_wrapper_functional_proxy_7 = None
        cat_67 = torch.ops.aten.cat.default([wait_tensor_168, full_default]);  wait_tensor_168 = None
        sym_size_int_29 = torch.ops.aten.sym_size.int(cat_67, 0)
        sym_sum_15 = torch.sym_sum((1, _local_scalar_dense_120, _local_scalar_dense_121, _local_scalar_dense_122, _local_scalar_dense_123, _local_scalar_dense_124, _local_scalar_dense_125, _local_scalar_dense_126, _local_scalar_dense_127))
        index_15 = torch.ops.aten.index.Tensor(cat_67, [getitem_792]);  cat_67 = None
        convert_element_type_448 = torch.ops.prims.convert_element_type.default(primals_145, torch.bfloat16)
        all_gather_into_tensor_138 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_448, 16, '1025');  convert_element_type_448 = None
        wait_tensor_169 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_138);  all_gather_into_tensor_138 = None
        split_43 = torch.ops.aten.split.Tensor(wait_tensor_169, 8);  wait_tensor_169 = None
        getitem_809 = split_43[0]
        getitem_810 = split_43[1]
        getitem_811 = split_43[2]
        getitem_812 = split_43[3]
        getitem_813 = split_43[4]
        getitem_814 = split_43[5]
        getitem_815 = split_43[6]
        getitem_816 = split_43[7]
        getitem_817 = split_43[8]
        getitem_818 = split_43[9]
        getitem_819 = split_43[10]
        getitem_820 = split_43[11]
        getitem_821 = split_43[12]
        getitem_822 = split_43[13]
        getitem_823 = split_43[14]
        getitem_824 = split_43[15];  split_43 = None
        cat_69 = torch.ops.aten.cat.default([getitem_809, getitem_810, getitem_811, getitem_812, getitem_813, getitem_814, getitem_815, getitem_816, getitem_817, getitem_818, getitem_819, getitem_820, getitem_821, getitem_822, getitem_823, getitem_824], 1);  getitem_809 = getitem_810 = getitem_811 = getitem_812 = getitem_813 = getitem_814 = getitem_815 = getitem_816 = getitem_817 = getitem_818 = getitem_819 = getitem_820 = getitem_821 = getitem_822 = getitem_823 = getitem_824 = None
        convert_element_type_450 = torch.ops.prims.convert_element_type.default(primals_146, torch.bfloat16)
        all_gather_into_tensor_140 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_450, 16, '1025');  convert_element_type_450 = None
        wait_tensor_171 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_140);  all_gather_into_tensor_140 = None
        split_44 = torch.ops.aten.split.Tensor(wait_tensor_171, 8);  wait_tensor_171 = None
        getitem_825 = split_44[0]
        getitem_826 = split_44[1]
        getitem_827 = split_44[2]
        getitem_828 = split_44[3]
        getitem_829 = split_44[4]
        getitem_830 = split_44[5]
        getitem_831 = split_44[6]
        getitem_832 = split_44[7]
        getitem_833 = split_44[8]
        getitem_834 = split_44[9]
        getitem_835 = split_44[10]
        getitem_836 = split_44[11]
        getitem_837 = split_44[12]
        getitem_838 = split_44[13]
        getitem_839 = split_44[14]
        getitem_840 = split_44[15];  split_44 = None
        cat_70 = torch.ops.aten.cat.default([getitem_825, getitem_826, getitem_827, getitem_828, getitem_829, getitem_830, getitem_831, getitem_832, getitem_833, getitem_834, getitem_835, getitem_836, getitem_837, getitem_838, getitem_839, getitem_840], 1);  getitem_825 = getitem_826 = getitem_827 = getitem_828 = getitem_829 = getitem_830 = getitem_831 = getitem_832 = getitem_833 = getitem_834 = getitem_835 = getitem_836 = getitem_837 = getitem_838 = getitem_839 = getitem_840 = None
        convert_element_type_451 = torch.ops.prims.convert_element_type.default(primals_147, torch.bfloat16)
        all_gather_into_tensor_141 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_451, 16, '1025');  convert_element_type_451 = None
        wait_tensor_172 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_141);  all_gather_into_tensor_141 = None
        split_45 = torch.ops.aten.split.Tensor(wait_tensor_172, 8);  wait_tensor_172 = None
        getitem_841 = split_45[0]
        getitem_842 = split_45[1]
        getitem_843 = split_45[2]
        getitem_844 = split_45[3]
        getitem_845 = split_45[4]
        getitem_846 = split_45[5]
        getitem_847 = split_45[6]
        getitem_848 = split_45[7]
        getitem_849 = split_45[8]
        getitem_850 = split_45[9]
        getitem_851 = split_45[10]
        getitem_852 = split_45[11]
        getitem_853 = split_45[12]
        getitem_854 = split_45[13]
        getitem_855 = split_45[14]
        getitem_856 = split_45[15];  split_45 = None
        cat_71 = torch.ops.aten.cat.default([getitem_841, getitem_842, getitem_843, getitem_844, getitem_845, getitem_846, getitem_847, getitem_848, getitem_849, getitem_850, getitem_851, getitem_852, getitem_853, getitem_854, getitem_855, getitem_856], 1);  getitem_841 = getitem_842 = getitem_843 = getitem_844 = getitem_845 = getitem_846 = getitem_847 = getitem_848 = getitem_849 = getitem_850 = getitem_851 = getitem_852 = getitem_853 = getitem_854 = getitem_855 = getitem_856 = None
        cumsum_23 = torch.ops.aten.cumsum.default(convert_element_type_446, 0, dtype = torch.int32);  convert_element_type_446 = None
        permute_125 = torch.ops.aten.permute.default(cat_69, [0, 2, 1]);  cat_69 = None
        _grouped_mm_21 = torch.ops.aten._grouped_mm.default(index_15, permute_125, cumsum_23)
        convert_element_type_454 = torch.ops.prims.convert_element_type.default(_grouped_mm_21, torch.float32)
        neg_15 = torch.ops.aten.neg.default(convert_element_type_454)
        exp_23 = torch.ops.aten.exp.default(neg_15);  neg_15 = None
        add_508 = torch.ops.aten.add.Tensor(exp_23, 1);  exp_23 = None
        div_39 = torch.ops.aten.div.Tensor(convert_element_type_454, add_508);  convert_element_type_454 = add_508 = None
        convert_element_type_455 = torch.ops.prims.convert_element_type.default(div_39, torch.bfloat16);  div_39 = None
        permute_126 = torch.ops.aten.permute.default(cat_71, [0, 2, 1]);  cat_71 = None
        _grouped_mm_22 = torch.ops.aten._grouped_mm.default(index_15, permute_126, cumsum_23)
        mul_378 = torch.ops.aten.mul.Tensor(convert_element_type_455, _grouped_mm_22);  convert_element_type_455 = None
        permute_127 = torch.ops.aten.permute.default(cat_70, [0, 2, 1]);  cat_70 = None
        _grouped_mm_23 = torch.ops.aten._grouped_mm.default(mul_378, permute_127, cumsum_23)
        empty_7 = torch.ops.aten.empty.memory_format([sym_size_int_29, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_14 = torch.ops.aten.index_put.default(empty_7, [getitem_792], _grouped_mm_23);  empty_7 = _grouped_mm_23 = None
        slice_53 = torch.ops.aten.slice.Tensor(index_put_14, 0, 0, -1);  index_put_14 = None
        all_to_all_single_23 = torch.ops._c10d_functional.all_to_all_single.default(slice_53, [_local_scalar_dense_112, _local_scalar_dense_113, _local_scalar_dense_114, _local_scalar_dense_115, _local_scalar_dense_116, _local_scalar_dense_117, _local_scalar_dense_118, _local_scalar_dense_119], [_local_scalar_dense_120, _local_scalar_dense_121, _local_scalar_dense_122, _local_scalar_dense_123, _local_scalar_dense_124, _local_scalar_dense_125, _local_scalar_dense_126, _local_scalar_dense_127], '1033');  slice_53 = None
        wait_tensor_175 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_23);  all_to_all_single_23 = None
        convert_element_type_456 = torch.ops.prims.convert_element_type.default(primals_148, torch.bfloat16)
        all_gather_into_tensor_144 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_456, 128, '0');  convert_element_type_456 = None
        wait_tensor_176 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_144);  all_gather_into_tensor_144 = None
        permute_128 = torch.ops.aten.permute.default(wait_tensor_176, [1, 0]);  wait_tensor_176 = None
        mm_68 = torch.ops.aten.mm.default(view_527, permute_128);  permute_128 = None
        convert_element_type_459 = torch.ops.prims.convert_element_type.default(mm_68, torch.float32)
        neg_16 = torch.ops.aten.neg.default(convert_element_type_459)
        exp_24 = torch.ops.aten.exp.default(neg_16);  neg_16 = None
        add_544 = torch.ops.aten.add.Tensor(exp_24, 1);  exp_24 = None
        div_40 = torch.ops.aten.div.Tensor(convert_element_type_459, add_544);  convert_element_type_459 = add_544 = None
        convert_element_type_460 = torch.ops.prims.convert_element_type.default(div_40, torch.bfloat16);  div_40 = None
        convert_element_type_461 = torch.ops.prims.convert_element_type.default(primals_149, torch.bfloat16)
        all_gather_into_tensor_145 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_461, 128, '0');  convert_element_type_461 = None
        wait_tensor_177 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_145);  all_gather_into_tensor_145 = None
        permute_129 = torch.ops.aten.permute.default(wait_tensor_177, [1, 0]);  wait_tensor_177 = None
        mm_69 = torch.ops.aten.mm.default(view_527, permute_129);  permute_129 = None
        mul_398 = torch.ops.aten.mul.Tensor(convert_element_type_460, mm_69);  convert_element_type_460 = None
        convert_element_type_464 = torch.ops.prims.convert_element_type.default(primals_150, torch.bfloat16)
        all_gather_into_tensor_146 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_464, 128, '0');  convert_element_type_464 = None
        wait_tensor_178 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_146);  all_gather_into_tensor_146 = None
        permute_130 = torch.ops.aten.permute.default(wait_tensor_178, [1, 0]);  wait_tensor_178 = None
        mm_70 = torch.ops.aten.mm.default(mul_398, permute_130);  permute_130 = None
        index_put_15 = torch.ops.aten.index_put.default(full_default_1, [getitem_791], wait_tensor_175);  wait_tensor_175 = None
        view_567 = torch.ops.aten.view.default(mul_360, [-1, 1, 6]);  mul_360 = None
        view_568 = torch.ops.aten.view.default(index_put_15, [-1, 6, 2048]);  index_put_15 = None
        convert_element_type_467 = torch.ops.prims.convert_element_type.default(view_568, torch.float32);  view_568 = None
        bmm_7 = torch.ops.aten.bmm.default(view_567, convert_element_type_467)
        convert_element_type_468 = torch.ops.prims.convert_element_type.default(bmm_7, torch.bfloat16);  bmm_7 = None
        squeeze_7 = torch.ops.aten.squeeze.dim(convert_element_type_468, 1);  convert_element_type_468 = None
        add_548 = torch.ops.aten.add.Tensor(mm_70, squeeze_7);  mm_70 = squeeze_7 = None
        view_569 = torch.ops.aten.view.default(add_548, [2, 4096, 2048]);  add_548 = None
        add_549 = torch.ops.aten.add.Tensor(add_484, view_569);  view_569 = None
        convert_element_type_469 = torch.ops.prims.convert_element_type.default(primals_151, torch.bfloat16)
        all_gather_into_tensor_147 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_469, 128, '0');  convert_element_type_469 = None
        wait_tensor_179 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_147);  all_gather_into_tensor_147 = None
        convert_element_type_470 = torch.ops.prims.convert_element_type.default(add_549, torch.float32)
        pow_28 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_470, 2)
        mean_27 = torch.ops.aten.mean.dim(pow_28, [2], True);  pow_28 = None
        add_550 = torch.ops.aten.add.Scalar(mean_27, 1e-05);  mean_27 = None
        rsqrt_27 = torch.ops.aten.rsqrt.default(add_550);  add_550 = None
        mul_401 = torch.ops.aten.mul.Tensor(convert_element_type_470, rsqrt_27);  convert_element_type_470 = None
        mul_402 = torch.ops.aten.mul.Tensor(mul_401, wait_tensor_179);  mul_401 = wait_tensor_179 = None
        convert_element_type_471 = torch.ops.prims.convert_element_type.default(mul_402, torch.bfloat16);  mul_402 = None
        convert_element_type_472 = torch.ops.prims.convert_element_type.default(primals_152, torch.bfloat16)
        all_gather_into_tensor_148 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_472, 128, '0');  convert_element_type_472 = None
        wait_tensor_180 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_148);  all_gather_into_tensor_148 = None
        permute_131 = torch.ops.aten.permute.default(wait_tensor_180, [1, 0]);  wait_tensor_180 = None
        view_572 = torch.ops.aten.view.default(convert_element_type_471, [8192, 2048]);  convert_element_type_471 = None
        mm_71 = torch.ops.aten.mm.default(view_572, permute_131);  permute_131 = None
        view_573 = torch.ops.aten.view.default(mm_71, [2, 4096, 3072]);  mm_71 = None
        view_574 = torch.ops.aten.view.default(view_573, [2, 4096, -1, 192]);  view_573 = None
        split_with_sizes_27 = torch.ops.aten.split_with_sizes.default(view_574, [128, 64], -1);  view_574 = None
        getitem_889 = split_with_sizes_27[0]
        getitem_890 = split_with_sizes_27[1];  split_with_sizes_27 = None
        convert_element_type_475 = torch.ops.prims.convert_element_type.default(getitem_890, torch.float32);  getitem_890 = None
        view_575 = torch.ops.aten.view.default(convert_element_type_475, [2, 4096, 16, -1, 2]);  convert_element_type_475 = None
        view_as_complex_18 = torch.ops.aten.view_as_complex.default(view_575);  view_575 = None
        mul_403 = torch.ops.aten.mul.Tensor(view_as_complex_18, view_7);  view_as_complex_18 = None
        view_as_real_18 = torch.ops.aten.view_as_real.default(mul_403);  mul_403 = None
        view_577 = torch.ops.aten.view.default(view_as_real_18, [2, 4096, 16, 64]);  view_as_real_18 = None
        convert_element_type_476 = torch.ops.prims.convert_element_type.default(view_577, torch.bfloat16);  view_577 = None
        cat_74 = torch.ops.aten.cat.default([getitem_889, convert_element_type_476], -1);  getitem_889 = convert_element_type_476 = None
        convert_element_type_477 = torch.ops.prims.convert_element_type.default(primals_153, torch.bfloat16)
        all_gather_into_tensor_149 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_477, 128, '0');  convert_element_type_477 = None
        wait_tensor_181 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_149);  all_gather_into_tensor_149 = None
        slice_55 = torch.ops.aten.slice.Tensor(wait_tensor_181, 0, 0, 576);  wait_tensor_181 = None
        permute_132 = torch.ops.aten.permute.default(slice_55, [1, 0]);  slice_55 = None
        mm_72 = torch.ops.aten.mm.default(view_572, permute_132);  permute_132 = None
        view_580 = torch.ops.aten.view.default(mm_72, [2, 4096, 576]);  mm_72 = None
        split_with_sizes_28 = torch.ops.aten.split_with_sizes.default(view_580, [512, 64], -1);  view_580 = None
        getitem_891 = split_with_sizes_28[0]
        getitem_892 = split_with_sizes_28[1];  split_with_sizes_28 = None
        unsqueeze_17 = torch.ops.aten.unsqueeze.default(getitem_892, 2);  getitem_892 = None
        convert_element_type_480 = torch.ops.prims.convert_element_type.default(unsqueeze_17, torch.float32);  unsqueeze_17 = None
        view_581 = torch.ops.aten.view.default(convert_element_type_480, [2, 4096, 1, -1, 2]);  convert_element_type_480 = None
        view_as_complex_19 = torch.ops.aten.view_as_complex.default(view_581);  view_581 = None
        mul_404 = torch.ops.aten.mul.Tensor(view_as_complex_19, view_7);  view_as_complex_19 = None
        view_as_real_19 = torch.ops.aten.view_as_real.default(mul_404);  mul_404 = None
        view_583 = torch.ops.aten.view.default(view_as_real_19, [2, 4096, 1, 64]);  view_as_real_19 = None
        convert_element_type_481 = torch.ops.prims.convert_element_type.default(view_583, torch.bfloat16);  view_583 = None
        convert_element_type_482 = torch.ops.prims.convert_element_type.default(primals_154, torch.bfloat16)
        all_gather_into_tensor_150 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_482, 128, '0');  convert_element_type_482 = None
        wait_tensor_182 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_150);  all_gather_into_tensor_150 = None
        convert_element_type_483 = torch.ops.prims.convert_element_type.default(getitem_891, torch.float32)
        pow_29 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_483, 2)
        mean_28 = torch.ops.aten.mean.dim(pow_29, [2], True);  pow_29 = None
        add_551 = torch.ops.aten.add.Scalar(mean_28, 1e-05);  mean_28 = None
        rsqrt_28 = torch.ops.aten.rsqrt.default(add_551);  add_551 = None
        mul_405 = torch.ops.aten.mul.Tensor(convert_element_type_483, rsqrt_28);  convert_element_type_483 = None
        mul_406 = torch.ops.aten.mul.Tensor(mul_405, wait_tensor_182);  mul_405 = wait_tensor_182 = None
        convert_element_type_484 = torch.ops.prims.convert_element_type.default(mul_406, torch.bfloat16);  mul_406 = None
        convert_element_type_485 = torch.ops.prims.convert_element_type.default(primals_155, torch.bfloat16)
        all_gather_into_tensor_151 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_485, 128, '0');  convert_element_type_485 = None
        wait_tensor_183 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_151);  all_gather_into_tensor_151 = None
        permute_133 = torch.ops.aten.permute.default(wait_tensor_183, [1, 0]);  wait_tensor_183 = None
        view_586 = torch.ops.aten.view.default(convert_element_type_484, [8192, 512]);  convert_element_type_484 = None
        mm_73 = torch.ops.aten.mm.default(view_586, permute_133);  permute_133 = None
        view_587 = torch.ops.aten.view.default(mm_73, [2, 4096, 4096]);  mm_73 = None
        view_588 = torch.ops.aten.view.default(view_587, [2, 4096, -1, 256]);  view_587 = None
        split_with_sizes_29 = torch.ops.aten.split_with_sizes.default(view_588, [128, 128], -1);  view_588 = None
        getitem_893 = split_with_sizes_29[0]
        getitem_894 = split_with_sizes_29[1];  split_with_sizes_29 = None
        expand_9 = torch.ops.aten.expand.default(convert_element_type_481, [-1, -1, 16, -1]);  convert_element_type_481 = None
        cat_75 = torch.ops.aten.cat.default([getitem_893, expand_9], -1);  getitem_893 = expand_9 = None
        permute_134 = torch.ops.aten.permute.default(cat_74, [0, 2, 1, 3]);  cat_74 = None
        permute_135 = torch.ops.aten.permute.default(cat_75, [0, 2, 1, 3]);  cat_75 = None
        permute_136 = torch.ops.aten.permute.default(getitem_894, [0, 2, 1, 3]);  getitem_894 = None
        sdpa_score9 = self.sdpa_score9
        sdpa_mask9 = self.sdpa_mask9
        flex_attention_9 = torch.ops.higher_order.flex_attention(permute_134, permute_135, permute_136, sdpa_score9, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask9), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score9 = sdpa_mask9 = None
        getitem_895 = flex_attention_9[0]
        getitem_896 = flex_attention_9[1];  flex_attention_9 = None
        permute_137 = torch.ops.aten.permute.default(getitem_895, [0, 2, 1, 3])
        view_589 = torch.ops.aten.view.default(permute_137, [2, 4096, -1]);  permute_137 = None
        convert_element_type_488 = torch.ops.prims.convert_element_type.default(primals_156, torch.bfloat16)
        all_gather_into_tensor_152 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_488, 128, '0');  convert_element_type_488 = None
        wait_tensor_184 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_152);  all_gather_into_tensor_152 = None
        permute_138 = torch.ops.aten.permute.default(wait_tensor_184, [1, 0]);  wait_tensor_184 = None
        view_591 = torch.ops.aten.view.default(view_589, [8192, 2048]);  view_589 = None
        mm_74 = torch.ops.aten.mm.default(view_591, permute_138);  view_591 = permute_138 = None
        view_592 = torch.ops.aten.view.default(mm_74, [2, 4096, 2048]);  mm_74 = None
        add_552 = torch.ops.aten.add.Tensor(add_549, view_592);  view_592 = None
        convert_element_type_491 = torch.ops.prims.convert_element_type.default(primals_157, torch.bfloat16)
        all_gather_into_tensor_153 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_491, 128, '0');  convert_element_type_491 = None
        wait_tensor_185 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_153);  all_gather_into_tensor_153 = None
        convert_element_type_492 = torch.ops.prims.convert_element_type.default(add_552, torch.float32)
        pow_30 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_492, 2)
        mean_29 = torch.ops.aten.mean.dim(pow_30, [2], True);  pow_30 = None
        add_553 = torch.ops.aten.add.Scalar(mean_29, 1e-05);  mean_29 = None
        rsqrt_29 = torch.ops.aten.rsqrt.default(add_553);  add_553 = None
        mul_407 = torch.ops.aten.mul.Tensor(convert_element_type_492, rsqrt_29);  convert_element_type_492 = None
        mul_408 = torch.ops.aten.mul.Tensor(mul_407, wait_tensor_185);  mul_407 = wait_tensor_185 = None
        convert_element_type_493 = torch.ops.prims.convert_element_type.default(mul_408, torch.bfloat16);  mul_408 = None
        view_594 = torch.ops.aten.view.default(convert_element_type_493, [-1, 2048]);  convert_element_type_493 = None
        convert_element_type_494 = torch.ops.prims.convert_element_type.default(primals_159, torch.bfloat16)
        all_gather_into_tensor_154 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_494, 128, '0');  convert_element_type_494 = None
        wait_tensor_186 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_154);  all_gather_into_tensor_154 = None
        slice_57 = torch.ops.aten.slice.Tensor(wait_tensor_186, 0, 0, 64);  wait_tensor_186 = None
        permute_139 = torch.ops.aten.permute.default(slice_57, [1, 0]);  slice_57 = None
        mm_75 = torch.ops.aten.mm.default(view_594, permute_139);  permute_139 = None
        convert_element_type_497 = torch.ops.prims.convert_element_type.default(mm_75, torch.float32)
        amax_8 = torch.ops.aten.amax.default(convert_element_type_497, [1], True)
        sub_192 = torch.ops.aten.sub.Tensor(convert_element_type_497, amax_8);  convert_element_type_497 = None
        exp_25 = torch.ops.aten.exp.default(sub_192);  sub_192 = None
        sum_33 = torch.ops.aten.sum.dim_IntList(exp_25, [1], True)
        div_41 = torch.ops.aten.div.Tensor(exp_25, sum_33);  exp_25 = None
        add_554 = torch.ops.aten.add.Tensor(div_41, primals_158);  primals_158 = None
        topk_8 = torch.ops.aten.topk.default(add_554, 6, -1, True, False);  add_554 = None
        getitem_899 = topk_8[1];  topk_8 = None
        gather_8 = torch.ops.aten.gather.default(div_41, 1, getitem_899);  div_41 = None
        mul_409 = torch.ops.aten.mul.Tensor(gather_8, 1.0);  gather_8 = None
        view_596 = torch.ops.aten.view.default(getitem_899, [-1])
        histc_16 = torch.ops.aten.histc.default(view_596, 64, 0, 64)
        add_555 = torch.ops.aten.add.Tensor(primals_160, histc_16)
        sort_8 = torch.ops.aten.sort.stable(view_596, stable = True);  view_596 = None
        getitem_901 = sort_8[1];  sort_8 = None
        div_42 = torch.ops.aten.div.Tensor_mode(getitem_901, 6, rounding_mode = 'floor')
        index_16 = torch.ops.aten.index.Tensor(view_594, [div_42])
        all_to_all_single_24 = torch.ops._c10d_functional.all_to_all_single.default(histc_16, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_187 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_24);  all_to_all_single_24 = None
        wait_tensor_188 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_187);  wait_tensor_187 = None
        view_600 = torch.ops.aten.view.default(histc_16, [8, -1]);  histc_16 = None
        sum_34 = torch.ops.aten.sum.dim_IntList(view_600, [1]);  view_600 = None
        device_put_16 = torch.ops.prims.device_put.default(sum_34, device(type='cpu'), True);  sum_34 = None
        view_601 = torch.ops.aten.view.default(wait_tensor_188, [8, -1])
        sum_35 = torch.ops.aten.sum.dim_IntList(view_601, [1])
        device_put_17 = torch.ops.prims.device_put.default(sum_35, device(type='cpu'));  sum_35 = None
        select_128 = torch.ops.aten.select.int(device_put_16, 0, 0)
        _local_scalar_dense_128 = torch.ops.aten._local_scalar_dense.default(select_128);  select_128 = None
        ge_160 = _local_scalar_dense_128 >= 0
        _assert_scalar_128 = torch.ops.aten._assert_scalar.default(ge_160, "Runtime assertion failed for expression u128 >= 0 on node 'ge_128'");  ge_160 = _assert_scalar_128 = None
        select_129 = torch.ops.aten.select.int(device_put_16, 0, 1)
        _local_scalar_dense_129 = torch.ops.aten._local_scalar_dense.default(select_129);  select_129 = None
        ge_161 = _local_scalar_dense_129 >= 0
        _assert_scalar_129 = torch.ops.aten._assert_scalar.default(ge_161, "Runtime assertion failed for expression u129 >= 0 on node 'ge_129'");  ge_161 = _assert_scalar_129 = None
        select_130 = torch.ops.aten.select.int(device_put_16, 0, 2)
        _local_scalar_dense_130 = torch.ops.aten._local_scalar_dense.default(select_130);  select_130 = None
        ge_162 = _local_scalar_dense_130 >= 0
        _assert_scalar_130 = torch.ops.aten._assert_scalar.default(ge_162, "Runtime assertion failed for expression u130 >= 0 on node 'ge_130'");  ge_162 = _assert_scalar_130 = None
        select_131 = torch.ops.aten.select.int(device_put_16, 0, 3)
        _local_scalar_dense_131 = torch.ops.aten._local_scalar_dense.default(select_131);  select_131 = None
        ge_163 = _local_scalar_dense_131 >= 0
        _assert_scalar_131 = torch.ops.aten._assert_scalar.default(ge_163, "Runtime assertion failed for expression u131 >= 0 on node 'ge_131'");  ge_163 = _assert_scalar_131 = None
        select_132 = torch.ops.aten.select.int(device_put_16, 0, 4)
        _local_scalar_dense_132 = torch.ops.aten._local_scalar_dense.default(select_132);  select_132 = None
        ge_164 = _local_scalar_dense_132 >= 0
        _assert_scalar_132 = torch.ops.aten._assert_scalar.default(ge_164, "Runtime assertion failed for expression u132 >= 0 on node 'ge_132'");  ge_164 = _assert_scalar_132 = None
        select_133 = torch.ops.aten.select.int(device_put_16, 0, 5)
        _local_scalar_dense_133 = torch.ops.aten._local_scalar_dense.default(select_133);  select_133 = None
        ge_165 = _local_scalar_dense_133 >= 0
        _assert_scalar_133 = torch.ops.aten._assert_scalar.default(ge_165, "Runtime assertion failed for expression u133 >= 0 on node 'ge_133'");  ge_165 = _assert_scalar_133 = None
        select_134 = torch.ops.aten.select.int(device_put_16, 0, 6)
        _local_scalar_dense_134 = torch.ops.aten._local_scalar_dense.default(select_134);  select_134 = None
        ge_166 = _local_scalar_dense_134 >= 0
        _assert_scalar_134 = torch.ops.aten._assert_scalar.default(ge_166, "Runtime assertion failed for expression u134 >= 0 on node 'ge_134'");  ge_166 = _assert_scalar_134 = None
        select_135 = torch.ops.aten.select.int(device_put_16, 0, 7);  device_put_16 = None
        _local_scalar_dense_135 = torch.ops.aten._local_scalar_dense.default(select_135);  select_135 = None
        ge_167 = _local_scalar_dense_135 >= 0
        _assert_scalar_135 = torch.ops.aten._assert_scalar.default(ge_167, "Runtime assertion failed for expression u135 >= 0 on node 'ge_135'");  ge_167 = _assert_scalar_135 = None
        select_136 = torch.ops.aten.select.int(device_put_17, 0, 0)
        _local_scalar_dense_136 = torch.ops.aten._local_scalar_dense.default(select_136);  select_136 = None
        ge_168 = _local_scalar_dense_136 >= 0
        _assert_scalar_136 = torch.ops.aten._assert_scalar.default(ge_168, "Runtime assertion failed for expression u136 >= 0 on node 'ge_136'");  ge_168 = _assert_scalar_136 = None
        select_137 = torch.ops.aten.select.int(device_put_17, 0, 1)
        _local_scalar_dense_137 = torch.ops.aten._local_scalar_dense.default(select_137);  select_137 = None
        ge_169 = _local_scalar_dense_137 >= 0
        _assert_scalar_137 = torch.ops.aten._assert_scalar.default(ge_169, "Runtime assertion failed for expression u137 >= 0 on node 'ge_137'");  ge_169 = _assert_scalar_137 = None
        select_138 = torch.ops.aten.select.int(device_put_17, 0, 2)
        _local_scalar_dense_138 = torch.ops.aten._local_scalar_dense.default(select_138);  select_138 = None
        ge_170 = _local_scalar_dense_138 >= 0
        _assert_scalar_138 = torch.ops.aten._assert_scalar.default(ge_170, "Runtime assertion failed for expression u138 >= 0 on node 'ge_138'");  ge_170 = _assert_scalar_138 = None
        select_139 = torch.ops.aten.select.int(device_put_17, 0, 3)
        _local_scalar_dense_139 = torch.ops.aten._local_scalar_dense.default(select_139);  select_139 = None
        ge_171 = _local_scalar_dense_139 >= 0
        _assert_scalar_139 = torch.ops.aten._assert_scalar.default(ge_171, "Runtime assertion failed for expression u139 >= 0 on node 'ge_139'");  ge_171 = _assert_scalar_139 = None
        select_140 = torch.ops.aten.select.int(device_put_17, 0, 4)
        _local_scalar_dense_140 = torch.ops.aten._local_scalar_dense.default(select_140);  select_140 = None
        ge_172 = _local_scalar_dense_140 >= 0
        _assert_scalar_140 = torch.ops.aten._assert_scalar.default(ge_172, "Runtime assertion failed for expression u140 >= 0 on node 'ge_140'");  ge_172 = _assert_scalar_140 = None
        select_141 = torch.ops.aten.select.int(device_put_17, 0, 5)
        _local_scalar_dense_141 = torch.ops.aten._local_scalar_dense.default(select_141);  select_141 = None
        ge_173 = _local_scalar_dense_141 >= 0
        _assert_scalar_141 = torch.ops.aten._assert_scalar.default(ge_173, "Runtime assertion failed for expression u141 >= 0 on node 'ge_141'");  ge_173 = _assert_scalar_141 = None
        select_142 = torch.ops.aten.select.int(device_put_17, 0, 6)
        _local_scalar_dense_142 = torch.ops.aten._local_scalar_dense.default(select_142);  select_142 = None
        ge_174 = _local_scalar_dense_142 >= 0
        _assert_scalar_142 = torch.ops.aten._assert_scalar.default(ge_174, "Runtime assertion failed for expression u142 >= 0 on node 'ge_142'");  ge_174 = _assert_scalar_142 = None
        select_143 = torch.ops.aten.select.int(device_put_17, 0, 7);  device_put_17 = None
        _local_scalar_dense_143 = torch.ops.aten._local_scalar_dense.default(select_143);  select_143 = None
        ge_175 = _local_scalar_dense_143 >= 0
        _assert_scalar_143 = torch.ops.aten._assert_scalar.default(ge_175, "Runtime assertion failed for expression u143 >= 0 on node 'ge_143'");  ge_175 = _assert_scalar_143 = None
        all_to_all_single_25 = torch.ops._c10d_functional.all_to_all_single.default(index_16, [_local_scalar_dense_136, _local_scalar_dense_137, _local_scalar_dense_138, _local_scalar_dense_139, _local_scalar_dense_140, _local_scalar_dense_141, _local_scalar_dense_142, _local_scalar_dense_143], [_local_scalar_dense_128, _local_scalar_dense_129, _local_scalar_dense_130, _local_scalar_dense_131, _local_scalar_dense_132, _local_scalar_dense_133, _local_scalar_dense_134, _local_scalar_dense_135], '1033');  index_16 = None
        sym_size_int_32 = torch.ops.aten.sym_size.int(all_to_all_single_25, 0)
        wait_tensor_189 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_25);  all_to_all_single_25 = None
        sym_sum_16 = torch.sym_sum((_local_scalar_dense_136, _local_scalar_dense_137, _local_scalar_dense_138, _local_scalar_dense_139, _local_scalar_dense_140, _local_scalar_dense_141, _local_scalar_dense_142, _local_scalar_dense_143))
        add_562 = sym_sum_16 + 64;  sym_sum_16 = None
        add_563 = add_562 + 8;  add_562 = None
        sub_195 = add_563 - 1;  add_563 = None
        floordiv_8 = sub_195 // 8;  sub_195 = None
        mul_414 = floordiv_8 * 8;  floordiv_8 = None
        cumsum_24 = torch.ops.aten.cumsum.default(wait_tensor_188, 0)
        sub_196 = torch.ops.aten.sub.Tensor(cumsum_24, wait_tensor_188);  cumsum_24 = None
        sum_36 = torch.ops.aten.sum.dim_IntList(view_601, [0]);  view_601 = None
        clamp_min_8 = torch.ops.aten.clamp_min.default(sum_36, 8);  sum_36 = None
        add_564 = torch.ops.aten.add.Tensor(clamp_min_8, 8);  clamp_min_8 = None
        sub_197 = torch.ops.aten.sub.Tensor(add_564, 1);  add_564 = None
        div_43 = torch.ops.aten.div.Tensor_mode(sub_197, 8, rounding_mode = 'floor');  sub_197 = None
        mul_415 = torch.ops.aten.mul.Tensor(div_43, 8);  div_43 = None
        convert_element_type_500 = torch.ops.prims.convert_element_type.default(mul_415, torch.int32);  mul_415 = None
        cumsum_25 = torch.ops.aten.cumsum.default(convert_element_type_500, 0)
        sub_198 = torch.ops.aten.sub.Tensor(cumsum_25, convert_element_type_500);  cumsum_25 = None
        full_124 = torch.ops.aten.full.default([mul_414], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_414 = None
        triton_kernel_wrapper_functional_proxy_8 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 8, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_188, 'start_index_values_ptr': sub_196, 'write_offsets_ptr': sub_198, 'output_ptr': full_124}, tensors_to_clone = ['output_ptr']);  wait_tensor_188 = sub_196 = sub_198 = full_124 = None
        getitem_902 = triton_kernel_wrapper_functional_proxy_8['output_ptr'];  triton_kernel_wrapper_functional_proxy_8 = None
        cat_76 = torch.ops.aten.cat.default([wait_tensor_189, full_default]);  wait_tensor_189 = None
        sym_size_int_33 = torch.ops.aten.sym_size.int(cat_76, 0)
        sym_sum_17 = torch.sym_sum((1, _local_scalar_dense_136, _local_scalar_dense_137, _local_scalar_dense_138, _local_scalar_dense_139, _local_scalar_dense_140, _local_scalar_dense_141, _local_scalar_dense_142, _local_scalar_dense_143))
        index_17 = torch.ops.aten.index.Tensor(cat_76, [getitem_902]);  cat_76 = None
        convert_element_type_502 = torch.ops.prims.convert_element_type.default(primals_161, torch.bfloat16)
        all_gather_into_tensor_155 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_502, 16, '1025');  convert_element_type_502 = None
        wait_tensor_190 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_155);  all_gather_into_tensor_155 = None
        split_49 = torch.ops.aten.split.Tensor(wait_tensor_190, 8);  wait_tensor_190 = None
        getitem_919 = split_49[0]
        getitem_920 = split_49[1]
        getitem_921 = split_49[2]
        getitem_922 = split_49[3]
        getitem_923 = split_49[4]
        getitem_924 = split_49[5]
        getitem_925 = split_49[6]
        getitem_926 = split_49[7]
        getitem_927 = split_49[8]
        getitem_928 = split_49[9]
        getitem_929 = split_49[10]
        getitem_930 = split_49[11]
        getitem_931 = split_49[12]
        getitem_932 = split_49[13]
        getitem_933 = split_49[14]
        getitem_934 = split_49[15];  split_49 = None
        cat_78 = torch.ops.aten.cat.default([getitem_919, getitem_920, getitem_921, getitem_922, getitem_923, getitem_924, getitem_925, getitem_926, getitem_927, getitem_928, getitem_929, getitem_930, getitem_931, getitem_932, getitem_933, getitem_934], 1);  getitem_919 = getitem_920 = getitem_921 = getitem_922 = getitem_923 = getitem_924 = getitem_925 = getitem_926 = getitem_927 = getitem_928 = getitem_929 = getitem_930 = getitem_931 = getitem_932 = getitem_933 = getitem_934 = None
        convert_element_type_504 = torch.ops.prims.convert_element_type.default(primals_162, torch.bfloat16)
        all_gather_into_tensor_157 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_504, 16, '1025');  convert_element_type_504 = None
        wait_tensor_192 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_157);  all_gather_into_tensor_157 = None
        split_50 = torch.ops.aten.split.Tensor(wait_tensor_192, 8);  wait_tensor_192 = None
        getitem_935 = split_50[0]
        getitem_936 = split_50[1]
        getitem_937 = split_50[2]
        getitem_938 = split_50[3]
        getitem_939 = split_50[4]
        getitem_940 = split_50[5]
        getitem_941 = split_50[6]
        getitem_942 = split_50[7]
        getitem_943 = split_50[8]
        getitem_944 = split_50[9]
        getitem_945 = split_50[10]
        getitem_946 = split_50[11]
        getitem_947 = split_50[12]
        getitem_948 = split_50[13]
        getitem_949 = split_50[14]
        getitem_950 = split_50[15];  split_50 = None
        cat_79 = torch.ops.aten.cat.default([getitem_935, getitem_936, getitem_937, getitem_938, getitem_939, getitem_940, getitem_941, getitem_942, getitem_943, getitem_944, getitem_945, getitem_946, getitem_947, getitem_948, getitem_949, getitem_950], 1);  getitem_935 = getitem_936 = getitem_937 = getitem_938 = getitem_939 = getitem_940 = getitem_941 = getitem_942 = getitem_943 = getitem_944 = getitem_945 = getitem_946 = getitem_947 = getitem_948 = getitem_949 = getitem_950 = None
        convert_element_type_505 = torch.ops.prims.convert_element_type.default(primals_163, torch.bfloat16)
        all_gather_into_tensor_158 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_505, 16, '1025');  convert_element_type_505 = None
        wait_tensor_193 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_158);  all_gather_into_tensor_158 = None
        split_51 = torch.ops.aten.split.Tensor(wait_tensor_193, 8);  wait_tensor_193 = None
        getitem_951 = split_51[0]
        getitem_952 = split_51[1]
        getitem_953 = split_51[2]
        getitem_954 = split_51[3]
        getitem_955 = split_51[4]
        getitem_956 = split_51[5]
        getitem_957 = split_51[6]
        getitem_958 = split_51[7]
        getitem_959 = split_51[8]
        getitem_960 = split_51[9]
        getitem_961 = split_51[10]
        getitem_962 = split_51[11]
        getitem_963 = split_51[12]
        getitem_964 = split_51[13]
        getitem_965 = split_51[14]
        getitem_966 = split_51[15];  split_51 = None
        cat_80 = torch.ops.aten.cat.default([getitem_951, getitem_952, getitem_953, getitem_954, getitem_955, getitem_956, getitem_957, getitem_958, getitem_959, getitem_960, getitem_961, getitem_962, getitem_963, getitem_964, getitem_965, getitem_966], 1);  getitem_951 = getitem_952 = getitem_953 = getitem_954 = getitem_955 = getitem_956 = getitem_957 = getitem_958 = getitem_959 = getitem_960 = getitem_961 = getitem_962 = getitem_963 = getitem_964 = getitem_965 = getitem_966 = None
        cumsum_26 = torch.ops.aten.cumsum.default(convert_element_type_500, 0, dtype = torch.int32);  convert_element_type_500 = None
        permute_140 = torch.ops.aten.permute.default(cat_78, [0, 2, 1]);  cat_78 = None
        _grouped_mm_24 = torch.ops.aten._grouped_mm.default(index_17, permute_140, cumsum_26)
        convert_element_type_508 = torch.ops.prims.convert_element_type.default(_grouped_mm_24, torch.float32)
        neg_17 = torch.ops.aten.neg.default(convert_element_type_508)
        exp_26 = torch.ops.aten.exp.default(neg_17);  neg_17 = None
        add_576 = torch.ops.aten.add.Tensor(exp_26, 1);  exp_26 = None
        div_44 = torch.ops.aten.div.Tensor(convert_element_type_508, add_576);  convert_element_type_508 = add_576 = None
        convert_element_type_509 = torch.ops.prims.convert_element_type.default(div_44, torch.bfloat16);  div_44 = None
        permute_141 = torch.ops.aten.permute.default(cat_80, [0, 2, 1]);  cat_80 = None
        _grouped_mm_25 = torch.ops.aten._grouped_mm.default(index_17, permute_141, cumsum_26)
        mul_427 = torch.ops.aten.mul.Tensor(convert_element_type_509, _grouped_mm_25);  convert_element_type_509 = None
        permute_142 = torch.ops.aten.permute.default(cat_79, [0, 2, 1]);  cat_79 = None
        _grouped_mm_26 = torch.ops.aten._grouped_mm.default(mul_427, permute_142, cumsum_26)
        empty_8 = torch.ops.aten.empty.memory_format([sym_size_int_33, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_16 = torch.ops.aten.index_put.default(empty_8, [getitem_902], _grouped_mm_26);  empty_8 = _grouped_mm_26 = None
        slice_59 = torch.ops.aten.slice.Tensor(index_put_16, 0, 0, -1);  index_put_16 = None
        all_to_all_single_26 = torch.ops._c10d_functional.all_to_all_single.default(slice_59, [_local_scalar_dense_128, _local_scalar_dense_129, _local_scalar_dense_130, _local_scalar_dense_131, _local_scalar_dense_132, _local_scalar_dense_133, _local_scalar_dense_134, _local_scalar_dense_135], [_local_scalar_dense_136, _local_scalar_dense_137, _local_scalar_dense_138, _local_scalar_dense_139, _local_scalar_dense_140, _local_scalar_dense_141, _local_scalar_dense_142, _local_scalar_dense_143], '1033');  slice_59 = None
        wait_tensor_196 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_26);  all_to_all_single_26 = None
        convert_element_type_510 = torch.ops.prims.convert_element_type.default(primals_164, torch.bfloat16)
        all_gather_into_tensor_161 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_510, 128, '0');  convert_element_type_510 = None
        wait_tensor_197 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_161);  all_gather_into_tensor_161 = None
        permute_143 = torch.ops.aten.permute.default(wait_tensor_197, [1, 0]);  wait_tensor_197 = None
        mm_76 = torch.ops.aten.mm.default(view_594, permute_143);  permute_143 = None
        convert_element_type_513 = torch.ops.prims.convert_element_type.default(mm_76, torch.float32)
        neg_18 = torch.ops.aten.neg.default(convert_element_type_513)
        exp_27 = torch.ops.aten.exp.default(neg_18);  neg_18 = None
        add_612 = torch.ops.aten.add.Tensor(exp_27, 1);  exp_27 = None
        div_45 = torch.ops.aten.div.Tensor(convert_element_type_513, add_612);  convert_element_type_513 = add_612 = None
        convert_element_type_514 = torch.ops.prims.convert_element_type.default(div_45, torch.bfloat16);  div_45 = None
        convert_element_type_515 = torch.ops.prims.convert_element_type.default(primals_165, torch.bfloat16)
        all_gather_into_tensor_162 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_515, 128, '0');  convert_element_type_515 = None
        wait_tensor_198 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_162);  all_gather_into_tensor_162 = None
        permute_144 = torch.ops.aten.permute.default(wait_tensor_198, [1, 0]);  wait_tensor_198 = None
        mm_77 = torch.ops.aten.mm.default(view_594, permute_144);  permute_144 = None
        mul_447 = torch.ops.aten.mul.Tensor(convert_element_type_514, mm_77);  convert_element_type_514 = None
        convert_element_type_518 = torch.ops.prims.convert_element_type.default(primals_166, torch.bfloat16)
        all_gather_into_tensor_163 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_518, 128, '0');  convert_element_type_518 = None
        wait_tensor_199 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_163);  all_gather_into_tensor_163 = None
        permute_145 = torch.ops.aten.permute.default(wait_tensor_199, [1, 0]);  wait_tensor_199 = None
        mm_78 = torch.ops.aten.mm.default(mul_447, permute_145);  permute_145 = None
        index_put_17 = torch.ops.aten.index_put.default(full_default_1, [getitem_901], wait_tensor_196);  wait_tensor_196 = None
        view_634 = torch.ops.aten.view.default(mul_409, [-1, 1, 6]);  mul_409 = None
        view_635 = torch.ops.aten.view.default(index_put_17, [-1, 6, 2048]);  index_put_17 = None
        convert_element_type_521 = torch.ops.prims.convert_element_type.default(view_635, torch.float32);  view_635 = None
        bmm_8 = torch.ops.aten.bmm.default(view_634, convert_element_type_521)
        convert_element_type_522 = torch.ops.prims.convert_element_type.default(bmm_8, torch.bfloat16);  bmm_8 = None
        squeeze_8 = torch.ops.aten.squeeze.dim(convert_element_type_522, 1);  convert_element_type_522 = None
        add_616 = torch.ops.aten.add.Tensor(mm_78, squeeze_8);  mm_78 = squeeze_8 = None
        view_636 = torch.ops.aten.view.default(add_616, [2, 4096, 2048]);  add_616 = None
        add_617 = torch.ops.aten.add.Tensor(add_552, view_636);  view_636 = None
        convert_element_type_523 = torch.ops.prims.convert_element_type.default(primals_167, torch.bfloat16)
        all_gather_into_tensor_164 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_523, 128, '0');  convert_element_type_523 = None
        wait_tensor_200 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_164);  all_gather_into_tensor_164 = None
        convert_element_type_524 = torch.ops.prims.convert_element_type.default(add_617, torch.float32)
        pow_31 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_524, 2)
        mean_30 = torch.ops.aten.mean.dim(pow_31, [2], True);  pow_31 = None
        add_618 = torch.ops.aten.add.Scalar(mean_30, 1e-05);  mean_30 = None
        rsqrt_30 = torch.ops.aten.rsqrt.default(add_618);  add_618 = None
        mul_450 = torch.ops.aten.mul.Tensor(convert_element_type_524, rsqrt_30);  convert_element_type_524 = None
        mul_451 = torch.ops.aten.mul.Tensor(mul_450, wait_tensor_200);  mul_450 = wait_tensor_200 = None
        convert_element_type_525 = torch.ops.prims.convert_element_type.default(mul_451, torch.bfloat16);  mul_451 = None
        convert_element_type_526 = torch.ops.prims.convert_element_type.default(primals_168, torch.bfloat16)
        all_gather_into_tensor_165 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_526, 128, '0');  convert_element_type_526 = None
        wait_tensor_201 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_165);  all_gather_into_tensor_165 = None
        permute_146 = torch.ops.aten.permute.default(wait_tensor_201, [1, 0]);  wait_tensor_201 = None
        view_639 = torch.ops.aten.view.default(convert_element_type_525, [8192, 2048]);  convert_element_type_525 = None
        mm_79 = torch.ops.aten.mm.default(view_639, permute_146);  permute_146 = None
        view_640 = torch.ops.aten.view.default(mm_79, [2, 4096, 3072]);  mm_79 = None
        view_641 = torch.ops.aten.view.default(view_640, [2, 4096, -1, 192]);  view_640 = None
        split_with_sizes_30 = torch.ops.aten.split_with_sizes.default(view_641, [128, 64], -1);  view_641 = None
        getitem_999 = split_with_sizes_30[0]
        getitem_1000 = split_with_sizes_30[1];  split_with_sizes_30 = None
        convert_element_type_529 = torch.ops.prims.convert_element_type.default(getitem_1000, torch.float32);  getitem_1000 = None
        view_642 = torch.ops.aten.view.default(convert_element_type_529, [2, 4096, 16, -1, 2]);  convert_element_type_529 = None
        view_as_complex_20 = torch.ops.aten.view_as_complex.default(view_642);  view_642 = None
        mul_452 = torch.ops.aten.mul.Tensor(view_as_complex_20, view_7);  view_as_complex_20 = None
        view_as_real_20 = torch.ops.aten.view_as_real.default(mul_452);  mul_452 = None
        view_644 = torch.ops.aten.view.default(view_as_real_20, [2, 4096, 16, 64]);  view_as_real_20 = None
        convert_element_type_530 = torch.ops.prims.convert_element_type.default(view_644, torch.bfloat16);  view_644 = None
        cat_83 = torch.ops.aten.cat.default([getitem_999, convert_element_type_530], -1);  getitem_999 = convert_element_type_530 = None
        convert_element_type_531 = torch.ops.prims.convert_element_type.default(primals_169, torch.bfloat16)
        all_gather_into_tensor_166 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_531, 128, '0');  convert_element_type_531 = None
        wait_tensor_202 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_166);  all_gather_into_tensor_166 = None
        slice_61 = torch.ops.aten.slice.Tensor(wait_tensor_202, 0, 0, 576);  wait_tensor_202 = None
        permute_147 = torch.ops.aten.permute.default(slice_61, [1, 0]);  slice_61 = None
        mm_80 = torch.ops.aten.mm.default(view_639, permute_147);  permute_147 = None
        view_647 = torch.ops.aten.view.default(mm_80, [2, 4096, 576]);  mm_80 = None
        split_with_sizes_31 = torch.ops.aten.split_with_sizes.default(view_647, [512, 64], -1);  view_647 = None
        getitem_1001 = split_with_sizes_31[0]
        getitem_1002 = split_with_sizes_31[1];  split_with_sizes_31 = None
        unsqueeze_19 = torch.ops.aten.unsqueeze.default(getitem_1002, 2);  getitem_1002 = None
        convert_element_type_534 = torch.ops.prims.convert_element_type.default(unsqueeze_19, torch.float32);  unsqueeze_19 = None
        view_648 = torch.ops.aten.view.default(convert_element_type_534, [2, 4096, 1, -1, 2]);  convert_element_type_534 = None
        view_as_complex_21 = torch.ops.aten.view_as_complex.default(view_648);  view_648 = None
        mul_453 = torch.ops.aten.mul.Tensor(view_as_complex_21, view_7);  view_as_complex_21 = None
        view_as_real_21 = torch.ops.aten.view_as_real.default(mul_453);  mul_453 = None
        view_650 = torch.ops.aten.view.default(view_as_real_21, [2, 4096, 1, 64]);  view_as_real_21 = None
        convert_element_type_535 = torch.ops.prims.convert_element_type.default(view_650, torch.bfloat16);  view_650 = None
        convert_element_type_536 = torch.ops.prims.convert_element_type.default(primals_170, torch.bfloat16)
        all_gather_into_tensor_167 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_536, 128, '0');  convert_element_type_536 = None
        wait_tensor_203 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_167);  all_gather_into_tensor_167 = None
        convert_element_type_537 = torch.ops.prims.convert_element_type.default(getitem_1001, torch.float32)
        pow_32 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_537, 2)
        mean_31 = torch.ops.aten.mean.dim(pow_32, [2], True);  pow_32 = None
        add_619 = torch.ops.aten.add.Scalar(mean_31, 1e-05);  mean_31 = None
        rsqrt_31 = torch.ops.aten.rsqrt.default(add_619);  add_619 = None
        mul_454 = torch.ops.aten.mul.Tensor(convert_element_type_537, rsqrt_31);  convert_element_type_537 = None
        mul_455 = torch.ops.aten.mul.Tensor(mul_454, wait_tensor_203);  mul_454 = wait_tensor_203 = None
        convert_element_type_538 = torch.ops.prims.convert_element_type.default(mul_455, torch.bfloat16);  mul_455 = None
        convert_element_type_539 = torch.ops.prims.convert_element_type.default(primals_171, torch.bfloat16)
        all_gather_into_tensor_168 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_539, 128, '0');  convert_element_type_539 = None
        wait_tensor_204 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_168);  all_gather_into_tensor_168 = None
        permute_148 = torch.ops.aten.permute.default(wait_tensor_204, [1, 0]);  wait_tensor_204 = None
        view_653 = torch.ops.aten.view.default(convert_element_type_538, [8192, 512]);  convert_element_type_538 = None
        mm_81 = torch.ops.aten.mm.default(view_653, permute_148);  permute_148 = None
        view_654 = torch.ops.aten.view.default(mm_81, [2, 4096, 4096]);  mm_81 = None
        view_655 = torch.ops.aten.view.default(view_654, [2, 4096, -1, 256]);  view_654 = None
        split_with_sizes_32 = torch.ops.aten.split_with_sizes.default(view_655, [128, 128], -1);  view_655 = None
        getitem_1003 = split_with_sizes_32[0]
        getitem_1004 = split_with_sizes_32[1];  split_with_sizes_32 = None
        expand_10 = torch.ops.aten.expand.default(convert_element_type_535, [-1, -1, 16, -1]);  convert_element_type_535 = None
        cat_84 = torch.ops.aten.cat.default([getitem_1003, expand_10], -1);  getitem_1003 = expand_10 = None
        permute_149 = torch.ops.aten.permute.default(cat_83, [0, 2, 1, 3]);  cat_83 = None
        permute_150 = torch.ops.aten.permute.default(cat_84, [0, 2, 1, 3]);  cat_84 = None
        permute_151 = torch.ops.aten.permute.default(getitem_1004, [0, 2, 1, 3]);  getitem_1004 = None
        sdpa_score10 = self.sdpa_score10
        sdpa_mask10 = self.sdpa_mask10
        flex_attention_10 = torch.ops.higher_order.flex_attention(permute_149, permute_150, permute_151, sdpa_score10, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask10), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score10 = sdpa_mask10 = None
        getitem_1005 = flex_attention_10[0]
        getitem_1006 = flex_attention_10[1];  flex_attention_10 = None
        permute_152 = torch.ops.aten.permute.default(getitem_1005, [0, 2, 1, 3])
        view_656 = torch.ops.aten.view.default(permute_152, [2, 4096, -1]);  permute_152 = None
        convert_element_type_542 = torch.ops.prims.convert_element_type.default(primals_172, torch.bfloat16)
        all_gather_into_tensor_169 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_542, 128, '0');  convert_element_type_542 = None
        wait_tensor_205 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_169);  all_gather_into_tensor_169 = None
        permute_153 = torch.ops.aten.permute.default(wait_tensor_205, [1, 0]);  wait_tensor_205 = None
        view_658 = torch.ops.aten.view.default(view_656, [8192, 2048]);  view_656 = None
        mm_82 = torch.ops.aten.mm.default(view_658, permute_153);  view_658 = permute_153 = None
        view_659 = torch.ops.aten.view.default(mm_82, [2, 4096, 2048]);  mm_82 = None
        add_620 = torch.ops.aten.add.Tensor(add_617, view_659);  view_659 = None
        convert_element_type_545 = torch.ops.prims.convert_element_type.default(primals_173, torch.bfloat16)
        all_gather_into_tensor_170 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_545, 128, '0');  convert_element_type_545 = None
        wait_tensor_206 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_170);  all_gather_into_tensor_170 = None
        convert_element_type_546 = torch.ops.prims.convert_element_type.default(add_620, torch.float32)
        pow_33 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_546, 2)
        mean_32 = torch.ops.aten.mean.dim(pow_33, [2], True);  pow_33 = None
        add_621 = torch.ops.aten.add.Scalar(mean_32, 1e-05);  mean_32 = None
        rsqrt_32 = torch.ops.aten.rsqrt.default(add_621);  add_621 = None
        mul_456 = torch.ops.aten.mul.Tensor(convert_element_type_546, rsqrt_32);  convert_element_type_546 = None
        mul_457 = torch.ops.aten.mul.Tensor(mul_456, wait_tensor_206);  mul_456 = wait_tensor_206 = None
        convert_element_type_547 = torch.ops.prims.convert_element_type.default(mul_457, torch.bfloat16);  mul_457 = None
        view_661 = torch.ops.aten.view.default(convert_element_type_547, [-1, 2048]);  convert_element_type_547 = None
        convert_element_type_548 = torch.ops.prims.convert_element_type.default(primals_175, torch.bfloat16)
        all_gather_into_tensor_171 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_548, 128, '0');  convert_element_type_548 = None
        wait_tensor_207 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_171);  all_gather_into_tensor_171 = None
        slice_63 = torch.ops.aten.slice.Tensor(wait_tensor_207, 0, 0, 64);  wait_tensor_207 = None
        permute_154 = torch.ops.aten.permute.default(slice_63, [1, 0]);  slice_63 = None
        mm_83 = torch.ops.aten.mm.default(view_661, permute_154);  permute_154 = None
        convert_element_type_551 = torch.ops.prims.convert_element_type.default(mm_83, torch.float32)
        amax_9 = torch.ops.aten.amax.default(convert_element_type_551, [1], True)
        sub_216 = torch.ops.aten.sub.Tensor(convert_element_type_551, amax_9);  convert_element_type_551 = None
        exp_28 = torch.ops.aten.exp.default(sub_216);  sub_216 = None
        sum_37 = torch.ops.aten.sum.dim_IntList(exp_28, [1], True)
        div_46 = torch.ops.aten.div.Tensor(exp_28, sum_37);  exp_28 = None
        add_622 = torch.ops.aten.add.Tensor(div_46, primals_174);  primals_174 = None
        topk_9 = torch.ops.aten.topk.default(add_622, 6, -1, True, False);  add_622 = None
        getitem_1009 = topk_9[1];  topk_9 = None
        gather_9 = torch.ops.aten.gather.default(div_46, 1, getitem_1009);  div_46 = None
        mul_458 = torch.ops.aten.mul.Tensor(gather_9, 1.0);  gather_9 = None
        view_663 = torch.ops.aten.view.default(getitem_1009, [-1])
        histc_18 = torch.ops.aten.histc.default(view_663, 64, 0, 64)
        add_623 = torch.ops.aten.add.Tensor(primals_176, histc_18)
        sort_9 = torch.ops.aten.sort.stable(view_663, stable = True);  view_663 = None
        getitem_1011 = sort_9[1];  sort_9 = None
        div_47 = torch.ops.aten.div.Tensor_mode(getitem_1011, 6, rounding_mode = 'floor')
        index_18 = torch.ops.aten.index.Tensor(view_661, [div_47])
        all_to_all_single_27 = torch.ops._c10d_functional.all_to_all_single.default(histc_18, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_208 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_27);  all_to_all_single_27 = None
        wait_tensor_209 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_208);  wait_tensor_208 = None
        view_667 = torch.ops.aten.view.default(histc_18, [8, -1]);  histc_18 = None
        sum_38 = torch.ops.aten.sum.dim_IntList(view_667, [1]);  view_667 = None
        device_put_18 = torch.ops.prims.device_put.default(sum_38, device(type='cpu'), True);  sum_38 = None
        view_668 = torch.ops.aten.view.default(wait_tensor_209, [8, -1])
        sum_39 = torch.ops.aten.sum.dim_IntList(view_668, [1])
        device_put_19 = torch.ops.prims.device_put.default(sum_39, device(type='cpu'));  sum_39 = None
        select_144 = torch.ops.aten.select.int(device_put_18, 0, 0)
        _local_scalar_dense_144 = torch.ops.aten._local_scalar_dense.default(select_144);  select_144 = None
        ge_180 = _local_scalar_dense_144 >= 0
        _assert_scalar_144 = torch.ops.aten._assert_scalar.default(ge_180, "Runtime assertion failed for expression u144 >= 0 on node 'ge_144'");  ge_180 = _assert_scalar_144 = None
        select_145 = torch.ops.aten.select.int(device_put_18, 0, 1)
        _local_scalar_dense_145 = torch.ops.aten._local_scalar_dense.default(select_145);  select_145 = None
        ge_181 = _local_scalar_dense_145 >= 0
        _assert_scalar_145 = torch.ops.aten._assert_scalar.default(ge_181, "Runtime assertion failed for expression u145 >= 0 on node 'ge_145'");  ge_181 = _assert_scalar_145 = None
        select_146 = torch.ops.aten.select.int(device_put_18, 0, 2)
        _local_scalar_dense_146 = torch.ops.aten._local_scalar_dense.default(select_146);  select_146 = None
        ge_182 = _local_scalar_dense_146 >= 0
        _assert_scalar_146 = torch.ops.aten._assert_scalar.default(ge_182, "Runtime assertion failed for expression u146 >= 0 on node 'ge_146'");  ge_182 = _assert_scalar_146 = None
        select_147 = torch.ops.aten.select.int(device_put_18, 0, 3)
        _local_scalar_dense_147 = torch.ops.aten._local_scalar_dense.default(select_147);  select_147 = None
        ge_183 = _local_scalar_dense_147 >= 0
        _assert_scalar_147 = torch.ops.aten._assert_scalar.default(ge_183, "Runtime assertion failed for expression u147 >= 0 on node 'ge_147'");  ge_183 = _assert_scalar_147 = None
        select_148 = torch.ops.aten.select.int(device_put_18, 0, 4)
        _local_scalar_dense_148 = torch.ops.aten._local_scalar_dense.default(select_148);  select_148 = None
        ge_184 = _local_scalar_dense_148 >= 0
        _assert_scalar_148 = torch.ops.aten._assert_scalar.default(ge_184, "Runtime assertion failed for expression u148 >= 0 on node 'ge_148'");  ge_184 = _assert_scalar_148 = None
        select_149 = torch.ops.aten.select.int(device_put_18, 0, 5)
        _local_scalar_dense_149 = torch.ops.aten._local_scalar_dense.default(select_149);  select_149 = None
        ge_185 = _local_scalar_dense_149 >= 0
        _assert_scalar_149 = torch.ops.aten._assert_scalar.default(ge_185, "Runtime assertion failed for expression u149 >= 0 on node 'ge_149'");  ge_185 = _assert_scalar_149 = None
        select_150 = torch.ops.aten.select.int(device_put_18, 0, 6)
        _local_scalar_dense_150 = torch.ops.aten._local_scalar_dense.default(select_150);  select_150 = None
        ge_186 = _local_scalar_dense_150 >= 0
        _assert_scalar_150 = torch.ops.aten._assert_scalar.default(ge_186, "Runtime assertion failed for expression u150 >= 0 on node 'ge_150'");  ge_186 = _assert_scalar_150 = None
        select_151 = torch.ops.aten.select.int(device_put_18, 0, 7);  device_put_18 = None
        _local_scalar_dense_151 = torch.ops.aten._local_scalar_dense.default(select_151);  select_151 = None
        ge_187 = _local_scalar_dense_151 >= 0
        _assert_scalar_151 = torch.ops.aten._assert_scalar.default(ge_187, "Runtime assertion failed for expression u151 >= 0 on node 'ge_151'");  ge_187 = _assert_scalar_151 = None
        select_152 = torch.ops.aten.select.int(device_put_19, 0, 0)
        _local_scalar_dense_152 = torch.ops.aten._local_scalar_dense.default(select_152);  select_152 = None
        ge_188 = _local_scalar_dense_152 >= 0
        _assert_scalar_152 = torch.ops.aten._assert_scalar.default(ge_188, "Runtime assertion failed for expression u152 >= 0 on node 'ge_152'");  ge_188 = _assert_scalar_152 = None
        select_153 = torch.ops.aten.select.int(device_put_19, 0, 1)
        _local_scalar_dense_153 = torch.ops.aten._local_scalar_dense.default(select_153);  select_153 = None
        ge_189 = _local_scalar_dense_153 >= 0
        _assert_scalar_153 = torch.ops.aten._assert_scalar.default(ge_189, "Runtime assertion failed for expression u153 >= 0 on node 'ge_153'");  ge_189 = _assert_scalar_153 = None
        select_154 = torch.ops.aten.select.int(device_put_19, 0, 2)
        _local_scalar_dense_154 = torch.ops.aten._local_scalar_dense.default(select_154);  select_154 = None
        ge_190 = _local_scalar_dense_154 >= 0
        _assert_scalar_154 = torch.ops.aten._assert_scalar.default(ge_190, "Runtime assertion failed for expression u154 >= 0 on node 'ge_154'");  ge_190 = _assert_scalar_154 = None
        select_155 = torch.ops.aten.select.int(device_put_19, 0, 3)
        _local_scalar_dense_155 = torch.ops.aten._local_scalar_dense.default(select_155);  select_155 = None
        ge_191 = _local_scalar_dense_155 >= 0
        _assert_scalar_155 = torch.ops.aten._assert_scalar.default(ge_191, "Runtime assertion failed for expression u155 >= 0 on node 'ge_155'");  ge_191 = _assert_scalar_155 = None
        select_156 = torch.ops.aten.select.int(device_put_19, 0, 4)
        _local_scalar_dense_156 = torch.ops.aten._local_scalar_dense.default(select_156);  select_156 = None
        ge_192 = _local_scalar_dense_156 >= 0
        _assert_scalar_156 = torch.ops.aten._assert_scalar.default(ge_192, "Runtime assertion failed for expression u156 >= 0 on node 'ge_156'");  ge_192 = _assert_scalar_156 = None
        select_157 = torch.ops.aten.select.int(device_put_19, 0, 5)
        _local_scalar_dense_157 = torch.ops.aten._local_scalar_dense.default(select_157);  select_157 = None
        ge_193 = _local_scalar_dense_157 >= 0
        _assert_scalar_157 = torch.ops.aten._assert_scalar.default(ge_193, "Runtime assertion failed for expression u157 >= 0 on node 'ge_157'");  ge_193 = _assert_scalar_157 = None
        select_158 = torch.ops.aten.select.int(device_put_19, 0, 6)
        _local_scalar_dense_158 = torch.ops.aten._local_scalar_dense.default(select_158);  select_158 = None
        ge_194 = _local_scalar_dense_158 >= 0
        _assert_scalar_158 = torch.ops.aten._assert_scalar.default(ge_194, "Runtime assertion failed for expression u158 >= 0 on node 'ge_158'");  ge_194 = _assert_scalar_158 = None
        select_159 = torch.ops.aten.select.int(device_put_19, 0, 7);  device_put_19 = None
        _local_scalar_dense_159 = torch.ops.aten._local_scalar_dense.default(select_159);  select_159 = None
        ge_195 = _local_scalar_dense_159 >= 0
        _assert_scalar_159 = torch.ops.aten._assert_scalar.default(ge_195, "Runtime assertion failed for expression u159 >= 0 on node 'ge_159'");  ge_195 = _assert_scalar_159 = None
        all_to_all_single_28 = torch.ops._c10d_functional.all_to_all_single.default(index_18, [_local_scalar_dense_152, _local_scalar_dense_153, _local_scalar_dense_154, _local_scalar_dense_155, _local_scalar_dense_156, _local_scalar_dense_157, _local_scalar_dense_158, _local_scalar_dense_159], [_local_scalar_dense_144, _local_scalar_dense_145, _local_scalar_dense_146, _local_scalar_dense_147, _local_scalar_dense_148, _local_scalar_dense_149, _local_scalar_dense_150, _local_scalar_dense_151], '1033');  index_18 = None
        sym_size_int_36 = torch.ops.aten.sym_size.int(all_to_all_single_28, 0)
        wait_tensor_210 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_28);  all_to_all_single_28 = None
        sym_sum_18 = torch.sym_sum((_local_scalar_dense_152, _local_scalar_dense_153, _local_scalar_dense_154, _local_scalar_dense_155, _local_scalar_dense_156, _local_scalar_dense_157, _local_scalar_dense_158, _local_scalar_dense_159))
        add_630 = sym_sum_18 + 64;  sym_sum_18 = None
        add_631 = add_630 + 8;  add_630 = None
        sub_219 = add_631 - 1;  add_631 = None
        floordiv_9 = sub_219 // 8;  sub_219 = None
        mul_463 = floordiv_9 * 8;  floordiv_9 = None
        cumsum_27 = torch.ops.aten.cumsum.default(wait_tensor_209, 0)
        sub_220 = torch.ops.aten.sub.Tensor(cumsum_27, wait_tensor_209);  cumsum_27 = None
        sum_40 = torch.ops.aten.sum.dim_IntList(view_668, [0]);  view_668 = None
        clamp_min_9 = torch.ops.aten.clamp_min.default(sum_40, 8);  sum_40 = None
        add_632 = torch.ops.aten.add.Tensor(clamp_min_9, 8);  clamp_min_9 = None
        sub_221 = torch.ops.aten.sub.Tensor(add_632, 1);  add_632 = None
        div_48 = torch.ops.aten.div.Tensor_mode(sub_221, 8, rounding_mode = 'floor');  sub_221 = None
        mul_464 = torch.ops.aten.mul.Tensor(div_48, 8);  div_48 = None
        convert_element_type_554 = torch.ops.prims.convert_element_type.default(mul_464, torch.int32);  mul_464 = None
        cumsum_28 = torch.ops.aten.cumsum.default(convert_element_type_554, 0)
        sub_222 = torch.ops.aten.sub.Tensor(cumsum_28, convert_element_type_554);  cumsum_28 = None
        full_137 = torch.ops.aten.full.default([mul_463], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_463 = None
        triton_kernel_wrapper_functional_proxy_9 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 9, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_209, 'start_index_values_ptr': sub_220, 'write_offsets_ptr': sub_222, 'output_ptr': full_137}, tensors_to_clone = ['output_ptr']);  wait_tensor_209 = sub_220 = sub_222 = full_137 = None
        getitem_1012 = triton_kernel_wrapper_functional_proxy_9['output_ptr'];  triton_kernel_wrapper_functional_proxy_9 = None
        cat_85 = torch.ops.aten.cat.default([wait_tensor_210, full_default]);  wait_tensor_210 = None
        sym_size_int_37 = torch.ops.aten.sym_size.int(cat_85, 0)
        sym_sum_19 = torch.sym_sum((1, _local_scalar_dense_152, _local_scalar_dense_153, _local_scalar_dense_154, _local_scalar_dense_155, _local_scalar_dense_156, _local_scalar_dense_157, _local_scalar_dense_158, _local_scalar_dense_159))
        index_19 = torch.ops.aten.index.Tensor(cat_85, [getitem_1012]);  cat_85 = None
        convert_element_type_556 = torch.ops.prims.convert_element_type.default(primals_177, torch.bfloat16)
        all_gather_into_tensor_172 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_556, 16, '1025');  convert_element_type_556 = None
        wait_tensor_211 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_172);  all_gather_into_tensor_172 = None
        split_55 = torch.ops.aten.split.Tensor(wait_tensor_211, 8);  wait_tensor_211 = None
        getitem_1029 = split_55[0]
        getitem_1030 = split_55[1]
        getitem_1031 = split_55[2]
        getitem_1032 = split_55[3]
        getitem_1033 = split_55[4]
        getitem_1034 = split_55[5]
        getitem_1035 = split_55[6]
        getitem_1036 = split_55[7]
        getitem_1037 = split_55[8]
        getitem_1038 = split_55[9]
        getitem_1039 = split_55[10]
        getitem_1040 = split_55[11]
        getitem_1041 = split_55[12]
        getitem_1042 = split_55[13]
        getitem_1043 = split_55[14]
        getitem_1044 = split_55[15];  split_55 = None
        cat_87 = torch.ops.aten.cat.default([getitem_1029, getitem_1030, getitem_1031, getitem_1032, getitem_1033, getitem_1034, getitem_1035, getitem_1036, getitem_1037, getitem_1038, getitem_1039, getitem_1040, getitem_1041, getitem_1042, getitem_1043, getitem_1044], 1);  getitem_1029 = getitem_1030 = getitem_1031 = getitem_1032 = getitem_1033 = getitem_1034 = getitem_1035 = getitem_1036 = getitem_1037 = getitem_1038 = getitem_1039 = getitem_1040 = getitem_1041 = getitem_1042 = getitem_1043 = getitem_1044 = None
        convert_element_type_558 = torch.ops.prims.convert_element_type.default(primals_178, torch.bfloat16)
        all_gather_into_tensor_174 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_558, 16, '1025');  convert_element_type_558 = None
        wait_tensor_213 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_174);  all_gather_into_tensor_174 = None
        split_56 = torch.ops.aten.split.Tensor(wait_tensor_213, 8);  wait_tensor_213 = None
        getitem_1045 = split_56[0]
        getitem_1046 = split_56[1]
        getitem_1047 = split_56[2]
        getitem_1048 = split_56[3]
        getitem_1049 = split_56[4]
        getitem_1050 = split_56[5]
        getitem_1051 = split_56[6]
        getitem_1052 = split_56[7]
        getitem_1053 = split_56[8]
        getitem_1054 = split_56[9]
        getitem_1055 = split_56[10]
        getitem_1056 = split_56[11]
        getitem_1057 = split_56[12]
        getitem_1058 = split_56[13]
        getitem_1059 = split_56[14]
        getitem_1060 = split_56[15];  split_56 = None
        cat_88 = torch.ops.aten.cat.default([getitem_1045, getitem_1046, getitem_1047, getitem_1048, getitem_1049, getitem_1050, getitem_1051, getitem_1052, getitem_1053, getitem_1054, getitem_1055, getitem_1056, getitem_1057, getitem_1058, getitem_1059, getitem_1060], 1);  getitem_1045 = getitem_1046 = getitem_1047 = getitem_1048 = getitem_1049 = getitem_1050 = getitem_1051 = getitem_1052 = getitem_1053 = getitem_1054 = getitem_1055 = getitem_1056 = getitem_1057 = getitem_1058 = getitem_1059 = getitem_1060 = None
        convert_element_type_559 = torch.ops.prims.convert_element_type.default(primals_179, torch.bfloat16)
        all_gather_into_tensor_175 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_559, 16, '1025');  convert_element_type_559 = None
        wait_tensor_214 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_175);  all_gather_into_tensor_175 = None
        split_57 = torch.ops.aten.split.Tensor(wait_tensor_214, 8);  wait_tensor_214 = None
        getitem_1061 = split_57[0]
        getitem_1062 = split_57[1]
        getitem_1063 = split_57[2]
        getitem_1064 = split_57[3]
        getitem_1065 = split_57[4]
        getitem_1066 = split_57[5]
        getitem_1067 = split_57[6]
        getitem_1068 = split_57[7]
        getitem_1069 = split_57[8]
        getitem_1070 = split_57[9]
        getitem_1071 = split_57[10]
        getitem_1072 = split_57[11]
        getitem_1073 = split_57[12]
        getitem_1074 = split_57[13]
        getitem_1075 = split_57[14]
        getitem_1076 = split_57[15];  split_57 = None
        cat_89 = torch.ops.aten.cat.default([getitem_1061, getitem_1062, getitem_1063, getitem_1064, getitem_1065, getitem_1066, getitem_1067, getitem_1068, getitem_1069, getitem_1070, getitem_1071, getitem_1072, getitem_1073, getitem_1074, getitem_1075, getitem_1076], 1);  getitem_1061 = getitem_1062 = getitem_1063 = getitem_1064 = getitem_1065 = getitem_1066 = getitem_1067 = getitem_1068 = getitem_1069 = getitem_1070 = getitem_1071 = getitem_1072 = getitem_1073 = getitem_1074 = getitem_1075 = getitem_1076 = None
        cumsum_29 = torch.ops.aten.cumsum.default(convert_element_type_554, 0, dtype = torch.int32);  convert_element_type_554 = None
        permute_155 = torch.ops.aten.permute.default(cat_87, [0, 2, 1]);  cat_87 = None
        _grouped_mm_27 = torch.ops.aten._grouped_mm.default(index_19, permute_155, cumsum_29)
        convert_element_type_562 = torch.ops.prims.convert_element_type.default(_grouped_mm_27, torch.float32)
        neg_19 = torch.ops.aten.neg.default(convert_element_type_562)
        exp_29 = torch.ops.aten.exp.default(neg_19);  neg_19 = None
        add_644 = torch.ops.aten.add.Tensor(exp_29, 1);  exp_29 = None
        div_49 = torch.ops.aten.div.Tensor(convert_element_type_562, add_644);  convert_element_type_562 = add_644 = None
        convert_element_type_563 = torch.ops.prims.convert_element_type.default(div_49, torch.bfloat16);  div_49 = None
        permute_156 = torch.ops.aten.permute.default(cat_89, [0, 2, 1]);  cat_89 = None
        _grouped_mm_28 = torch.ops.aten._grouped_mm.default(index_19, permute_156, cumsum_29)
        mul_476 = torch.ops.aten.mul.Tensor(convert_element_type_563, _grouped_mm_28);  convert_element_type_563 = None
        permute_157 = torch.ops.aten.permute.default(cat_88, [0, 2, 1]);  cat_88 = None
        _grouped_mm_29 = torch.ops.aten._grouped_mm.default(mul_476, permute_157, cumsum_29)
        empty_9 = torch.ops.aten.empty.memory_format([sym_size_int_37, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_18 = torch.ops.aten.index_put.default(empty_9, [getitem_1012], _grouped_mm_29);  empty_9 = _grouped_mm_29 = None
        slice_65 = torch.ops.aten.slice.Tensor(index_put_18, 0, 0, -1);  index_put_18 = None
        all_to_all_single_29 = torch.ops._c10d_functional.all_to_all_single.default(slice_65, [_local_scalar_dense_144, _local_scalar_dense_145, _local_scalar_dense_146, _local_scalar_dense_147, _local_scalar_dense_148, _local_scalar_dense_149, _local_scalar_dense_150, _local_scalar_dense_151], [_local_scalar_dense_152, _local_scalar_dense_153, _local_scalar_dense_154, _local_scalar_dense_155, _local_scalar_dense_156, _local_scalar_dense_157, _local_scalar_dense_158, _local_scalar_dense_159], '1033');  slice_65 = None
        wait_tensor_217 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_29);  all_to_all_single_29 = None
        convert_element_type_564 = torch.ops.prims.convert_element_type.default(primals_180, torch.bfloat16)
        all_gather_into_tensor_178 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_564, 128, '0');  convert_element_type_564 = None
        wait_tensor_218 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_178);  all_gather_into_tensor_178 = None
        permute_158 = torch.ops.aten.permute.default(wait_tensor_218, [1, 0]);  wait_tensor_218 = None
        mm_84 = torch.ops.aten.mm.default(view_661, permute_158);  permute_158 = None
        convert_element_type_567 = torch.ops.prims.convert_element_type.default(mm_84, torch.float32)
        neg_20 = torch.ops.aten.neg.default(convert_element_type_567)
        exp_30 = torch.ops.aten.exp.default(neg_20);  neg_20 = None
        add_680 = torch.ops.aten.add.Tensor(exp_30, 1);  exp_30 = None
        div_50 = torch.ops.aten.div.Tensor(convert_element_type_567, add_680);  convert_element_type_567 = add_680 = None
        convert_element_type_568 = torch.ops.prims.convert_element_type.default(div_50, torch.bfloat16);  div_50 = None
        convert_element_type_569 = torch.ops.prims.convert_element_type.default(primals_181, torch.bfloat16)
        all_gather_into_tensor_179 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_569, 128, '0');  convert_element_type_569 = None
        wait_tensor_219 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_179);  all_gather_into_tensor_179 = None
        permute_159 = torch.ops.aten.permute.default(wait_tensor_219, [1, 0]);  wait_tensor_219 = None
        mm_85 = torch.ops.aten.mm.default(view_661, permute_159);  permute_159 = None
        mul_496 = torch.ops.aten.mul.Tensor(convert_element_type_568, mm_85);  convert_element_type_568 = None
        convert_element_type_572 = torch.ops.prims.convert_element_type.default(primals_182, torch.bfloat16)
        all_gather_into_tensor_180 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_572, 128, '0');  convert_element_type_572 = None
        wait_tensor_220 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_180);  all_gather_into_tensor_180 = None
        permute_160 = torch.ops.aten.permute.default(wait_tensor_220, [1, 0]);  wait_tensor_220 = None
        mm_86 = torch.ops.aten.mm.default(mul_496, permute_160);  permute_160 = None
        index_put_19 = torch.ops.aten.index_put.default(full_default_1, [getitem_1011], wait_tensor_217);  wait_tensor_217 = None
        view_701 = torch.ops.aten.view.default(mul_458, [-1, 1, 6]);  mul_458 = None
        view_702 = torch.ops.aten.view.default(index_put_19, [-1, 6, 2048]);  index_put_19 = None
        convert_element_type_575 = torch.ops.prims.convert_element_type.default(view_702, torch.float32);  view_702 = None
        bmm_9 = torch.ops.aten.bmm.default(view_701, convert_element_type_575)
        convert_element_type_576 = torch.ops.prims.convert_element_type.default(bmm_9, torch.bfloat16);  bmm_9 = None
        squeeze_9 = torch.ops.aten.squeeze.dim(convert_element_type_576, 1);  convert_element_type_576 = None
        add_684 = torch.ops.aten.add.Tensor(mm_86, squeeze_9);  mm_86 = squeeze_9 = None
        view_703 = torch.ops.aten.view.default(add_684, [2, 4096, 2048]);  add_684 = None
        add_685 = torch.ops.aten.add.Tensor(add_620, view_703);  view_703 = None
        convert_element_type_577 = torch.ops.prims.convert_element_type.default(primals_183, torch.bfloat16)
        all_gather_into_tensor_181 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_577, 128, '0');  convert_element_type_577 = None
        wait_tensor_221 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_181);  all_gather_into_tensor_181 = None
        convert_element_type_578 = torch.ops.prims.convert_element_type.default(add_685, torch.float32)
        pow_34 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_578, 2)
        mean_33 = torch.ops.aten.mean.dim(pow_34, [2], True);  pow_34 = None
        add_686 = torch.ops.aten.add.Scalar(mean_33, 1e-05);  mean_33 = None
        rsqrt_33 = torch.ops.aten.rsqrt.default(add_686);  add_686 = None
        mul_499 = torch.ops.aten.mul.Tensor(convert_element_type_578, rsqrt_33);  convert_element_type_578 = None
        mul_500 = torch.ops.aten.mul.Tensor(mul_499, wait_tensor_221);  mul_499 = wait_tensor_221 = None
        convert_element_type_579 = torch.ops.prims.convert_element_type.default(mul_500, torch.bfloat16);  mul_500 = None
        convert_element_type_580 = torch.ops.prims.convert_element_type.default(primals_184, torch.bfloat16)
        all_gather_into_tensor_182 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_580, 128, '0');  convert_element_type_580 = None
        wait_tensor_222 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_182);  all_gather_into_tensor_182 = None
        permute_161 = torch.ops.aten.permute.default(wait_tensor_222, [1, 0]);  wait_tensor_222 = None
        view_706 = torch.ops.aten.view.default(convert_element_type_579, [8192, 2048]);  convert_element_type_579 = None
        mm_87 = torch.ops.aten.mm.default(view_706, permute_161);  permute_161 = None
        view_707 = torch.ops.aten.view.default(mm_87, [2, 4096, 3072]);  mm_87 = None
        view_708 = torch.ops.aten.view.default(view_707, [2, 4096, -1, 192]);  view_707 = None
        split_with_sizes_33 = torch.ops.aten.split_with_sizes.default(view_708, [128, 64], -1);  view_708 = None
        getitem_1109 = split_with_sizes_33[0]
        getitem_1110 = split_with_sizes_33[1];  split_with_sizes_33 = None
        convert_element_type_583 = torch.ops.prims.convert_element_type.default(getitem_1110, torch.float32);  getitem_1110 = None
        view_709 = torch.ops.aten.view.default(convert_element_type_583, [2, 4096, 16, -1, 2]);  convert_element_type_583 = None
        view_as_complex_22 = torch.ops.aten.view_as_complex.default(view_709);  view_709 = None
        mul_501 = torch.ops.aten.mul.Tensor(view_as_complex_22, view_7);  view_as_complex_22 = None
        view_as_real_22 = torch.ops.aten.view_as_real.default(mul_501);  mul_501 = None
        view_711 = torch.ops.aten.view.default(view_as_real_22, [2, 4096, 16, 64]);  view_as_real_22 = None
        convert_element_type_584 = torch.ops.prims.convert_element_type.default(view_711, torch.bfloat16);  view_711 = None
        cat_92 = torch.ops.aten.cat.default([getitem_1109, convert_element_type_584], -1);  getitem_1109 = convert_element_type_584 = None
        convert_element_type_585 = torch.ops.prims.convert_element_type.default(primals_185, torch.bfloat16)
        all_gather_into_tensor_183 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_585, 128, '0');  convert_element_type_585 = None
        wait_tensor_223 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_183);  all_gather_into_tensor_183 = None
        slice_67 = torch.ops.aten.slice.Tensor(wait_tensor_223, 0, 0, 576);  wait_tensor_223 = None
        permute_162 = torch.ops.aten.permute.default(slice_67, [1, 0]);  slice_67 = None
        mm_88 = torch.ops.aten.mm.default(view_706, permute_162);  permute_162 = None
        view_714 = torch.ops.aten.view.default(mm_88, [2, 4096, 576]);  mm_88 = None
        split_with_sizes_34 = torch.ops.aten.split_with_sizes.default(view_714, [512, 64], -1);  view_714 = None
        getitem_1111 = split_with_sizes_34[0]
        getitem_1112 = split_with_sizes_34[1];  split_with_sizes_34 = None
        unsqueeze_21 = torch.ops.aten.unsqueeze.default(getitem_1112, 2);  getitem_1112 = None
        convert_element_type_588 = torch.ops.prims.convert_element_type.default(unsqueeze_21, torch.float32);  unsqueeze_21 = None
        view_715 = torch.ops.aten.view.default(convert_element_type_588, [2, 4096, 1, -1, 2]);  convert_element_type_588 = None
        view_as_complex_23 = torch.ops.aten.view_as_complex.default(view_715);  view_715 = None
        mul_502 = torch.ops.aten.mul.Tensor(view_as_complex_23, view_7);  view_as_complex_23 = None
        view_as_real_23 = torch.ops.aten.view_as_real.default(mul_502);  mul_502 = None
        view_717 = torch.ops.aten.view.default(view_as_real_23, [2, 4096, 1, 64]);  view_as_real_23 = None
        convert_element_type_589 = torch.ops.prims.convert_element_type.default(view_717, torch.bfloat16);  view_717 = None
        convert_element_type_590 = torch.ops.prims.convert_element_type.default(primals_186, torch.bfloat16)
        all_gather_into_tensor_184 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_590, 128, '0');  convert_element_type_590 = None
        wait_tensor_224 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_184);  all_gather_into_tensor_184 = None
        convert_element_type_591 = torch.ops.prims.convert_element_type.default(getitem_1111, torch.float32)
        pow_35 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_591, 2)
        mean_34 = torch.ops.aten.mean.dim(pow_35, [2], True);  pow_35 = None
        add_687 = torch.ops.aten.add.Scalar(mean_34, 1e-05);  mean_34 = None
        rsqrt_34 = torch.ops.aten.rsqrt.default(add_687);  add_687 = None
        mul_503 = torch.ops.aten.mul.Tensor(convert_element_type_591, rsqrt_34);  convert_element_type_591 = None
        mul_504 = torch.ops.aten.mul.Tensor(mul_503, wait_tensor_224);  mul_503 = wait_tensor_224 = None
        convert_element_type_592 = torch.ops.prims.convert_element_type.default(mul_504, torch.bfloat16);  mul_504 = None
        convert_element_type_593 = torch.ops.prims.convert_element_type.default(primals_187, torch.bfloat16)
        all_gather_into_tensor_185 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_593, 128, '0');  convert_element_type_593 = None
        wait_tensor_225 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_185);  all_gather_into_tensor_185 = None
        permute_163 = torch.ops.aten.permute.default(wait_tensor_225, [1, 0]);  wait_tensor_225 = None
        view_720 = torch.ops.aten.view.default(convert_element_type_592, [8192, 512]);  convert_element_type_592 = None
        mm_89 = torch.ops.aten.mm.default(view_720, permute_163);  permute_163 = None
        view_721 = torch.ops.aten.view.default(mm_89, [2, 4096, 4096]);  mm_89 = None
        view_722 = torch.ops.aten.view.default(view_721, [2, 4096, -1, 256]);  view_721 = None
        split_with_sizes_35 = torch.ops.aten.split_with_sizes.default(view_722, [128, 128], -1);  view_722 = None
        getitem_1113 = split_with_sizes_35[0]
        getitem_1114 = split_with_sizes_35[1];  split_with_sizes_35 = None
        expand_11 = torch.ops.aten.expand.default(convert_element_type_589, [-1, -1, 16, -1]);  convert_element_type_589 = None
        cat_93 = torch.ops.aten.cat.default([getitem_1113, expand_11], -1);  getitem_1113 = expand_11 = None
        permute_164 = torch.ops.aten.permute.default(cat_92, [0, 2, 1, 3]);  cat_92 = None
        permute_165 = torch.ops.aten.permute.default(cat_93, [0, 2, 1, 3]);  cat_93 = None
        permute_166 = torch.ops.aten.permute.default(getitem_1114, [0, 2, 1, 3]);  getitem_1114 = None
        sdpa_score11 = self.sdpa_score11
        sdpa_mask11 = self.sdpa_mask11
        flex_attention_11 = torch.ops.higher_order.flex_attention(permute_164, permute_165, permute_166, sdpa_score11, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask11), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score11 = sdpa_mask11 = None
        getitem_1115 = flex_attention_11[0]
        getitem_1116 = flex_attention_11[1];  flex_attention_11 = None
        permute_167 = torch.ops.aten.permute.default(getitem_1115, [0, 2, 1, 3])
        view_723 = torch.ops.aten.view.default(permute_167, [2, 4096, -1]);  permute_167 = None
        convert_element_type_596 = torch.ops.prims.convert_element_type.default(primals_188, torch.bfloat16)
        all_gather_into_tensor_186 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_596, 128, '0');  convert_element_type_596 = None
        wait_tensor_226 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_186);  all_gather_into_tensor_186 = None
        permute_168 = torch.ops.aten.permute.default(wait_tensor_226, [1, 0]);  wait_tensor_226 = None
        view_725 = torch.ops.aten.view.default(view_723, [8192, 2048]);  view_723 = None
        mm_90 = torch.ops.aten.mm.default(view_725, permute_168);  view_725 = permute_168 = None
        view_726 = torch.ops.aten.view.default(mm_90, [2, 4096, 2048]);  mm_90 = None
        add_688 = torch.ops.aten.add.Tensor(add_685, view_726);  view_726 = None
        convert_element_type_599 = torch.ops.prims.convert_element_type.default(primals_189, torch.bfloat16)
        all_gather_into_tensor_187 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_599, 128, '0');  convert_element_type_599 = None
        wait_tensor_227 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_187);  all_gather_into_tensor_187 = None
        convert_element_type_600 = torch.ops.prims.convert_element_type.default(add_688, torch.float32)
        pow_36 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_600, 2)
        mean_35 = torch.ops.aten.mean.dim(pow_36, [2], True);  pow_36 = None
        add_689 = torch.ops.aten.add.Scalar(mean_35, 1e-05);  mean_35 = None
        rsqrt_35 = torch.ops.aten.rsqrt.default(add_689);  add_689 = None
        mul_505 = torch.ops.aten.mul.Tensor(convert_element_type_600, rsqrt_35);  convert_element_type_600 = None
        mul_506 = torch.ops.aten.mul.Tensor(mul_505, wait_tensor_227);  mul_505 = wait_tensor_227 = None
        convert_element_type_601 = torch.ops.prims.convert_element_type.default(mul_506, torch.bfloat16);  mul_506 = None
        view_728 = torch.ops.aten.view.default(convert_element_type_601, [-1, 2048]);  convert_element_type_601 = None
        convert_element_type_602 = torch.ops.prims.convert_element_type.default(primals_191, torch.bfloat16)
        all_gather_into_tensor_188 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_602, 128, '0');  convert_element_type_602 = None
        wait_tensor_228 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_188);  all_gather_into_tensor_188 = None
        slice_69 = torch.ops.aten.slice.Tensor(wait_tensor_228, 0, 0, 64);  wait_tensor_228 = None
        permute_169 = torch.ops.aten.permute.default(slice_69, [1, 0]);  slice_69 = None
        mm_91 = torch.ops.aten.mm.default(view_728, permute_169);  permute_169 = None
        convert_element_type_605 = torch.ops.prims.convert_element_type.default(mm_91, torch.float32)
        amax_10 = torch.ops.aten.amax.default(convert_element_type_605, [1], True)
        sub_240 = torch.ops.aten.sub.Tensor(convert_element_type_605, amax_10);  convert_element_type_605 = None
        exp_31 = torch.ops.aten.exp.default(sub_240);  sub_240 = None
        sum_41 = torch.ops.aten.sum.dim_IntList(exp_31, [1], True)
        div_51 = torch.ops.aten.div.Tensor(exp_31, sum_41);  exp_31 = None
        add_690 = torch.ops.aten.add.Tensor(div_51, primals_190);  primals_190 = None
        topk_10 = torch.ops.aten.topk.default(add_690, 6, -1, True, False);  add_690 = None
        getitem_1119 = topk_10[1];  topk_10 = None
        gather_10 = torch.ops.aten.gather.default(div_51, 1, getitem_1119);  div_51 = None
        mul_507 = torch.ops.aten.mul.Tensor(gather_10, 1.0);  gather_10 = None
        view_730 = torch.ops.aten.view.default(getitem_1119, [-1])
        histc_20 = torch.ops.aten.histc.default(view_730, 64, 0, 64)
        add_691 = torch.ops.aten.add.Tensor(primals_192, histc_20)
        sort_10 = torch.ops.aten.sort.stable(view_730, stable = True);  view_730 = None
        getitem_1121 = sort_10[1];  sort_10 = None
        div_52 = torch.ops.aten.div.Tensor_mode(getitem_1121, 6, rounding_mode = 'floor')
        index_20 = torch.ops.aten.index.Tensor(view_728, [div_52])
        all_to_all_single_30 = torch.ops._c10d_functional.all_to_all_single.default(histc_20, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_229 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_30);  all_to_all_single_30 = None
        wait_tensor_230 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_229);  wait_tensor_229 = None
        view_734 = torch.ops.aten.view.default(histc_20, [8, -1]);  histc_20 = None
        sum_42 = torch.ops.aten.sum.dim_IntList(view_734, [1]);  view_734 = None
        device_put_20 = torch.ops.prims.device_put.default(sum_42, device(type='cpu'), True);  sum_42 = None
        view_735 = torch.ops.aten.view.default(wait_tensor_230, [8, -1])
        sum_43 = torch.ops.aten.sum.dim_IntList(view_735, [1])
        device_put_21 = torch.ops.prims.device_put.default(sum_43, device(type='cpu'));  sum_43 = None
        select_160 = torch.ops.aten.select.int(device_put_20, 0, 0)
        _local_scalar_dense_160 = torch.ops.aten._local_scalar_dense.default(select_160);  select_160 = None
        ge_200 = _local_scalar_dense_160 >= 0
        _assert_scalar_160 = torch.ops.aten._assert_scalar.default(ge_200, "Runtime assertion failed for expression u160 >= 0 on node 'ge_160'");  ge_200 = _assert_scalar_160 = None
        select_161 = torch.ops.aten.select.int(device_put_20, 0, 1)
        _local_scalar_dense_161 = torch.ops.aten._local_scalar_dense.default(select_161);  select_161 = None
        ge_201 = _local_scalar_dense_161 >= 0
        _assert_scalar_161 = torch.ops.aten._assert_scalar.default(ge_201, "Runtime assertion failed for expression u161 >= 0 on node 'ge_161'");  ge_201 = _assert_scalar_161 = None
        select_162 = torch.ops.aten.select.int(device_put_20, 0, 2)
        _local_scalar_dense_162 = torch.ops.aten._local_scalar_dense.default(select_162);  select_162 = None
        ge_202 = _local_scalar_dense_162 >= 0
        _assert_scalar_162 = torch.ops.aten._assert_scalar.default(ge_202, "Runtime assertion failed for expression u162 >= 0 on node 'ge_162'");  ge_202 = _assert_scalar_162 = None
        select_163 = torch.ops.aten.select.int(device_put_20, 0, 3)
        _local_scalar_dense_163 = torch.ops.aten._local_scalar_dense.default(select_163);  select_163 = None
        ge_203 = _local_scalar_dense_163 >= 0
        _assert_scalar_163 = torch.ops.aten._assert_scalar.default(ge_203, "Runtime assertion failed for expression u163 >= 0 on node 'ge_163'");  ge_203 = _assert_scalar_163 = None
        select_164 = torch.ops.aten.select.int(device_put_20, 0, 4)
        _local_scalar_dense_164 = torch.ops.aten._local_scalar_dense.default(select_164);  select_164 = None
        ge_204 = _local_scalar_dense_164 >= 0
        _assert_scalar_164 = torch.ops.aten._assert_scalar.default(ge_204, "Runtime assertion failed for expression u164 >= 0 on node 'ge_164'");  ge_204 = _assert_scalar_164 = None
        select_165 = torch.ops.aten.select.int(device_put_20, 0, 5)
        _local_scalar_dense_165 = torch.ops.aten._local_scalar_dense.default(select_165);  select_165 = None
        ge_205 = _local_scalar_dense_165 >= 0
        _assert_scalar_165 = torch.ops.aten._assert_scalar.default(ge_205, "Runtime assertion failed for expression u165 >= 0 on node 'ge_165'");  ge_205 = _assert_scalar_165 = None
        select_166 = torch.ops.aten.select.int(device_put_20, 0, 6)
        _local_scalar_dense_166 = torch.ops.aten._local_scalar_dense.default(select_166);  select_166 = None
        ge_206 = _local_scalar_dense_166 >= 0
        _assert_scalar_166 = torch.ops.aten._assert_scalar.default(ge_206, "Runtime assertion failed for expression u166 >= 0 on node 'ge_166'");  ge_206 = _assert_scalar_166 = None
        select_167 = torch.ops.aten.select.int(device_put_20, 0, 7);  device_put_20 = None
        _local_scalar_dense_167 = torch.ops.aten._local_scalar_dense.default(select_167);  select_167 = None
        ge_207 = _local_scalar_dense_167 >= 0
        _assert_scalar_167 = torch.ops.aten._assert_scalar.default(ge_207, "Runtime assertion failed for expression u167 >= 0 on node 'ge_167'");  ge_207 = _assert_scalar_167 = None
        select_168 = torch.ops.aten.select.int(device_put_21, 0, 0)
        _local_scalar_dense_168 = torch.ops.aten._local_scalar_dense.default(select_168);  select_168 = None
        ge_208 = _local_scalar_dense_168 >= 0
        _assert_scalar_168 = torch.ops.aten._assert_scalar.default(ge_208, "Runtime assertion failed for expression u168 >= 0 on node 'ge_168'");  ge_208 = _assert_scalar_168 = None
        select_169 = torch.ops.aten.select.int(device_put_21, 0, 1)
        _local_scalar_dense_169 = torch.ops.aten._local_scalar_dense.default(select_169);  select_169 = None
        ge_209 = _local_scalar_dense_169 >= 0
        _assert_scalar_169 = torch.ops.aten._assert_scalar.default(ge_209, "Runtime assertion failed for expression u169 >= 0 on node 'ge_169'");  ge_209 = _assert_scalar_169 = None
        select_170 = torch.ops.aten.select.int(device_put_21, 0, 2)
        _local_scalar_dense_170 = torch.ops.aten._local_scalar_dense.default(select_170);  select_170 = None
        ge_210 = _local_scalar_dense_170 >= 0
        _assert_scalar_170 = torch.ops.aten._assert_scalar.default(ge_210, "Runtime assertion failed for expression u170 >= 0 on node 'ge_170'");  ge_210 = _assert_scalar_170 = None
        select_171 = torch.ops.aten.select.int(device_put_21, 0, 3)
        _local_scalar_dense_171 = torch.ops.aten._local_scalar_dense.default(select_171);  select_171 = None
        ge_211 = _local_scalar_dense_171 >= 0
        _assert_scalar_171 = torch.ops.aten._assert_scalar.default(ge_211, "Runtime assertion failed for expression u171 >= 0 on node 'ge_171'");  ge_211 = _assert_scalar_171 = None
        select_172 = torch.ops.aten.select.int(device_put_21, 0, 4)
        _local_scalar_dense_172 = torch.ops.aten._local_scalar_dense.default(select_172);  select_172 = None
        ge_212 = _local_scalar_dense_172 >= 0
        _assert_scalar_172 = torch.ops.aten._assert_scalar.default(ge_212, "Runtime assertion failed for expression u172 >= 0 on node 'ge_172'");  ge_212 = _assert_scalar_172 = None
        select_173 = torch.ops.aten.select.int(device_put_21, 0, 5)
        _local_scalar_dense_173 = torch.ops.aten._local_scalar_dense.default(select_173);  select_173 = None
        ge_213 = _local_scalar_dense_173 >= 0
        _assert_scalar_173 = torch.ops.aten._assert_scalar.default(ge_213, "Runtime assertion failed for expression u173 >= 0 on node 'ge_173'");  ge_213 = _assert_scalar_173 = None
        select_174 = torch.ops.aten.select.int(device_put_21, 0, 6)
        _local_scalar_dense_174 = torch.ops.aten._local_scalar_dense.default(select_174);  select_174 = None
        ge_214 = _local_scalar_dense_174 >= 0
        _assert_scalar_174 = torch.ops.aten._assert_scalar.default(ge_214, "Runtime assertion failed for expression u174 >= 0 on node 'ge_174'");  ge_214 = _assert_scalar_174 = None
        select_175 = torch.ops.aten.select.int(device_put_21, 0, 7);  device_put_21 = None
        _local_scalar_dense_175 = torch.ops.aten._local_scalar_dense.default(select_175);  select_175 = None
        ge_215 = _local_scalar_dense_175 >= 0
        _assert_scalar_175 = torch.ops.aten._assert_scalar.default(ge_215, "Runtime assertion failed for expression u175 >= 0 on node 'ge_175'");  ge_215 = _assert_scalar_175 = None
        all_to_all_single_31 = torch.ops._c10d_functional.all_to_all_single.default(index_20, [_local_scalar_dense_168, _local_scalar_dense_169, _local_scalar_dense_170, _local_scalar_dense_171, _local_scalar_dense_172, _local_scalar_dense_173, _local_scalar_dense_174, _local_scalar_dense_175], [_local_scalar_dense_160, _local_scalar_dense_161, _local_scalar_dense_162, _local_scalar_dense_163, _local_scalar_dense_164, _local_scalar_dense_165, _local_scalar_dense_166, _local_scalar_dense_167], '1033');  index_20 = None
        sym_size_int_40 = torch.ops.aten.sym_size.int(all_to_all_single_31, 0)
        wait_tensor_231 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_31);  all_to_all_single_31 = None
        sym_sum_20 = torch.sym_sum((_local_scalar_dense_168, _local_scalar_dense_169, _local_scalar_dense_170, _local_scalar_dense_171, _local_scalar_dense_172, _local_scalar_dense_173, _local_scalar_dense_174, _local_scalar_dense_175))
        add_698 = sym_sum_20 + 64;  sym_sum_20 = None
        add_699 = add_698 + 8;  add_698 = None
        sub_243 = add_699 - 1;  add_699 = None
        floordiv_10 = sub_243 // 8;  sub_243 = None
        mul_512 = floordiv_10 * 8;  floordiv_10 = None
        cumsum_30 = torch.ops.aten.cumsum.default(wait_tensor_230, 0)
        sub_244 = torch.ops.aten.sub.Tensor(cumsum_30, wait_tensor_230);  cumsum_30 = None
        sum_44 = torch.ops.aten.sum.dim_IntList(view_735, [0]);  view_735 = None
        clamp_min_10 = torch.ops.aten.clamp_min.default(sum_44, 8);  sum_44 = None
        add_700 = torch.ops.aten.add.Tensor(clamp_min_10, 8);  clamp_min_10 = None
        sub_245 = torch.ops.aten.sub.Tensor(add_700, 1);  add_700 = None
        div_53 = torch.ops.aten.div.Tensor_mode(sub_245, 8, rounding_mode = 'floor');  sub_245 = None
        mul_513 = torch.ops.aten.mul.Tensor(div_53, 8);  div_53 = None
        convert_element_type_608 = torch.ops.prims.convert_element_type.default(mul_513, torch.int32);  mul_513 = None
        cumsum_31 = torch.ops.aten.cumsum.default(convert_element_type_608, 0)
        sub_246 = torch.ops.aten.sub.Tensor(cumsum_31, convert_element_type_608);  cumsum_31 = None
        full_150 = torch.ops.aten.full.default([mul_512], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_512 = None
        triton_kernel_wrapper_functional_proxy_10 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 10, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_230, 'start_index_values_ptr': sub_244, 'write_offsets_ptr': sub_246, 'output_ptr': full_150}, tensors_to_clone = ['output_ptr']);  wait_tensor_230 = sub_244 = sub_246 = full_150 = None
        getitem_1122 = triton_kernel_wrapper_functional_proxy_10['output_ptr'];  triton_kernel_wrapper_functional_proxy_10 = None
        cat_94 = torch.ops.aten.cat.default([wait_tensor_231, full_default]);  wait_tensor_231 = None
        sym_size_int_41 = torch.ops.aten.sym_size.int(cat_94, 0)
        sym_sum_21 = torch.sym_sum((1, _local_scalar_dense_168, _local_scalar_dense_169, _local_scalar_dense_170, _local_scalar_dense_171, _local_scalar_dense_172, _local_scalar_dense_173, _local_scalar_dense_174, _local_scalar_dense_175))
        index_21 = torch.ops.aten.index.Tensor(cat_94, [getitem_1122]);  cat_94 = None
        convert_element_type_610 = torch.ops.prims.convert_element_type.default(primals_193, torch.bfloat16)
        all_gather_into_tensor_189 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_610, 16, '1025');  convert_element_type_610 = None
        wait_tensor_232 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_189);  all_gather_into_tensor_189 = None
        split_61 = torch.ops.aten.split.Tensor(wait_tensor_232, 8);  wait_tensor_232 = None
        getitem_1139 = split_61[0]
        getitem_1140 = split_61[1]
        getitem_1141 = split_61[2]
        getitem_1142 = split_61[3]
        getitem_1143 = split_61[4]
        getitem_1144 = split_61[5]
        getitem_1145 = split_61[6]
        getitem_1146 = split_61[7]
        getitem_1147 = split_61[8]
        getitem_1148 = split_61[9]
        getitem_1149 = split_61[10]
        getitem_1150 = split_61[11]
        getitem_1151 = split_61[12]
        getitem_1152 = split_61[13]
        getitem_1153 = split_61[14]
        getitem_1154 = split_61[15];  split_61 = None
        cat_96 = torch.ops.aten.cat.default([getitem_1139, getitem_1140, getitem_1141, getitem_1142, getitem_1143, getitem_1144, getitem_1145, getitem_1146, getitem_1147, getitem_1148, getitem_1149, getitem_1150, getitem_1151, getitem_1152, getitem_1153, getitem_1154], 1);  getitem_1139 = getitem_1140 = getitem_1141 = getitem_1142 = getitem_1143 = getitem_1144 = getitem_1145 = getitem_1146 = getitem_1147 = getitem_1148 = getitem_1149 = getitem_1150 = getitem_1151 = getitem_1152 = getitem_1153 = getitem_1154 = None
        convert_element_type_612 = torch.ops.prims.convert_element_type.default(primals_194, torch.bfloat16)
        all_gather_into_tensor_191 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_612, 16, '1025');  convert_element_type_612 = None
        wait_tensor_234 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_191);  all_gather_into_tensor_191 = None
        split_62 = torch.ops.aten.split.Tensor(wait_tensor_234, 8);  wait_tensor_234 = None
        getitem_1155 = split_62[0]
        getitem_1156 = split_62[1]
        getitem_1157 = split_62[2]
        getitem_1158 = split_62[3]
        getitem_1159 = split_62[4]
        getitem_1160 = split_62[5]
        getitem_1161 = split_62[6]
        getitem_1162 = split_62[7]
        getitem_1163 = split_62[8]
        getitem_1164 = split_62[9]
        getitem_1165 = split_62[10]
        getitem_1166 = split_62[11]
        getitem_1167 = split_62[12]
        getitem_1168 = split_62[13]
        getitem_1169 = split_62[14]
        getitem_1170 = split_62[15];  split_62 = None
        cat_97 = torch.ops.aten.cat.default([getitem_1155, getitem_1156, getitem_1157, getitem_1158, getitem_1159, getitem_1160, getitem_1161, getitem_1162, getitem_1163, getitem_1164, getitem_1165, getitem_1166, getitem_1167, getitem_1168, getitem_1169, getitem_1170], 1);  getitem_1155 = getitem_1156 = getitem_1157 = getitem_1158 = getitem_1159 = getitem_1160 = getitem_1161 = getitem_1162 = getitem_1163 = getitem_1164 = getitem_1165 = getitem_1166 = getitem_1167 = getitem_1168 = getitem_1169 = getitem_1170 = None
        convert_element_type_613 = torch.ops.prims.convert_element_type.default(primals_195, torch.bfloat16)
        all_gather_into_tensor_192 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_613, 16, '1025');  convert_element_type_613 = None
        wait_tensor_235 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_192);  all_gather_into_tensor_192 = None
        split_63 = torch.ops.aten.split.Tensor(wait_tensor_235, 8);  wait_tensor_235 = None
        getitem_1171 = split_63[0]
        getitem_1172 = split_63[1]
        getitem_1173 = split_63[2]
        getitem_1174 = split_63[3]
        getitem_1175 = split_63[4]
        getitem_1176 = split_63[5]
        getitem_1177 = split_63[6]
        getitem_1178 = split_63[7]
        getitem_1179 = split_63[8]
        getitem_1180 = split_63[9]
        getitem_1181 = split_63[10]
        getitem_1182 = split_63[11]
        getitem_1183 = split_63[12]
        getitem_1184 = split_63[13]
        getitem_1185 = split_63[14]
        getitem_1186 = split_63[15];  split_63 = None
        cat_98 = torch.ops.aten.cat.default([getitem_1171, getitem_1172, getitem_1173, getitem_1174, getitem_1175, getitem_1176, getitem_1177, getitem_1178, getitem_1179, getitem_1180, getitem_1181, getitem_1182, getitem_1183, getitem_1184, getitem_1185, getitem_1186], 1);  getitem_1171 = getitem_1172 = getitem_1173 = getitem_1174 = getitem_1175 = getitem_1176 = getitem_1177 = getitem_1178 = getitem_1179 = getitem_1180 = getitem_1181 = getitem_1182 = getitem_1183 = getitem_1184 = getitem_1185 = getitem_1186 = None
        cumsum_32 = torch.ops.aten.cumsum.default(convert_element_type_608, 0, dtype = torch.int32);  convert_element_type_608 = None
        permute_170 = torch.ops.aten.permute.default(cat_96, [0, 2, 1]);  cat_96 = None
        _grouped_mm_30 = torch.ops.aten._grouped_mm.default(index_21, permute_170, cumsum_32)
        convert_element_type_616 = torch.ops.prims.convert_element_type.default(_grouped_mm_30, torch.float32)
        neg_21 = torch.ops.aten.neg.default(convert_element_type_616)
        exp_32 = torch.ops.aten.exp.default(neg_21);  neg_21 = None
        add_712 = torch.ops.aten.add.Tensor(exp_32, 1);  exp_32 = None
        div_54 = torch.ops.aten.div.Tensor(convert_element_type_616, add_712);  convert_element_type_616 = add_712 = None
        convert_element_type_617 = torch.ops.prims.convert_element_type.default(div_54, torch.bfloat16);  div_54 = None
        permute_171 = torch.ops.aten.permute.default(cat_98, [0, 2, 1]);  cat_98 = None
        _grouped_mm_31 = torch.ops.aten._grouped_mm.default(index_21, permute_171, cumsum_32)
        mul_525 = torch.ops.aten.mul.Tensor(convert_element_type_617, _grouped_mm_31);  convert_element_type_617 = None
        permute_172 = torch.ops.aten.permute.default(cat_97, [0, 2, 1]);  cat_97 = None
        _grouped_mm_32 = torch.ops.aten._grouped_mm.default(mul_525, permute_172, cumsum_32)
        empty_10 = torch.ops.aten.empty.memory_format([sym_size_int_41, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_20 = torch.ops.aten.index_put.default(empty_10, [getitem_1122], _grouped_mm_32);  empty_10 = _grouped_mm_32 = None
        slice_71 = torch.ops.aten.slice.Tensor(index_put_20, 0, 0, -1);  index_put_20 = None
        all_to_all_single_32 = torch.ops._c10d_functional.all_to_all_single.default(slice_71, [_local_scalar_dense_160, _local_scalar_dense_161, _local_scalar_dense_162, _local_scalar_dense_163, _local_scalar_dense_164, _local_scalar_dense_165, _local_scalar_dense_166, _local_scalar_dense_167], [_local_scalar_dense_168, _local_scalar_dense_169, _local_scalar_dense_170, _local_scalar_dense_171, _local_scalar_dense_172, _local_scalar_dense_173, _local_scalar_dense_174, _local_scalar_dense_175], '1033');  slice_71 = None
        wait_tensor_238 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_32);  all_to_all_single_32 = None
        convert_element_type_618 = torch.ops.prims.convert_element_type.default(primals_196, torch.bfloat16)
        all_gather_into_tensor_195 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_618, 128, '0');  convert_element_type_618 = None
        wait_tensor_239 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_195);  all_gather_into_tensor_195 = None
        permute_173 = torch.ops.aten.permute.default(wait_tensor_239, [1, 0]);  wait_tensor_239 = None
        mm_92 = torch.ops.aten.mm.default(view_728, permute_173);  permute_173 = None
        convert_element_type_621 = torch.ops.prims.convert_element_type.default(mm_92, torch.float32)
        neg_22 = torch.ops.aten.neg.default(convert_element_type_621)
        exp_33 = torch.ops.aten.exp.default(neg_22);  neg_22 = None
        add_748 = torch.ops.aten.add.Tensor(exp_33, 1);  exp_33 = None
        div_55 = torch.ops.aten.div.Tensor(convert_element_type_621, add_748);  convert_element_type_621 = add_748 = None
        convert_element_type_622 = torch.ops.prims.convert_element_type.default(div_55, torch.bfloat16);  div_55 = None
        convert_element_type_623 = torch.ops.prims.convert_element_type.default(primals_197, torch.bfloat16)
        all_gather_into_tensor_196 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_623, 128, '0');  convert_element_type_623 = None
        wait_tensor_240 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_196);  all_gather_into_tensor_196 = None
        permute_174 = torch.ops.aten.permute.default(wait_tensor_240, [1, 0]);  wait_tensor_240 = None
        mm_93 = torch.ops.aten.mm.default(view_728, permute_174);  permute_174 = None
        mul_545 = torch.ops.aten.mul.Tensor(convert_element_type_622, mm_93);  convert_element_type_622 = None
        convert_element_type_626 = torch.ops.prims.convert_element_type.default(primals_198, torch.bfloat16)
        all_gather_into_tensor_197 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_626, 128, '0');  convert_element_type_626 = None
        wait_tensor_241 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_197);  all_gather_into_tensor_197 = None
        permute_175 = torch.ops.aten.permute.default(wait_tensor_241, [1, 0]);  wait_tensor_241 = None
        mm_94 = torch.ops.aten.mm.default(mul_545, permute_175);  permute_175 = None
        index_put_21 = torch.ops.aten.index_put.default(full_default_1, [getitem_1121], wait_tensor_238);  wait_tensor_238 = None
        view_768 = torch.ops.aten.view.default(mul_507, [-1, 1, 6]);  mul_507 = None
        view_769 = torch.ops.aten.view.default(index_put_21, [-1, 6, 2048]);  index_put_21 = None
        convert_element_type_629 = torch.ops.prims.convert_element_type.default(view_769, torch.float32);  view_769 = None
        bmm_10 = torch.ops.aten.bmm.default(view_768, convert_element_type_629)
        convert_element_type_630 = torch.ops.prims.convert_element_type.default(bmm_10, torch.bfloat16);  bmm_10 = None
        squeeze_10 = torch.ops.aten.squeeze.dim(convert_element_type_630, 1);  convert_element_type_630 = None
        add_752 = torch.ops.aten.add.Tensor(mm_94, squeeze_10);  mm_94 = squeeze_10 = None
        view_770 = torch.ops.aten.view.default(add_752, [2, 4096, 2048]);  add_752 = None
        add_753 = torch.ops.aten.add.Tensor(add_688, view_770);  view_770 = None
        convert_element_type_631 = torch.ops.prims.convert_element_type.default(primals_199, torch.bfloat16)
        all_gather_into_tensor_198 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_631, 128, '0');  convert_element_type_631 = None
        wait_tensor_242 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_198);  all_gather_into_tensor_198 = None
        convert_element_type_632 = torch.ops.prims.convert_element_type.default(add_753, torch.float32)
        pow_37 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_632, 2)
        mean_36 = torch.ops.aten.mean.dim(pow_37, [2], True);  pow_37 = None
        add_754 = torch.ops.aten.add.Scalar(mean_36, 1e-05);  mean_36 = None
        rsqrt_36 = torch.ops.aten.rsqrt.default(add_754);  add_754 = None
        mul_548 = torch.ops.aten.mul.Tensor(convert_element_type_632, rsqrt_36);  convert_element_type_632 = None
        mul_549 = torch.ops.aten.mul.Tensor(mul_548, wait_tensor_242);  mul_548 = wait_tensor_242 = None
        convert_element_type_633 = torch.ops.prims.convert_element_type.default(mul_549, torch.bfloat16);  mul_549 = None
        convert_element_type_634 = torch.ops.prims.convert_element_type.default(primals_200, torch.bfloat16)
        all_gather_into_tensor_199 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_634, 128, '0');  convert_element_type_634 = None
        wait_tensor_243 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_199);  all_gather_into_tensor_199 = None
        permute_176 = torch.ops.aten.permute.default(wait_tensor_243, [1, 0]);  wait_tensor_243 = None
        view_773 = torch.ops.aten.view.default(convert_element_type_633, [8192, 2048]);  convert_element_type_633 = None
        mm_95 = torch.ops.aten.mm.default(view_773, permute_176);  permute_176 = None
        view_774 = torch.ops.aten.view.default(mm_95, [2, 4096, 3072]);  mm_95 = None
        view_775 = torch.ops.aten.view.default(view_774, [2, 4096, -1, 192]);  view_774 = None
        split_with_sizes_36 = torch.ops.aten.split_with_sizes.default(view_775, [128, 64], -1);  view_775 = None
        getitem_1219 = split_with_sizes_36[0]
        getitem_1220 = split_with_sizes_36[1];  split_with_sizes_36 = None
        convert_element_type_637 = torch.ops.prims.convert_element_type.default(getitem_1220, torch.float32);  getitem_1220 = None
        view_776 = torch.ops.aten.view.default(convert_element_type_637, [2, 4096, 16, -1, 2]);  convert_element_type_637 = None
        view_as_complex_24 = torch.ops.aten.view_as_complex.default(view_776);  view_776 = None
        mul_550 = torch.ops.aten.mul.Tensor(view_as_complex_24, view_7);  view_as_complex_24 = None
        view_as_real_24 = torch.ops.aten.view_as_real.default(mul_550);  mul_550 = None
        view_778 = torch.ops.aten.view.default(view_as_real_24, [2, 4096, 16, 64]);  view_as_real_24 = None
        convert_element_type_638 = torch.ops.prims.convert_element_type.default(view_778, torch.bfloat16);  view_778 = None
        cat_101 = torch.ops.aten.cat.default([getitem_1219, convert_element_type_638], -1);  getitem_1219 = convert_element_type_638 = None
        convert_element_type_639 = torch.ops.prims.convert_element_type.default(primals_201, torch.bfloat16)
        all_gather_into_tensor_200 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_639, 128, '0');  convert_element_type_639 = None
        wait_tensor_244 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_200);  all_gather_into_tensor_200 = None
        slice_73 = torch.ops.aten.slice.Tensor(wait_tensor_244, 0, 0, 576);  wait_tensor_244 = None
        permute_177 = torch.ops.aten.permute.default(slice_73, [1, 0]);  slice_73 = None
        mm_96 = torch.ops.aten.mm.default(view_773, permute_177);  permute_177 = None
        view_781 = torch.ops.aten.view.default(mm_96, [2, 4096, 576]);  mm_96 = None
        split_with_sizes_37 = torch.ops.aten.split_with_sizes.default(view_781, [512, 64], -1);  view_781 = None
        getitem_1221 = split_with_sizes_37[0]
        getitem_1222 = split_with_sizes_37[1];  split_with_sizes_37 = None
        unsqueeze_23 = torch.ops.aten.unsqueeze.default(getitem_1222, 2);  getitem_1222 = None
        convert_element_type_642 = torch.ops.prims.convert_element_type.default(unsqueeze_23, torch.float32);  unsqueeze_23 = None
        view_782 = torch.ops.aten.view.default(convert_element_type_642, [2, 4096, 1, -1, 2]);  convert_element_type_642 = None
        view_as_complex_25 = torch.ops.aten.view_as_complex.default(view_782);  view_782 = None
        mul_551 = torch.ops.aten.mul.Tensor(view_as_complex_25, view_7);  view_as_complex_25 = None
        view_as_real_25 = torch.ops.aten.view_as_real.default(mul_551);  mul_551 = None
        view_784 = torch.ops.aten.view.default(view_as_real_25, [2, 4096, 1, 64]);  view_as_real_25 = None
        convert_element_type_643 = torch.ops.prims.convert_element_type.default(view_784, torch.bfloat16);  view_784 = None
        convert_element_type_644 = torch.ops.prims.convert_element_type.default(primals_202, torch.bfloat16)
        all_gather_into_tensor_201 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_644, 128, '0');  convert_element_type_644 = None
        wait_tensor_245 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_201);  all_gather_into_tensor_201 = None
        convert_element_type_645 = torch.ops.prims.convert_element_type.default(getitem_1221, torch.float32)
        pow_38 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_645, 2)
        mean_37 = torch.ops.aten.mean.dim(pow_38, [2], True);  pow_38 = None
        add_755 = torch.ops.aten.add.Scalar(mean_37, 1e-05);  mean_37 = None
        rsqrt_37 = torch.ops.aten.rsqrt.default(add_755);  add_755 = None
        mul_552 = torch.ops.aten.mul.Tensor(convert_element_type_645, rsqrt_37);  convert_element_type_645 = None
        mul_553 = torch.ops.aten.mul.Tensor(mul_552, wait_tensor_245);  mul_552 = wait_tensor_245 = None
        convert_element_type_646 = torch.ops.prims.convert_element_type.default(mul_553, torch.bfloat16);  mul_553 = None
        convert_element_type_647 = torch.ops.prims.convert_element_type.default(primals_203, torch.bfloat16)
        all_gather_into_tensor_202 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_647, 128, '0');  convert_element_type_647 = None
        wait_tensor_246 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_202);  all_gather_into_tensor_202 = None
        permute_178 = torch.ops.aten.permute.default(wait_tensor_246, [1, 0]);  wait_tensor_246 = None
        view_787 = torch.ops.aten.view.default(convert_element_type_646, [8192, 512]);  convert_element_type_646 = None
        mm_97 = torch.ops.aten.mm.default(view_787, permute_178);  permute_178 = None
        view_788 = torch.ops.aten.view.default(mm_97, [2, 4096, 4096]);  mm_97 = None
        view_789 = torch.ops.aten.view.default(view_788, [2, 4096, -1, 256]);  view_788 = None
        split_with_sizes_38 = torch.ops.aten.split_with_sizes.default(view_789, [128, 128], -1);  view_789 = None
        getitem_1223 = split_with_sizes_38[0]
        getitem_1224 = split_with_sizes_38[1];  split_with_sizes_38 = None
        expand_12 = torch.ops.aten.expand.default(convert_element_type_643, [-1, -1, 16, -1]);  convert_element_type_643 = None
        cat_102 = torch.ops.aten.cat.default([getitem_1223, expand_12], -1);  getitem_1223 = expand_12 = None
        permute_179 = torch.ops.aten.permute.default(cat_101, [0, 2, 1, 3]);  cat_101 = None
        permute_180 = torch.ops.aten.permute.default(cat_102, [0, 2, 1, 3]);  cat_102 = None
        permute_181 = torch.ops.aten.permute.default(getitem_1224, [0, 2, 1, 3]);  getitem_1224 = None
        sdpa_score12 = self.sdpa_score12
        sdpa_mask12 = self.sdpa_mask12
        flex_attention_12 = torch.ops.higher_order.flex_attention(permute_179, permute_180, permute_181, sdpa_score12, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask12), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score12 = sdpa_mask12 = None
        getitem_1225 = flex_attention_12[0]
        getitem_1226 = flex_attention_12[1];  flex_attention_12 = None
        permute_182 = torch.ops.aten.permute.default(getitem_1225, [0, 2, 1, 3])
        view_790 = torch.ops.aten.view.default(permute_182, [2, 4096, -1]);  permute_182 = None
        convert_element_type_650 = torch.ops.prims.convert_element_type.default(primals_204, torch.bfloat16)
        all_gather_into_tensor_203 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_650, 128, '0');  convert_element_type_650 = None
        wait_tensor_247 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_203);  all_gather_into_tensor_203 = None
        permute_183 = torch.ops.aten.permute.default(wait_tensor_247, [1, 0]);  wait_tensor_247 = None
        view_792 = torch.ops.aten.view.default(view_790, [8192, 2048]);  view_790 = None
        mm_98 = torch.ops.aten.mm.default(view_792, permute_183);  view_792 = permute_183 = None
        view_793 = torch.ops.aten.view.default(mm_98, [2, 4096, 2048]);  mm_98 = None
        add_756 = torch.ops.aten.add.Tensor(add_753, view_793);  view_793 = None
        convert_element_type_653 = torch.ops.prims.convert_element_type.default(primals_205, torch.bfloat16)
        all_gather_into_tensor_204 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_653, 128, '0');  convert_element_type_653 = None
        wait_tensor_248 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_204);  all_gather_into_tensor_204 = None
        convert_element_type_654 = torch.ops.prims.convert_element_type.default(add_756, torch.float32)
        pow_39 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_654, 2)
        mean_38 = torch.ops.aten.mean.dim(pow_39, [2], True);  pow_39 = None
        add_757 = torch.ops.aten.add.Scalar(mean_38, 1e-05);  mean_38 = None
        rsqrt_38 = torch.ops.aten.rsqrt.default(add_757);  add_757 = None
        mul_554 = torch.ops.aten.mul.Tensor(convert_element_type_654, rsqrt_38);  convert_element_type_654 = None
        mul_555 = torch.ops.aten.mul.Tensor(mul_554, wait_tensor_248);  mul_554 = wait_tensor_248 = None
        convert_element_type_655 = torch.ops.prims.convert_element_type.default(mul_555, torch.bfloat16);  mul_555 = None
        view_795 = torch.ops.aten.view.default(convert_element_type_655, [-1, 2048]);  convert_element_type_655 = None
        convert_element_type_656 = torch.ops.prims.convert_element_type.default(primals_207, torch.bfloat16)
        all_gather_into_tensor_205 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_656, 128, '0');  convert_element_type_656 = None
        wait_tensor_249 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_205);  all_gather_into_tensor_205 = None
        slice_75 = torch.ops.aten.slice.Tensor(wait_tensor_249, 0, 0, 64);  wait_tensor_249 = None
        permute_184 = torch.ops.aten.permute.default(slice_75, [1, 0]);  slice_75 = None
        mm_99 = torch.ops.aten.mm.default(view_795, permute_184);  permute_184 = None
        convert_element_type_659 = torch.ops.prims.convert_element_type.default(mm_99, torch.float32)
        amax_11 = torch.ops.aten.amax.default(convert_element_type_659, [1], True)
        sub_264 = torch.ops.aten.sub.Tensor(convert_element_type_659, amax_11);  convert_element_type_659 = None
        exp_34 = torch.ops.aten.exp.default(sub_264);  sub_264 = None
        sum_45 = torch.ops.aten.sum.dim_IntList(exp_34, [1], True)
        div_56 = torch.ops.aten.div.Tensor(exp_34, sum_45);  exp_34 = None
        add_758 = torch.ops.aten.add.Tensor(div_56, primals_206);  primals_206 = None
        topk_11 = torch.ops.aten.topk.default(add_758, 6, -1, True, False);  add_758 = None
        getitem_1229 = topk_11[1];  topk_11 = None
        gather_11 = torch.ops.aten.gather.default(div_56, 1, getitem_1229);  div_56 = None
        mul_556 = torch.ops.aten.mul.Tensor(gather_11, 1.0);  gather_11 = None
        view_797 = torch.ops.aten.view.default(getitem_1229, [-1])
        histc_22 = torch.ops.aten.histc.default(view_797, 64, 0, 64)
        add_759 = torch.ops.aten.add.Tensor(primals_208, histc_22)
        sort_11 = torch.ops.aten.sort.stable(view_797, stable = True);  view_797 = None
        getitem_1231 = sort_11[1];  sort_11 = None
        div_57 = torch.ops.aten.div.Tensor_mode(getitem_1231, 6, rounding_mode = 'floor')
        index_22 = torch.ops.aten.index.Tensor(view_795, [div_57])
        all_to_all_single_33 = torch.ops._c10d_functional.all_to_all_single.default(histc_22, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_250 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_33);  all_to_all_single_33 = None
        wait_tensor_251 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_250);  wait_tensor_250 = None
        view_801 = torch.ops.aten.view.default(histc_22, [8, -1]);  histc_22 = None
        sum_46 = torch.ops.aten.sum.dim_IntList(view_801, [1]);  view_801 = None
        device_put_22 = torch.ops.prims.device_put.default(sum_46, device(type='cpu'), True);  sum_46 = None
        view_802 = torch.ops.aten.view.default(wait_tensor_251, [8, -1])
        sum_47 = torch.ops.aten.sum.dim_IntList(view_802, [1])
        device_put_23 = torch.ops.prims.device_put.default(sum_47, device(type='cpu'));  sum_47 = None
        select_176 = torch.ops.aten.select.int(device_put_22, 0, 0)
        _local_scalar_dense_176 = torch.ops.aten._local_scalar_dense.default(select_176);  select_176 = None
        ge_220 = _local_scalar_dense_176 >= 0
        _assert_scalar_176 = torch.ops.aten._assert_scalar.default(ge_220, "Runtime assertion failed for expression u176 >= 0 on node 'ge_176'");  ge_220 = _assert_scalar_176 = None
        select_177 = torch.ops.aten.select.int(device_put_22, 0, 1)
        _local_scalar_dense_177 = torch.ops.aten._local_scalar_dense.default(select_177);  select_177 = None
        ge_221 = _local_scalar_dense_177 >= 0
        _assert_scalar_177 = torch.ops.aten._assert_scalar.default(ge_221, "Runtime assertion failed for expression u177 >= 0 on node 'ge_177'");  ge_221 = _assert_scalar_177 = None
        select_178 = torch.ops.aten.select.int(device_put_22, 0, 2)
        _local_scalar_dense_178 = torch.ops.aten._local_scalar_dense.default(select_178);  select_178 = None
        ge_222 = _local_scalar_dense_178 >= 0
        _assert_scalar_178 = torch.ops.aten._assert_scalar.default(ge_222, "Runtime assertion failed for expression u178 >= 0 on node 'ge_178'");  ge_222 = _assert_scalar_178 = None
        select_179 = torch.ops.aten.select.int(device_put_22, 0, 3)
        _local_scalar_dense_179 = torch.ops.aten._local_scalar_dense.default(select_179);  select_179 = None
        ge_223 = _local_scalar_dense_179 >= 0
        _assert_scalar_179 = torch.ops.aten._assert_scalar.default(ge_223, "Runtime assertion failed for expression u179 >= 0 on node 'ge_179'");  ge_223 = _assert_scalar_179 = None
        select_180 = torch.ops.aten.select.int(device_put_22, 0, 4)
        _local_scalar_dense_180 = torch.ops.aten._local_scalar_dense.default(select_180);  select_180 = None
        ge_224 = _local_scalar_dense_180 >= 0
        _assert_scalar_180 = torch.ops.aten._assert_scalar.default(ge_224, "Runtime assertion failed for expression u180 >= 0 on node 'ge_180'");  ge_224 = _assert_scalar_180 = None
        select_181 = torch.ops.aten.select.int(device_put_22, 0, 5)
        _local_scalar_dense_181 = torch.ops.aten._local_scalar_dense.default(select_181);  select_181 = None
        ge_225 = _local_scalar_dense_181 >= 0
        _assert_scalar_181 = torch.ops.aten._assert_scalar.default(ge_225, "Runtime assertion failed for expression u181 >= 0 on node 'ge_181'");  ge_225 = _assert_scalar_181 = None
        select_182 = torch.ops.aten.select.int(device_put_22, 0, 6)
        _local_scalar_dense_182 = torch.ops.aten._local_scalar_dense.default(select_182);  select_182 = None
        ge_226 = _local_scalar_dense_182 >= 0
        _assert_scalar_182 = torch.ops.aten._assert_scalar.default(ge_226, "Runtime assertion failed for expression u182 >= 0 on node 'ge_182'");  ge_226 = _assert_scalar_182 = None
        select_183 = torch.ops.aten.select.int(device_put_22, 0, 7);  device_put_22 = None
        _local_scalar_dense_183 = torch.ops.aten._local_scalar_dense.default(select_183);  select_183 = None
        ge_227 = _local_scalar_dense_183 >= 0
        _assert_scalar_183 = torch.ops.aten._assert_scalar.default(ge_227, "Runtime assertion failed for expression u183 >= 0 on node 'ge_183'");  ge_227 = _assert_scalar_183 = None
        select_184 = torch.ops.aten.select.int(device_put_23, 0, 0)
        _local_scalar_dense_184 = torch.ops.aten._local_scalar_dense.default(select_184);  select_184 = None
        ge_228 = _local_scalar_dense_184 >= 0
        _assert_scalar_184 = torch.ops.aten._assert_scalar.default(ge_228, "Runtime assertion failed for expression u184 >= 0 on node 'ge_184'");  ge_228 = _assert_scalar_184 = None
        select_185 = torch.ops.aten.select.int(device_put_23, 0, 1)
        _local_scalar_dense_185 = torch.ops.aten._local_scalar_dense.default(select_185);  select_185 = None
        ge_229 = _local_scalar_dense_185 >= 0
        _assert_scalar_185 = torch.ops.aten._assert_scalar.default(ge_229, "Runtime assertion failed for expression u185 >= 0 on node 'ge_185'");  ge_229 = _assert_scalar_185 = None
        select_186 = torch.ops.aten.select.int(device_put_23, 0, 2)
        _local_scalar_dense_186 = torch.ops.aten._local_scalar_dense.default(select_186);  select_186 = None
        ge_230 = _local_scalar_dense_186 >= 0
        _assert_scalar_186 = torch.ops.aten._assert_scalar.default(ge_230, "Runtime assertion failed for expression u186 >= 0 on node 'ge_186'");  ge_230 = _assert_scalar_186 = None
        select_187 = torch.ops.aten.select.int(device_put_23, 0, 3)
        _local_scalar_dense_187 = torch.ops.aten._local_scalar_dense.default(select_187);  select_187 = None
        ge_231 = _local_scalar_dense_187 >= 0
        _assert_scalar_187 = torch.ops.aten._assert_scalar.default(ge_231, "Runtime assertion failed for expression u187 >= 0 on node 'ge_187'");  ge_231 = _assert_scalar_187 = None
        select_188 = torch.ops.aten.select.int(device_put_23, 0, 4)
        _local_scalar_dense_188 = torch.ops.aten._local_scalar_dense.default(select_188);  select_188 = None
        ge_232 = _local_scalar_dense_188 >= 0
        _assert_scalar_188 = torch.ops.aten._assert_scalar.default(ge_232, "Runtime assertion failed for expression u188 >= 0 on node 'ge_188'");  ge_232 = _assert_scalar_188 = None
        select_189 = torch.ops.aten.select.int(device_put_23, 0, 5)
        _local_scalar_dense_189 = torch.ops.aten._local_scalar_dense.default(select_189);  select_189 = None
        ge_233 = _local_scalar_dense_189 >= 0
        _assert_scalar_189 = torch.ops.aten._assert_scalar.default(ge_233, "Runtime assertion failed for expression u189 >= 0 on node 'ge_189'");  ge_233 = _assert_scalar_189 = None
        select_190 = torch.ops.aten.select.int(device_put_23, 0, 6)
        _local_scalar_dense_190 = torch.ops.aten._local_scalar_dense.default(select_190);  select_190 = None
        ge_234 = _local_scalar_dense_190 >= 0
        _assert_scalar_190 = torch.ops.aten._assert_scalar.default(ge_234, "Runtime assertion failed for expression u190 >= 0 on node 'ge_190'");  ge_234 = _assert_scalar_190 = None
        select_191 = torch.ops.aten.select.int(device_put_23, 0, 7);  device_put_23 = None
        _local_scalar_dense_191 = torch.ops.aten._local_scalar_dense.default(select_191);  select_191 = None
        ge_235 = _local_scalar_dense_191 >= 0
        _assert_scalar_191 = torch.ops.aten._assert_scalar.default(ge_235, "Runtime assertion failed for expression u191 >= 0 on node 'ge_191'");  ge_235 = _assert_scalar_191 = None
        all_to_all_single_34 = torch.ops._c10d_functional.all_to_all_single.default(index_22, [_local_scalar_dense_184, _local_scalar_dense_185, _local_scalar_dense_186, _local_scalar_dense_187, _local_scalar_dense_188, _local_scalar_dense_189, _local_scalar_dense_190, _local_scalar_dense_191], [_local_scalar_dense_176, _local_scalar_dense_177, _local_scalar_dense_178, _local_scalar_dense_179, _local_scalar_dense_180, _local_scalar_dense_181, _local_scalar_dense_182, _local_scalar_dense_183], '1033');  index_22 = None
        sym_size_int_44 = torch.ops.aten.sym_size.int(all_to_all_single_34, 0)
        wait_tensor_252 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_34);  all_to_all_single_34 = None
        sym_sum_22 = torch.sym_sum((_local_scalar_dense_184, _local_scalar_dense_185, _local_scalar_dense_186, _local_scalar_dense_187, _local_scalar_dense_188, _local_scalar_dense_189, _local_scalar_dense_190, _local_scalar_dense_191))
        add_766 = sym_sum_22 + 64;  sym_sum_22 = None
        add_767 = add_766 + 8;  add_766 = None
        sub_267 = add_767 - 1;  add_767 = None
        floordiv_11 = sub_267 // 8;  sub_267 = None
        mul_561 = floordiv_11 * 8;  floordiv_11 = None
        cumsum_33 = torch.ops.aten.cumsum.default(wait_tensor_251, 0)
        sub_268 = torch.ops.aten.sub.Tensor(cumsum_33, wait_tensor_251);  cumsum_33 = None
        sum_48 = torch.ops.aten.sum.dim_IntList(view_802, [0]);  view_802 = None
        clamp_min_11 = torch.ops.aten.clamp_min.default(sum_48, 8);  sum_48 = None
        add_768 = torch.ops.aten.add.Tensor(clamp_min_11, 8);  clamp_min_11 = None
        sub_269 = torch.ops.aten.sub.Tensor(add_768, 1);  add_768 = None
        div_58 = torch.ops.aten.div.Tensor_mode(sub_269, 8, rounding_mode = 'floor');  sub_269 = None
        mul_562 = torch.ops.aten.mul.Tensor(div_58, 8);  div_58 = None
        convert_element_type_662 = torch.ops.prims.convert_element_type.default(mul_562, torch.int32);  mul_562 = None
        cumsum_34 = torch.ops.aten.cumsum.default(convert_element_type_662, 0)
        sub_270 = torch.ops.aten.sub.Tensor(cumsum_34, convert_element_type_662);  cumsum_34 = None
        full_163 = torch.ops.aten.full.default([mul_561], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_561 = None
        triton_kernel_wrapper_functional_proxy_11 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 11, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_251, 'start_index_values_ptr': sub_268, 'write_offsets_ptr': sub_270, 'output_ptr': full_163}, tensors_to_clone = ['output_ptr']);  wait_tensor_251 = sub_268 = sub_270 = full_163 = None
        getitem_1232 = triton_kernel_wrapper_functional_proxy_11['output_ptr'];  triton_kernel_wrapper_functional_proxy_11 = None
        cat_103 = torch.ops.aten.cat.default([wait_tensor_252, full_default]);  wait_tensor_252 = None
        sym_size_int_45 = torch.ops.aten.sym_size.int(cat_103, 0)
        sym_sum_23 = torch.sym_sum((1, _local_scalar_dense_184, _local_scalar_dense_185, _local_scalar_dense_186, _local_scalar_dense_187, _local_scalar_dense_188, _local_scalar_dense_189, _local_scalar_dense_190, _local_scalar_dense_191))
        index_23 = torch.ops.aten.index.Tensor(cat_103, [getitem_1232]);  cat_103 = None
        convert_element_type_664 = torch.ops.prims.convert_element_type.default(primals_209, torch.bfloat16)
        all_gather_into_tensor_206 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_664, 16, '1025');  convert_element_type_664 = None
        wait_tensor_253 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_206);  all_gather_into_tensor_206 = None
        split_67 = torch.ops.aten.split.Tensor(wait_tensor_253, 8);  wait_tensor_253 = None
        getitem_1249 = split_67[0]
        getitem_1250 = split_67[1]
        getitem_1251 = split_67[2]
        getitem_1252 = split_67[3]
        getitem_1253 = split_67[4]
        getitem_1254 = split_67[5]
        getitem_1255 = split_67[6]
        getitem_1256 = split_67[7]
        getitem_1257 = split_67[8]
        getitem_1258 = split_67[9]
        getitem_1259 = split_67[10]
        getitem_1260 = split_67[11]
        getitem_1261 = split_67[12]
        getitem_1262 = split_67[13]
        getitem_1263 = split_67[14]
        getitem_1264 = split_67[15];  split_67 = None
        cat_105 = torch.ops.aten.cat.default([getitem_1249, getitem_1250, getitem_1251, getitem_1252, getitem_1253, getitem_1254, getitem_1255, getitem_1256, getitem_1257, getitem_1258, getitem_1259, getitem_1260, getitem_1261, getitem_1262, getitem_1263, getitem_1264], 1);  getitem_1249 = getitem_1250 = getitem_1251 = getitem_1252 = getitem_1253 = getitem_1254 = getitem_1255 = getitem_1256 = getitem_1257 = getitem_1258 = getitem_1259 = getitem_1260 = getitem_1261 = getitem_1262 = getitem_1263 = getitem_1264 = None
        convert_element_type_666 = torch.ops.prims.convert_element_type.default(primals_210, torch.bfloat16)
        all_gather_into_tensor_208 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_666, 16, '1025');  convert_element_type_666 = None
        wait_tensor_255 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_208);  all_gather_into_tensor_208 = None
        split_68 = torch.ops.aten.split.Tensor(wait_tensor_255, 8);  wait_tensor_255 = None
        getitem_1265 = split_68[0]
        getitem_1266 = split_68[1]
        getitem_1267 = split_68[2]
        getitem_1268 = split_68[3]
        getitem_1269 = split_68[4]
        getitem_1270 = split_68[5]
        getitem_1271 = split_68[6]
        getitem_1272 = split_68[7]
        getitem_1273 = split_68[8]
        getitem_1274 = split_68[9]
        getitem_1275 = split_68[10]
        getitem_1276 = split_68[11]
        getitem_1277 = split_68[12]
        getitem_1278 = split_68[13]
        getitem_1279 = split_68[14]
        getitem_1280 = split_68[15];  split_68 = None
        cat_106 = torch.ops.aten.cat.default([getitem_1265, getitem_1266, getitem_1267, getitem_1268, getitem_1269, getitem_1270, getitem_1271, getitem_1272, getitem_1273, getitem_1274, getitem_1275, getitem_1276, getitem_1277, getitem_1278, getitem_1279, getitem_1280], 1);  getitem_1265 = getitem_1266 = getitem_1267 = getitem_1268 = getitem_1269 = getitem_1270 = getitem_1271 = getitem_1272 = getitem_1273 = getitem_1274 = getitem_1275 = getitem_1276 = getitem_1277 = getitem_1278 = getitem_1279 = getitem_1280 = None
        convert_element_type_667 = torch.ops.prims.convert_element_type.default(primals_211, torch.bfloat16)
        all_gather_into_tensor_209 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_667, 16, '1025');  convert_element_type_667 = None
        wait_tensor_256 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_209);  all_gather_into_tensor_209 = None
        split_69 = torch.ops.aten.split.Tensor(wait_tensor_256, 8);  wait_tensor_256 = None
        getitem_1281 = split_69[0]
        getitem_1282 = split_69[1]
        getitem_1283 = split_69[2]
        getitem_1284 = split_69[3]
        getitem_1285 = split_69[4]
        getitem_1286 = split_69[5]
        getitem_1287 = split_69[6]
        getitem_1288 = split_69[7]
        getitem_1289 = split_69[8]
        getitem_1290 = split_69[9]
        getitem_1291 = split_69[10]
        getitem_1292 = split_69[11]
        getitem_1293 = split_69[12]
        getitem_1294 = split_69[13]
        getitem_1295 = split_69[14]
        getitem_1296 = split_69[15];  split_69 = None
        cat_107 = torch.ops.aten.cat.default([getitem_1281, getitem_1282, getitem_1283, getitem_1284, getitem_1285, getitem_1286, getitem_1287, getitem_1288, getitem_1289, getitem_1290, getitem_1291, getitem_1292, getitem_1293, getitem_1294, getitem_1295, getitem_1296], 1);  getitem_1281 = getitem_1282 = getitem_1283 = getitem_1284 = getitem_1285 = getitem_1286 = getitem_1287 = getitem_1288 = getitem_1289 = getitem_1290 = getitem_1291 = getitem_1292 = getitem_1293 = getitem_1294 = getitem_1295 = getitem_1296 = None
        cumsum_35 = torch.ops.aten.cumsum.default(convert_element_type_662, 0, dtype = torch.int32);  convert_element_type_662 = None
        permute_185 = torch.ops.aten.permute.default(cat_105, [0, 2, 1]);  cat_105 = None
        _grouped_mm_33 = torch.ops.aten._grouped_mm.default(index_23, permute_185, cumsum_35)
        convert_element_type_670 = torch.ops.prims.convert_element_type.default(_grouped_mm_33, torch.float32)
        neg_23 = torch.ops.aten.neg.default(convert_element_type_670)
        exp_35 = torch.ops.aten.exp.default(neg_23);  neg_23 = None
        add_780 = torch.ops.aten.add.Tensor(exp_35, 1);  exp_35 = None
        div_59 = torch.ops.aten.div.Tensor(convert_element_type_670, add_780);  convert_element_type_670 = add_780 = None
        convert_element_type_671 = torch.ops.prims.convert_element_type.default(div_59, torch.bfloat16);  div_59 = None
        permute_186 = torch.ops.aten.permute.default(cat_107, [0, 2, 1]);  cat_107 = None
        _grouped_mm_34 = torch.ops.aten._grouped_mm.default(index_23, permute_186, cumsum_35)
        mul_574 = torch.ops.aten.mul.Tensor(convert_element_type_671, _grouped_mm_34);  convert_element_type_671 = None
        permute_187 = torch.ops.aten.permute.default(cat_106, [0, 2, 1]);  cat_106 = None
        _grouped_mm_35 = torch.ops.aten._grouped_mm.default(mul_574, permute_187, cumsum_35)
        empty_11 = torch.ops.aten.empty.memory_format([sym_size_int_45, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_22 = torch.ops.aten.index_put.default(empty_11, [getitem_1232], _grouped_mm_35);  empty_11 = _grouped_mm_35 = None
        slice_77 = torch.ops.aten.slice.Tensor(index_put_22, 0, 0, -1);  index_put_22 = None
        all_to_all_single_35 = torch.ops._c10d_functional.all_to_all_single.default(slice_77, [_local_scalar_dense_176, _local_scalar_dense_177, _local_scalar_dense_178, _local_scalar_dense_179, _local_scalar_dense_180, _local_scalar_dense_181, _local_scalar_dense_182, _local_scalar_dense_183], [_local_scalar_dense_184, _local_scalar_dense_185, _local_scalar_dense_186, _local_scalar_dense_187, _local_scalar_dense_188, _local_scalar_dense_189, _local_scalar_dense_190, _local_scalar_dense_191], '1033');  slice_77 = None
        wait_tensor_259 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_35);  all_to_all_single_35 = None
        convert_element_type_672 = torch.ops.prims.convert_element_type.default(primals_212, torch.bfloat16)
        all_gather_into_tensor_212 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_672, 128, '0');  convert_element_type_672 = None
        wait_tensor_260 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_212);  all_gather_into_tensor_212 = None
        permute_188 = torch.ops.aten.permute.default(wait_tensor_260, [1, 0]);  wait_tensor_260 = None
        mm_100 = torch.ops.aten.mm.default(view_795, permute_188);  permute_188 = None
        convert_element_type_675 = torch.ops.prims.convert_element_type.default(mm_100, torch.float32)
        neg_24 = torch.ops.aten.neg.default(convert_element_type_675)
        exp_36 = torch.ops.aten.exp.default(neg_24);  neg_24 = None
        add_816 = torch.ops.aten.add.Tensor(exp_36, 1);  exp_36 = None
        div_60 = torch.ops.aten.div.Tensor(convert_element_type_675, add_816);  convert_element_type_675 = add_816 = None
        convert_element_type_676 = torch.ops.prims.convert_element_type.default(div_60, torch.bfloat16);  div_60 = None
        convert_element_type_677 = torch.ops.prims.convert_element_type.default(primals_213, torch.bfloat16)
        all_gather_into_tensor_213 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_677, 128, '0');  convert_element_type_677 = None
        wait_tensor_261 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_213);  all_gather_into_tensor_213 = None
        permute_189 = torch.ops.aten.permute.default(wait_tensor_261, [1, 0]);  wait_tensor_261 = None
        mm_101 = torch.ops.aten.mm.default(view_795, permute_189);  permute_189 = None
        mul_594 = torch.ops.aten.mul.Tensor(convert_element_type_676, mm_101);  convert_element_type_676 = None
        convert_element_type_680 = torch.ops.prims.convert_element_type.default(primals_214, torch.bfloat16)
        all_gather_into_tensor_214 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_680, 128, '0');  convert_element_type_680 = None
        wait_tensor_262 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_214);  all_gather_into_tensor_214 = None
        permute_190 = torch.ops.aten.permute.default(wait_tensor_262, [1, 0]);  wait_tensor_262 = None
        mm_102 = torch.ops.aten.mm.default(mul_594, permute_190);  permute_190 = None
        index_put_23 = torch.ops.aten.index_put.default(full_default_1, [getitem_1231], wait_tensor_259);  wait_tensor_259 = None
        view_835 = torch.ops.aten.view.default(mul_556, [-1, 1, 6]);  mul_556 = None
        view_836 = torch.ops.aten.view.default(index_put_23, [-1, 6, 2048]);  index_put_23 = None
        convert_element_type_683 = torch.ops.prims.convert_element_type.default(view_836, torch.float32);  view_836 = None
        bmm_11 = torch.ops.aten.bmm.default(view_835, convert_element_type_683)
        convert_element_type_684 = torch.ops.prims.convert_element_type.default(bmm_11, torch.bfloat16);  bmm_11 = None
        squeeze_11 = torch.ops.aten.squeeze.dim(convert_element_type_684, 1);  convert_element_type_684 = None
        add_820 = torch.ops.aten.add.Tensor(mm_102, squeeze_11);  mm_102 = squeeze_11 = None
        view_837 = torch.ops.aten.view.default(add_820, [2, 4096, 2048]);  add_820 = None
        add_821 = torch.ops.aten.add.Tensor(add_756, view_837);  view_837 = None
        convert_element_type_685 = torch.ops.prims.convert_element_type.default(primals_215, torch.bfloat16)
        all_gather_into_tensor_215 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_685, 128, '0');  convert_element_type_685 = None
        wait_tensor_263 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_215);  all_gather_into_tensor_215 = None
        convert_element_type_686 = torch.ops.prims.convert_element_type.default(add_821, torch.float32)
        pow_40 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_686, 2)
        mean_39 = torch.ops.aten.mean.dim(pow_40, [2], True);  pow_40 = None
        add_822 = torch.ops.aten.add.Scalar(mean_39, 1e-05);  mean_39 = None
        rsqrt_39 = torch.ops.aten.rsqrt.default(add_822);  add_822 = None
        mul_597 = torch.ops.aten.mul.Tensor(convert_element_type_686, rsqrt_39);  convert_element_type_686 = None
        mul_598 = torch.ops.aten.mul.Tensor(mul_597, wait_tensor_263);  mul_597 = wait_tensor_263 = None
        convert_element_type_687 = torch.ops.prims.convert_element_type.default(mul_598, torch.bfloat16);  mul_598 = None
        convert_element_type_688 = torch.ops.prims.convert_element_type.default(primals_216, torch.bfloat16)
        all_gather_into_tensor_216 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_688, 128, '0');  convert_element_type_688 = None
        wait_tensor_264 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_216);  all_gather_into_tensor_216 = None
        permute_191 = torch.ops.aten.permute.default(wait_tensor_264, [1, 0]);  wait_tensor_264 = None
        view_840 = torch.ops.aten.view.default(convert_element_type_687, [8192, 2048]);  convert_element_type_687 = None
        mm_103 = torch.ops.aten.mm.default(view_840, permute_191);  permute_191 = None
        view_841 = torch.ops.aten.view.default(mm_103, [2, 4096, 3072]);  mm_103 = None
        view_842 = torch.ops.aten.view.default(view_841, [2, 4096, -1, 192]);  view_841 = None
        split_with_sizes_39 = torch.ops.aten.split_with_sizes.default(view_842, [128, 64], -1);  view_842 = None
        getitem_1329 = split_with_sizes_39[0]
        getitem_1330 = split_with_sizes_39[1];  split_with_sizes_39 = None
        convert_element_type_691 = torch.ops.prims.convert_element_type.default(getitem_1330, torch.float32);  getitem_1330 = None
        view_843 = torch.ops.aten.view.default(convert_element_type_691, [2, 4096, 16, -1, 2]);  convert_element_type_691 = None
        view_as_complex_26 = torch.ops.aten.view_as_complex.default(view_843);  view_843 = None
        mul_599 = torch.ops.aten.mul.Tensor(view_as_complex_26, view_7);  view_as_complex_26 = None
        view_as_real_26 = torch.ops.aten.view_as_real.default(mul_599);  mul_599 = None
        view_845 = torch.ops.aten.view.default(view_as_real_26, [2, 4096, 16, 64]);  view_as_real_26 = None
        convert_element_type_692 = torch.ops.prims.convert_element_type.default(view_845, torch.bfloat16);  view_845 = None
        cat_110 = torch.ops.aten.cat.default([getitem_1329, convert_element_type_692], -1);  getitem_1329 = convert_element_type_692 = None
        convert_element_type_693 = torch.ops.prims.convert_element_type.default(primals_217, torch.bfloat16)
        all_gather_into_tensor_217 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_693, 128, '0');  convert_element_type_693 = None
        wait_tensor_265 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_217);  all_gather_into_tensor_217 = None
        slice_79 = torch.ops.aten.slice.Tensor(wait_tensor_265, 0, 0, 576);  wait_tensor_265 = None
        permute_192 = torch.ops.aten.permute.default(slice_79, [1, 0]);  slice_79 = None
        mm_104 = torch.ops.aten.mm.default(view_840, permute_192);  permute_192 = None
        view_848 = torch.ops.aten.view.default(mm_104, [2, 4096, 576]);  mm_104 = None
        split_with_sizes_40 = torch.ops.aten.split_with_sizes.default(view_848, [512, 64], -1);  view_848 = None
        getitem_1331 = split_with_sizes_40[0]
        getitem_1332 = split_with_sizes_40[1];  split_with_sizes_40 = None
        unsqueeze_25 = torch.ops.aten.unsqueeze.default(getitem_1332, 2);  getitem_1332 = None
        convert_element_type_696 = torch.ops.prims.convert_element_type.default(unsqueeze_25, torch.float32);  unsqueeze_25 = None
        view_849 = torch.ops.aten.view.default(convert_element_type_696, [2, 4096, 1, -1, 2]);  convert_element_type_696 = None
        view_as_complex_27 = torch.ops.aten.view_as_complex.default(view_849);  view_849 = None
        mul_600 = torch.ops.aten.mul.Tensor(view_as_complex_27, view_7);  view_as_complex_27 = None
        view_as_real_27 = torch.ops.aten.view_as_real.default(mul_600);  mul_600 = None
        view_851 = torch.ops.aten.view.default(view_as_real_27, [2, 4096, 1, 64]);  view_as_real_27 = None
        convert_element_type_697 = torch.ops.prims.convert_element_type.default(view_851, torch.bfloat16);  view_851 = None
        convert_element_type_698 = torch.ops.prims.convert_element_type.default(primals_218, torch.bfloat16)
        all_gather_into_tensor_218 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_698, 128, '0');  convert_element_type_698 = None
        wait_tensor_266 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_218);  all_gather_into_tensor_218 = None
        convert_element_type_699 = torch.ops.prims.convert_element_type.default(getitem_1331, torch.float32)
        pow_41 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_699, 2)
        mean_40 = torch.ops.aten.mean.dim(pow_41, [2], True);  pow_41 = None
        add_823 = torch.ops.aten.add.Scalar(mean_40, 1e-05);  mean_40 = None
        rsqrt_40 = torch.ops.aten.rsqrt.default(add_823);  add_823 = None
        mul_601 = torch.ops.aten.mul.Tensor(convert_element_type_699, rsqrt_40);  convert_element_type_699 = None
        mul_602 = torch.ops.aten.mul.Tensor(mul_601, wait_tensor_266);  mul_601 = wait_tensor_266 = None
        convert_element_type_700 = torch.ops.prims.convert_element_type.default(mul_602, torch.bfloat16);  mul_602 = None
        convert_element_type_701 = torch.ops.prims.convert_element_type.default(primals_219, torch.bfloat16)
        all_gather_into_tensor_219 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_701, 128, '0');  convert_element_type_701 = None
        wait_tensor_267 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_219);  all_gather_into_tensor_219 = None
        permute_193 = torch.ops.aten.permute.default(wait_tensor_267, [1, 0]);  wait_tensor_267 = None
        view_854 = torch.ops.aten.view.default(convert_element_type_700, [8192, 512]);  convert_element_type_700 = None
        mm_105 = torch.ops.aten.mm.default(view_854, permute_193);  permute_193 = None
        view_855 = torch.ops.aten.view.default(mm_105, [2, 4096, 4096]);  mm_105 = None
        view_856 = torch.ops.aten.view.default(view_855, [2, 4096, -1, 256]);  view_855 = None
        split_with_sizes_41 = torch.ops.aten.split_with_sizes.default(view_856, [128, 128], -1);  view_856 = None
        getitem_1333 = split_with_sizes_41[0]
        getitem_1334 = split_with_sizes_41[1];  split_with_sizes_41 = None
        expand_13 = torch.ops.aten.expand.default(convert_element_type_697, [-1, -1, 16, -1]);  convert_element_type_697 = None
        cat_111 = torch.ops.aten.cat.default([getitem_1333, expand_13], -1);  getitem_1333 = expand_13 = None
        permute_194 = torch.ops.aten.permute.default(cat_110, [0, 2, 1, 3]);  cat_110 = None
        permute_195 = torch.ops.aten.permute.default(cat_111, [0, 2, 1, 3]);  cat_111 = None
        permute_196 = torch.ops.aten.permute.default(getitem_1334, [0, 2, 1, 3]);  getitem_1334 = None
        sdpa_score13 = self.sdpa_score13
        sdpa_mask13 = self.sdpa_mask13
        flex_attention_13 = torch.ops.higher_order.flex_attention(permute_194, permute_195, permute_196, sdpa_score13, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask13), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score13 = sdpa_mask13 = None
        getitem_1335 = flex_attention_13[0]
        getitem_1336 = flex_attention_13[1];  flex_attention_13 = None
        permute_197 = torch.ops.aten.permute.default(getitem_1335, [0, 2, 1, 3])
        view_857 = torch.ops.aten.view.default(permute_197, [2, 4096, -1]);  permute_197 = None
        convert_element_type_704 = torch.ops.prims.convert_element_type.default(primals_220, torch.bfloat16)
        all_gather_into_tensor_220 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_704, 128, '0');  convert_element_type_704 = None
        wait_tensor_268 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_220);  all_gather_into_tensor_220 = None
        permute_198 = torch.ops.aten.permute.default(wait_tensor_268, [1, 0]);  wait_tensor_268 = None
        view_859 = torch.ops.aten.view.default(view_857, [8192, 2048]);  view_857 = None
        mm_106 = torch.ops.aten.mm.default(view_859, permute_198);  view_859 = permute_198 = None
        view_860 = torch.ops.aten.view.default(mm_106, [2, 4096, 2048]);  mm_106 = None
        add_824 = torch.ops.aten.add.Tensor(add_821, view_860);  view_860 = None
        convert_element_type_707 = torch.ops.prims.convert_element_type.default(primals_221, torch.bfloat16)
        all_gather_into_tensor_221 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_707, 128, '0');  convert_element_type_707 = None
        wait_tensor_269 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_221);  all_gather_into_tensor_221 = None
        convert_element_type_708 = torch.ops.prims.convert_element_type.default(add_824, torch.float32)
        pow_42 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_708, 2)
        mean_41 = torch.ops.aten.mean.dim(pow_42, [2], True);  pow_42 = None
        add_825 = torch.ops.aten.add.Scalar(mean_41, 1e-05);  mean_41 = None
        rsqrt_41 = torch.ops.aten.rsqrt.default(add_825);  add_825 = None
        mul_603 = torch.ops.aten.mul.Tensor(convert_element_type_708, rsqrt_41);  convert_element_type_708 = None
        mul_604 = torch.ops.aten.mul.Tensor(mul_603, wait_tensor_269);  mul_603 = wait_tensor_269 = None
        convert_element_type_709 = torch.ops.prims.convert_element_type.default(mul_604, torch.bfloat16);  mul_604 = None
        view_862 = torch.ops.aten.view.default(convert_element_type_709, [-1, 2048]);  convert_element_type_709 = None
        convert_element_type_710 = torch.ops.prims.convert_element_type.default(primals_223, torch.bfloat16)
        all_gather_into_tensor_222 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_710, 128, '0');  convert_element_type_710 = None
        wait_tensor_270 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_222);  all_gather_into_tensor_222 = None
        slice_81 = torch.ops.aten.slice.Tensor(wait_tensor_270, 0, 0, 64);  wait_tensor_270 = None
        permute_199 = torch.ops.aten.permute.default(slice_81, [1, 0]);  slice_81 = None
        mm_107 = torch.ops.aten.mm.default(view_862, permute_199);  permute_199 = None
        convert_element_type_713 = torch.ops.prims.convert_element_type.default(mm_107, torch.float32)
        amax_12 = torch.ops.aten.amax.default(convert_element_type_713, [1], True)
        sub_288 = torch.ops.aten.sub.Tensor(convert_element_type_713, amax_12);  convert_element_type_713 = None
        exp_37 = torch.ops.aten.exp.default(sub_288);  sub_288 = None
        sum_49 = torch.ops.aten.sum.dim_IntList(exp_37, [1], True)
        div_61 = torch.ops.aten.div.Tensor(exp_37, sum_49);  exp_37 = None
        add_826 = torch.ops.aten.add.Tensor(div_61, primals_222);  primals_222 = None
        topk_12 = torch.ops.aten.topk.default(add_826, 6, -1, True, False);  add_826 = None
        getitem_1339 = topk_12[1];  topk_12 = None
        gather_12 = torch.ops.aten.gather.default(div_61, 1, getitem_1339);  div_61 = None
        mul_605 = torch.ops.aten.mul.Tensor(gather_12, 1.0);  gather_12 = None
        view_864 = torch.ops.aten.view.default(getitem_1339, [-1])
        histc_24 = torch.ops.aten.histc.default(view_864, 64, 0, 64)
        add_827 = torch.ops.aten.add.Tensor(primals_224, histc_24)
        sort_12 = torch.ops.aten.sort.stable(view_864, stable = True);  view_864 = None
        getitem_1341 = sort_12[1];  sort_12 = None
        div_62 = torch.ops.aten.div.Tensor_mode(getitem_1341, 6, rounding_mode = 'floor')
        index_24 = torch.ops.aten.index.Tensor(view_862, [div_62])
        all_to_all_single_36 = torch.ops._c10d_functional.all_to_all_single.default(histc_24, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_271 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_36);  all_to_all_single_36 = None
        wait_tensor_272 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_271);  wait_tensor_271 = None
        view_868 = torch.ops.aten.view.default(histc_24, [8, -1]);  histc_24 = None
        sum_50 = torch.ops.aten.sum.dim_IntList(view_868, [1]);  view_868 = None
        device_put_24 = torch.ops.prims.device_put.default(sum_50, device(type='cpu'), True);  sum_50 = None
        view_869 = torch.ops.aten.view.default(wait_tensor_272, [8, -1])
        sum_51 = torch.ops.aten.sum.dim_IntList(view_869, [1])
        device_put_25 = torch.ops.prims.device_put.default(sum_51, device(type='cpu'));  sum_51 = None
        select_192 = torch.ops.aten.select.int(device_put_24, 0, 0)
        _local_scalar_dense_192 = torch.ops.aten._local_scalar_dense.default(select_192);  select_192 = None
        ge_240 = _local_scalar_dense_192 >= 0
        _assert_scalar_192 = torch.ops.aten._assert_scalar.default(ge_240, "Runtime assertion failed for expression u192 >= 0 on node 'ge_192'");  ge_240 = _assert_scalar_192 = None
        select_193 = torch.ops.aten.select.int(device_put_24, 0, 1)
        _local_scalar_dense_193 = torch.ops.aten._local_scalar_dense.default(select_193);  select_193 = None
        ge_241 = _local_scalar_dense_193 >= 0
        _assert_scalar_193 = torch.ops.aten._assert_scalar.default(ge_241, "Runtime assertion failed for expression u193 >= 0 on node 'ge_193'");  ge_241 = _assert_scalar_193 = None
        select_194 = torch.ops.aten.select.int(device_put_24, 0, 2)
        _local_scalar_dense_194 = torch.ops.aten._local_scalar_dense.default(select_194);  select_194 = None
        ge_242 = _local_scalar_dense_194 >= 0
        _assert_scalar_194 = torch.ops.aten._assert_scalar.default(ge_242, "Runtime assertion failed for expression u194 >= 0 on node 'ge_194'");  ge_242 = _assert_scalar_194 = None
        select_195 = torch.ops.aten.select.int(device_put_24, 0, 3)
        _local_scalar_dense_195 = torch.ops.aten._local_scalar_dense.default(select_195);  select_195 = None
        ge_243 = _local_scalar_dense_195 >= 0
        _assert_scalar_195 = torch.ops.aten._assert_scalar.default(ge_243, "Runtime assertion failed for expression u195 >= 0 on node 'ge_195'");  ge_243 = _assert_scalar_195 = None
        select_196 = torch.ops.aten.select.int(device_put_24, 0, 4)
        _local_scalar_dense_196 = torch.ops.aten._local_scalar_dense.default(select_196);  select_196 = None
        ge_244 = _local_scalar_dense_196 >= 0
        _assert_scalar_196 = torch.ops.aten._assert_scalar.default(ge_244, "Runtime assertion failed for expression u196 >= 0 on node 'ge_196'");  ge_244 = _assert_scalar_196 = None
        select_197 = torch.ops.aten.select.int(device_put_24, 0, 5)
        _local_scalar_dense_197 = torch.ops.aten._local_scalar_dense.default(select_197);  select_197 = None
        ge_245 = _local_scalar_dense_197 >= 0
        _assert_scalar_197 = torch.ops.aten._assert_scalar.default(ge_245, "Runtime assertion failed for expression u197 >= 0 on node 'ge_197'");  ge_245 = _assert_scalar_197 = None
        select_198 = torch.ops.aten.select.int(device_put_24, 0, 6)
        _local_scalar_dense_198 = torch.ops.aten._local_scalar_dense.default(select_198);  select_198 = None
        ge_246 = _local_scalar_dense_198 >= 0
        _assert_scalar_198 = torch.ops.aten._assert_scalar.default(ge_246, "Runtime assertion failed for expression u198 >= 0 on node 'ge_198'");  ge_246 = _assert_scalar_198 = None
        select_199 = torch.ops.aten.select.int(device_put_24, 0, 7);  device_put_24 = None
        _local_scalar_dense_199 = torch.ops.aten._local_scalar_dense.default(select_199);  select_199 = None
        ge_247 = _local_scalar_dense_199 >= 0
        _assert_scalar_199 = torch.ops.aten._assert_scalar.default(ge_247, "Runtime assertion failed for expression u199 >= 0 on node 'ge_199'");  ge_247 = _assert_scalar_199 = None
        select_200 = torch.ops.aten.select.int(device_put_25, 0, 0)
        _local_scalar_dense_200 = torch.ops.aten._local_scalar_dense.default(select_200);  select_200 = None
        ge_248 = _local_scalar_dense_200 >= 0
        _assert_scalar_200 = torch.ops.aten._assert_scalar.default(ge_248, "Runtime assertion failed for expression u200 >= 0 on node 'ge_200'");  ge_248 = _assert_scalar_200 = None
        select_201 = torch.ops.aten.select.int(device_put_25, 0, 1)
        _local_scalar_dense_201 = torch.ops.aten._local_scalar_dense.default(select_201);  select_201 = None
        ge_249 = _local_scalar_dense_201 >= 0
        _assert_scalar_201 = torch.ops.aten._assert_scalar.default(ge_249, "Runtime assertion failed for expression u201 >= 0 on node 'ge_201'");  ge_249 = _assert_scalar_201 = None
        select_202 = torch.ops.aten.select.int(device_put_25, 0, 2)
        _local_scalar_dense_202 = torch.ops.aten._local_scalar_dense.default(select_202);  select_202 = None
        ge_250 = _local_scalar_dense_202 >= 0
        _assert_scalar_202 = torch.ops.aten._assert_scalar.default(ge_250, "Runtime assertion failed for expression u202 >= 0 on node 'ge_202'");  ge_250 = _assert_scalar_202 = None
        select_203 = torch.ops.aten.select.int(device_put_25, 0, 3)
        _local_scalar_dense_203 = torch.ops.aten._local_scalar_dense.default(select_203);  select_203 = None
        ge_251 = _local_scalar_dense_203 >= 0
        _assert_scalar_203 = torch.ops.aten._assert_scalar.default(ge_251, "Runtime assertion failed for expression u203 >= 0 on node 'ge_203'");  ge_251 = _assert_scalar_203 = None
        select_204 = torch.ops.aten.select.int(device_put_25, 0, 4)
        _local_scalar_dense_204 = torch.ops.aten._local_scalar_dense.default(select_204);  select_204 = None
        ge_252 = _local_scalar_dense_204 >= 0
        _assert_scalar_204 = torch.ops.aten._assert_scalar.default(ge_252, "Runtime assertion failed for expression u204 >= 0 on node 'ge_204'");  ge_252 = _assert_scalar_204 = None
        select_205 = torch.ops.aten.select.int(device_put_25, 0, 5)
        _local_scalar_dense_205 = torch.ops.aten._local_scalar_dense.default(select_205);  select_205 = None
        ge_253 = _local_scalar_dense_205 >= 0
        _assert_scalar_205 = torch.ops.aten._assert_scalar.default(ge_253, "Runtime assertion failed for expression u205 >= 0 on node 'ge_205'");  ge_253 = _assert_scalar_205 = None
        select_206 = torch.ops.aten.select.int(device_put_25, 0, 6)
        _local_scalar_dense_206 = torch.ops.aten._local_scalar_dense.default(select_206);  select_206 = None
        ge_254 = _local_scalar_dense_206 >= 0
        _assert_scalar_206 = torch.ops.aten._assert_scalar.default(ge_254, "Runtime assertion failed for expression u206 >= 0 on node 'ge_206'");  ge_254 = _assert_scalar_206 = None
        select_207 = torch.ops.aten.select.int(device_put_25, 0, 7);  device_put_25 = None
        _local_scalar_dense_207 = torch.ops.aten._local_scalar_dense.default(select_207);  select_207 = None
        ge_255 = _local_scalar_dense_207 >= 0
        _assert_scalar_207 = torch.ops.aten._assert_scalar.default(ge_255, "Runtime assertion failed for expression u207 >= 0 on node 'ge_207'");  ge_255 = _assert_scalar_207 = None
        all_to_all_single_37 = torch.ops._c10d_functional.all_to_all_single.default(index_24, [_local_scalar_dense_200, _local_scalar_dense_201, _local_scalar_dense_202, _local_scalar_dense_203, _local_scalar_dense_204, _local_scalar_dense_205, _local_scalar_dense_206, _local_scalar_dense_207], [_local_scalar_dense_192, _local_scalar_dense_193, _local_scalar_dense_194, _local_scalar_dense_195, _local_scalar_dense_196, _local_scalar_dense_197, _local_scalar_dense_198, _local_scalar_dense_199], '1033');  index_24 = None
        sym_size_int_48 = torch.ops.aten.sym_size.int(all_to_all_single_37, 0)
        wait_tensor_273 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_37);  all_to_all_single_37 = None
        sym_sum_24 = torch.sym_sum((_local_scalar_dense_200, _local_scalar_dense_201, _local_scalar_dense_202, _local_scalar_dense_203, _local_scalar_dense_204, _local_scalar_dense_205, _local_scalar_dense_206, _local_scalar_dense_207))
        add_834 = sym_sum_24 + 64;  sym_sum_24 = None
        add_835 = add_834 + 8;  add_834 = None
        sub_291 = add_835 - 1;  add_835 = None
        floordiv_12 = sub_291 // 8;  sub_291 = None
        mul_610 = floordiv_12 * 8;  floordiv_12 = None
        cumsum_36 = torch.ops.aten.cumsum.default(wait_tensor_272, 0)
        sub_292 = torch.ops.aten.sub.Tensor(cumsum_36, wait_tensor_272);  cumsum_36 = None
        sum_52 = torch.ops.aten.sum.dim_IntList(view_869, [0]);  view_869 = None
        clamp_min_12 = torch.ops.aten.clamp_min.default(sum_52, 8);  sum_52 = None
        add_836 = torch.ops.aten.add.Tensor(clamp_min_12, 8);  clamp_min_12 = None
        sub_293 = torch.ops.aten.sub.Tensor(add_836, 1);  add_836 = None
        div_63 = torch.ops.aten.div.Tensor_mode(sub_293, 8, rounding_mode = 'floor');  sub_293 = None
        mul_611 = torch.ops.aten.mul.Tensor(div_63, 8);  div_63 = None
        convert_element_type_716 = torch.ops.prims.convert_element_type.default(mul_611, torch.int32);  mul_611 = None
        cumsum_37 = torch.ops.aten.cumsum.default(convert_element_type_716, 0)
        sub_294 = torch.ops.aten.sub.Tensor(cumsum_37, convert_element_type_716);  cumsum_37 = None
        full_176 = torch.ops.aten.full.default([mul_610], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_610 = None
        triton_kernel_wrapper_functional_proxy_12 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 12, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_272, 'start_index_values_ptr': sub_292, 'write_offsets_ptr': sub_294, 'output_ptr': full_176}, tensors_to_clone = ['output_ptr']);  wait_tensor_272 = sub_292 = sub_294 = full_176 = None
        getitem_1342 = triton_kernel_wrapper_functional_proxy_12['output_ptr'];  triton_kernel_wrapper_functional_proxy_12 = None
        cat_112 = torch.ops.aten.cat.default([wait_tensor_273, full_default]);  wait_tensor_273 = None
        sym_size_int_49 = torch.ops.aten.sym_size.int(cat_112, 0)
        sym_sum_25 = torch.sym_sum((1, _local_scalar_dense_200, _local_scalar_dense_201, _local_scalar_dense_202, _local_scalar_dense_203, _local_scalar_dense_204, _local_scalar_dense_205, _local_scalar_dense_206, _local_scalar_dense_207))
        index_25 = torch.ops.aten.index.Tensor(cat_112, [getitem_1342]);  cat_112 = None
        convert_element_type_718 = torch.ops.prims.convert_element_type.default(primals_225, torch.bfloat16)
        all_gather_into_tensor_223 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_718, 16, '1025');  convert_element_type_718 = None
        wait_tensor_274 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_223);  all_gather_into_tensor_223 = None
        split_73 = torch.ops.aten.split.Tensor(wait_tensor_274, 8);  wait_tensor_274 = None
        getitem_1359 = split_73[0]
        getitem_1360 = split_73[1]
        getitem_1361 = split_73[2]
        getitem_1362 = split_73[3]
        getitem_1363 = split_73[4]
        getitem_1364 = split_73[5]
        getitem_1365 = split_73[6]
        getitem_1366 = split_73[7]
        getitem_1367 = split_73[8]
        getitem_1368 = split_73[9]
        getitem_1369 = split_73[10]
        getitem_1370 = split_73[11]
        getitem_1371 = split_73[12]
        getitem_1372 = split_73[13]
        getitem_1373 = split_73[14]
        getitem_1374 = split_73[15];  split_73 = None
        cat_114 = torch.ops.aten.cat.default([getitem_1359, getitem_1360, getitem_1361, getitem_1362, getitem_1363, getitem_1364, getitem_1365, getitem_1366, getitem_1367, getitem_1368, getitem_1369, getitem_1370, getitem_1371, getitem_1372, getitem_1373, getitem_1374], 1);  getitem_1359 = getitem_1360 = getitem_1361 = getitem_1362 = getitem_1363 = getitem_1364 = getitem_1365 = getitem_1366 = getitem_1367 = getitem_1368 = getitem_1369 = getitem_1370 = getitem_1371 = getitem_1372 = getitem_1373 = getitem_1374 = None
        convert_element_type_720 = torch.ops.prims.convert_element_type.default(primals_226, torch.bfloat16)
        all_gather_into_tensor_225 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_720, 16, '1025');  convert_element_type_720 = None
        wait_tensor_276 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_225);  all_gather_into_tensor_225 = None
        split_74 = torch.ops.aten.split.Tensor(wait_tensor_276, 8);  wait_tensor_276 = None
        getitem_1375 = split_74[0]
        getitem_1376 = split_74[1]
        getitem_1377 = split_74[2]
        getitem_1378 = split_74[3]
        getitem_1379 = split_74[4]
        getitem_1380 = split_74[5]
        getitem_1381 = split_74[6]
        getitem_1382 = split_74[7]
        getitem_1383 = split_74[8]
        getitem_1384 = split_74[9]
        getitem_1385 = split_74[10]
        getitem_1386 = split_74[11]
        getitem_1387 = split_74[12]
        getitem_1388 = split_74[13]
        getitem_1389 = split_74[14]
        getitem_1390 = split_74[15];  split_74 = None
        cat_115 = torch.ops.aten.cat.default([getitem_1375, getitem_1376, getitem_1377, getitem_1378, getitem_1379, getitem_1380, getitem_1381, getitem_1382, getitem_1383, getitem_1384, getitem_1385, getitem_1386, getitem_1387, getitem_1388, getitem_1389, getitem_1390], 1);  getitem_1375 = getitem_1376 = getitem_1377 = getitem_1378 = getitem_1379 = getitem_1380 = getitem_1381 = getitem_1382 = getitem_1383 = getitem_1384 = getitem_1385 = getitem_1386 = getitem_1387 = getitem_1388 = getitem_1389 = getitem_1390 = None
        convert_element_type_721 = torch.ops.prims.convert_element_type.default(primals_227, torch.bfloat16)
        all_gather_into_tensor_226 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_721, 16, '1025');  convert_element_type_721 = None
        wait_tensor_277 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_226);  all_gather_into_tensor_226 = None
        split_75 = torch.ops.aten.split.Tensor(wait_tensor_277, 8);  wait_tensor_277 = None
        getitem_1391 = split_75[0]
        getitem_1392 = split_75[1]
        getitem_1393 = split_75[2]
        getitem_1394 = split_75[3]
        getitem_1395 = split_75[4]
        getitem_1396 = split_75[5]
        getitem_1397 = split_75[6]
        getitem_1398 = split_75[7]
        getitem_1399 = split_75[8]
        getitem_1400 = split_75[9]
        getitem_1401 = split_75[10]
        getitem_1402 = split_75[11]
        getitem_1403 = split_75[12]
        getitem_1404 = split_75[13]
        getitem_1405 = split_75[14]
        getitem_1406 = split_75[15];  split_75 = None
        cat_116 = torch.ops.aten.cat.default([getitem_1391, getitem_1392, getitem_1393, getitem_1394, getitem_1395, getitem_1396, getitem_1397, getitem_1398, getitem_1399, getitem_1400, getitem_1401, getitem_1402, getitem_1403, getitem_1404, getitem_1405, getitem_1406], 1);  getitem_1391 = getitem_1392 = getitem_1393 = getitem_1394 = getitem_1395 = getitem_1396 = getitem_1397 = getitem_1398 = getitem_1399 = getitem_1400 = getitem_1401 = getitem_1402 = getitem_1403 = getitem_1404 = getitem_1405 = getitem_1406 = None
        cumsum_38 = torch.ops.aten.cumsum.default(convert_element_type_716, 0, dtype = torch.int32);  convert_element_type_716 = None
        permute_200 = torch.ops.aten.permute.default(cat_114, [0, 2, 1]);  cat_114 = None
        _grouped_mm_36 = torch.ops.aten._grouped_mm.default(index_25, permute_200, cumsum_38)
        convert_element_type_724 = torch.ops.prims.convert_element_type.default(_grouped_mm_36, torch.float32)
        neg_25 = torch.ops.aten.neg.default(convert_element_type_724)
        exp_38 = torch.ops.aten.exp.default(neg_25);  neg_25 = None
        add_848 = torch.ops.aten.add.Tensor(exp_38, 1);  exp_38 = None
        div_64 = torch.ops.aten.div.Tensor(convert_element_type_724, add_848);  convert_element_type_724 = add_848 = None
        convert_element_type_725 = torch.ops.prims.convert_element_type.default(div_64, torch.bfloat16);  div_64 = None
        permute_201 = torch.ops.aten.permute.default(cat_116, [0, 2, 1]);  cat_116 = None
        _grouped_mm_37 = torch.ops.aten._grouped_mm.default(index_25, permute_201, cumsum_38)
        mul_623 = torch.ops.aten.mul.Tensor(convert_element_type_725, _grouped_mm_37);  convert_element_type_725 = None
        permute_202 = torch.ops.aten.permute.default(cat_115, [0, 2, 1]);  cat_115 = None
        _grouped_mm_38 = torch.ops.aten._grouped_mm.default(mul_623, permute_202, cumsum_38)
        empty_12 = torch.ops.aten.empty.memory_format([sym_size_int_49, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_24 = torch.ops.aten.index_put.default(empty_12, [getitem_1342], _grouped_mm_38);  empty_12 = _grouped_mm_38 = None
        slice_83 = torch.ops.aten.slice.Tensor(index_put_24, 0, 0, -1);  index_put_24 = None
        all_to_all_single_38 = torch.ops._c10d_functional.all_to_all_single.default(slice_83, [_local_scalar_dense_192, _local_scalar_dense_193, _local_scalar_dense_194, _local_scalar_dense_195, _local_scalar_dense_196, _local_scalar_dense_197, _local_scalar_dense_198, _local_scalar_dense_199], [_local_scalar_dense_200, _local_scalar_dense_201, _local_scalar_dense_202, _local_scalar_dense_203, _local_scalar_dense_204, _local_scalar_dense_205, _local_scalar_dense_206, _local_scalar_dense_207], '1033');  slice_83 = None
        wait_tensor_280 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_38);  all_to_all_single_38 = None
        convert_element_type_726 = torch.ops.prims.convert_element_type.default(primals_228, torch.bfloat16)
        all_gather_into_tensor_229 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_726, 128, '0');  convert_element_type_726 = None
        wait_tensor_281 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_229);  all_gather_into_tensor_229 = None
        permute_203 = torch.ops.aten.permute.default(wait_tensor_281, [1, 0]);  wait_tensor_281 = None
        mm_108 = torch.ops.aten.mm.default(view_862, permute_203);  permute_203 = None
        convert_element_type_729 = torch.ops.prims.convert_element_type.default(mm_108, torch.float32)
        neg_26 = torch.ops.aten.neg.default(convert_element_type_729)
        exp_39 = torch.ops.aten.exp.default(neg_26);  neg_26 = None
        add_884 = torch.ops.aten.add.Tensor(exp_39, 1);  exp_39 = None
        div_65 = torch.ops.aten.div.Tensor(convert_element_type_729, add_884);  convert_element_type_729 = add_884 = None
        convert_element_type_730 = torch.ops.prims.convert_element_type.default(div_65, torch.bfloat16);  div_65 = None
        convert_element_type_731 = torch.ops.prims.convert_element_type.default(primals_229, torch.bfloat16)
        all_gather_into_tensor_230 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_731, 128, '0');  convert_element_type_731 = None
        wait_tensor_282 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_230);  all_gather_into_tensor_230 = None
        permute_204 = torch.ops.aten.permute.default(wait_tensor_282, [1, 0]);  wait_tensor_282 = None
        mm_109 = torch.ops.aten.mm.default(view_862, permute_204);  permute_204 = None
        mul_643 = torch.ops.aten.mul.Tensor(convert_element_type_730, mm_109);  convert_element_type_730 = None
        convert_element_type_734 = torch.ops.prims.convert_element_type.default(primals_230, torch.bfloat16)
        all_gather_into_tensor_231 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_734, 128, '0');  convert_element_type_734 = None
        wait_tensor_283 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_231);  all_gather_into_tensor_231 = None
        permute_205 = torch.ops.aten.permute.default(wait_tensor_283, [1, 0]);  wait_tensor_283 = None
        mm_110 = torch.ops.aten.mm.default(mul_643, permute_205);  permute_205 = None
        index_put_25 = torch.ops.aten.index_put.default(full_default_1, [getitem_1341], wait_tensor_280);  wait_tensor_280 = None
        view_902 = torch.ops.aten.view.default(mul_605, [-1, 1, 6]);  mul_605 = None
        view_903 = torch.ops.aten.view.default(index_put_25, [-1, 6, 2048]);  index_put_25 = None
        convert_element_type_737 = torch.ops.prims.convert_element_type.default(view_903, torch.float32);  view_903 = None
        bmm_12 = torch.ops.aten.bmm.default(view_902, convert_element_type_737)
        convert_element_type_738 = torch.ops.prims.convert_element_type.default(bmm_12, torch.bfloat16);  bmm_12 = None
        squeeze_12 = torch.ops.aten.squeeze.dim(convert_element_type_738, 1);  convert_element_type_738 = None
        add_888 = torch.ops.aten.add.Tensor(mm_110, squeeze_12);  mm_110 = squeeze_12 = None
        view_904 = torch.ops.aten.view.default(add_888, [2, 4096, 2048]);  add_888 = None
        add_889 = torch.ops.aten.add.Tensor(add_824, view_904);  view_904 = None
        convert_element_type_739 = torch.ops.prims.convert_element_type.default(primals_231, torch.bfloat16)
        all_gather_into_tensor_232 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_739, 128, '0');  convert_element_type_739 = None
        wait_tensor_284 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_232);  all_gather_into_tensor_232 = None
        convert_element_type_740 = torch.ops.prims.convert_element_type.default(add_889, torch.float32)
        pow_43 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_740, 2)
        mean_42 = torch.ops.aten.mean.dim(pow_43, [2], True);  pow_43 = None
        add_890 = torch.ops.aten.add.Scalar(mean_42, 1e-05);  mean_42 = None
        rsqrt_42 = torch.ops.aten.rsqrt.default(add_890);  add_890 = None
        mul_646 = torch.ops.aten.mul.Tensor(convert_element_type_740, rsqrt_42);  convert_element_type_740 = None
        mul_647 = torch.ops.aten.mul.Tensor(mul_646, wait_tensor_284);  mul_646 = wait_tensor_284 = None
        convert_element_type_741 = torch.ops.prims.convert_element_type.default(mul_647, torch.bfloat16);  mul_647 = None
        convert_element_type_742 = torch.ops.prims.convert_element_type.default(primals_232, torch.bfloat16)
        all_gather_into_tensor_233 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_742, 128, '0');  convert_element_type_742 = None
        wait_tensor_285 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_233);  all_gather_into_tensor_233 = None
        permute_206 = torch.ops.aten.permute.default(wait_tensor_285, [1, 0]);  wait_tensor_285 = None
        view_907 = torch.ops.aten.view.default(convert_element_type_741, [8192, 2048]);  convert_element_type_741 = None
        mm_111 = torch.ops.aten.mm.default(view_907, permute_206);  permute_206 = None
        view_908 = torch.ops.aten.view.default(mm_111, [2, 4096, 3072]);  mm_111 = None
        view_909 = torch.ops.aten.view.default(view_908, [2, 4096, -1, 192]);  view_908 = None
        split_with_sizes_42 = torch.ops.aten.split_with_sizes.default(view_909, [128, 64], -1);  view_909 = None
        getitem_1439 = split_with_sizes_42[0]
        getitem_1440 = split_with_sizes_42[1];  split_with_sizes_42 = None
        convert_element_type_745 = torch.ops.prims.convert_element_type.default(getitem_1440, torch.float32);  getitem_1440 = None
        view_910 = torch.ops.aten.view.default(convert_element_type_745, [2, 4096, 16, -1, 2]);  convert_element_type_745 = None
        view_as_complex_28 = torch.ops.aten.view_as_complex.default(view_910);  view_910 = None
        mul_648 = torch.ops.aten.mul.Tensor(view_as_complex_28, view_7);  view_as_complex_28 = None
        view_as_real_28 = torch.ops.aten.view_as_real.default(mul_648);  mul_648 = None
        view_912 = torch.ops.aten.view.default(view_as_real_28, [2, 4096, 16, 64]);  view_as_real_28 = None
        convert_element_type_746 = torch.ops.prims.convert_element_type.default(view_912, torch.bfloat16);  view_912 = None
        cat_119 = torch.ops.aten.cat.default([getitem_1439, convert_element_type_746], -1);  getitem_1439 = convert_element_type_746 = None
        convert_element_type_747 = torch.ops.prims.convert_element_type.default(primals_233, torch.bfloat16)
        all_gather_into_tensor_234 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_747, 128, '0');  convert_element_type_747 = None
        wait_tensor_286 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_234);  all_gather_into_tensor_234 = None
        slice_85 = torch.ops.aten.slice.Tensor(wait_tensor_286, 0, 0, 576);  wait_tensor_286 = None
        permute_207 = torch.ops.aten.permute.default(slice_85, [1, 0]);  slice_85 = None
        mm_112 = torch.ops.aten.mm.default(view_907, permute_207);  permute_207 = None
        view_915 = torch.ops.aten.view.default(mm_112, [2, 4096, 576]);  mm_112 = None
        split_with_sizes_43 = torch.ops.aten.split_with_sizes.default(view_915, [512, 64], -1);  view_915 = None
        getitem_1441 = split_with_sizes_43[0]
        getitem_1442 = split_with_sizes_43[1];  split_with_sizes_43 = None
        unsqueeze_27 = torch.ops.aten.unsqueeze.default(getitem_1442, 2);  getitem_1442 = None
        convert_element_type_750 = torch.ops.prims.convert_element_type.default(unsqueeze_27, torch.float32);  unsqueeze_27 = None
        view_916 = torch.ops.aten.view.default(convert_element_type_750, [2, 4096, 1, -1, 2]);  convert_element_type_750 = None
        view_as_complex_29 = torch.ops.aten.view_as_complex.default(view_916);  view_916 = None
        mul_649 = torch.ops.aten.mul.Tensor(view_as_complex_29, view_7);  view_as_complex_29 = None
        view_as_real_29 = torch.ops.aten.view_as_real.default(mul_649);  mul_649 = None
        view_918 = torch.ops.aten.view.default(view_as_real_29, [2, 4096, 1, 64]);  view_as_real_29 = None
        convert_element_type_751 = torch.ops.prims.convert_element_type.default(view_918, torch.bfloat16);  view_918 = None
        convert_element_type_752 = torch.ops.prims.convert_element_type.default(primals_234, torch.bfloat16)
        all_gather_into_tensor_235 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_752, 128, '0');  convert_element_type_752 = None
        wait_tensor_287 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_235);  all_gather_into_tensor_235 = None
        convert_element_type_753 = torch.ops.prims.convert_element_type.default(getitem_1441, torch.float32)
        pow_44 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_753, 2)
        mean_43 = torch.ops.aten.mean.dim(pow_44, [2], True);  pow_44 = None
        add_891 = torch.ops.aten.add.Scalar(mean_43, 1e-05);  mean_43 = None
        rsqrt_43 = torch.ops.aten.rsqrt.default(add_891);  add_891 = None
        mul_650 = torch.ops.aten.mul.Tensor(convert_element_type_753, rsqrt_43);  convert_element_type_753 = None
        mul_651 = torch.ops.aten.mul.Tensor(mul_650, wait_tensor_287);  mul_650 = wait_tensor_287 = None
        convert_element_type_754 = torch.ops.prims.convert_element_type.default(mul_651, torch.bfloat16);  mul_651 = None
        convert_element_type_755 = torch.ops.prims.convert_element_type.default(primals_235, torch.bfloat16)
        all_gather_into_tensor_236 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_755, 128, '0');  convert_element_type_755 = None
        wait_tensor_288 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_236);  all_gather_into_tensor_236 = None
        permute_208 = torch.ops.aten.permute.default(wait_tensor_288, [1, 0]);  wait_tensor_288 = None
        view_921 = torch.ops.aten.view.default(convert_element_type_754, [8192, 512]);  convert_element_type_754 = None
        mm_113 = torch.ops.aten.mm.default(view_921, permute_208);  permute_208 = None
        view_922 = torch.ops.aten.view.default(mm_113, [2, 4096, 4096]);  mm_113 = None
        view_923 = torch.ops.aten.view.default(view_922, [2, 4096, -1, 256]);  view_922 = None
        split_with_sizes_44 = torch.ops.aten.split_with_sizes.default(view_923, [128, 128], -1);  view_923 = None
        getitem_1443 = split_with_sizes_44[0]
        getitem_1444 = split_with_sizes_44[1];  split_with_sizes_44 = None
        expand_14 = torch.ops.aten.expand.default(convert_element_type_751, [-1, -1, 16, -1]);  convert_element_type_751 = None
        cat_120 = torch.ops.aten.cat.default([getitem_1443, expand_14], -1);  getitem_1443 = expand_14 = None
        permute_209 = torch.ops.aten.permute.default(cat_119, [0, 2, 1, 3]);  cat_119 = None
        permute_210 = torch.ops.aten.permute.default(cat_120, [0, 2, 1, 3]);  cat_120 = None
        permute_211 = torch.ops.aten.permute.default(getitem_1444, [0, 2, 1, 3]);  getitem_1444 = None
        sdpa_score14 = self.sdpa_score14
        sdpa_mask14 = self.sdpa_mask14
        flex_attention_14 = torch.ops.higher_order.flex_attention(permute_209, permute_210, permute_211, sdpa_score14, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask14), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score14 = sdpa_mask14 = None
        getitem_1445 = flex_attention_14[0]
        getitem_1446 = flex_attention_14[1];  flex_attention_14 = None
        permute_212 = torch.ops.aten.permute.default(getitem_1445, [0, 2, 1, 3])
        view_924 = torch.ops.aten.view.default(permute_212, [2, 4096, -1]);  permute_212 = None
        convert_element_type_758 = torch.ops.prims.convert_element_type.default(primals_236, torch.bfloat16)
        all_gather_into_tensor_237 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_758, 128, '0');  convert_element_type_758 = None
        wait_tensor_289 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_237);  all_gather_into_tensor_237 = None
        permute_213 = torch.ops.aten.permute.default(wait_tensor_289, [1, 0]);  wait_tensor_289 = None
        view_926 = torch.ops.aten.view.default(view_924, [8192, 2048]);  view_924 = None
        mm_114 = torch.ops.aten.mm.default(view_926, permute_213);  view_926 = permute_213 = None
        view_927 = torch.ops.aten.view.default(mm_114, [2, 4096, 2048]);  mm_114 = None
        add_892 = torch.ops.aten.add.Tensor(add_889, view_927);  view_927 = None
        convert_element_type_761 = torch.ops.prims.convert_element_type.default(primals_237, torch.bfloat16)
        all_gather_into_tensor_238 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_761, 128, '0');  convert_element_type_761 = None
        wait_tensor_290 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_238);  all_gather_into_tensor_238 = None
        convert_element_type_762 = torch.ops.prims.convert_element_type.default(add_892, torch.float32)
        pow_45 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_762, 2)
        mean_44 = torch.ops.aten.mean.dim(pow_45, [2], True);  pow_45 = None
        add_893 = torch.ops.aten.add.Scalar(mean_44, 1e-05);  mean_44 = None
        rsqrt_44 = torch.ops.aten.rsqrt.default(add_893);  add_893 = None
        mul_652 = torch.ops.aten.mul.Tensor(convert_element_type_762, rsqrt_44);  convert_element_type_762 = None
        mul_653 = torch.ops.aten.mul.Tensor(mul_652, wait_tensor_290);  mul_652 = wait_tensor_290 = None
        convert_element_type_763 = torch.ops.prims.convert_element_type.default(mul_653, torch.bfloat16);  mul_653 = None
        view_929 = torch.ops.aten.view.default(convert_element_type_763, [-1, 2048]);  convert_element_type_763 = None
        convert_element_type_764 = torch.ops.prims.convert_element_type.default(primals_239, torch.bfloat16)
        all_gather_into_tensor_239 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_764, 128, '0');  convert_element_type_764 = None
        wait_tensor_291 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_239);  all_gather_into_tensor_239 = None
        slice_87 = torch.ops.aten.slice.Tensor(wait_tensor_291, 0, 0, 64);  wait_tensor_291 = None
        permute_214 = torch.ops.aten.permute.default(slice_87, [1, 0]);  slice_87 = None
        mm_115 = torch.ops.aten.mm.default(view_929, permute_214);  permute_214 = None
        convert_element_type_767 = torch.ops.prims.convert_element_type.default(mm_115, torch.float32)
        amax_13 = torch.ops.aten.amax.default(convert_element_type_767, [1], True)
        sub_312 = torch.ops.aten.sub.Tensor(convert_element_type_767, amax_13);  convert_element_type_767 = None
        exp_40 = torch.ops.aten.exp.default(sub_312);  sub_312 = None
        sum_53 = torch.ops.aten.sum.dim_IntList(exp_40, [1], True)
        div_66 = torch.ops.aten.div.Tensor(exp_40, sum_53);  exp_40 = None
        add_894 = torch.ops.aten.add.Tensor(div_66, primals_238);  primals_238 = None
        topk_13 = torch.ops.aten.topk.default(add_894, 6, -1, True, False);  add_894 = None
        getitem_1449 = topk_13[1];  topk_13 = None
        gather_13 = torch.ops.aten.gather.default(div_66, 1, getitem_1449);  div_66 = None
        mul_654 = torch.ops.aten.mul.Tensor(gather_13, 1.0);  gather_13 = None
        view_931 = torch.ops.aten.view.default(getitem_1449, [-1])
        histc_26 = torch.ops.aten.histc.default(view_931, 64, 0, 64)
        add_895 = torch.ops.aten.add.Tensor(primals_240, histc_26)
        sort_13 = torch.ops.aten.sort.stable(view_931, stable = True);  view_931 = None
        getitem_1451 = sort_13[1];  sort_13 = None
        div_67 = torch.ops.aten.div.Tensor_mode(getitem_1451, 6, rounding_mode = 'floor')
        index_26 = torch.ops.aten.index.Tensor(view_929, [div_67])
        all_to_all_single_39 = torch.ops._c10d_functional.all_to_all_single.default(histc_26, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_292 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_39);  all_to_all_single_39 = None
        wait_tensor_293 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_292);  wait_tensor_292 = None
        view_935 = torch.ops.aten.view.default(histc_26, [8, -1]);  histc_26 = None
        sum_54 = torch.ops.aten.sum.dim_IntList(view_935, [1]);  view_935 = None
        device_put_26 = torch.ops.prims.device_put.default(sum_54, device(type='cpu'), True);  sum_54 = None
        view_936 = torch.ops.aten.view.default(wait_tensor_293, [8, -1])
        sum_55 = torch.ops.aten.sum.dim_IntList(view_936, [1])
        device_put_27 = torch.ops.prims.device_put.default(sum_55, device(type='cpu'));  sum_55 = None
        select_208 = torch.ops.aten.select.int(device_put_26, 0, 0)
        _local_scalar_dense_208 = torch.ops.aten._local_scalar_dense.default(select_208);  select_208 = None
        ge_260 = _local_scalar_dense_208 >= 0
        _assert_scalar_208 = torch.ops.aten._assert_scalar.default(ge_260, "Runtime assertion failed for expression u208 >= 0 on node 'ge_208'");  ge_260 = _assert_scalar_208 = None
        select_209 = torch.ops.aten.select.int(device_put_26, 0, 1)
        _local_scalar_dense_209 = torch.ops.aten._local_scalar_dense.default(select_209);  select_209 = None
        ge_261 = _local_scalar_dense_209 >= 0
        _assert_scalar_209 = torch.ops.aten._assert_scalar.default(ge_261, "Runtime assertion failed for expression u209 >= 0 on node 'ge_209'");  ge_261 = _assert_scalar_209 = None
        select_210 = torch.ops.aten.select.int(device_put_26, 0, 2)
        _local_scalar_dense_210 = torch.ops.aten._local_scalar_dense.default(select_210);  select_210 = None
        ge_262 = _local_scalar_dense_210 >= 0
        _assert_scalar_210 = torch.ops.aten._assert_scalar.default(ge_262, "Runtime assertion failed for expression u210 >= 0 on node 'ge_210'");  ge_262 = _assert_scalar_210 = None
        select_211 = torch.ops.aten.select.int(device_put_26, 0, 3)
        _local_scalar_dense_211 = torch.ops.aten._local_scalar_dense.default(select_211);  select_211 = None
        ge_263 = _local_scalar_dense_211 >= 0
        _assert_scalar_211 = torch.ops.aten._assert_scalar.default(ge_263, "Runtime assertion failed for expression u211 >= 0 on node 'ge_211'");  ge_263 = _assert_scalar_211 = None
        select_212 = torch.ops.aten.select.int(device_put_26, 0, 4)
        _local_scalar_dense_212 = torch.ops.aten._local_scalar_dense.default(select_212);  select_212 = None
        ge_264 = _local_scalar_dense_212 >= 0
        _assert_scalar_212 = torch.ops.aten._assert_scalar.default(ge_264, "Runtime assertion failed for expression u212 >= 0 on node 'ge_212'");  ge_264 = _assert_scalar_212 = None
        select_213 = torch.ops.aten.select.int(device_put_26, 0, 5)
        _local_scalar_dense_213 = torch.ops.aten._local_scalar_dense.default(select_213);  select_213 = None
        ge_265 = _local_scalar_dense_213 >= 0
        _assert_scalar_213 = torch.ops.aten._assert_scalar.default(ge_265, "Runtime assertion failed for expression u213 >= 0 on node 'ge_213'");  ge_265 = _assert_scalar_213 = None
        select_214 = torch.ops.aten.select.int(device_put_26, 0, 6)
        _local_scalar_dense_214 = torch.ops.aten._local_scalar_dense.default(select_214);  select_214 = None
        ge_266 = _local_scalar_dense_214 >= 0
        _assert_scalar_214 = torch.ops.aten._assert_scalar.default(ge_266, "Runtime assertion failed for expression u214 >= 0 on node 'ge_214'");  ge_266 = _assert_scalar_214 = None
        select_215 = torch.ops.aten.select.int(device_put_26, 0, 7);  device_put_26 = None
        _local_scalar_dense_215 = torch.ops.aten._local_scalar_dense.default(select_215);  select_215 = None
        ge_267 = _local_scalar_dense_215 >= 0
        _assert_scalar_215 = torch.ops.aten._assert_scalar.default(ge_267, "Runtime assertion failed for expression u215 >= 0 on node 'ge_215'");  ge_267 = _assert_scalar_215 = None
        select_216 = torch.ops.aten.select.int(device_put_27, 0, 0)
        _local_scalar_dense_216 = torch.ops.aten._local_scalar_dense.default(select_216);  select_216 = None
        ge_268 = _local_scalar_dense_216 >= 0
        _assert_scalar_216 = torch.ops.aten._assert_scalar.default(ge_268, "Runtime assertion failed for expression u216 >= 0 on node 'ge_216'");  ge_268 = _assert_scalar_216 = None
        select_217 = torch.ops.aten.select.int(device_put_27, 0, 1)
        _local_scalar_dense_217 = torch.ops.aten._local_scalar_dense.default(select_217);  select_217 = None
        ge_269 = _local_scalar_dense_217 >= 0
        _assert_scalar_217 = torch.ops.aten._assert_scalar.default(ge_269, "Runtime assertion failed for expression u217 >= 0 on node 'ge_217'");  ge_269 = _assert_scalar_217 = None
        select_218 = torch.ops.aten.select.int(device_put_27, 0, 2)
        _local_scalar_dense_218 = torch.ops.aten._local_scalar_dense.default(select_218);  select_218 = None
        ge_270 = _local_scalar_dense_218 >= 0
        _assert_scalar_218 = torch.ops.aten._assert_scalar.default(ge_270, "Runtime assertion failed for expression u218 >= 0 on node 'ge_218'");  ge_270 = _assert_scalar_218 = None
        select_219 = torch.ops.aten.select.int(device_put_27, 0, 3)
        _local_scalar_dense_219 = torch.ops.aten._local_scalar_dense.default(select_219);  select_219 = None
        ge_271 = _local_scalar_dense_219 >= 0
        _assert_scalar_219 = torch.ops.aten._assert_scalar.default(ge_271, "Runtime assertion failed for expression u219 >= 0 on node 'ge_219'");  ge_271 = _assert_scalar_219 = None
        select_220 = torch.ops.aten.select.int(device_put_27, 0, 4)
        _local_scalar_dense_220 = torch.ops.aten._local_scalar_dense.default(select_220);  select_220 = None
        ge_272 = _local_scalar_dense_220 >= 0
        _assert_scalar_220 = torch.ops.aten._assert_scalar.default(ge_272, "Runtime assertion failed for expression u220 >= 0 on node 'ge_220'");  ge_272 = _assert_scalar_220 = None
        select_221 = torch.ops.aten.select.int(device_put_27, 0, 5)
        _local_scalar_dense_221 = torch.ops.aten._local_scalar_dense.default(select_221);  select_221 = None
        ge_273 = _local_scalar_dense_221 >= 0
        _assert_scalar_221 = torch.ops.aten._assert_scalar.default(ge_273, "Runtime assertion failed for expression u221 >= 0 on node 'ge_221'");  ge_273 = _assert_scalar_221 = None
        select_222 = torch.ops.aten.select.int(device_put_27, 0, 6)
        _local_scalar_dense_222 = torch.ops.aten._local_scalar_dense.default(select_222);  select_222 = None
        ge_274 = _local_scalar_dense_222 >= 0
        _assert_scalar_222 = torch.ops.aten._assert_scalar.default(ge_274, "Runtime assertion failed for expression u222 >= 0 on node 'ge_222'");  ge_274 = _assert_scalar_222 = None
        select_223 = torch.ops.aten.select.int(device_put_27, 0, 7);  device_put_27 = None
        _local_scalar_dense_223 = torch.ops.aten._local_scalar_dense.default(select_223);  select_223 = None
        ge_275 = _local_scalar_dense_223 >= 0
        _assert_scalar_223 = torch.ops.aten._assert_scalar.default(ge_275, "Runtime assertion failed for expression u223 >= 0 on node 'ge_223'");  ge_275 = _assert_scalar_223 = None
        all_to_all_single_40 = torch.ops._c10d_functional.all_to_all_single.default(index_26, [_local_scalar_dense_216, _local_scalar_dense_217, _local_scalar_dense_218, _local_scalar_dense_219, _local_scalar_dense_220, _local_scalar_dense_221, _local_scalar_dense_222, _local_scalar_dense_223], [_local_scalar_dense_208, _local_scalar_dense_209, _local_scalar_dense_210, _local_scalar_dense_211, _local_scalar_dense_212, _local_scalar_dense_213, _local_scalar_dense_214, _local_scalar_dense_215], '1033');  index_26 = None
        sym_size_int_52 = torch.ops.aten.sym_size.int(all_to_all_single_40, 0)
        wait_tensor_294 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_40);  all_to_all_single_40 = None
        sym_sum_26 = torch.sym_sum((_local_scalar_dense_216, _local_scalar_dense_217, _local_scalar_dense_218, _local_scalar_dense_219, _local_scalar_dense_220, _local_scalar_dense_221, _local_scalar_dense_222, _local_scalar_dense_223))
        add_902 = sym_sum_26 + 64;  sym_sum_26 = None
        add_903 = add_902 + 8;  add_902 = None
        sub_315 = add_903 - 1;  add_903 = None
        floordiv_13 = sub_315 // 8;  sub_315 = None
        mul_659 = floordiv_13 * 8;  floordiv_13 = None
        cumsum_39 = torch.ops.aten.cumsum.default(wait_tensor_293, 0)
        sub_316 = torch.ops.aten.sub.Tensor(cumsum_39, wait_tensor_293);  cumsum_39 = None
        sum_56 = torch.ops.aten.sum.dim_IntList(view_936, [0]);  view_936 = None
        clamp_min_13 = torch.ops.aten.clamp_min.default(sum_56, 8);  sum_56 = None
        add_904 = torch.ops.aten.add.Tensor(clamp_min_13, 8);  clamp_min_13 = None
        sub_317 = torch.ops.aten.sub.Tensor(add_904, 1);  add_904 = None
        div_68 = torch.ops.aten.div.Tensor_mode(sub_317, 8, rounding_mode = 'floor');  sub_317 = None
        mul_660 = torch.ops.aten.mul.Tensor(div_68, 8);  div_68 = None
        convert_element_type_770 = torch.ops.prims.convert_element_type.default(mul_660, torch.int32);  mul_660 = None
        cumsum_40 = torch.ops.aten.cumsum.default(convert_element_type_770, 0)
        sub_318 = torch.ops.aten.sub.Tensor(cumsum_40, convert_element_type_770);  cumsum_40 = None
        full_189 = torch.ops.aten.full.default([mul_659], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_659 = None
        triton_kernel_wrapper_functional_proxy_13 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 13, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_293, 'start_index_values_ptr': sub_316, 'write_offsets_ptr': sub_318, 'output_ptr': full_189}, tensors_to_clone = ['output_ptr']);  wait_tensor_293 = sub_316 = sub_318 = full_189 = None
        getitem_1452 = triton_kernel_wrapper_functional_proxy_13['output_ptr'];  triton_kernel_wrapper_functional_proxy_13 = None
        cat_121 = torch.ops.aten.cat.default([wait_tensor_294, full_default]);  wait_tensor_294 = None
        sym_size_int_53 = torch.ops.aten.sym_size.int(cat_121, 0)
        sym_sum_27 = torch.sym_sum((1, _local_scalar_dense_216, _local_scalar_dense_217, _local_scalar_dense_218, _local_scalar_dense_219, _local_scalar_dense_220, _local_scalar_dense_221, _local_scalar_dense_222, _local_scalar_dense_223))
        index_27 = torch.ops.aten.index.Tensor(cat_121, [getitem_1452]);  cat_121 = None
        convert_element_type_772 = torch.ops.prims.convert_element_type.default(primals_241, torch.bfloat16)
        all_gather_into_tensor_240 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_772, 16, '1025');  convert_element_type_772 = None
        wait_tensor_295 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_240);  all_gather_into_tensor_240 = None
        split_79 = torch.ops.aten.split.Tensor(wait_tensor_295, 8);  wait_tensor_295 = None
        getitem_1469 = split_79[0]
        getitem_1470 = split_79[1]
        getitem_1471 = split_79[2]
        getitem_1472 = split_79[3]
        getitem_1473 = split_79[4]
        getitem_1474 = split_79[5]
        getitem_1475 = split_79[6]
        getitem_1476 = split_79[7]
        getitem_1477 = split_79[8]
        getitem_1478 = split_79[9]
        getitem_1479 = split_79[10]
        getitem_1480 = split_79[11]
        getitem_1481 = split_79[12]
        getitem_1482 = split_79[13]
        getitem_1483 = split_79[14]
        getitem_1484 = split_79[15];  split_79 = None
        cat_123 = torch.ops.aten.cat.default([getitem_1469, getitem_1470, getitem_1471, getitem_1472, getitem_1473, getitem_1474, getitem_1475, getitem_1476, getitem_1477, getitem_1478, getitem_1479, getitem_1480, getitem_1481, getitem_1482, getitem_1483, getitem_1484], 1);  getitem_1469 = getitem_1470 = getitem_1471 = getitem_1472 = getitem_1473 = getitem_1474 = getitem_1475 = getitem_1476 = getitem_1477 = getitem_1478 = getitem_1479 = getitem_1480 = getitem_1481 = getitem_1482 = getitem_1483 = getitem_1484 = None
        convert_element_type_774 = torch.ops.prims.convert_element_type.default(primals_242, torch.bfloat16)
        all_gather_into_tensor_242 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_774, 16, '1025');  convert_element_type_774 = None
        wait_tensor_297 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_242);  all_gather_into_tensor_242 = None
        split_80 = torch.ops.aten.split.Tensor(wait_tensor_297, 8);  wait_tensor_297 = None
        getitem_1485 = split_80[0]
        getitem_1486 = split_80[1]
        getitem_1487 = split_80[2]
        getitem_1488 = split_80[3]
        getitem_1489 = split_80[4]
        getitem_1490 = split_80[5]
        getitem_1491 = split_80[6]
        getitem_1492 = split_80[7]
        getitem_1493 = split_80[8]
        getitem_1494 = split_80[9]
        getitem_1495 = split_80[10]
        getitem_1496 = split_80[11]
        getitem_1497 = split_80[12]
        getitem_1498 = split_80[13]
        getitem_1499 = split_80[14]
        getitem_1500 = split_80[15];  split_80 = None
        cat_124 = torch.ops.aten.cat.default([getitem_1485, getitem_1486, getitem_1487, getitem_1488, getitem_1489, getitem_1490, getitem_1491, getitem_1492, getitem_1493, getitem_1494, getitem_1495, getitem_1496, getitem_1497, getitem_1498, getitem_1499, getitem_1500], 1);  getitem_1485 = getitem_1486 = getitem_1487 = getitem_1488 = getitem_1489 = getitem_1490 = getitem_1491 = getitem_1492 = getitem_1493 = getitem_1494 = getitem_1495 = getitem_1496 = getitem_1497 = getitem_1498 = getitem_1499 = getitem_1500 = None
        convert_element_type_775 = torch.ops.prims.convert_element_type.default(primals_243, torch.bfloat16)
        all_gather_into_tensor_243 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_775, 16, '1025');  convert_element_type_775 = None
        wait_tensor_298 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_243);  all_gather_into_tensor_243 = None
        split_81 = torch.ops.aten.split.Tensor(wait_tensor_298, 8);  wait_tensor_298 = None
        getitem_1501 = split_81[0]
        getitem_1502 = split_81[1]
        getitem_1503 = split_81[2]
        getitem_1504 = split_81[3]
        getitem_1505 = split_81[4]
        getitem_1506 = split_81[5]
        getitem_1507 = split_81[6]
        getitem_1508 = split_81[7]
        getitem_1509 = split_81[8]
        getitem_1510 = split_81[9]
        getitem_1511 = split_81[10]
        getitem_1512 = split_81[11]
        getitem_1513 = split_81[12]
        getitem_1514 = split_81[13]
        getitem_1515 = split_81[14]
        getitem_1516 = split_81[15];  split_81 = None
        cat_125 = torch.ops.aten.cat.default([getitem_1501, getitem_1502, getitem_1503, getitem_1504, getitem_1505, getitem_1506, getitem_1507, getitem_1508, getitem_1509, getitem_1510, getitem_1511, getitem_1512, getitem_1513, getitem_1514, getitem_1515, getitem_1516], 1);  getitem_1501 = getitem_1502 = getitem_1503 = getitem_1504 = getitem_1505 = getitem_1506 = getitem_1507 = getitem_1508 = getitem_1509 = getitem_1510 = getitem_1511 = getitem_1512 = getitem_1513 = getitem_1514 = getitem_1515 = getitem_1516 = None
        cumsum_41 = torch.ops.aten.cumsum.default(convert_element_type_770, 0, dtype = torch.int32);  convert_element_type_770 = None
        permute_215 = torch.ops.aten.permute.default(cat_123, [0, 2, 1]);  cat_123 = None
        _grouped_mm_39 = torch.ops.aten._grouped_mm.default(index_27, permute_215, cumsum_41)
        convert_element_type_778 = torch.ops.prims.convert_element_type.default(_grouped_mm_39, torch.float32)
        neg_27 = torch.ops.aten.neg.default(convert_element_type_778)
        exp_41 = torch.ops.aten.exp.default(neg_27);  neg_27 = None
        add_916 = torch.ops.aten.add.Tensor(exp_41, 1);  exp_41 = None
        div_69 = torch.ops.aten.div.Tensor(convert_element_type_778, add_916);  convert_element_type_778 = add_916 = None
        convert_element_type_779 = torch.ops.prims.convert_element_type.default(div_69, torch.bfloat16);  div_69 = None
        permute_216 = torch.ops.aten.permute.default(cat_125, [0, 2, 1]);  cat_125 = None
        _grouped_mm_40 = torch.ops.aten._grouped_mm.default(index_27, permute_216, cumsum_41)
        mul_672 = torch.ops.aten.mul.Tensor(convert_element_type_779, _grouped_mm_40);  convert_element_type_779 = None
        permute_217 = torch.ops.aten.permute.default(cat_124, [0, 2, 1]);  cat_124 = None
        _grouped_mm_41 = torch.ops.aten._grouped_mm.default(mul_672, permute_217, cumsum_41)
        empty_13 = torch.ops.aten.empty.memory_format([sym_size_int_53, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_26 = torch.ops.aten.index_put.default(empty_13, [getitem_1452], _grouped_mm_41);  empty_13 = _grouped_mm_41 = None
        slice_89 = torch.ops.aten.slice.Tensor(index_put_26, 0, 0, -1);  index_put_26 = None
        all_to_all_single_41 = torch.ops._c10d_functional.all_to_all_single.default(slice_89, [_local_scalar_dense_208, _local_scalar_dense_209, _local_scalar_dense_210, _local_scalar_dense_211, _local_scalar_dense_212, _local_scalar_dense_213, _local_scalar_dense_214, _local_scalar_dense_215], [_local_scalar_dense_216, _local_scalar_dense_217, _local_scalar_dense_218, _local_scalar_dense_219, _local_scalar_dense_220, _local_scalar_dense_221, _local_scalar_dense_222, _local_scalar_dense_223], '1033');  slice_89 = None
        wait_tensor_301 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_41);  all_to_all_single_41 = None
        convert_element_type_780 = torch.ops.prims.convert_element_type.default(primals_244, torch.bfloat16)
        all_gather_into_tensor_246 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_780, 128, '0');  convert_element_type_780 = None
        wait_tensor_302 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_246);  all_gather_into_tensor_246 = None
        permute_218 = torch.ops.aten.permute.default(wait_tensor_302, [1, 0]);  wait_tensor_302 = None
        mm_116 = torch.ops.aten.mm.default(view_929, permute_218);  permute_218 = None
        convert_element_type_783 = torch.ops.prims.convert_element_type.default(mm_116, torch.float32)
        neg_28 = torch.ops.aten.neg.default(convert_element_type_783)
        exp_42 = torch.ops.aten.exp.default(neg_28);  neg_28 = None
        add_952 = torch.ops.aten.add.Tensor(exp_42, 1);  exp_42 = None
        div_70 = torch.ops.aten.div.Tensor(convert_element_type_783, add_952);  convert_element_type_783 = add_952 = None
        convert_element_type_784 = torch.ops.prims.convert_element_type.default(div_70, torch.bfloat16);  div_70 = None
        convert_element_type_785 = torch.ops.prims.convert_element_type.default(primals_245, torch.bfloat16)
        all_gather_into_tensor_247 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_785, 128, '0');  convert_element_type_785 = None
        wait_tensor_303 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_247);  all_gather_into_tensor_247 = None
        permute_219 = torch.ops.aten.permute.default(wait_tensor_303, [1, 0]);  wait_tensor_303 = None
        mm_117 = torch.ops.aten.mm.default(view_929, permute_219);  permute_219 = None
        mul_692 = torch.ops.aten.mul.Tensor(convert_element_type_784, mm_117);  convert_element_type_784 = None
        convert_element_type_788 = torch.ops.prims.convert_element_type.default(primals_246, torch.bfloat16)
        all_gather_into_tensor_248 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_788, 128, '0');  convert_element_type_788 = None
        wait_tensor_304 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_248);  all_gather_into_tensor_248 = None
        permute_220 = torch.ops.aten.permute.default(wait_tensor_304, [1, 0]);  wait_tensor_304 = None
        mm_118 = torch.ops.aten.mm.default(mul_692, permute_220);  permute_220 = None
        index_put_27 = torch.ops.aten.index_put.default(full_default_1, [getitem_1451], wait_tensor_301);  wait_tensor_301 = None
        view_969 = torch.ops.aten.view.default(mul_654, [-1, 1, 6]);  mul_654 = None
        view_970 = torch.ops.aten.view.default(index_put_27, [-1, 6, 2048]);  index_put_27 = None
        convert_element_type_791 = torch.ops.prims.convert_element_type.default(view_970, torch.float32);  view_970 = None
        bmm_13 = torch.ops.aten.bmm.default(view_969, convert_element_type_791)
        convert_element_type_792 = torch.ops.prims.convert_element_type.default(bmm_13, torch.bfloat16);  bmm_13 = None
        squeeze_13 = torch.ops.aten.squeeze.dim(convert_element_type_792, 1);  convert_element_type_792 = None
        add_956 = torch.ops.aten.add.Tensor(mm_118, squeeze_13);  mm_118 = squeeze_13 = None
        view_971 = torch.ops.aten.view.default(add_956, [2, 4096, 2048]);  add_956 = None
        add_957 = torch.ops.aten.add.Tensor(add_892, view_971);  view_971 = None
        convert_element_type_793 = torch.ops.prims.convert_element_type.default(primals_247, torch.bfloat16)
        all_gather_into_tensor_249 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_793, 128, '0');  convert_element_type_793 = None
        wait_tensor_305 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_249);  all_gather_into_tensor_249 = None
        convert_element_type_794 = torch.ops.prims.convert_element_type.default(add_957, torch.float32)
        pow_46 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_794, 2)
        mean_45 = torch.ops.aten.mean.dim(pow_46, [2], True);  pow_46 = None
        add_958 = torch.ops.aten.add.Scalar(mean_45, 1e-05);  mean_45 = None
        rsqrt_45 = torch.ops.aten.rsqrt.default(add_958);  add_958 = None
        mul_695 = torch.ops.aten.mul.Tensor(convert_element_type_794, rsqrt_45);  convert_element_type_794 = None
        mul_696 = torch.ops.aten.mul.Tensor(mul_695, wait_tensor_305);  mul_695 = wait_tensor_305 = None
        convert_element_type_795 = torch.ops.prims.convert_element_type.default(mul_696, torch.bfloat16);  mul_696 = None
        convert_element_type_796 = torch.ops.prims.convert_element_type.default(primals_248, torch.bfloat16)
        all_gather_into_tensor_250 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_796, 128, '0');  convert_element_type_796 = None
        wait_tensor_306 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_250);  all_gather_into_tensor_250 = None
        permute_221 = torch.ops.aten.permute.default(wait_tensor_306, [1, 0]);  wait_tensor_306 = None
        view_974 = torch.ops.aten.view.default(convert_element_type_795, [8192, 2048]);  convert_element_type_795 = None
        mm_119 = torch.ops.aten.mm.default(view_974, permute_221);  permute_221 = None
        view_975 = torch.ops.aten.view.default(mm_119, [2, 4096, 3072]);  mm_119 = None
        view_976 = torch.ops.aten.view.default(view_975, [2, 4096, -1, 192]);  view_975 = None
        split_with_sizes_45 = torch.ops.aten.split_with_sizes.default(view_976, [128, 64], -1);  view_976 = None
        getitem_1549 = split_with_sizes_45[0]
        getitem_1550 = split_with_sizes_45[1];  split_with_sizes_45 = None
        convert_element_type_799 = torch.ops.prims.convert_element_type.default(getitem_1550, torch.float32);  getitem_1550 = None
        view_977 = torch.ops.aten.view.default(convert_element_type_799, [2, 4096, 16, -1, 2]);  convert_element_type_799 = None
        view_as_complex_30 = torch.ops.aten.view_as_complex.default(view_977);  view_977 = None
        mul_697 = torch.ops.aten.mul.Tensor(view_as_complex_30, view_7);  view_as_complex_30 = None
        view_as_real_30 = torch.ops.aten.view_as_real.default(mul_697);  mul_697 = None
        view_979 = torch.ops.aten.view.default(view_as_real_30, [2, 4096, 16, 64]);  view_as_real_30 = None
        convert_element_type_800 = torch.ops.prims.convert_element_type.default(view_979, torch.bfloat16);  view_979 = None
        cat_128 = torch.ops.aten.cat.default([getitem_1549, convert_element_type_800], -1);  getitem_1549 = convert_element_type_800 = None
        convert_element_type_801 = torch.ops.prims.convert_element_type.default(primals_249, torch.bfloat16)
        all_gather_into_tensor_251 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_801, 128, '0');  convert_element_type_801 = None
        wait_tensor_307 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_251);  all_gather_into_tensor_251 = None
        slice_91 = torch.ops.aten.slice.Tensor(wait_tensor_307, 0, 0, 576);  wait_tensor_307 = None
        permute_222 = torch.ops.aten.permute.default(slice_91, [1, 0]);  slice_91 = None
        mm_120 = torch.ops.aten.mm.default(view_974, permute_222);  permute_222 = None
        view_982 = torch.ops.aten.view.default(mm_120, [2, 4096, 576]);  mm_120 = None
        split_with_sizes_46 = torch.ops.aten.split_with_sizes.default(view_982, [512, 64], -1);  view_982 = None
        getitem_1551 = split_with_sizes_46[0]
        getitem_1552 = split_with_sizes_46[1];  split_with_sizes_46 = None
        unsqueeze_29 = torch.ops.aten.unsqueeze.default(getitem_1552, 2);  getitem_1552 = None
        convert_element_type_804 = torch.ops.prims.convert_element_type.default(unsqueeze_29, torch.float32);  unsqueeze_29 = None
        view_983 = torch.ops.aten.view.default(convert_element_type_804, [2, 4096, 1, -1, 2]);  convert_element_type_804 = None
        view_as_complex_31 = torch.ops.aten.view_as_complex.default(view_983);  view_983 = None
        mul_698 = torch.ops.aten.mul.Tensor(view_as_complex_31, view_7);  view_as_complex_31 = None
        view_as_real_31 = torch.ops.aten.view_as_real.default(mul_698);  mul_698 = None
        view_985 = torch.ops.aten.view.default(view_as_real_31, [2, 4096, 1, 64]);  view_as_real_31 = None
        convert_element_type_805 = torch.ops.prims.convert_element_type.default(view_985, torch.bfloat16);  view_985 = None
        convert_element_type_806 = torch.ops.prims.convert_element_type.default(primals_250, torch.bfloat16)
        all_gather_into_tensor_252 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_806, 128, '0');  convert_element_type_806 = None
        wait_tensor_308 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_252);  all_gather_into_tensor_252 = None
        convert_element_type_807 = torch.ops.prims.convert_element_type.default(getitem_1551, torch.float32)
        pow_47 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_807, 2)
        mean_46 = torch.ops.aten.mean.dim(pow_47, [2], True);  pow_47 = None
        add_959 = torch.ops.aten.add.Scalar(mean_46, 1e-05);  mean_46 = None
        rsqrt_46 = torch.ops.aten.rsqrt.default(add_959);  add_959 = None
        mul_699 = torch.ops.aten.mul.Tensor(convert_element_type_807, rsqrt_46);  convert_element_type_807 = None
        mul_700 = torch.ops.aten.mul.Tensor(mul_699, wait_tensor_308);  mul_699 = wait_tensor_308 = None
        convert_element_type_808 = torch.ops.prims.convert_element_type.default(mul_700, torch.bfloat16);  mul_700 = None
        convert_element_type_809 = torch.ops.prims.convert_element_type.default(primals_251, torch.bfloat16)
        all_gather_into_tensor_253 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_809, 128, '0');  convert_element_type_809 = None
        wait_tensor_309 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_253);  all_gather_into_tensor_253 = None
        permute_223 = torch.ops.aten.permute.default(wait_tensor_309, [1, 0]);  wait_tensor_309 = None
        view_988 = torch.ops.aten.view.default(convert_element_type_808, [8192, 512]);  convert_element_type_808 = None
        mm_121 = torch.ops.aten.mm.default(view_988, permute_223);  permute_223 = None
        view_989 = torch.ops.aten.view.default(mm_121, [2, 4096, 4096]);  mm_121 = None
        view_990 = torch.ops.aten.view.default(view_989, [2, 4096, -1, 256]);  view_989 = None
        split_with_sizes_47 = torch.ops.aten.split_with_sizes.default(view_990, [128, 128], -1);  view_990 = None
        getitem_1553 = split_with_sizes_47[0]
        getitem_1554 = split_with_sizes_47[1];  split_with_sizes_47 = None
        expand_15 = torch.ops.aten.expand.default(convert_element_type_805, [-1, -1, 16, -1]);  convert_element_type_805 = None
        cat_129 = torch.ops.aten.cat.default([getitem_1553, expand_15], -1);  getitem_1553 = expand_15 = None
        permute_224 = torch.ops.aten.permute.default(cat_128, [0, 2, 1, 3]);  cat_128 = None
        permute_225 = torch.ops.aten.permute.default(cat_129, [0, 2, 1, 3]);  cat_129 = None
        permute_226 = torch.ops.aten.permute.default(getitem_1554, [0, 2, 1, 3]);  getitem_1554 = None
        sdpa_score15 = self.sdpa_score15
        sdpa_mask15 = self.sdpa_mask15
        flex_attention_15 = torch.ops.higher_order.flex_attention(permute_224, permute_225, permute_226, sdpa_score15, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask15), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score15 = sdpa_mask15 = None
        getitem_1555 = flex_attention_15[0]
        getitem_1556 = flex_attention_15[1];  flex_attention_15 = None
        permute_227 = torch.ops.aten.permute.default(getitem_1555, [0, 2, 1, 3])
        view_991 = torch.ops.aten.view.default(permute_227, [2, 4096, -1]);  permute_227 = None
        convert_element_type_812 = torch.ops.prims.convert_element_type.default(primals_252, torch.bfloat16)
        all_gather_into_tensor_254 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_812, 128, '0');  convert_element_type_812 = None
        wait_tensor_310 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_254);  all_gather_into_tensor_254 = None
        permute_228 = torch.ops.aten.permute.default(wait_tensor_310, [1, 0]);  wait_tensor_310 = None
        view_993 = torch.ops.aten.view.default(view_991, [8192, 2048]);  view_991 = None
        mm_122 = torch.ops.aten.mm.default(view_993, permute_228);  view_993 = permute_228 = None
        view_994 = torch.ops.aten.view.default(mm_122, [2, 4096, 2048]);  mm_122 = None
        add_960 = torch.ops.aten.add.Tensor(add_957, view_994);  view_994 = None
        convert_element_type_815 = torch.ops.prims.convert_element_type.default(primals_253, torch.bfloat16)
        all_gather_into_tensor_255 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_815, 128, '0');  convert_element_type_815 = None
        wait_tensor_311 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_255);  all_gather_into_tensor_255 = None
        convert_element_type_816 = torch.ops.prims.convert_element_type.default(add_960, torch.float32)
        pow_48 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_816, 2)
        mean_47 = torch.ops.aten.mean.dim(pow_48, [2], True);  pow_48 = None
        add_961 = torch.ops.aten.add.Scalar(mean_47, 1e-05);  mean_47 = None
        rsqrt_47 = torch.ops.aten.rsqrt.default(add_961);  add_961 = None
        mul_701 = torch.ops.aten.mul.Tensor(convert_element_type_816, rsqrt_47);  convert_element_type_816 = None
        mul_702 = torch.ops.aten.mul.Tensor(mul_701, wait_tensor_311);  mul_701 = wait_tensor_311 = None
        convert_element_type_817 = torch.ops.prims.convert_element_type.default(mul_702, torch.bfloat16);  mul_702 = None
        view_996 = torch.ops.aten.view.default(convert_element_type_817, [-1, 2048]);  convert_element_type_817 = None
        convert_element_type_818 = torch.ops.prims.convert_element_type.default(primals_255, torch.bfloat16)
        all_gather_into_tensor_256 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_818, 128, '0');  convert_element_type_818 = None
        wait_tensor_312 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_256);  all_gather_into_tensor_256 = None
        slice_93 = torch.ops.aten.slice.Tensor(wait_tensor_312, 0, 0, 64);  wait_tensor_312 = None
        permute_229 = torch.ops.aten.permute.default(slice_93, [1, 0]);  slice_93 = None
        mm_123 = torch.ops.aten.mm.default(view_996, permute_229);  permute_229 = None
        convert_element_type_821 = torch.ops.prims.convert_element_type.default(mm_123, torch.float32)
        amax_14 = torch.ops.aten.amax.default(convert_element_type_821, [1], True)
        sub_336 = torch.ops.aten.sub.Tensor(convert_element_type_821, amax_14);  convert_element_type_821 = None
        exp_43 = torch.ops.aten.exp.default(sub_336);  sub_336 = None
        sum_57 = torch.ops.aten.sum.dim_IntList(exp_43, [1], True)
        div_71 = torch.ops.aten.div.Tensor(exp_43, sum_57);  exp_43 = None
        add_962 = torch.ops.aten.add.Tensor(div_71, primals_254);  primals_254 = None
        topk_14 = torch.ops.aten.topk.default(add_962, 6, -1, True, False);  add_962 = None
        getitem_1559 = topk_14[1];  topk_14 = None
        gather_14 = torch.ops.aten.gather.default(div_71, 1, getitem_1559);  div_71 = None
        mul_703 = torch.ops.aten.mul.Tensor(gather_14, 1.0);  gather_14 = None
        view_998 = torch.ops.aten.view.default(getitem_1559, [-1])
        histc_28 = torch.ops.aten.histc.default(view_998, 64, 0, 64)
        add_963 = torch.ops.aten.add.Tensor(primals_256, histc_28)
        sort_14 = torch.ops.aten.sort.stable(view_998, stable = True);  view_998 = None
        getitem_1561 = sort_14[1];  sort_14 = None
        div_72 = torch.ops.aten.div.Tensor_mode(getitem_1561, 6, rounding_mode = 'floor')
        index_28 = torch.ops.aten.index.Tensor(view_996, [div_72])
        all_to_all_single_42 = torch.ops._c10d_functional.all_to_all_single.default(histc_28, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_313 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_42);  all_to_all_single_42 = None
        wait_tensor_314 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_313);  wait_tensor_313 = None
        view_1002 = torch.ops.aten.view.default(histc_28, [8, -1]);  histc_28 = None
        sum_58 = torch.ops.aten.sum.dim_IntList(view_1002, [1]);  view_1002 = None
        device_put_28 = torch.ops.prims.device_put.default(sum_58, device(type='cpu'), True);  sum_58 = None
        view_1003 = torch.ops.aten.view.default(wait_tensor_314, [8, -1])
        sum_59 = torch.ops.aten.sum.dim_IntList(view_1003, [1])
        device_put_29 = torch.ops.prims.device_put.default(sum_59, device(type='cpu'));  sum_59 = None
        select_224 = torch.ops.aten.select.int(device_put_28, 0, 0)
        _local_scalar_dense_224 = torch.ops.aten._local_scalar_dense.default(select_224);  select_224 = None
        ge_280 = _local_scalar_dense_224 >= 0
        _assert_scalar_224 = torch.ops.aten._assert_scalar.default(ge_280, "Runtime assertion failed for expression u224 >= 0 on node 'ge_224'");  ge_280 = _assert_scalar_224 = None
        select_225 = torch.ops.aten.select.int(device_put_28, 0, 1)
        _local_scalar_dense_225 = torch.ops.aten._local_scalar_dense.default(select_225);  select_225 = None
        ge_281 = _local_scalar_dense_225 >= 0
        _assert_scalar_225 = torch.ops.aten._assert_scalar.default(ge_281, "Runtime assertion failed for expression u225 >= 0 on node 'ge_225'");  ge_281 = _assert_scalar_225 = None
        select_226 = torch.ops.aten.select.int(device_put_28, 0, 2)
        _local_scalar_dense_226 = torch.ops.aten._local_scalar_dense.default(select_226);  select_226 = None
        ge_282 = _local_scalar_dense_226 >= 0
        _assert_scalar_226 = torch.ops.aten._assert_scalar.default(ge_282, "Runtime assertion failed for expression u226 >= 0 on node 'ge_226'");  ge_282 = _assert_scalar_226 = None
        select_227 = torch.ops.aten.select.int(device_put_28, 0, 3)
        _local_scalar_dense_227 = torch.ops.aten._local_scalar_dense.default(select_227);  select_227 = None
        ge_283 = _local_scalar_dense_227 >= 0
        _assert_scalar_227 = torch.ops.aten._assert_scalar.default(ge_283, "Runtime assertion failed for expression u227 >= 0 on node 'ge_227'");  ge_283 = _assert_scalar_227 = None
        select_228 = torch.ops.aten.select.int(device_put_28, 0, 4)
        _local_scalar_dense_228 = torch.ops.aten._local_scalar_dense.default(select_228);  select_228 = None
        ge_284 = _local_scalar_dense_228 >= 0
        _assert_scalar_228 = torch.ops.aten._assert_scalar.default(ge_284, "Runtime assertion failed for expression u228 >= 0 on node 'ge_228'");  ge_284 = _assert_scalar_228 = None
        select_229 = torch.ops.aten.select.int(device_put_28, 0, 5)
        _local_scalar_dense_229 = torch.ops.aten._local_scalar_dense.default(select_229);  select_229 = None
        ge_285 = _local_scalar_dense_229 >= 0
        _assert_scalar_229 = torch.ops.aten._assert_scalar.default(ge_285, "Runtime assertion failed for expression u229 >= 0 on node 'ge_229'");  ge_285 = _assert_scalar_229 = None
        select_230 = torch.ops.aten.select.int(device_put_28, 0, 6)
        _local_scalar_dense_230 = torch.ops.aten._local_scalar_dense.default(select_230);  select_230 = None
        ge_286 = _local_scalar_dense_230 >= 0
        _assert_scalar_230 = torch.ops.aten._assert_scalar.default(ge_286, "Runtime assertion failed for expression u230 >= 0 on node 'ge_230'");  ge_286 = _assert_scalar_230 = None
        select_231 = torch.ops.aten.select.int(device_put_28, 0, 7);  device_put_28 = None
        _local_scalar_dense_231 = torch.ops.aten._local_scalar_dense.default(select_231);  select_231 = None
        ge_287 = _local_scalar_dense_231 >= 0
        _assert_scalar_231 = torch.ops.aten._assert_scalar.default(ge_287, "Runtime assertion failed for expression u231 >= 0 on node 'ge_231'");  ge_287 = _assert_scalar_231 = None
        select_232 = torch.ops.aten.select.int(device_put_29, 0, 0)
        _local_scalar_dense_232 = torch.ops.aten._local_scalar_dense.default(select_232);  select_232 = None
        ge_288 = _local_scalar_dense_232 >= 0
        _assert_scalar_232 = torch.ops.aten._assert_scalar.default(ge_288, "Runtime assertion failed for expression u232 >= 0 on node 'ge_232'");  ge_288 = _assert_scalar_232 = None
        select_233 = torch.ops.aten.select.int(device_put_29, 0, 1)
        _local_scalar_dense_233 = torch.ops.aten._local_scalar_dense.default(select_233);  select_233 = None
        ge_289 = _local_scalar_dense_233 >= 0
        _assert_scalar_233 = torch.ops.aten._assert_scalar.default(ge_289, "Runtime assertion failed for expression u233 >= 0 on node 'ge_233'");  ge_289 = _assert_scalar_233 = None
        select_234 = torch.ops.aten.select.int(device_put_29, 0, 2)
        _local_scalar_dense_234 = torch.ops.aten._local_scalar_dense.default(select_234);  select_234 = None
        ge_290 = _local_scalar_dense_234 >= 0
        _assert_scalar_234 = torch.ops.aten._assert_scalar.default(ge_290, "Runtime assertion failed for expression u234 >= 0 on node 'ge_234'");  ge_290 = _assert_scalar_234 = None
        select_235 = torch.ops.aten.select.int(device_put_29, 0, 3)
        _local_scalar_dense_235 = torch.ops.aten._local_scalar_dense.default(select_235);  select_235 = None
        ge_291 = _local_scalar_dense_235 >= 0
        _assert_scalar_235 = torch.ops.aten._assert_scalar.default(ge_291, "Runtime assertion failed for expression u235 >= 0 on node 'ge_235'");  ge_291 = _assert_scalar_235 = None
        select_236 = torch.ops.aten.select.int(device_put_29, 0, 4)
        _local_scalar_dense_236 = torch.ops.aten._local_scalar_dense.default(select_236);  select_236 = None
        ge_292 = _local_scalar_dense_236 >= 0
        _assert_scalar_236 = torch.ops.aten._assert_scalar.default(ge_292, "Runtime assertion failed for expression u236 >= 0 on node 'ge_236'");  ge_292 = _assert_scalar_236 = None
        select_237 = torch.ops.aten.select.int(device_put_29, 0, 5)
        _local_scalar_dense_237 = torch.ops.aten._local_scalar_dense.default(select_237);  select_237 = None
        ge_293 = _local_scalar_dense_237 >= 0
        _assert_scalar_237 = torch.ops.aten._assert_scalar.default(ge_293, "Runtime assertion failed for expression u237 >= 0 on node 'ge_237'");  ge_293 = _assert_scalar_237 = None
        select_238 = torch.ops.aten.select.int(device_put_29, 0, 6)
        _local_scalar_dense_238 = torch.ops.aten._local_scalar_dense.default(select_238);  select_238 = None
        ge_294 = _local_scalar_dense_238 >= 0
        _assert_scalar_238 = torch.ops.aten._assert_scalar.default(ge_294, "Runtime assertion failed for expression u238 >= 0 on node 'ge_238'");  ge_294 = _assert_scalar_238 = None
        select_239 = torch.ops.aten.select.int(device_put_29, 0, 7);  device_put_29 = None
        _local_scalar_dense_239 = torch.ops.aten._local_scalar_dense.default(select_239);  select_239 = None
        ge_295 = _local_scalar_dense_239 >= 0
        _assert_scalar_239 = torch.ops.aten._assert_scalar.default(ge_295, "Runtime assertion failed for expression u239 >= 0 on node 'ge_239'");  ge_295 = _assert_scalar_239 = None
        all_to_all_single_43 = torch.ops._c10d_functional.all_to_all_single.default(index_28, [_local_scalar_dense_232, _local_scalar_dense_233, _local_scalar_dense_234, _local_scalar_dense_235, _local_scalar_dense_236, _local_scalar_dense_237, _local_scalar_dense_238, _local_scalar_dense_239], [_local_scalar_dense_224, _local_scalar_dense_225, _local_scalar_dense_226, _local_scalar_dense_227, _local_scalar_dense_228, _local_scalar_dense_229, _local_scalar_dense_230, _local_scalar_dense_231], '1033');  index_28 = None
        sym_size_int_56 = torch.ops.aten.sym_size.int(all_to_all_single_43, 0)
        wait_tensor_315 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_43);  all_to_all_single_43 = None
        sym_sum_28 = torch.sym_sum((_local_scalar_dense_232, _local_scalar_dense_233, _local_scalar_dense_234, _local_scalar_dense_235, _local_scalar_dense_236, _local_scalar_dense_237, _local_scalar_dense_238, _local_scalar_dense_239))
        add_970 = sym_sum_28 + 64;  sym_sum_28 = None
        add_971 = add_970 + 8;  add_970 = None
        sub_339 = add_971 - 1;  add_971 = None
        floordiv_14 = sub_339 // 8;  sub_339 = None
        mul_708 = floordiv_14 * 8;  floordiv_14 = None
        cumsum_42 = torch.ops.aten.cumsum.default(wait_tensor_314, 0)
        sub_340 = torch.ops.aten.sub.Tensor(cumsum_42, wait_tensor_314);  cumsum_42 = None
        sum_60 = torch.ops.aten.sum.dim_IntList(view_1003, [0]);  view_1003 = None
        clamp_min_14 = torch.ops.aten.clamp_min.default(sum_60, 8);  sum_60 = None
        add_972 = torch.ops.aten.add.Tensor(clamp_min_14, 8);  clamp_min_14 = None
        sub_341 = torch.ops.aten.sub.Tensor(add_972, 1);  add_972 = None
        div_73 = torch.ops.aten.div.Tensor_mode(sub_341, 8, rounding_mode = 'floor');  sub_341 = None
        mul_709 = torch.ops.aten.mul.Tensor(div_73, 8);  div_73 = None
        convert_element_type_824 = torch.ops.prims.convert_element_type.default(mul_709, torch.int32);  mul_709 = None
        cumsum_43 = torch.ops.aten.cumsum.default(convert_element_type_824, 0)
        sub_342 = torch.ops.aten.sub.Tensor(cumsum_43, convert_element_type_824);  cumsum_43 = None
        full_202 = torch.ops.aten.full.default([mul_708], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_708 = None
        triton_kernel_wrapper_functional_proxy_14 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 14, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_314, 'start_index_values_ptr': sub_340, 'write_offsets_ptr': sub_342, 'output_ptr': full_202}, tensors_to_clone = ['output_ptr']);  wait_tensor_314 = sub_340 = sub_342 = full_202 = None
        getitem_1562 = triton_kernel_wrapper_functional_proxy_14['output_ptr'];  triton_kernel_wrapper_functional_proxy_14 = None
        cat_130 = torch.ops.aten.cat.default([wait_tensor_315, full_default]);  wait_tensor_315 = None
        sym_size_int_57 = torch.ops.aten.sym_size.int(cat_130, 0)
        sym_sum_29 = torch.sym_sum((1, _local_scalar_dense_232, _local_scalar_dense_233, _local_scalar_dense_234, _local_scalar_dense_235, _local_scalar_dense_236, _local_scalar_dense_237, _local_scalar_dense_238, _local_scalar_dense_239))
        index_29 = torch.ops.aten.index.Tensor(cat_130, [getitem_1562]);  cat_130 = None
        convert_element_type_826 = torch.ops.prims.convert_element_type.default(primals_257, torch.bfloat16)
        all_gather_into_tensor_257 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_826, 16, '1025');  convert_element_type_826 = None
        wait_tensor_316 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_257);  all_gather_into_tensor_257 = None
        split_85 = torch.ops.aten.split.Tensor(wait_tensor_316, 8);  wait_tensor_316 = None
        getitem_1579 = split_85[0]
        getitem_1580 = split_85[1]
        getitem_1581 = split_85[2]
        getitem_1582 = split_85[3]
        getitem_1583 = split_85[4]
        getitem_1584 = split_85[5]
        getitem_1585 = split_85[6]
        getitem_1586 = split_85[7]
        getitem_1587 = split_85[8]
        getitem_1588 = split_85[9]
        getitem_1589 = split_85[10]
        getitem_1590 = split_85[11]
        getitem_1591 = split_85[12]
        getitem_1592 = split_85[13]
        getitem_1593 = split_85[14]
        getitem_1594 = split_85[15];  split_85 = None
        cat_132 = torch.ops.aten.cat.default([getitem_1579, getitem_1580, getitem_1581, getitem_1582, getitem_1583, getitem_1584, getitem_1585, getitem_1586, getitem_1587, getitem_1588, getitem_1589, getitem_1590, getitem_1591, getitem_1592, getitem_1593, getitem_1594], 1);  getitem_1579 = getitem_1580 = getitem_1581 = getitem_1582 = getitem_1583 = getitem_1584 = getitem_1585 = getitem_1586 = getitem_1587 = getitem_1588 = getitem_1589 = getitem_1590 = getitem_1591 = getitem_1592 = getitem_1593 = getitem_1594 = None
        convert_element_type_828 = torch.ops.prims.convert_element_type.default(primals_258, torch.bfloat16)
        all_gather_into_tensor_259 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_828, 16, '1025');  convert_element_type_828 = None
        wait_tensor_318 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_259);  all_gather_into_tensor_259 = None
        split_86 = torch.ops.aten.split.Tensor(wait_tensor_318, 8);  wait_tensor_318 = None
        getitem_1595 = split_86[0]
        getitem_1596 = split_86[1]
        getitem_1597 = split_86[2]
        getitem_1598 = split_86[3]
        getitem_1599 = split_86[4]
        getitem_1600 = split_86[5]
        getitem_1601 = split_86[6]
        getitem_1602 = split_86[7]
        getitem_1603 = split_86[8]
        getitem_1604 = split_86[9]
        getitem_1605 = split_86[10]
        getitem_1606 = split_86[11]
        getitem_1607 = split_86[12]
        getitem_1608 = split_86[13]
        getitem_1609 = split_86[14]
        getitem_1610 = split_86[15];  split_86 = None
        cat_133 = torch.ops.aten.cat.default([getitem_1595, getitem_1596, getitem_1597, getitem_1598, getitem_1599, getitem_1600, getitem_1601, getitem_1602, getitem_1603, getitem_1604, getitem_1605, getitem_1606, getitem_1607, getitem_1608, getitem_1609, getitem_1610], 1);  getitem_1595 = getitem_1596 = getitem_1597 = getitem_1598 = getitem_1599 = getitem_1600 = getitem_1601 = getitem_1602 = getitem_1603 = getitem_1604 = getitem_1605 = getitem_1606 = getitem_1607 = getitem_1608 = getitem_1609 = getitem_1610 = None
        convert_element_type_829 = torch.ops.prims.convert_element_type.default(primals_259, torch.bfloat16)
        all_gather_into_tensor_260 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_829, 16, '1025');  convert_element_type_829 = None
        wait_tensor_319 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_260);  all_gather_into_tensor_260 = None
        split_87 = torch.ops.aten.split.Tensor(wait_tensor_319, 8);  wait_tensor_319 = None
        getitem_1611 = split_87[0]
        getitem_1612 = split_87[1]
        getitem_1613 = split_87[2]
        getitem_1614 = split_87[3]
        getitem_1615 = split_87[4]
        getitem_1616 = split_87[5]
        getitem_1617 = split_87[6]
        getitem_1618 = split_87[7]
        getitem_1619 = split_87[8]
        getitem_1620 = split_87[9]
        getitem_1621 = split_87[10]
        getitem_1622 = split_87[11]
        getitem_1623 = split_87[12]
        getitem_1624 = split_87[13]
        getitem_1625 = split_87[14]
        getitem_1626 = split_87[15];  split_87 = None
        cat_134 = torch.ops.aten.cat.default([getitem_1611, getitem_1612, getitem_1613, getitem_1614, getitem_1615, getitem_1616, getitem_1617, getitem_1618, getitem_1619, getitem_1620, getitem_1621, getitem_1622, getitem_1623, getitem_1624, getitem_1625, getitem_1626], 1);  getitem_1611 = getitem_1612 = getitem_1613 = getitem_1614 = getitem_1615 = getitem_1616 = getitem_1617 = getitem_1618 = getitem_1619 = getitem_1620 = getitem_1621 = getitem_1622 = getitem_1623 = getitem_1624 = getitem_1625 = getitem_1626 = None
        cumsum_44 = torch.ops.aten.cumsum.default(convert_element_type_824, 0, dtype = torch.int32);  convert_element_type_824 = None
        permute_230 = torch.ops.aten.permute.default(cat_132, [0, 2, 1]);  cat_132 = None
        _grouped_mm_42 = torch.ops.aten._grouped_mm.default(index_29, permute_230, cumsum_44)
        convert_element_type_832 = torch.ops.prims.convert_element_type.default(_grouped_mm_42, torch.float32)
        neg_29 = torch.ops.aten.neg.default(convert_element_type_832)
        exp_44 = torch.ops.aten.exp.default(neg_29);  neg_29 = None
        add_984 = torch.ops.aten.add.Tensor(exp_44, 1);  exp_44 = None
        div_74 = torch.ops.aten.div.Tensor(convert_element_type_832, add_984);  convert_element_type_832 = add_984 = None
        convert_element_type_833 = torch.ops.prims.convert_element_type.default(div_74, torch.bfloat16);  div_74 = None
        permute_231 = torch.ops.aten.permute.default(cat_134, [0, 2, 1]);  cat_134 = None
        _grouped_mm_43 = torch.ops.aten._grouped_mm.default(index_29, permute_231, cumsum_44)
        mul_721 = torch.ops.aten.mul.Tensor(convert_element_type_833, _grouped_mm_43);  convert_element_type_833 = None
        permute_232 = torch.ops.aten.permute.default(cat_133, [0, 2, 1]);  cat_133 = None
        _grouped_mm_44 = torch.ops.aten._grouped_mm.default(mul_721, permute_232, cumsum_44)
        empty_14 = torch.ops.aten.empty.memory_format([sym_size_int_57, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_28 = torch.ops.aten.index_put.default(empty_14, [getitem_1562], _grouped_mm_44);  empty_14 = _grouped_mm_44 = None
        slice_95 = torch.ops.aten.slice.Tensor(index_put_28, 0, 0, -1);  index_put_28 = None
        all_to_all_single_44 = torch.ops._c10d_functional.all_to_all_single.default(slice_95, [_local_scalar_dense_224, _local_scalar_dense_225, _local_scalar_dense_226, _local_scalar_dense_227, _local_scalar_dense_228, _local_scalar_dense_229, _local_scalar_dense_230, _local_scalar_dense_231], [_local_scalar_dense_232, _local_scalar_dense_233, _local_scalar_dense_234, _local_scalar_dense_235, _local_scalar_dense_236, _local_scalar_dense_237, _local_scalar_dense_238, _local_scalar_dense_239], '1033');  slice_95 = None
        wait_tensor_322 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_44);  all_to_all_single_44 = None
        convert_element_type_834 = torch.ops.prims.convert_element_type.default(primals_260, torch.bfloat16)
        all_gather_into_tensor_263 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_834, 128, '0');  convert_element_type_834 = None
        wait_tensor_323 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_263);  all_gather_into_tensor_263 = None
        permute_233 = torch.ops.aten.permute.default(wait_tensor_323, [1, 0]);  wait_tensor_323 = None
        mm_124 = torch.ops.aten.mm.default(view_996, permute_233);  permute_233 = None
        convert_element_type_837 = torch.ops.prims.convert_element_type.default(mm_124, torch.float32)
        neg_30 = torch.ops.aten.neg.default(convert_element_type_837)
        exp_45 = torch.ops.aten.exp.default(neg_30);  neg_30 = None
        add_1020 = torch.ops.aten.add.Tensor(exp_45, 1);  exp_45 = None
        div_75 = torch.ops.aten.div.Tensor(convert_element_type_837, add_1020);  convert_element_type_837 = add_1020 = None
        convert_element_type_838 = torch.ops.prims.convert_element_type.default(div_75, torch.bfloat16);  div_75 = None
        convert_element_type_839 = torch.ops.prims.convert_element_type.default(primals_261, torch.bfloat16)
        all_gather_into_tensor_264 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_839, 128, '0');  convert_element_type_839 = None
        wait_tensor_324 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_264);  all_gather_into_tensor_264 = None
        permute_234 = torch.ops.aten.permute.default(wait_tensor_324, [1, 0]);  wait_tensor_324 = None
        mm_125 = torch.ops.aten.mm.default(view_996, permute_234);  permute_234 = None
        mul_741 = torch.ops.aten.mul.Tensor(convert_element_type_838, mm_125);  convert_element_type_838 = None
        convert_element_type_842 = torch.ops.prims.convert_element_type.default(primals_262, torch.bfloat16)
        all_gather_into_tensor_265 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_842, 128, '0');  convert_element_type_842 = None
        wait_tensor_325 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_265);  all_gather_into_tensor_265 = None
        permute_235 = torch.ops.aten.permute.default(wait_tensor_325, [1, 0]);  wait_tensor_325 = None
        mm_126 = torch.ops.aten.mm.default(mul_741, permute_235);  permute_235 = None
        index_put_29 = torch.ops.aten.index_put.default(full_default_1, [getitem_1561], wait_tensor_322);  wait_tensor_322 = None
        view_1036 = torch.ops.aten.view.default(mul_703, [-1, 1, 6]);  mul_703 = None
        view_1037 = torch.ops.aten.view.default(index_put_29, [-1, 6, 2048]);  index_put_29 = None
        convert_element_type_845 = torch.ops.prims.convert_element_type.default(view_1037, torch.float32);  view_1037 = None
        bmm_14 = torch.ops.aten.bmm.default(view_1036, convert_element_type_845)
        convert_element_type_846 = torch.ops.prims.convert_element_type.default(bmm_14, torch.bfloat16);  bmm_14 = None
        squeeze_14 = torch.ops.aten.squeeze.dim(convert_element_type_846, 1);  convert_element_type_846 = None
        add_1024 = torch.ops.aten.add.Tensor(mm_126, squeeze_14);  mm_126 = squeeze_14 = None
        view_1038 = torch.ops.aten.view.default(add_1024, [2, 4096, 2048]);  add_1024 = None
        add_1025 = torch.ops.aten.add.Tensor(add_960, view_1038);  view_1038 = None
        convert_element_type_847 = torch.ops.prims.convert_element_type.default(primals_263, torch.bfloat16)
        all_gather_into_tensor_266 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_847, 128, '0');  convert_element_type_847 = None
        wait_tensor_326 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_266);  all_gather_into_tensor_266 = None
        convert_element_type_848 = torch.ops.prims.convert_element_type.default(add_1025, torch.float32)
        pow_49 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_848, 2)
        mean_48 = torch.ops.aten.mean.dim(pow_49, [2], True);  pow_49 = None
        add_1026 = torch.ops.aten.add.Scalar(mean_48, 1e-05);  mean_48 = None
        rsqrt_48 = torch.ops.aten.rsqrt.default(add_1026);  add_1026 = None
        mul_744 = torch.ops.aten.mul.Tensor(convert_element_type_848, rsqrt_48);  convert_element_type_848 = None
        mul_745 = torch.ops.aten.mul.Tensor(mul_744, wait_tensor_326);  mul_744 = wait_tensor_326 = None
        convert_element_type_849 = torch.ops.prims.convert_element_type.default(mul_745, torch.bfloat16);  mul_745 = None
        convert_element_type_850 = torch.ops.prims.convert_element_type.default(primals_264, torch.bfloat16)
        all_gather_into_tensor_267 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_850, 128, '0');  convert_element_type_850 = None
        wait_tensor_327 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_267);  all_gather_into_tensor_267 = None
        permute_236 = torch.ops.aten.permute.default(wait_tensor_327, [1, 0]);  wait_tensor_327 = None
        view_1041 = torch.ops.aten.view.default(convert_element_type_849, [8192, 2048]);  convert_element_type_849 = None
        mm_127 = torch.ops.aten.mm.default(view_1041, permute_236);  permute_236 = None
        view_1042 = torch.ops.aten.view.default(mm_127, [2, 4096, 3072]);  mm_127 = None
        view_1043 = torch.ops.aten.view.default(view_1042, [2, 4096, -1, 192]);  view_1042 = None
        split_with_sizes_48 = torch.ops.aten.split_with_sizes.default(view_1043, [128, 64], -1);  view_1043 = None
        getitem_1659 = split_with_sizes_48[0]
        getitem_1660 = split_with_sizes_48[1];  split_with_sizes_48 = None
        convert_element_type_853 = torch.ops.prims.convert_element_type.default(getitem_1660, torch.float32);  getitem_1660 = None
        view_1044 = torch.ops.aten.view.default(convert_element_type_853, [2, 4096, 16, -1, 2]);  convert_element_type_853 = None
        view_as_complex_32 = torch.ops.aten.view_as_complex.default(view_1044);  view_1044 = None
        mul_746 = torch.ops.aten.mul.Tensor(view_as_complex_32, view_7);  view_as_complex_32 = None
        view_as_real_32 = torch.ops.aten.view_as_real.default(mul_746);  mul_746 = None
        view_1046 = torch.ops.aten.view.default(view_as_real_32, [2, 4096, 16, 64]);  view_as_real_32 = None
        convert_element_type_854 = torch.ops.prims.convert_element_type.default(view_1046, torch.bfloat16);  view_1046 = None
        cat_137 = torch.ops.aten.cat.default([getitem_1659, convert_element_type_854], -1);  getitem_1659 = convert_element_type_854 = None
        convert_element_type_855 = torch.ops.prims.convert_element_type.default(primals_265, torch.bfloat16)
        all_gather_into_tensor_268 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_855, 128, '0');  convert_element_type_855 = None
        wait_tensor_328 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_268);  all_gather_into_tensor_268 = None
        slice_97 = torch.ops.aten.slice.Tensor(wait_tensor_328, 0, 0, 576);  wait_tensor_328 = None
        permute_237 = torch.ops.aten.permute.default(slice_97, [1, 0]);  slice_97 = None
        mm_128 = torch.ops.aten.mm.default(view_1041, permute_237);  permute_237 = None
        view_1049 = torch.ops.aten.view.default(mm_128, [2, 4096, 576]);  mm_128 = None
        split_with_sizes_49 = torch.ops.aten.split_with_sizes.default(view_1049, [512, 64], -1);  view_1049 = None
        getitem_1661 = split_with_sizes_49[0]
        getitem_1662 = split_with_sizes_49[1];  split_with_sizes_49 = None
        unsqueeze_31 = torch.ops.aten.unsqueeze.default(getitem_1662, 2);  getitem_1662 = None
        convert_element_type_858 = torch.ops.prims.convert_element_type.default(unsqueeze_31, torch.float32);  unsqueeze_31 = None
        view_1050 = torch.ops.aten.view.default(convert_element_type_858, [2, 4096, 1, -1, 2]);  convert_element_type_858 = None
        view_as_complex_33 = torch.ops.aten.view_as_complex.default(view_1050);  view_1050 = None
        mul_747 = torch.ops.aten.mul.Tensor(view_as_complex_33, view_7);  view_as_complex_33 = None
        view_as_real_33 = torch.ops.aten.view_as_real.default(mul_747);  mul_747 = None
        view_1052 = torch.ops.aten.view.default(view_as_real_33, [2, 4096, 1, 64]);  view_as_real_33 = None
        convert_element_type_859 = torch.ops.prims.convert_element_type.default(view_1052, torch.bfloat16);  view_1052 = None
        convert_element_type_860 = torch.ops.prims.convert_element_type.default(primals_266, torch.bfloat16)
        all_gather_into_tensor_269 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_860, 128, '0');  convert_element_type_860 = None
        wait_tensor_329 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_269);  all_gather_into_tensor_269 = None
        convert_element_type_861 = torch.ops.prims.convert_element_type.default(getitem_1661, torch.float32)
        pow_50 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_861, 2)
        mean_49 = torch.ops.aten.mean.dim(pow_50, [2], True);  pow_50 = None
        add_1027 = torch.ops.aten.add.Scalar(mean_49, 1e-05);  mean_49 = None
        rsqrt_49 = torch.ops.aten.rsqrt.default(add_1027);  add_1027 = None
        mul_748 = torch.ops.aten.mul.Tensor(convert_element_type_861, rsqrt_49);  convert_element_type_861 = None
        mul_749 = torch.ops.aten.mul.Tensor(mul_748, wait_tensor_329);  mul_748 = wait_tensor_329 = None
        convert_element_type_862 = torch.ops.prims.convert_element_type.default(mul_749, torch.bfloat16);  mul_749 = None
        convert_element_type_863 = torch.ops.prims.convert_element_type.default(primals_267, torch.bfloat16)
        all_gather_into_tensor_270 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_863, 128, '0');  convert_element_type_863 = None
        wait_tensor_330 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_270);  all_gather_into_tensor_270 = None
        permute_238 = torch.ops.aten.permute.default(wait_tensor_330, [1, 0]);  wait_tensor_330 = None
        view_1055 = torch.ops.aten.view.default(convert_element_type_862, [8192, 512]);  convert_element_type_862 = None
        mm_129 = torch.ops.aten.mm.default(view_1055, permute_238);  permute_238 = None
        view_1056 = torch.ops.aten.view.default(mm_129, [2, 4096, 4096]);  mm_129 = None
        view_1057 = torch.ops.aten.view.default(view_1056, [2, 4096, -1, 256]);  view_1056 = None
        split_with_sizes_50 = torch.ops.aten.split_with_sizes.default(view_1057, [128, 128], -1);  view_1057 = None
        getitem_1663 = split_with_sizes_50[0]
        getitem_1664 = split_with_sizes_50[1];  split_with_sizes_50 = None
        expand_16 = torch.ops.aten.expand.default(convert_element_type_859, [-1, -1, 16, -1]);  convert_element_type_859 = None
        cat_138 = torch.ops.aten.cat.default([getitem_1663, expand_16], -1);  getitem_1663 = expand_16 = None
        permute_239 = torch.ops.aten.permute.default(cat_137, [0, 2, 1, 3]);  cat_137 = None
        permute_240 = torch.ops.aten.permute.default(cat_138, [0, 2, 1, 3]);  cat_138 = None
        permute_241 = torch.ops.aten.permute.default(getitem_1664, [0, 2, 1, 3]);  getitem_1664 = None
        sdpa_score16 = self.sdpa_score16
        sdpa_mask16 = self.sdpa_mask16
        flex_attention_16 = torch.ops.higher_order.flex_attention(permute_239, permute_240, permute_241, sdpa_score16, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask16), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score16 = sdpa_mask16 = None
        getitem_1665 = flex_attention_16[0]
        getitem_1666 = flex_attention_16[1];  flex_attention_16 = None
        permute_242 = torch.ops.aten.permute.default(getitem_1665, [0, 2, 1, 3])
        view_1058 = torch.ops.aten.view.default(permute_242, [2, 4096, -1]);  permute_242 = None
        convert_element_type_866 = torch.ops.prims.convert_element_type.default(primals_268, torch.bfloat16)
        all_gather_into_tensor_271 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_866, 128, '0');  convert_element_type_866 = None
        wait_tensor_331 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_271);  all_gather_into_tensor_271 = None
        permute_243 = torch.ops.aten.permute.default(wait_tensor_331, [1, 0]);  wait_tensor_331 = None
        view_1060 = torch.ops.aten.view.default(view_1058, [8192, 2048]);  view_1058 = None
        mm_130 = torch.ops.aten.mm.default(view_1060, permute_243);  view_1060 = permute_243 = None
        view_1061 = torch.ops.aten.view.default(mm_130, [2, 4096, 2048]);  mm_130 = None
        add_1028 = torch.ops.aten.add.Tensor(add_1025, view_1061);  view_1061 = None
        convert_element_type_869 = torch.ops.prims.convert_element_type.default(primals_269, torch.bfloat16)
        all_gather_into_tensor_272 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_869, 128, '0');  convert_element_type_869 = None
        wait_tensor_332 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_272);  all_gather_into_tensor_272 = None
        convert_element_type_870 = torch.ops.prims.convert_element_type.default(add_1028, torch.float32)
        pow_51 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_870, 2)
        mean_50 = torch.ops.aten.mean.dim(pow_51, [2], True);  pow_51 = None
        add_1029 = torch.ops.aten.add.Scalar(mean_50, 1e-05);  mean_50 = None
        rsqrt_50 = torch.ops.aten.rsqrt.default(add_1029);  add_1029 = None
        mul_750 = torch.ops.aten.mul.Tensor(convert_element_type_870, rsqrt_50);  convert_element_type_870 = None
        mul_751 = torch.ops.aten.mul.Tensor(mul_750, wait_tensor_332);  mul_750 = wait_tensor_332 = None
        convert_element_type_871 = torch.ops.prims.convert_element_type.default(mul_751, torch.bfloat16);  mul_751 = None
        view_1063 = torch.ops.aten.view.default(convert_element_type_871, [-1, 2048]);  convert_element_type_871 = None
        convert_element_type_872 = torch.ops.prims.convert_element_type.default(primals_271, torch.bfloat16)
        all_gather_into_tensor_273 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_872, 128, '0');  convert_element_type_872 = None
        wait_tensor_333 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_273);  all_gather_into_tensor_273 = None
        slice_99 = torch.ops.aten.slice.Tensor(wait_tensor_333, 0, 0, 64);  wait_tensor_333 = None
        permute_244 = torch.ops.aten.permute.default(slice_99, [1, 0]);  slice_99 = None
        mm_131 = torch.ops.aten.mm.default(view_1063, permute_244);  permute_244 = None
        convert_element_type_875 = torch.ops.prims.convert_element_type.default(mm_131, torch.float32)
        amax_15 = torch.ops.aten.amax.default(convert_element_type_875, [1], True)
        sub_360 = torch.ops.aten.sub.Tensor(convert_element_type_875, amax_15);  convert_element_type_875 = None
        exp_46 = torch.ops.aten.exp.default(sub_360);  sub_360 = None
        sum_61 = torch.ops.aten.sum.dim_IntList(exp_46, [1], True)
        div_76 = torch.ops.aten.div.Tensor(exp_46, sum_61);  exp_46 = None
        add_1030 = torch.ops.aten.add.Tensor(div_76, primals_270);  primals_270 = None
        topk_15 = torch.ops.aten.topk.default(add_1030, 6, -1, True, False);  add_1030 = None
        getitem_1669 = topk_15[1];  topk_15 = None
        gather_15 = torch.ops.aten.gather.default(div_76, 1, getitem_1669);  div_76 = None
        mul_752 = torch.ops.aten.mul.Tensor(gather_15, 1.0);  gather_15 = None
        view_1065 = torch.ops.aten.view.default(getitem_1669, [-1])
        histc_30 = torch.ops.aten.histc.default(view_1065, 64, 0, 64)
        add_1031 = torch.ops.aten.add.Tensor(primals_272, histc_30)
        sort_15 = torch.ops.aten.sort.stable(view_1065, stable = True);  view_1065 = None
        getitem_1671 = sort_15[1];  sort_15 = None
        div_77 = torch.ops.aten.div.Tensor_mode(getitem_1671, 6, rounding_mode = 'floor')
        index_30 = torch.ops.aten.index.Tensor(view_1063, [div_77])
        all_to_all_single_45 = torch.ops._c10d_functional.all_to_all_single.default(histc_30, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_334 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_45);  all_to_all_single_45 = None
        wait_tensor_335 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_334);  wait_tensor_334 = None
        view_1069 = torch.ops.aten.view.default(histc_30, [8, -1]);  histc_30 = None
        sum_62 = torch.ops.aten.sum.dim_IntList(view_1069, [1]);  view_1069 = None
        device_put_30 = torch.ops.prims.device_put.default(sum_62, device(type='cpu'), True);  sum_62 = None
        view_1070 = torch.ops.aten.view.default(wait_tensor_335, [8, -1])
        sum_63 = torch.ops.aten.sum.dim_IntList(view_1070, [1])
        device_put_31 = torch.ops.prims.device_put.default(sum_63, device(type='cpu'));  sum_63 = None
        select_240 = torch.ops.aten.select.int(device_put_30, 0, 0)
        _local_scalar_dense_240 = torch.ops.aten._local_scalar_dense.default(select_240);  select_240 = None
        ge_300 = _local_scalar_dense_240 >= 0
        _assert_scalar_240 = torch.ops.aten._assert_scalar.default(ge_300, "Runtime assertion failed for expression u240 >= 0 on node 'ge_240'");  ge_300 = _assert_scalar_240 = None
        select_241 = torch.ops.aten.select.int(device_put_30, 0, 1)
        _local_scalar_dense_241 = torch.ops.aten._local_scalar_dense.default(select_241);  select_241 = None
        ge_301 = _local_scalar_dense_241 >= 0
        _assert_scalar_241 = torch.ops.aten._assert_scalar.default(ge_301, "Runtime assertion failed for expression u241 >= 0 on node 'ge_241'");  ge_301 = _assert_scalar_241 = None
        select_242 = torch.ops.aten.select.int(device_put_30, 0, 2)
        _local_scalar_dense_242 = torch.ops.aten._local_scalar_dense.default(select_242);  select_242 = None
        ge_302 = _local_scalar_dense_242 >= 0
        _assert_scalar_242 = torch.ops.aten._assert_scalar.default(ge_302, "Runtime assertion failed for expression u242 >= 0 on node 'ge_242'");  ge_302 = _assert_scalar_242 = None
        select_243 = torch.ops.aten.select.int(device_put_30, 0, 3)
        _local_scalar_dense_243 = torch.ops.aten._local_scalar_dense.default(select_243);  select_243 = None
        ge_303 = _local_scalar_dense_243 >= 0
        _assert_scalar_243 = torch.ops.aten._assert_scalar.default(ge_303, "Runtime assertion failed for expression u243 >= 0 on node 'ge_243'");  ge_303 = _assert_scalar_243 = None
        select_244 = torch.ops.aten.select.int(device_put_30, 0, 4)
        _local_scalar_dense_244 = torch.ops.aten._local_scalar_dense.default(select_244);  select_244 = None
        ge_304 = _local_scalar_dense_244 >= 0
        _assert_scalar_244 = torch.ops.aten._assert_scalar.default(ge_304, "Runtime assertion failed for expression u244 >= 0 on node 'ge_244'");  ge_304 = _assert_scalar_244 = None
        select_245 = torch.ops.aten.select.int(device_put_30, 0, 5)
        _local_scalar_dense_245 = torch.ops.aten._local_scalar_dense.default(select_245);  select_245 = None
        ge_305 = _local_scalar_dense_245 >= 0
        _assert_scalar_245 = torch.ops.aten._assert_scalar.default(ge_305, "Runtime assertion failed for expression u245 >= 0 on node 'ge_245'");  ge_305 = _assert_scalar_245 = None
        select_246 = torch.ops.aten.select.int(device_put_30, 0, 6)
        _local_scalar_dense_246 = torch.ops.aten._local_scalar_dense.default(select_246);  select_246 = None
        ge_306 = _local_scalar_dense_246 >= 0
        _assert_scalar_246 = torch.ops.aten._assert_scalar.default(ge_306, "Runtime assertion failed for expression u246 >= 0 on node 'ge_246'");  ge_306 = _assert_scalar_246 = None
        select_247 = torch.ops.aten.select.int(device_put_30, 0, 7);  device_put_30 = None
        _local_scalar_dense_247 = torch.ops.aten._local_scalar_dense.default(select_247);  select_247 = None
        ge_307 = _local_scalar_dense_247 >= 0
        _assert_scalar_247 = torch.ops.aten._assert_scalar.default(ge_307, "Runtime assertion failed for expression u247 >= 0 on node 'ge_247'");  ge_307 = _assert_scalar_247 = None
        select_248 = torch.ops.aten.select.int(device_put_31, 0, 0)
        _local_scalar_dense_248 = torch.ops.aten._local_scalar_dense.default(select_248);  select_248 = None
        ge_308 = _local_scalar_dense_248 >= 0
        _assert_scalar_248 = torch.ops.aten._assert_scalar.default(ge_308, "Runtime assertion failed for expression u248 >= 0 on node 'ge_248'");  ge_308 = _assert_scalar_248 = None
        select_249 = torch.ops.aten.select.int(device_put_31, 0, 1)
        _local_scalar_dense_249 = torch.ops.aten._local_scalar_dense.default(select_249);  select_249 = None
        ge_309 = _local_scalar_dense_249 >= 0
        _assert_scalar_249 = torch.ops.aten._assert_scalar.default(ge_309, "Runtime assertion failed for expression u249 >= 0 on node 'ge_249'");  ge_309 = _assert_scalar_249 = None
        select_250 = torch.ops.aten.select.int(device_put_31, 0, 2)
        _local_scalar_dense_250 = torch.ops.aten._local_scalar_dense.default(select_250);  select_250 = None
        ge_310 = _local_scalar_dense_250 >= 0
        _assert_scalar_250 = torch.ops.aten._assert_scalar.default(ge_310, "Runtime assertion failed for expression u250 >= 0 on node 'ge_250'");  ge_310 = _assert_scalar_250 = None
        select_251 = torch.ops.aten.select.int(device_put_31, 0, 3)
        _local_scalar_dense_251 = torch.ops.aten._local_scalar_dense.default(select_251);  select_251 = None
        ge_311 = _local_scalar_dense_251 >= 0
        _assert_scalar_251 = torch.ops.aten._assert_scalar.default(ge_311, "Runtime assertion failed for expression u251 >= 0 on node 'ge_251'");  ge_311 = _assert_scalar_251 = None
        select_252 = torch.ops.aten.select.int(device_put_31, 0, 4)
        _local_scalar_dense_252 = torch.ops.aten._local_scalar_dense.default(select_252);  select_252 = None
        ge_312 = _local_scalar_dense_252 >= 0
        _assert_scalar_252 = torch.ops.aten._assert_scalar.default(ge_312, "Runtime assertion failed for expression u252 >= 0 on node 'ge_252'");  ge_312 = _assert_scalar_252 = None
        select_253 = torch.ops.aten.select.int(device_put_31, 0, 5)
        _local_scalar_dense_253 = torch.ops.aten._local_scalar_dense.default(select_253);  select_253 = None
        ge_313 = _local_scalar_dense_253 >= 0
        _assert_scalar_253 = torch.ops.aten._assert_scalar.default(ge_313, "Runtime assertion failed for expression u253 >= 0 on node 'ge_253'");  ge_313 = _assert_scalar_253 = None
        select_254 = torch.ops.aten.select.int(device_put_31, 0, 6)
        _local_scalar_dense_254 = torch.ops.aten._local_scalar_dense.default(select_254);  select_254 = None
        ge_314 = _local_scalar_dense_254 >= 0
        _assert_scalar_254 = torch.ops.aten._assert_scalar.default(ge_314, "Runtime assertion failed for expression u254 >= 0 on node 'ge_254'");  ge_314 = _assert_scalar_254 = None
        select_255 = torch.ops.aten.select.int(device_put_31, 0, 7);  device_put_31 = None
        _local_scalar_dense_255 = torch.ops.aten._local_scalar_dense.default(select_255);  select_255 = None
        ge_315 = _local_scalar_dense_255 >= 0
        _assert_scalar_255 = torch.ops.aten._assert_scalar.default(ge_315, "Runtime assertion failed for expression u255 >= 0 on node 'ge_255'");  ge_315 = _assert_scalar_255 = None
        all_to_all_single_46 = torch.ops._c10d_functional.all_to_all_single.default(index_30, [_local_scalar_dense_248, _local_scalar_dense_249, _local_scalar_dense_250, _local_scalar_dense_251, _local_scalar_dense_252, _local_scalar_dense_253, _local_scalar_dense_254, _local_scalar_dense_255], [_local_scalar_dense_240, _local_scalar_dense_241, _local_scalar_dense_242, _local_scalar_dense_243, _local_scalar_dense_244, _local_scalar_dense_245, _local_scalar_dense_246, _local_scalar_dense_247], '1033');  index_30 = None
        sym_size_int_60 = torch.ops.aten.sym_size.int(all_to_all_single_46, 0)
        wait_tensor_336 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_46);  all_to_all_single_46 = None
        sym_sum_30 = torch.sym_sum((_local_scalar_dense_248, _local_scalar_dense_249, _local_scalar_dense_250, _local_scalar_dense_251, _local_scalar_dense_252, _local_scalar_dense_253, _local_scalar_dense_254, _local_scalar_dense_255))
        add_1038 = sym_sum_30 + 64;  sym_sum_30 = None
        add_1039 = add_1038 + 8;  add_1038 = None
        sub_363 = add_1039 - 1;  add_1039 = None
        floordiv_15 = sub_363 // 8;  sub_363 = None
        mul_757 = floordiv_15 * 8;  floordiv_15 = None
        cumsum_45 = torch.ops.aten.cumsum.default(wait_tensor_335, 0)
        sub_364 = torch.ops.aten.sub.Tensor(cumsum_45, wait_tensor_335);  cumsum_45 = None
        sum_64 = torch.ops.aten.sum.dim_IntList(view_1070, [0]);  view_1070 = None
        clamp_min_15 = torch.ops.aten.clamp_min.default(sum_64, 8);  sum_64 = None
        add_1040 = torch.ops.aten.add.Tensor(clamp_min_15, 8);  clamp_min_15 = None
        sub_365 = torch.ops.aten.sub.Tensor(add_1040, 1);  add_1040 = None
        div_78 = torch.ops.aten.div.Tensor_mode(sub_365, 8, rounding_mode = 'floor');  sub_365 = None
        mul_758 = torch.ops.aten.mul.Tensor(div_78, 8);  div_78 = None
        convert_element_type_878 = torch.ops.prims.convert_element_type.default(mul_758, torch.int32);  mul_758 = None
        cumsum_46 = torch.ops.aten.cumsum.default(convert_element_type_878, 0)
        sub_366 = torch.ops.aten.sub.Tensor(cumsum_46, convert_element_type_878);  cumsum_46 = None
        full_215 = torch.ops.aten.full.default([mul_757], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_757 = None
        triton_kernel_wrapper_functional_proxy_15 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 15, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_335, 'start_index_values_ptr': sub_364, 'write_offsets_ptr': sub_366, 'output_ptr': full_215}, tensors_to_clone = ['output_ptr']);  wait_tensor_335 = sub_364 = sub_366 = full_215 = None
        getitem_1672 = triton_kernel_wrapper_functional_proxy_15['output_ptr'];  triton_kernel_wrapper_functional_proxy_15 = None
        cat_139 = torch.ops.aten.cat.default([wait_tensor_336, full_default]);  wait_tensor_336 = None
        sym_size_int_61 = torch.ops.aten.sym_size.int(cat_139, 0)
        sym_sum_31 = torch.sym_sum((1, _local_scalar_dense_248, _local_scalar_dense_249, _local_scalar_dense_250, _local_scalar_dense_251, _local_scalar_dense_252, _local_scalar_dense_253, _local_scalar_dense_254, _local_scalar_dense_255))
        index_31 = torch.ops.aten.index.Tensor(cat_139, [getitem_1672]);  cat_139 = None
        convert_element_type_880 = torch.ops.prims.convert_element_type.default(primals_273, torch.bfloat16)
        all_gather_into_tensor_274 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_880, 16, '1025');  convert_element_type_880 = None
        wait_tensor_337 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_274);  all_gather_into_tensor_274 = None
        split_91 = torch.ops.aten.split.Tensor(wait_tensor_337, 8);  wait_tensor_337 = None
        getitem_1689 = split_91[0]
        getitem_1690 = split_91[1]
        getitem_1691 = split_91[2]
        getitem_1692 = split_91[3]
        getitem_1693 = split_91[4]
        getitem_1694 = split_91[5]
        getitem_1695 = split_91[6]
        getitem_1696 = split_91[7]
        getitem_1697 = split_91[8]
        getitem_1698 = split_91[9]
        getitem_1699 = split_91[10]
        getitem_1700 = split_91[11]
        getitem_1701 = split_91[12]
        getitem_1702 = split_91[13]
        getitem_1703 = split_91[14]
        getitem_1704 = split_91[15];  split_91 = None
        cat_141 = torch.ops.aten.cat.default([getitem_1689, getitem_1690, getitem_1691, getitem_1692, getitem_1693, getitem_1694, getitem_1695, getitem_1696, getitem_1697, getitem_1698, getitem_1699, getitem_1700, getitem_1701, getitem_1702, getitem_1703, getitem_1704], 1);  getitem_1689 = getitem_1690 = getitem_1691 = getitem_1692 = getitem_1693 = getitem_1694 = getitem_1695 = getitem_1696 = getitem_1697 = getitem_1698 = getitem_1699 = getitem_1700 = getitem_1701 = getitem_1702 = getitem_1703 = getitem_1704 = None
        convert_element_type_882 = torch.ops.prims.convert_element_type.default(primals_274, torch.bfloat16)
        all_gather_into_tensor_276 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_882, 16, '1025');  convert_element_type_882 = None
        wait_tensor_339 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_276);  all_gather_into_tensor_276 = None
        split_92 = torch.ops.aten.split.Tensor(wait_tensor_339, 8);  wait_tensor_339 = None
        getitem_1705 = split_92[0]
        getitem_1706 = split_92[1]
        getitem_1707 = split_92[2]
        getitem_1708 = split_92[3]
        getitem_1709 = split_92[4]
        getitem_1710 = split_92[5]
        getitem_1711 = split_92[6]
        getitem_1712 = split_92[7]
        getitem_1713 = split_92[8]
        getitem_1714 = split_92[9]
        getitem_1715 = split_92[10]
        getitem_1716 = split_92[11]
        getitem_1717 = split_92[12]
        getitem_1718 = split_92[13]
        getitem_1719 = split_92[14]
        getitem_1720 = split_92[15];  split_92 = None
        cat_142 = torch.ops.aten.cat.default([getitem_1705, getitem_1706, getitem_1707, getitem_1708, getitem_1709, getitem_1710, getitem_1711, getitem_1712, getitem_1713, getitem_1714, getitem_1715, getitem_1716, getitem_1717, getitem_1718, getitem_1719, getitem_1720], 1);  getitem_1705 = getitem_1706 = getitem_1707 = getitem_1708 = getitem_1709 = getitem_1710 = getitem_1711 = getitem_1712 = getitem_1713 = getitem_1714 = getitem_1715 = getitem_1716 = getitem_1717 = getitem_1718 = getitem_1719 = getitem_1720 = None
        convert_element_type_883 = torch.ops.prims.convert_element_type.default(primals_275, torch.bfloat16)
        all_gather_into_tensor_277 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_883, 16, '1025');  convert_element_type_883 = None
        wait_tensor_340 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_277);  all_gather_into_tensor_277 = None
        split_93 = torch.ops.aten.split.Tensor(wait_tensor_340, 8);  wait_tensor_340 = None
        getitem_1721 = split_93[0]
        getitem_1722 = split_93[1]
        getitem_1723 = split_93[2]
        getitem_1724 = split_93[3]
        getitem_1725 = split_93[4]
        getitem_1726 = split_93[5]
        getitem_1727 = split_93[6]
        getitem_1728 = split_93[7]
        getitem_1729 = split_93[8]
        getitem_1730 = split_93[9]
        getitem_1731 = split_93[10]
        getitem_1732 = split_93[11]
        getitem_1733 = split_93[12]
        getitem_1734 = split_93[13]
        getitem_1735 = split_93[14]
        getitem_1736 = split_93[15];  split_93 = None
        cat_143 = torch.ops.aten.cat.default([getitem_1721, getitem_1722, getitem_1723, getitem_1724, getitem_1725, getitem_1726, getitem_1727, getitem_1728, getitem_1729, getitem_1730, getitem_1731, getitem_1732, getitem_1733, getitem_1734, getitem_1735, getitem_1736], 1);  getitem_1721 = getitem_1722 = getitem_1723 = getitem_1724 = getitem_1725 = getitem_1726 = getitem_1727 = getitem_1728 = getitem_1729 = getitem_1730 = getitem_1731 = getitem_1732 = getitem_1733 = getitem_1734 = getitem_1735 = getitem_1736 = None
        cumsum_47 = torch.ops.aten.cumsum.default(convert_element_type_878, 0, dtype = torch.int32);  convert_element_type_878 = None
        permute_245 = torch.ops.aten.permute.default(cat_141, [0, 2, 1]);  cat_141 = None
        _grouped_mm_45 = torch.ops.aten._grouped_mm.default(index_31, permute_245, cumsum_47)
        convert_element_type_886 = torch.ops.prims.convert_element_type.default(_grouped_mm_45, torch.float32)
        neg_31 = torch.ops.aten.neg.default(convert_element_type_886)
        exp_47 = torch.ops.aten.exp.default(neg_31);  neg_31 = None
        add_1052 = torch.ops.aten.add.Tensor(exp_47, 1);  exp_47 = None
        div_79 = torch.ops.aten.div.Tensor(convert_element_type_886, add_1052);  convert_element_type_886 = add_1052 = None
        convert_element_type_887 = torch.ops.prims.convert_element_type.default(div_79, torch.bfloat16);  div_79 = None
        permute_246 = torch.ops.aten.permute.default(cat_143, [0, 2, 1]);  cat_143 = None
        _grouped_mm_46 = torch.ops.aten._grouped_mm.default(index_31, permute_246, cumsum_47)
        mul_770 = torch.ops.aten.mul.Tensor(convert_element_type_887, _grouped_mm_46);  convert_element_type_887 = None
        permute_247 = torch.ops.aten.permute.default(cat_142, [0, 2, 1]);  cat_142 = None
        _grouped_mm_47 = torch.ops.aten._grouped_mm.default(mul_770, permute_247, cumsum_47)
        empty_15 = torch.ops.aten.empty.memory_format([sym_size_int_61, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_30 = torch.ops.aten.index_put.default(empty_15, [getitem_1672], _grouped_mm_47);  empty_15 = _grouped_mm_47 = None
        slice_101 = torch.ops.aten.slice.Tensor(index_put_30, 0, 0, -1);  index_put_30 = None
        all_to_all_single_47 = torch.ops._c10d_functional.all_to_all_single.default(slice_101, [_local_scalar_dense_240, _local_scalar_dense_241, _local_scalar_dense_242, _local_scalar_dense_243, _local_scalar_dense_244, _local_scalar_dense_245, _local_scalar_dense_246, _local_scalar_dense_247], [_local_scalar_dense_248, _local_scalar_dense_249, _local_scalar_dense_250, _local_scalar_dense_251, _local_scalar_dense_252, _local_scalar_dense_253, _local_scalar_dense_254, _local_scalar_dense_255], '1033');  slice_101 = None
        wait_tensor_343 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_47);  all_to_all_single_47 = None
        convert_element_type_888 = torch.ops.prims.convert_element_type.default(primals_276, torch.bfloat16)
        all_gather_into_tensor_280 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_888, 128, '0');  convert_element_type_888 = None
        wait_tensor_344 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_280);  all_gather_into_tensor_280 = None
        permute_248 = torch.ops.aten.permute.default(wait_tensor_344, [1, 0]);  wait_tensor_344 = None
        mm_132 = torch.ops.aten.mm.default(view_1063, permute_248);  permute_248 = None
        convert_element_type_891 = torch.ops.prims.convert_element_type.default(mm_132, torch.float32)
        neg_32 = torch.ops.aten.neg.default(convert_element_type_891)
        exp_48 = torch.ops.aten.exp.default(neg_32);  neg_32 = None
        add_1088 = torch.ops.aten.add.Tensor(exp_48, 1);  exp_48 = None
        div_80 = torch.ops.aten.div.Tensor(convert_element_type_891, add_1088);  convert_element_type_891 = add_1088 = None
        convert_element_type_892 = torch.ops.prims.convert_element_type.default(div_80, torch.bfloat16);  div_80 = None
        convert_element_type_893 = torch.ops.prims.convert_element_type.default(primals_277, torch.bfloat16)
        all_gather_into_tensor_281 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_893, 128, '0');  convert_element_type_893 = None
        wait_tensor_345 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_281);  all_gather_into_tensor_281 = None
        permute_249 = torch.ops.aten.permute.default(wait_tensor_345, [1, 0]);  wait_tensor_345 = None
        mm_133 = torch.ops.aten.mm.default(view_1063, permute_249);  permute_249 = None
        mul_790 = torch.ops.aten.mul.Tensor(convert_element_type_892, mm_133);  convert_element_type_892 = None
        convert_element_type_896 = torch.ops.prims.convert_element_type.default(primals_278, torch.bfloat16)
        all_gather_into_tensor_282 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_896, 128, '0');  convert_element_type_896 = None
        wait_tensor_346 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_282);  all_gather_into_tensor_282 = None
        permute_250 = torch.ops.aten.permute.default(wait_tensor_346, [1, 0]);  wait_tensor_346 = None
        mm_134 = torch.ops.aten.mm.default(mul_790, permute_250);  permute_250 = None
        index_put_31 = torch.ops.aten.index_put.default(full_default_1, [getitem_1671], wait_tensor_343);  wait_tensor_343 = None
        view_1103 = torch.ops.aten.view.default(mul_752, [-1, 1, 6]);  mul_752 = None
        view_1104 = torch.ops.aten.view.default(index_put_31, [-1, 6, 2048]);  index_put_31 = None
        convert_element_type_899 = torch.ops.prims.convert_element_type.default(view_1104, torch.float32);  view_1104 = None
        bmm_15 = torch.ops.aten.bmm.default(view_1103, convert_element_type_899)
        convert_element_type_900 = torch.ops.prims.convert_element_type.default(bmm_15, torch.bfloat16);  bmm_15 = None
        squeeze_15 = torch.ops.aten.squeeze.dim(convert_element_type_900, 1);  convert_element_type_900 = None
        add_1092 = torch.ops.aten.add.Tensor(mm_134, squeeze_15);  mm_134 = squeeze_15 = None
        view_1105 = torch.ops.aten.view.default(add_1092, [2, 4096, 2048]);  add_1092 = None
        add_1093 = torch.ops.aten.add.Tensor(add_1028, view_1105);  view_1105 = None
        convert_element_type_901 = torch.ops.prims.convert_element_type.default(primals_279, torch.bfloat16)
        all_gather_into_tensor_283 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_901, 128, '0');  convert_element_type_901 = None
        wait_tensor_347 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_283);  all_gather_into_tensor_283 = None
        convert_element_type_902 = torch.ops.prims.convert_element_type.default(add_1093, torch.float32)
        pow_52 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_902, 2)
        mean_51 = torch.ops.aten.mean.dim(pow_52, [2], True);  pow_52 = None
        add_1094 = torch.ops.aten.add.Scalar(mean_51, 1e-05);  mean_51 = None
        rsqrt_51 = torch.ops.aten.rsqrt.default(add_1094);  add_1094 = None
        mul_793 = torch.ops.aten.mul.Tensor(convert_element_type_902, rsqrt_51);  convert_element_type_902 = None
        mul_794 = torch.ops.aten.mul.Tensor(mul_793, wait_tensor_347);  mul_793 = wait_tensor_347 = None
        convert_element_type_903 = torch.ops.prims.convert_element_type.default(mul_794, torch.bfloat16);  mul_794 = None
        convert_element_type_904 = torch.ops.prims.convert_element_type.default(primals_280, torch.bfloat16)
        all_gather_into_tensor_284 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_904, 128, '0');  convert_element_type_904 = None
        wait_tensor_348 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_284);  all_gather_into_tensor_284 = None
        permute_251 = torch.ops.aten.permute.default(wait_tensor_348, [1, 0]);  wait_tensor_348 = None
        view_1108 = torch.ops.aten.view.default(convert_element_type_903, [8192, 2048]);  convert_element_type_903 = None
        mm_135 = torch.ops.aten.mm.default(view_1108, permute_251);  permute_251 = None
        view_1109 = torch.ops.aten.view.default(mm_135, [2, 4096, 3072]);  mm_135 = None
        view_1110 = torch.ops.aten.view.default(view_1109, [2, 4096, -1, 192]);  view_1109 = None
        split_with_sizes_51 = torch.ops.aten.split_with_sizes.default(view_1110, [128, 64], -1);  view_1110 = None
        getitem_1769 = split_with_sizes_51[0]
        getitem_1770 = split_with_sizes_51[1];  split_with_sizes_51 = None
        convert_element_type_907 = torch.ops.prims.convert_element_type.default(getitem_1770, torch.float32);  getitem_1770 = None
        view_1111 = torch.ops.aten.view.default(convert_element_type_907, [2, 4096, 16, -1, 2]);  convert_element_type_907 = None
        view_as_complex_34 = torch.ops.aten.view_as_complex.default(view_1111);  view_1111 = None
        mul_795 = torch.ops.aten.mul.Tensor(view_as_complex_34, view_7);  view_as_complex_34 = None
        view_as_real_34 = torch.ops.aten.view_as_real.default(mul_795);  mul_795 = None
        view_1113 = torch.ops.aten.view.default(view_as_real_34, [2, 4096, 16, 64]);  view_as_real_34 = None
        convert_element_type_908 = torch.ops.prims.convert_element_type.default(view_1113, torch.bfloat16);  view_1113 = None
        cat_146 = torch.ops.aten.cat.default([getitem_1769, convert_element_type_908], -1);  getitem_1769 = convert_element_type_908 = None
        convert_element_type_909 = torch.ops.prims.convert_element_type.default(primals_281, torch.bfloat16)
        all_gather_into_tensor_285 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_909, 128, '0');  convert_element_type_909 = None
        wait_tensor_349 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_285);  all_gather_into_tensor_285 = None
        slice_103 = torch.ops.aten.slice.Tensor(wait_tensor_349, 0, 0, 576);  wait_tensor_349 = None
        permute_252 = torch.ops.aten.permute.default(slice_103, [1, 0]);  slice_103 = None
        mm_136 = torch.ops.aten.mm.default(view_1108, permute_252);  permute_252 = None
        view_1116 = torch.ops.aten.view.default(mm_136, [2, 4096, 576]);  mm_136 = None
        split_with_sizes_52 = torch.ops.aten.split_with_sizes.default(view_1116, [512, 64], -1);  view_1116 = None
        getitem_1771 = split_with_sizes_52[0]
        getitem_1772 = split_with_sizes_52[1];  split_with_sizes_52 = None
        unsqueeze_33 = torch.ops.aten.unsqueeze.default(getitem_1772, 2);  getitem_1772 = None
        convert_element_type_912 = torch.ops.prims.convert_element_type.default(unsqueeze_33, torch.float32);  unsqueeze_33 = None
        view_1117 = torch.ops.aten.view.default(convert_element_type_912, [2, 4096, 1, -1, 2]);  convert_element_type_912 = None
        view_as_complex_35 = torch.ops.aten.view_as_complex.default(view_1117);  view_1117 = None
        mul_796 = torch.ops.aten.mul.Tensor(view_as_complex_35, view_7);  view_as_complex_35 = None
        view_as_real_35 = torch.ops.aten.view_as_real.default(mul_796);  mul_796 = None
        view_1119 = torch.ops.aten.view.default(view_as_real_35, [2, 4096, 1, 64]);  view_as_real_35 = None
        convert_element_type_913 = torch.ops.prims.convert_element_type.default(view_1119, torch.bfloat16);  view_1119 = None
        convert_element_type_914 = torch.ops.prims.convert_element_type.default(primals_282, torch.bfloat16)
        all_gather_into_tensor_286 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_914, 128, '0');  convert_element_type_914 = None
        wait_tensor_350 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_286);  all_gather_into_tensor_286 = None
        convert_element_type_915 = torch.ops.prims.convert_element_type.default(getitem_1771, torch.float32)
        pow_53 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_915, 2)
        mean_52 = torch.ops.aten.mean.dim(pow_53, [2], True);  pow_53 = None
        add_1095 = torch.ops.aten.add.Scalar(mean_52, 1e-05);  mean_52 = None
        rsqrt_52 = torch.ops.aten.rsqrt.default(add_1095);  add_1095 = None
        mul_797 = torch.ops.aten.mul.Tensor(convert_element_type_915, rsqrt_52);  convert_element_type_915 = None
        mul_798 = torch.ops.aten.mul.Tensor(mul_797, wait_tensor_350);  mul_797 = wait_tensor_350 = None
        convert_element_type_916 = torch.ops.prims.convert_element_type.default(mul_798, torch.bfloat16);  mul_798 = None
        convert_element_type_917 = torch.ops.prims.convert_element_type.default(primals_283, torch.bfloat16)
        all_gather_into_tensor_287 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_917, 128, '0');  convert_element_type_917 = None
        wait_tensor_351 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_287);  all_gather_into_tensor_287 = None
        permute_253 = torch.ops.aten.permute.default(wait_tensor_351, [1, 0]);  wait_tensor_351 = None
        view_1122 = torch.ops.aten.view.default(convert_element_type_916, [8192, 512]);  convert_element_type_916 = None
        mm_137 = torch.ops.aten.mm.default(view_1122, permute_253);  permute_253 = None
        view_1123 = torch.ops.aten.view.default(mm_137, [2, 4096, 4096]);  mm_137 = None
        view_1124 = torch.ops.aten.view.default(view_1123, [2, 4096, -1, 256]);  view_1123 = None
        split_with_sizes_53 = torch.ops.aten.split_with_sizes.default(view_1124, [128, 128], -1);  view_1124 = None
        getitem_1773 = split_with_sizes_53[0]
        getitem_1774 = split_with_sizes_53[1];  split_with_sizes_53 = None
        expand_17 = torch.ops.aten.expand.default(convert_element_type_913, [-1, -1, 16, -1]);  convert_element_type_913 = None
        cat_147 = torch.ops.aten.cat.default([getitem_1773, expand_17], -1);  getitem_1773 = expand_17 = None
        permute_254 = torch.ops.aten.permute.default(cat_146, [0, 2, 1, 3]);  cat_146 = None
        permute_255 = torch.ops.aten.permute.default(cat_147, [0, 2, 1, 3]);  cat_147 = None
        permute_256 = torch.ops.aten.permute.default(getitem_1774, [0, 2, 1, 3]);  getitem_1774 = None
        sdpa_score17 = self.sdpa_score17
        sdpa_mask17 = self.sdpa_mask17
        flex_attention_17 = torch.ops.higher_order.flex_attention(permute_254, permute_255, permute_256, sdpa_score17, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask17), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score17 = sdpa_mask17 = None
        getitem_1775 = flex_attention_17[0]
        getitem_1776 = flex_attention_17[1];  flex_attention_17 = None
        permute_257 = torch.ops.aten.permute.default(getitem_1775, [0, 2, 1, 3])
        view_1125 = torch.ops.aten.view.default(permute_257, [2, 4096, -1]);  permute_257 = None
        convert_element_type_920 = torch.ops.prims.convert_element_type.default(primals_284, torch.bfloat16)
        all_gather_into_tensor_288 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_920, 128, '0');  convert_element_type_920 = None
        wait_tensor_352 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_288);  all_gather_into_tensor_288 = None
        permute_258 = torch.ops.aten.permute.default(wait_tensor_352, [1, 0]);  wait_tensor_352 = None
        view_1127 = torch.ops.aten.view.default(view_1125, [8192, 2048]);  view_1125 = None
        mm_138 = torch.ops.aten.mm.default(view_1127, permute_258);  view_1127 = permute_258 = None
        view_1128 = torch.ops.aten.view.default(mm_138, [2, 4096, 2048]);  mm_138 = None
        add_1096 = torch.ops.aten.add.Tensor(add_1093, view_1128);  view_1128 = None
        convert_element_type_923 = torch.ops.prims.convert_element_type.default(primals_285, torch.bfloat16)
        all_gather_into_tensor_289 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_923, 128, '0');  convert_element_type_923 = None
        wait_tensor_353 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_289);  all_gather_into_tensor_289 = None
        convert_element_type_924 = torch.ops.prims.convert_element_type.default(add_1096, torch.float32)
        pow_54 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_924, 2)
        mean_53 = torch.ops.aten.mean.dim(pow_54, [2], True);  pow_54 = None
        add_1097 = torch.ops.aten.add.Scalar(mean_53, 1e-05);  mean_53 = None
        rsqrt_53 = torch.ops.aten.rsqrt.default(add_1097);  add_1097 = None
        mul_799 = torch.ops.aten.mul.Tensor(convert_element_type_924, rsqrt_53);  convert_element_type_924 = None
        mul_800 = torch.ops.aten.mul.Tensor(mul_799, wait_tensor_353);  mul_799 = wait_tensor_353 = None
        convert_element_type_925 = torch.ops.prims.convert_element_type.default(mul_800, torch.bfloat16);  mul_800 = None
        view_1130 = torch.ops.aten.view.default(convert_element_type_925, [-1, 2048]);  convert_element_type_925 = None
        convert_element_type_926 = torch.ops.prims.convert_element_type.default(primals_287, torch.bfloat16)
        all_gather_into_tensor_290 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_926, 128, '0');  convert_element_type_926 = None
        wait_tensor_354 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_290);  all_gather_into_tensor_290 = None
        slice_105 = torch.ops.aten.slice.Tensor(wait_tensor_354, 0, 0, 64);  wait_tensor_354 = None
        permute_259 = torch.ops.aten.permute.default(slice_105, [1, 0]);  slice_105 = None
        mm_139 = torch.ops.aten.mm.default(view_1130, permute_259);  permute_259 = None
        convert_element_type_929 = torch.ops.prims.convert_element_type.default(mm_139, torch.float32)
        amax_16 = torch.ops.aten.amax.default(convert_element_type_929, [1], True)
        sub_384 = torch.ops.aten.sub.Tensor(convert_element_type_929, amax_16);  convert_element_type_929 = None
        exp_49 = torch.ops.aten.exp.default(sub_384);  sub_384 = None
        sum_65 = torch.ops.aten.sum.dim_IntList(exp_49, [1], True)
        div_81 = torch.ops.aten.div.Tensor(exp_49, sum_65);  exp_49 = None
        add_1098 = torch.ops.aten.add.Tensor(div_81, primals_286);  primals_286 = None
        topk_16 = torch.ops.aten.topk.default(add_1098, 6, -1, True, False);  add_1098 = None
        getitem_1779 = topk_16[1];  topk_16 = None
        gather_16 = torch.ops.aten.gather.default(div_81, 1, getitem_1779);  div_81 = None
        mul_801 = torch.ops.aten.mul.Tensor(gather_16, 1.0);  gather_16 = None
        view_1132 = torch.ops.aten.view.default(getitem_1779, [-1])
        histc_32 = torch.ops.aten.histc.default(view_1132, 64, 0, 64)
        add_1099 = torch.ops.aten.add.Tensor(primals_288, histc_32)
        sort_16 = torch.ops.aten.sort.stable(view_1132, stable = True);  view_1132 = None
        getitem_1781 = sort_16[1];  sort_16 = None
        div_82 = torch.ops.aten.div.Tensor_mode(getitem_1781, 6, rounding_mode = 'floor')
        index_32 = torch.ops.aten.index.Tensor(view_1130, [div_82])
        all_to_all_single_48 = torch.ops._c10d_functional.all_to_all_single.default(histc_32, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_355 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_48);  all_to_all_single_48 = None
        wait_tensor_356 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_355);  wait_tensor_355 = None
        view_1136 = torch.ops.aten.view.default(histc_32, [8, -1]);  histc_32 = None
        sum_66 = torch.ops.aten.sum.dim_IntList(view_1136, [1]);  view_1136 = None
        device_put_32 = torch.ops.prims.device_put.default(sum_66, device(type='cpu'), True);  sum_66 = None
        view_1137 = torch.ops.aten.view.default(wait_tensor_356, [8, -1])
        sum_67 = torch.ops.aten.sum.dim_IntList(view_1137, [1])
        device_put_33 = torch.ops.prims.device_put.default(sum_67, device(type='cpu'));  sum_67 = None
        select_256 = torch.ops.aten.select.int(device_put_32, 0, 0)
        _local_scalar_dense_256 = torch.ops.aten._local_scalar_dense.default(select_256);  select_256 = None
        ge_320 = _local_scalar_dense_256 >= 0
        _assert_scalar_256 = torch.ops.aten._assert_scalar.default(ge_320, "Runtime assertion failed for expression u256 >= 0 on node 'ge_256'");  ge_320 = _assert_scalar_256 = None
        select_257 = torch.ops.aten.select.int(device_put_32, 0, 1)
        _local_scalar_dense_257 = torch.ops.aten._local_scalar_dense.default(select_257);  select_257 = None
        ge_321 = _local_scalar_dense_257 >= 0
        _assert_scalar_257 = torch.ops.aten._assert_scalar.default(ge_321, "Runtime assertion failed for expression u257 >= 0 on node 'ge_257'");  ge_321 = _assert_scalar_257 = None
        select_258 = torch.ops.aten.select.int(device_put_32, 0, 2)
        _local_scalar_dense_258 = torch.ops.aten._local_scalar_dense.default(select_258);  select_258 = None
        ge_322 = _local_scalar_dense_258 >= 0
        _assert_scalar_258 = torch.ops.aten._assert_scalar.default(ge_322, "Runtime assertion failed for expression u258 >= 0 on node 'ge_258'");  ge_322 = _assert_scalar_258 = None
        select_259 = torch.ops.aten.select.int(device_put_32, 0, 3)
        _local_scalar_dense_259 = torch.ops.aten._local_scalar_dense.default(select_259);  select_259 = None
        ge_323 = _local_scalar_dense_259 >= 0
        _assert_scalar_259 = torch.ops.aten._assert_scalar.default(ge_323, "Runtime assertion failed for expression u259 >= 0 on node 'ge_259'");  ge_323 = _assert_scalar_259 = None
        select_260 = torch.ops.aten.select.int(device_put_32, 0, 4)
        _local_scalar_dense_260 = torch.ops.aten._local_scalar_dense.default(select_260);  select_260 = None
        ge_324 = _local_scalar_dense_260 >= 0
        _assert_scalar_260 = torch.ops.aten._assert_scalar.default(ge_324, "Runtime assertion failed for expression u260 >= 0 on node 'ge_260'");  ge_324 = _assert_scalar_260 = None
        select_261 = torch.ops.aten.select.int(device_put_32, 0, 5)
        _local_scalar_dense_261 = torch.ops.aten._local_scalar_dense.default(select_261);  select_261 = None
        ge_325 = _local_scalar_dense_261 >= 0
        _assert_scalar_261 = torch.ops.aten._assert_scalar.default(ge_325, "Runtime assertion failed for expression u261 >= 0 on node 'ge_261'");  ge_325 = _assert_scalar_261 = None
        select_262 = torch.ops.aten.select.int(device_put_32, 0, 6)
        _local_scalar_dense_262 = torch.ops.aten._local_scalar_dense.default(select_262);  select_262 = None
        ge_326 = _local_scalar_dense_262 >= 0
        _assert_scalar_262 = torch.ops.aten._assert_scalar.default(ge_326, "Runtime assertion failed for expression u262 >= 0 on node 'ge_262'");  ge_326 = _assert_scalar_262 = None
        select_263 = torch.ops.aten.select.int(device_put_32, 0, 7);  device_put_32 = None
        _local_scalar_dense_263 = torch.ops.aten._local_scalar_dense.default(select_263);  select_263 = None
        ge_327 = _local_scalar_dense_263 >= 0
        _assert_scalar_263 = torch.ops.aten._assert_scalar.default(ge_327, "Runtime assertion failed for expression u263 >= 0 on node 'ge_263'");  ge_327 = _assert_scalar_263 = None
        select_264 = torch.ops.aten.select.int(device_put_33, 0, 0)
        _local_scalar_dense_264 = torch.ops.aten._local_scalar_dense.default(select_264);  select_264 = None
        ge_328 = _local_scalar_dense_264 >= 0
        _assert_scalar_264 = torch.ops.aten._assert_scalar.default(ge_328, "Runtime assertion failed for expression u264 >= 0 on node 'ge_264'");  ge_328 = _assert_scalar_264 = None
        select_265 = torch.ops.aten.select.int(device_put_33, 0, 1)
        _local_scalar_dense_265 = torch.ops.aten._local_scalar_dense.default(select_265);  select_265 = None
        ge_329 = _local_scalar_dense_265 >= 0
        _assert_scalar_265 = torch.ops.aten._assert_scalar.default(ge_329, "Runtime assertion failed for expression u265 >= 0 on node 'ge_265'");  ge_329 = _assert_scalar_265 = None
        select_266 = torch.ops.aten.select.int(device_put_33, 0, 2)
        _local_scalar_dense_266 = torch.ops.aten._local_scalar_dense.default(select_266);  select_266 = None
        ge_330 = _local_scalar_dense_266 >= 0
        _assert_scalar_266 = torch.ops.aten._assert_scalar.default(ge_330, "Runtime assertion failed for expression u266 >= 0 on node 'ge_266'");  ge_330 = _assert_scalar_266 = None
        select_267 = torch.ops.aten.select.int(device_put_33, 0, 3)
        _local_scalar_dense_267 = torch.ops.aten._local_scalar_dense.default(select_267);  select_267 = None
        ge_331 = _local_scalar_dense_267 >= 0
        _assert_scalar_267 = torch.ops.aten._assert_scalar.default(ge_331, "Runtime assertion failed for expression u267 >= 0 on node 'ge_267'");  ge_331 = _assert_scalar_267 = None
        select_268 = torch.ops.aten.select.int(device_put_33, 0, 4)
        _local_scalar_dense_268 = torch.ops.aten._local_scalar_dense.default(select_268);  select_268 = None
        ge_332 = _local_scalar_dense_268 >= 0
        _assert_scalar_268 = torch.ops.aten._assert_scalar.default(ge_332, "Runtime assertion failed for expression u268 >= 0 on node 'ge_268'");  ge_332 = _assert_scalar_268 = None
        select_269 = torch.ops.aten.select.int(device_put_33, 0, 5)
        _local_scalar_dense_269 = torch.ops.aten._local_scalar_dense.default(select_269);  select_269 = None
        ge_333 = _local_scalar_dense_269 >= 0
        _assert_scalar_269 = torch.ops.aten._assert_scalar.default(ge_333, "Runtime assertion failed for expression u269 >= 0 on node 'ge_269'");  ge_333 = _assert_scalar_269 = None
        select_270 = torch.ops.aten.select.int(device_put_33, 0, 6)
        _local_scalar_dense_270 = torch.ops.aten._local_scalar_dense.default(select_270);  select_270 = None
        ge_334 = _local_scalar_dense_270 >= 0
        _assert_scalar_270 = torch.ops.aten._assert_scalar.default(ge_334, "Runtime assertion failed for expression u270 >= 0 on node 'ge_270'");  ge_334 = _assert_scalar_270 = None
        select_271 = torch.ops.aten.select.int(device_put_33, 0, 7);  device_put_33 = None
        _local_scalar_dense_271 = torch.ops.aten._local_scalar_dense.default(select_271);  select_271 = None
        ge_335 = _local_scalar_dense_271 >= 0
        _assert_scalar_271 = torch.ops.aten._assert_scalar.default(ge_335, "Runtime assertion failed for expression u271 >= 0 on node 'ge_271'");  ge_335 = _assert_scalar_271 = None
        all_to_all_single_49 = torch.ops._c10d_functional.all_to_all_single.default(index_32, [_local_scalar_dense_264, _local_scalar_dense_265, _local_scalar_dense_266, _local_scalar_dense_267, _local_scalar_dense_268, _local_scalar_dense_269, _local_scalar_dense_270, _local_scalar_dense_271], [_local_scalar_dense_256, _local_scalar_dense_257, _local_scalar_dense_258, _local_scalar_dense_259, _local_scalar_dense_260, _local_scalar_dense_261, _local_scalar_dense_262, _local_scalar_dense_263], '1033');  index_32 = None
        sym_size_int_64 = torch.ops.aten.sym_size.int(all_to_all_single_49, 0)
        wait_tensor_357 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_49);  all_to_all_single_49 = None
        sym_sum_32 = torch.sym_sum((_local_scalar_dense_264, _local_scalar_dense_265, _local_scalar_dense_266, _local_scalar_dense_267, _local_scalar_dense_268, _local_scalar_dense_269, _local_scalar_dense_270, _local_scalar_dense_271))
        add_1106 = sym_sum_32 + 64;  sym_sum_32 = None
        add_1107 = add_1106 + 8;  add_1106 = None
        sub_387 = add_1107 - 1;  add_1107 = None
        floordiv_16 = sub_387 // 8;  sub_387 = None
        mul_806 = floordiv_16 * 8;  floordiv_16 = None
        cumsum_48 = torch.ops.aten.cumsum.default(wait_tensor_356, 0)
        sub_388 = torch.ops.aten.sub.Tensor(cumsum_48, wait_tensor_356);  cumsum_48 = None
        sum_68 = torch.ops.aten.sum.dim_IntList(view_1137, [0]);  view_1137 = None
        clamp_min_16 = torch.ops.aten.clamp_min.default(sum_68, 8);  sum_68 = None
        add_1108 = torch.ops.aten.add.Tensor(clamp_min_16, 8);  clamp_min_16 = None
        sub_389 = torch.ops.aten.sub.Tensor(add_1108, 1);  add_1108 = None
        div_83 = torch.ops.aten.div.Tensor_mode(sub_389, 8, rounding_mode = 'floor');  sub_389 = None
        mul_807 = torch.ops.aten.mul.Tensor(div_83, 8);  div_83 = None
        convert_element_type_932 = torch.ops.prims.convert_element_type.default(mul_807, torch.int32);  mul_807 = None
        cumsum_49 = torch.ops.aten.cumsum.default(convert_element_type_932, 0)
        sub_390 = torch.ops.aten.sub.Tensor(cumsum_49, convert_element_type_932);  cumsum_49 = None
        full_228 = torch.ops.aten.full.default([mul_806], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_806 = None
        triton_kernel_wrapper_functional_proxy_16 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 16, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_356, 'start_index_values_ptr': sub_388, 'write_offsets_ptr': sub_390, 'output_ptr': full_228}, tensors_to_clone = ['output_ptr']);  wait_tensor_356 = sub_388 = sub_390 = full_228 = None
        getitem_1782 = triton_kernel_wrapper_functional_proxy_16['output_ptr'];  triton_kernel_wrapper_functional_proxy_16 = None
        cat_148 = torch.ops.aten.cat.default([wait_tensor_357, full_default]);  wait_tensor_357 = None
        sym_size_int_65 = torch.ops.aten.sym_size.int(cat_148, 0)
        sym_sum_33 = torch.sym_sum((1, _local_scalar_dense_264, _local_scalar_dense_265, _local_scalar_dense_266, _local_scalar_dense_267, _local_scalar_dense_268, _local_scalar_dense_269, _local_scalar_dense_270, _local_scalar_dense_271))
        index_33 = torch.ops.aten.index.Tensor(cat_148, [getitem_1782]);  cat_148 = None
        convert_element_type_934 = torch.ops.prims.convert_element_type.default(primals_289, torch.bfloat16)
        all_gather_into_tensor_291 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_934, 16, '1025');  convert_element_type_934 = None
        wait_tensor_358 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_291);  all_gather_into_tensor_291 = None
        split_97 = torch.ops.aten.split.Tensor(wait_tensor_358, 8);  wait_tensor_358 = None
        getitem_1799 = split_97[0]
        getitem_1800 = split_97[1]
        getitem_1801 = split_97[2]
        getitem_1802 = split_97[3]
        getitem_1803 = split_97[4]
        getitem_1804 = split_97[5]
        getitem_1805 = split_97[6]
        getitem_1806 = split_97[7]
        getitem_1807 = split_97[8]
        getitem_1808 = split_97[9]
        getitem_1809 = split_97[10]
        getitem_1810 = split_97[11]
        getitem_1811 = split_97[12]
        getitem_1812 = split_97[13]
        getitem_1813 = split_97[14]
        getitem_1814 = split_97[15];  split_97 = None
        cat_150 = torch.ops.aten.cat.default([getitem_1799, getitem_1800, getitem_1801, getitem_1802, getitem_1803, getitem_1804, getitem_1805, getitem_1806, getitem_1807, getitem_1808, getitem_1809, getitem_1810, getitem_1811, getitem_1812, getitem_1813, getitem_1814], 1);  getitem_1799 = getitem_1800 = getitem_1801 = getitem_1802 = getitem_1803 = getitem_1804 = getitem_1805 = getitem_1806 = getitem_1807 = getitem_1808 = getitem_1809 = getitem_1810 = getitem_1811 = getitem_1812 = getitem_1813 = getitem_1814 = None
        convert_element_type_936 = torch.ops.prims.convert_element_type.default(primals_290, torch.bfloat16)
        all_gather_into_tensor_293 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_936, 16, '1025');  convert_element_type_936 = None
        wait_tensor_360 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_293);  all_gather_into_tensor_293 = None
        split_98 = torch.ops.aten.split.Tensor(wait_tensor_360, 8);  wait_tensor_360 = None
        getitem_1815 = split_98[0]
        getitem_1816 = split_98[1]
        getitem_1817 = split_98[2]
        getitem_1818 = split_98[3]
        getitem_1819 = split_98[4]
        getitem_1820 = split_98[5]
        getitem_1821 = split_98[6]
        getitem_1822 = split_98[7]
        getitem_1823 = split_98[8]
        getitem_1824 = split_98[9]
        getitem_1825 = split_98[10]
        getitem_1826 = split_98[11]
        getitem_1827 = split_98[12]
        getitem_1828 = split_98[13]
        getitem_1829 = split_98[14]
        getitem_1830 = split_98[15];  split_98 = None
        cat_151 = torch.ops.aten.cat.default([getitem_1815, getitem_1816, getitem_1817, getitem_1818, getitem_1819, getitem_1820, getitem_1821, getitem_1822, getitem_1823, getitem_1824, getitem_1825, getitem_1826, getitem_1827, getitem_1828, getitem_1829, getitem_1830], 1);  getitem_1815 = getitem_1816 = getitem_1817 = getitem_1818 = getitem_1819 = getitem_1820 = getitem_1821 = getitem_1822 = getitem_1823 = getitem_1824 = getitem_1825 = getitem_1826 = getitem_1827 = getitem_1828 = getitem_1829 = getitem_1830 = None
        convert_element_type_937 = torch.ops.prims.convert_element_type.default(primals_291, torch.bfloat16)
        all_gather_into_tensor_294 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_937, 16, '1025');  convert_element_type_937 = None
        wait_tensor_361 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_294);  all_gather_into_tensor_294 = None
        split_99 = torch.ops.aten.split.Tensor(wait_tensor_361, 8);  wait_tensor_361 = None
        getitem_1831 = split_99[0]
        getitem_1832 = split_99[1]
        getitem_1833 = split_99[2]
        getitem_1834 = split_99[3]
        getitem_1835 = split_99[4]
        getitem_1836 = split_99[5]
        getitem_1837 = split_99[6]
        getitem_1838 = split_99[7]
        getitem_1839 = split_99[8]
        getitem_1840 = split_99[9]
        getitem_1841 = split_99[10]
        getitem_1842 = split_99[11]
        getitem_1843 = split_99[12]
        getitem_1844 = split_99[13]
        getitem_1845 = split_99[14]
        getitem_1846 = split_99[15];  split_99 = None
        cat_152 = torch.ops.aten.cat.default([getitem_1831, getitem_1832, getitem_1833, getitem_1834, getitem_1835, getitem_1836, getitem_1837, getitem_1838, getitem_1839, getitem_1840, getitem_1841, getitem_1842, getitem_1843, getitem_1844, getitem_1845, getitem_1846], 1);  getitem_1831 = getitem_1832 = getitem_1833 = getitem_1834 = getitem_1835 = getitem_1836 = getitem_1837 = getitem_1838 = getitem_1839 = getitem_1840 = getitem_1841 = getitem_1842 = getitem_1843 = getitem_1844 = getitem_1845 = getitem_1846 = None
        cumsum_50 = torch.ops.aten.cumsum.default(convert_element_type_932, 0, dtype = torch.int32);  convert_element_type_932 = None
        permute_260 = torch.ops.aten.permute.default(cat_150, [0, 2, 1]);  cat_150 = None
        _grouped_mm_48 = torch.ops.aten._grouped_mm.default(index_33, permute_260, cumsum_50)
        convert_element_type_940 = torch.ops.prims.convert_element_type.default(_grouped_mm_48, torch.float32)
        neg_33 = torch.ops.aten.neg.default(convert_element_type_940)
        exp_50 = torch.ops.aten.exp.default(neg_33);  neg_33 = None
        add_1120 = torch.ops.aten.add.Tensor(exp_50, 1);  exp_50 = None
        div_84 = torch.ops.aten.div.Tensor(convert_element_type_940, add_1120);  convert_element_type_940 = add_1120 = None
        convert_element_type_941 = torch.ops.prims.convert_element_type.default(div_84, torch.bfloat16);  div_84 = None
        permute_261 = torch.ops.aten.permute.default(cat_152, [0, 2, 1]);  cat_152 = None
        _grouped_mm_49 = torch.ops.aten._grouped_mm.default(index_33, permute_261, cumsum_50)
        mul_819 = torch.ops.aten.mul.Tensor(convert_element_type_941, _grouped_mm_49);  convert_element_type_941 = None
        permute_262 = torch.ops.aten.permute.default(cat_151, [0, 2, 1]);  cat_151 = None
        _grouped_mm_50 = torch.ops.aten._grouped_mm.default(mul_819, permute_262, cumsum_50)
        empty_16 = torch.ops.aten.empty.memory_format([sym_size_int_65, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_32 = torch.ops.aten.index_put.default(empty_16, [getitem_1782], _grouped_mm_50);  empty_16 = _grouped_mm_50 = None
        slice_107 = torch.ops.aten.slice.Tensor(index_put_32, 0, 0, -1);  index_put_32 = None
        all_to_all_single_50 = torch.ops._c10d_functional.all_to_all_single.default(slice_107, [_local_scalar_dense_256, _local_scalar_dense_257, _local_scalar_dense_258, _local_scalar_dense_259, _local_scalar_dense_260, _local_scalar_dense_261, _local_scalar_dense_262, _local_scalar_dense_263], [_local_scalar_dense_264, _local_scalar_dense_265, _local_scalar_dense_266, _local_scalar_dense_267, _local_scalar_dense_268, _local_scalar_dense_269, _local_scalar_dense_270, _local_scalar_dense_271], '1033');  slice_107 = None
        wait_tensor_364 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_50);  all_to_all_single_50 = None
        convert_element_type_942 = torch.ops.prims.convert_element_type.default(primals_292, torch.bfloat16)
        all_gather_into_tensor_297 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_942, 128, '0');  convert_element_type_942 = None
        wait_tensor_365 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_297);  all_gather_into_tensor_297 = None
        permute_263 = torch.ops.aten.permute.default(wait_tensor_365, [1, 0]);  wait_tensor_365 = None
        mm_140 = torch.ops.aten.mm.default(view_1130, permute_263);  permute_263 = None
        convert_element_type_945 = torch.ops.prims.convert_element_type.default(mm_140, torch.float32)
        neg_34 = torch.ops.aten.neg.default(convert_element_type_945)
        exp_51 = torch.ops.aten.exp.default(neg_34);  neg_34 = None
        add_1156 = torch.ops.aten.add.Tensor(exp_51, 1);  exp_51 = None
        div_85 = torch.ops.aten.div.Tensor(convert_element_type_945, add_1156);  convert_element_type_945 = add_1156 = None
        convert_element_type_946 = torch.ops.prims.convert_element_type.default(div_85, torch.bfloat16);  div_85 = None
        convert_element_type_947 = torch.ops.prims.convert_element_type.default(primals_293, torch.bfloat16)
        all_gather_into_tensor_298 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_947, 128, '0');  convert_element_type_947 = None
        wait_tensor_366 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_298);  all_gather_into_tensor_298 = None
        permute_264 = torch.ops.aten.permute.default(wait_tensor_366, [1, 0]);  wait_tensor_366 = None
        mm_141 = torch.ops.aten.mm.default(view_1130, permute_264);  permute_264 = None
        mul_839 = torch.ops.aten.mul.Tensor(convert_element_type_946, mm_141);  convert_element_type_946 = None
        convert_element_type_950 = torch.ops.prims.convert_element_type.default(primals_294, torch.bfloat16)
        all_gather_into_tensor_299 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_950, 128, '0');  convert_element_type_950 = None
        wait_tensor_367 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_299);  all_gather_into_tensor_299 = None
        permute_265 = torch.ops.aten.permute.default(wait_tensor_367, [1, 0]);  wait_tensor_367 = None
        mm_142 = torch.ops.aten.mm.default(mul_839, permute_265);  permute_265 = None
        index_put_33 = torch.ops.aten.index_put.default(full_default_1, [getitem_1781], wait_tensor_364);  wait_tensor_364 = None
        view_1170 = torch.ops.aten.view.default(mul_801, [-1, 1, 6]);  mul_801 = None
        view_1171 = torch.ops.aten.view.default(index_put_33, [-1, 6, 2048]);  index_put_33 = None
        convert_element_type_953 = torch.ops.prims.convert_element_type.default(view_1171, torch.float32);  view_1171 = None
        bmm_16 = torch.ops.aten.bmm.default(view_1170, convert_element_type_953)
        convert_element_type_954 = torch.ops.prims.convert_element_type.default(bmm_16, torch.bfloat16);  bmm_16 = None
        squeeze_16 = torch.ops.aten.squeeze.dim(convert_element_type_954, 1);  convert_element_type_954 = None
        add_1160 = torch.ops.aten.add.Tensor(mm_142, squeeze_16);  mm_142 = squeeze_16 = None
        view_1172 = torch.ops.aten.view.default(add_1160, [2, 4096, 2048]);  add_1160 = None
        add_1161 = torch.ops.aten.add.Tensor(add_1096, view_1172);  view_1172 = None
        convert_element_type_955 = torch.ops.prims.convert_element_type.default(primals_295, torch.bfloat16)
        all_gather_into_tensor_300 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_955, 128, '0');  convert_element_type_955 = None
        wait_tensor_368 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_300);  all_gather_into_tensor_300 = None
        convert_element_type_956 = torch.ops.prims.convert_element_type.default(add_1161, torch.float32)
        pow_55 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_956, 2)
        mean_54 = torch.ops.aten.mean.dim(pow_55, [2], True);  pow_55 = None
        add_1162 = torch.ops.aten.add.Scalar(mean_54, 1e-05);  mean_54 = None
        rsqrt_54 = torch.ops.aten.rsqrt.default(add_1162);  add_1162 = None
        mul_842 = torch.ops.aten.mul.Tensor(convert_element_type_956, rsqrt_54);  convert_element_type_956 = None
        mul_843 = torch.ops.aten.mul.Tensor(mul_842, wait_tensor_368);  mul_842 = wait_tensor_368 = None
        convert_element_type_957 = torch.ops.prims.convert_element_type.default(mul_843, torch.bfloat16);  mul_843 = None
        convert_element_type_958 = torch.ops.prims.convert_element_type.default(primals_296, torch.bfloat16)
        all_gather_into_tensor_301 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_958, 128, '0');  convert_element_type_958 = None
        wait_tensor_369 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_301);  all_gather_into_tensor_301 = None
        permute_266 = torch.ops.aten.permute.default(wait_tensor_369, [1, 0]);  wait_tensor_369 = None
        view_1175 = torch.ops.aten.view.default(convert_element_type_957, [8192, 2048]);  convert_element_type_957 = None
        mm_143 = torch.ops.aten.mm.default(view_1175, permute_266);  permute_266 = None
        view_1176 = torch.ops.aten.view.default(mm_143, [2, 4096, 3072]);  mm_143 = None
        view_1177 = torch.ops.aten.view.default(view_1176, [2, 4096, -1, 192]);  view_1176 = None
        split_with_sizes_54 = torch.ops.aten.split_with_sizes.default(view_1177, [128, 64], -1);  view_1177 = None
        getitem_1879 = split_with_sizes_54[0]
        getitem_1880 = split_with_sizes_54[1];  split_with_sizes_54 = None
        convert_element_type_961 = torch.ops.prims.convert_element_type.default(getitem_1880, torch.float32);  getitem_1880 = None
        view_1178 = torch.ops.aten.view.default(convert_element_type_961, [2, 4096, 16, -1, 2]);  convert_element_type_961 = None
        view_as_complex_36 = torch.ops.aten.view_as_complex.default(view_1178);  view_1178 = None
        mul_844 = torch.ops.aten.mul.Tensor(view_as_complex_36, view_7);  view_as_complex_36 = None
        view_as_real_36 = torch.ops.aten.view_as_real.default(mul_844);  mul_844 = None
        view_1180 = torch.ops.aten.view.default(view_as_real_36, [2, 4096, 16, 64]);  view_as_real_36 = None
        convert_element_type_962 = torch.ops.prims.convert_element_type.default(view_1180, torch.bfloat16);  view_1180 = None
        cat_155 = torch.ops.aten.cat.default([getitem_1879, convert_element_type_962], -1);  getitem_1879 = convert_element_type_962 = None
        convert_element_type_963 = torch.ops.prims.convert_element_type.default(primals_297, torch.bfloat16)
        all_gather_into_tensor_302 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_963, 128, '0');  convert_element_type_963 = None
        wait_tensor_370 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_302);  all_gather_into_tensor_302 = None
        slice_109 = torch.ops.aten.slice.Tensor(wait_tensor_370, 0, 0, 576);  wait_tensor_370 = None
        permute_267 = torch.ops.aten.permute.default(slice_109, [1, 0]);  slice_109 = None
        mm_144 = torch.ops.aten.mm.default(view_1175, permute_267);  permute_267 = None
        view_1183 = torch.ops.aten.view.default(mm_144, [2, 4096, 576]);  mm_144 = None
        split_with_sizes_55 = torch.ops.aten.split_with_sizes.default(view_1183, [512, 64], -1);  view_1183 = None
        getitem_1881 = split_with_sizes_55[0]
        getitem_1882 = split_with_sizes_55[1];  split_with_sizes_55 = None
        unsqueeze_35 = torch.ops.aten.unsqueeze.default(getitem_1882, 2);  getitem_1882 = None
        convert_element_type_966 = torch.ops.prims.convert_element_type.default(unsqueeze_35, torch.float32);  unsqueeze_35 = None
        view_1184 = torch.ops.aten.view.default(convert_element_type_966, [2, 4096, 1, -1, 2]);  convert_element_type_966 = None
        view_as_complex_37 = torch.ops.aten.view_as_complex.default(view_1184);  view_1184 = None
        mul_845 = torch.ops.aten.mul.Tensor(view_as_complex_37, view_7);  view_as_complex_37 = None
        view_as_real_37 = torch.ops.aten.view_as_real.default(mul_845);  mul_845 = None
        view_1186 = torch.ops.aten.view.default(view_as_real_37, [2, 4096, 1, 64]);  view_as_real_37 = None
        convert_element_type_967 = torch.ops.prims.convert_element_type.default(view_1186, torch.bfloat16);  view_1186 = None
        convert_element_type_968 = torch.ops.prims.convert_element_type.default(primals_298, torch.bfloat16)
        all_gather_into_tensor_303 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_968, 128, '0');  convert_element_type_968 = None
        wait_tensor_371 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_303);  all_gather_into_tensor_303 = None
        convert_element_type_969 = torch.ops.prims.convert_element_type.default(getitem_1881, torch.float32)
        pow_56 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_969, 2)
        mean_55 = torch.ops.aten.mean.dim(pow_56, [2], True);  pow_56 = None
        add_1163 = torch.ops.aten.add.Scalar(mean_55, 1e-05);  mean_55 = None
        rsqrt_55 = torch.ops.aten.rsqrt.default(add_1163);  add_1163 = None
        mul_846 = torch.ops.aten.mul.Tensor(convert_element_type_969, rsqrt_55);  convert_element_type_969 = None
        mul_847 = torch.ops.aten.mul.Tensor(mul_846, wait_tensor_371);  mul_846 = wait_tensor_371 = None
        convert_element_type_970 = torch.ops.prims.convert_element_type.default(mul_847, torch.bfloat16);  mul_847 = None
        convert_element_type_971 = torch.ops.prims.convert_element_type.default(primals_299, torch.bfloat16)
        all_gather_into_tensor_304 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_971, 128, '0');  convert_element_type_971 = None
        wait_tensor_372 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_304);  all_gather_into_tensor_304 = None
        permute_268 = torch.ops.aten.permute.default(wait_tensor_372, [1, 0]);  wait_tensor_372 = None
        view_1189 = torch.ops.aten.view.default(convert_element_type_970, [8192, 512]);  convert_element_type_970 = None
        mm_145 = torch.ops.aten.mm.default(view_1189, permute_268);  permute_268 = None
        view_1190 = torch.ops.aten.view.default(mm_145, [2, 4096, 4096]);  mm_145 = None
        view_1191 = torch.ops.aten.view.default(view_1190, [2, 4096, -1, 256]);  view_1190 = None
        split_with_sizes_56 = torch.ops.aten.split_with_sizes.default(view_1191, [128, 128], -1);  view_1191 = None
        getitem_1883 = split_with_sizes_56[0]
        getitem_1884 = split_with_sizes_56[1];  split_with_sizes_56 = None
        expand_18 = torch.ops.aten.expand.default(convert_element_type_967, [-1, -1, 16, -1]);  convert_element_type_967 = None
        cat_156 = torch.ops.aten.cat.default([getitem_1883, expand_18], -1);  getitem_1883 = expand_18 = None
        permute_269 = torch.ops.aten.permute.default(cat_155, [0, 2, 1, 3]);  cat_155 = None
        permute_270 = torch.ops.aten.permute.default(cat_156, [0, 2, 1, 3]);  cat_156 = None
        permute_271 = torch.ops.aten.permute.default(getitem_1884, [0, 2, 1, 3]);  getitem_1884 = None
        sdpa_score18 = self.sdpa_score18
        sdpa_mask18 = self.sdpa_mask18
        flex_attention_18 = torch.ops.higher_order.flex_attention(permute_269, permute_270, permute_271, sdpa_score18, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask18), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score18 = sdpa_mask18 = None
        getitem_1885 = flex_attention_18[0]
        getitem_1886 = flex_attention_18[1];  flex_attention_18 = None
        permute_272 = torch.ops.aten.permute.default(getitem_1885, [0, 2, 1, 3])
        view_1192 = torch.ops.aten.view.default(permute_272, [2, 4096, -1]);  permute_272 = None
        convert_element_type_974 = torch.ops.prims.convert_element_type.default(primals_300, torch.bfloat16)
        all_gather_into_tensor_305 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_974, 128, '0');  convert_element_type_974 = None
        wait_tensor_373 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_305);  all_gather_into_tensor_305 = None
        permute_273 = torch.ops.aten.permute.default(wait_tensor_373, [1, 0]);  wait_tensor_373 = None
        view_1194 = torch.ops.aten.view.default(view_1192, [8192, 2048]);  view_1192 = None
        mm_146 = torch.ops.aten.mm.default(view_1194, permute_273);  view_1194 = permute_273 = None
        view_1195 = torch.ops.aten.view.default(mm_146, [2, 4096, 2048]);  mm_146 = None
        add_1164 = torch.ops.aten.add.Tensor(add_1161, view_1195);  view_1195 = None
        convert_element_type_977 = torch.ops.prims.convert_element_type.default(primals_301, torch.bfloat16)
        all_gather_into_tensor_306 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_977, 128, '0');  convert_element_type_977 = None
        wait_tensor_374 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_306);  all_gather_into_tensor_306 = None
        convert_element_type_978 = torch.ops.prims.convert_element_type.default(add_1164, torch.float32)
        pow_57 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_978, 2)
        mean_56 = torch.ops.aten.mean.dim(pow_57, [2], True);  pow_57 = None
        add_1165 = torch.ops.aten.add.Scalar(mean_56, 1e-05);  mean_56 = None
        rsqrt_56 = torch.ops.aten.rsqrt.default(add_1165);  add_1165 = None
        mul_848 = torch.ops.aten.mul.Tensor(convert_element_type_978, rsqrt_56);  convert_element_type_978 = None
        mul_849 = torch.ops.aten.mul.Tensor(mul_848, wait_tensor_374);  mul_848 = wait_tensor_374 = None
        convert_element_type_979 = torch.ops.prims.convert_element_type.default(mul_849, torch.bfloat16);  mul_849 = None
        view_1197 = torch.ops.aten.view.default(convert_element_type_979, [-1, 2048]);  convert_element_type_979 = None
        convert_element_type_980 = torch.ops.prims.convert_element_type.default(primals_303, torch.bfloat16)
        all_gather_into_tensor_307 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_980, 128, '0');  convert_element_type_980 = None
        wait_tensor_375 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_307);  all_gather_into_tensor_307 = None
        slice_111 = torch.ops.aten.slice.Tensor(wait_tensor_375, 0, 0, 64);  wait_tensor_375 = None
        permute_274 = torch.ops.aten.permute.default(slice_111, [1, 0]);  slice_111 = None
        mm_147 = torch.ops.aten.mm.default(view_1197, permute_274);  permute_274 = None
        convert_element_type_983 = torch.ops.prims.convert_element_type.default(mm_147, torch.float32)
        amax_17 = torch.ops.aten.amax.default(convert_element_type_983, [1], True)
        sub_408 = torch.ops.aten.sub.Tensor(convert_element_type_983, amax_17);  convert_element_type_983 = None
        exp_52 = torch.ops.aten.exp.default(sub_408);  sub_408 = None
        sum_69 = torch.ops.aten.sum.dim_IntList(exp_52, [1], True)
        div_86 = torch.ops.aten.div.Tensor(exp_52, sum_69);  exp_52 = None
        add_1166 = torch.ops.aten.add.Tensor(div_86, primals_302);  primals_302 = None
        topk_17 = torch.ops.aten.topk.default(add_1166, 6, -1, True, False);  add_1166 = None
        getitem_1889 = topk_17[1];  topk_17 = None
        gather_17 = torch.ops.aten.gather.default(div_86, 1, getitem_1889);  div_86 = None
        mul_850 = torch.ops.aten.mul.Tensor(gather_17, 1.0);  gather_17 = None
        view_1199 = torch.ops.aten.view.default(getitem_1889, [-1])
        histc_34 = torch.ops.aten.histc.default(view_1199, 64, 0, 64)
        add_1167 = torch.ops.aten.add.Tensor(primals_304, histc_34)
        sort_17 = torch.ops.aten.sort.stable(view_1199, stable = True);  view_1199 = None
        getitem_1891 = sort_17[1];  sort_17 = None
        div_87 = torch.ops.aten.div.Tensor_mode(getitem_1891, 6, rounding_mode = 'floor')
        index_34 = torch.ops.aten.index.Tensor(view_1197, [div_87])
        all_to_all_single_51 = torch.ops._c10d_functional.all_to_all_single.default(histc_34, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_376 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_51);  all_to_all_single_51 = None
        wait_tensor_377 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_376);  wait_tensor_376 = None
        view_1203 = torch.ops.aten.view.default(histc_34, [8, -1]);  histc_34 = None
        sum_70 = torch.ops.aten.sum.dim_IntList(view_1203, [1]);  view_1203 = None
        device_put_34 = torch.ops.prims.device_put.default(sum_70, device(type='cpu'), True);  sum_70 = None
        view_1204 = torch.ops.aten.view.default(wait_tensor_377, [8, -1])
        sum_71 = torch.ops.aten.sum.dim_IntList(view_1204, [1])
        device_put_35 = torch.ops.prims.device_put.default(sum_71, device(type='cpu'));  sum_71 = None
        select_272 = torch.ops.aten.select.int(device_put_34, 0, 0)
        _local_scalar_dense_272 = torch.ops.aten._local_scalar_dense.default(select_272);  select_272 = None
        ge_340 = _local_scalar_dense_272 >= 0
        _assert_scalar_272 = torch.ops.aten._assert_scalar.default(ge_340, "Runtime assertion failed for expression u272 >= 0 on node 'ge_272'");  ge_340 = _assert_scalar_272 = None
        select_273 = torch.ops.aten.select.int(device_put_34, 0, 1)
        _local_scalar_dense_273 = torch.ops.aten._local_scalar_dense.default(select_273);  select_273 = None
        ge_341 = _local_scalar_dense_273 >= 0
        _assert_scalar_273 = torch.ops.aten._assert_scalar.default(ge_341, "Runtime assertion failed for expression u273 >= 0 on node 'ge_273'");  ge_341 = _assert_scalar_273 = None
        select_274 = torch.ops.aten.select.int(device_put_34, 0, 2)
        _local_scalar_dense_274 = torch.ops.aten._local_scalar_dense.default(select_274);  select_274 = None
        ge_342 = _local_scalar_dense_274 >= 0
        _assert_scalar_274 = torch.ops.aten._assert_scalar.default(ge_342, "Runtime assertion failed for expression u274 >= 0 on node 'ge_274'");  ge_342 = _assert_scalar_274 = None
        select_275 = torch.ops.aten.select.int(device_put_34, 0, 3)
        _local_scalar_dense_275 = torch.ops.aten._local_scalar_dense.default(select_275);  select_275 = None
        ge_343 = _local_scalar_dense_275 >= 0
        _assert_scalar_275 = torch.ops.aten._assert_scalar.default(ge_343, "Runtime assertion failed for expression u275 >= 0 on node 'ge_275'");  ge_343 = _assert_scalar_275 = None
        select_276 = torch.ops.aten.select.int(device_put_34, 0, 4)
        _local_scalar_dense_276 = torch.ops.aten._local_scalar_dense.default(select_276);  select_276 = None
        ge_344 = _local_scalar_dense_276 >= 0
        _assert_scalar_276 = torch.ops.aten._assert_scalar.default(ge_344, "Runtime assertion failed for expression u276 >= 0 on node 'ge_276'");  ge_344 = _assert_scalar_276 = None
        select_277 = torch.ops.aten.select.int(device_put_34, 0, 5)
        _local_scalar_dense_277 = torch.ops.aten._local_scalar_dense.default(select_277);  select_277 = None
        ge_345 = _local_scalar_dense_277 >= 0
        _assert_scalar_277 = torch.ops.aten._assert_scalar.default(ge_345, "Runtime assertion failed for expression u277 >= 0 on node 'ge_277'");  ge_345 = _assert_scalar_277 = None
        select_278 = torch.ops.aten.select.int(device_put_34, 0, 6)
        _local_scalar_dense_278 = torch.ops.aten._local_scalar_dense.default(select_278);  select_278 = None
        ge_346 = _local_scalar_dense_278 >= 0
        _assert_scalar_278 = torch.ops.aten._assert_scalar.default(ge_346, "Runtime assertion failed for expression u278 >= 0 on node 'ge_278'");  ge_346 = _assert_scalar_278 = None
        select_279 = torch.ops.aten.select.int(device_put_34, 0, 7);  device_put_34 = None
        _local_scalar_dense_279 = torch.ops.aten._local_scalar_dense.default(select_279);  select_279 = None
        ge_347 = _local_scalar_dense_279 >= 0
        _assert_scalar_279 = torch.ops.aten._assert_scalar.default(ge_347, "Runtime assertion failed for expression u279 >= 0 on node 'ge_279'");  ge_347 = _assert_scalar_279 = None
        select_280 = torch.ops.aten.select.int(device_put_35, 0, 0)
        _local_scalar_dense_280 = torch.ops.aten._local_scalar_dense.default(select_280);  select_280 = None
        ge_348 = _local_scalar_dense_280 >= 0
        _assert_scalar_280 = torch.ops.aten._assert_scalar.default(ge_348, "Runtime assertion failed for expression u280 >= 0 on node 'ge_280'");  ge_348 = _assert_scalar_280 = None
        select_281 = torch.ops.aten.select.int(device_put_35, 0, 1)
        _local_scalar_dense_281 = torch.ops.aten._local_scalar_dense.default(select_281);  select_281 = None
        ge_349 = _local_scalar_dense_281 >= 0
        _assert_scalar_281 = torch.ops.aten._assert_scalar.default(ge_349, "Runtime assertion failed for expression u281 >= 0 on node 'ge_281'");  ge_349 = _assert_scalar_281 = None
        select_282 = torch.ops.aten.select.int(device_put_35, 0, 2)
        _local_scalar_dense_282 = torch.ops.aten._local_scalar_dense.default(select_282);  select_282 = None
        ge_350 = _local_scalar_dense_282 >= 0
        _assert_scalar_282 = torch.ops.aten._assert_scalar.default(ge_350, "Runtime assertion failed for expression u282 >= 0 on node 'ge_282'");  ge_350 = _assert_scalar_282 = None
        select_283 = torch.ops.aten.select.int(device_put_35, 0, 3)
        _local_scalar_dense_283 = torch.ops.aten._local_scalar_dense.default(select_283);  select_283 = None
        ge_351 = _local_scalar_dense_283 >= 0
        _assert_scalar_283 = torch.ops.aten._assert_scalar.default(ge_351, "Runtime assertion failed for expression u283 >= 0 on node 'ge_283'");  ge_351 = _assert_scalar_283 = None
        select_284 = torch.ops.aten.select.int(device_put_35, 0, 4)
        _local_scalar_dense_284 = torch.ops.aten._local_scalar_dense.default(select_284);  select_284 = None
        ge_352 = _local_scalar_dense_284 >= 0
        _assert_scalar_284 = torch.ops.aten._assert_scalar.default(ge_352, "Runtime assertion failed for expression u284 >= 0 on node 'ge_284'");  ge_352 = _assert_scalar_284 = None
        select_285 = torch.ops.aten.select.int(device_put_35, 0, 5)
        _local_scalar_dense_285 = torch.ops.aten._local_scalar_dense.default(select_285);  select_285 = None
        ge_353 = _local_scalar_dense_285 >= 0
        _assert_scalar_285 = torch.ops.aten._assert_scalar.default(ge_353, "Runtime assertion failed for expression u285 >= 0 on node 'ge_285'");  ge_353 = _assert_scalar_285 = None
        select_286 = torch.ops.aten.select.int(device_put_35, 0, 6)
        _local_scalar_dense_286 = torch.ops.aten._local_scalar_dense.default(select_286);  select_286 = None
        ge_354 = _local_scalar_dense_286 >= 0
        _assert_scalar_286 = torch.ops.aten._assert_scalar.default(ge_354, "Runtime assertion failed for expression u286 >= 0 on node 'ge_286'");  ge_354 = _assert_scalar_286 = None
        select_287 = torch.ops.aten.select.int(device_put_35, 0, 7);  device_put_35 = None
        _local_scalar_dense_287 = torch.ops.aten._local_scalar_dense.default(select_287);  select_287 = None
        ge_355 = _local_scalar_dense_287 >= 0
        _assert_scalar_287 = torch.ops.aten._assert_scalar.default(ge_355, "Runtime assertion failed for expression u287 >= 0 on node 'ge_287'");  ge_355 = _assert_scalar_287 = None
        all_to_all_single_52 = torch.ops._c10d_functional.all_to_all_single.default(index_34, [_local_scalar_dense_280, _local_scalar_dense_281, _local_scalar_dense_282, _local_scalar_dense_283, _local_scalar_dense_284, _local_scalar_dense_285, _local_scalar_dense_286, _local_scalar_dense_287], [_local_scalar_dense_272, _local_scalar_dense_273, _local_scalar_dense_274, _local_scalar_dense_275, _local_scalar_dense_276, _local_scalar_dense_277, _local_scalar_dense_278, _local_scalar_dense_279], '1033');  index_34 = None
        sym_size_int_68 = torch.ops.aten.sym_size.int(all_to_all_single_52, 0)
        wait_tensor_378 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_52);  all_to_all_single_52 = None
        sym_sum_34 = torch.sym_sum((_local_scalar_dense_280, _local_scalar_dense_281, _local_scalar_dense_282, _local_scalar_dense_283, _local_scalar_dense_284, _local_scalar_dense_285, _local_scalar_dense_286, _local_scalar_dense_287))
        add_1174 = sym_sum_34 + 64;  sym_sum_34 = None
        add_1175 = add_1174 + 8;  add_1174 = None
        sub_411 = add_1175 - 1;  add_1175 = None
        floordiv_17 = sub_411 // 8;  sub_411 = None
        mul_855 = floordiv_17 * 8;  floordiv_17 = None
        cumsum_51 = torch.ops.aten.cumsum.default(wait_tensor_377, 0)
        sub_412 = torch.ops.aten.sub.Tensor(cumsum_51, wait_tensor_377);  cumsum_51 = None
        sum_72 = torch.ops.aten.sum.dim_IntList(view_1204, [0]);  view_1204 = None
        clamp_min_17 = torch.ops.aten.clamp_min.default(sum_72, 8);  sum_72 = None
        add_1176 = torch.ops.aten.add.Tensor(clamp_min_17, 8);  clamp_min_17 = None
        sub_413 = torch.ops.aten.sub.Tensor(add_1176, 1);  add_1176 = None
        div_88 = torch.ops.aten.div.Tensor_mode(sub_413, 8, rounding_mode = 'floor');  sub_413 = None
        mul_856 = torch.ops.aten.mul.Tensor(div_88, 8);  div_88 = None
        convert_element_type_986 = torch.ops.prims.convert_element_type.default(mul_856, torch.int32);  mul_856 = None
        cumsum_52 = torch.ops.aten.cumsum.default(convert_element_type_986, 0)
        sub_414 = torch.ops.aten.sub.Tensor(cumsum_52, convert_element_type_986);  cumsum_52 = None
        full_241 = torch.ops.aten.full.default([mul_855], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_855 = None
        triton_kernel_wrapper_functional_proxy_17 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 17, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_377, 'start_index_values_ptr': sub_412, 'write_offsets_ptr': sub_414, 'output_ptr': full_241}, tensors_to_clone = ['output_ptr']);  wait_tensor_377 = sub_412 = sub_414 = full_241 = None
        getitem_1892 = triton_kernel_wrapper_functional_proxy_17['output_ptr'];  triton_kernel_wrapper_functional_proxy_17 = None
        cat_157 = torch.ops.aten.cat.default([wait_tensor_378, full_default]);  wait_tensor_378 = None
        sym_size_int_69 = torch.ops.aten.sym_size.int(cat_157, 0)
        sym_sum_35 = torch.sym_sum((1, _local_scalar_dense_280, _local_scalar_dense_281, _local_scalar_dense_282, _local_scalar_dense_283, _local_scalar_dense_284, _local_scalar_dense_285, _local_scalar_dense_286, _local_scalar_dense_287))
        index_35 = torch.ops.aten.index.Tensor(cat_157, [getitem_1892]);  cat_157 = None
        convert_element_type_988 = torch.ops.prims.convert_element_type.default(primals_305, torch.bfloat16)
        all_gather_into_tensor_308 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_988, 16, '1025');  convert_element_type_988 = None
        wait_tensor_379 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_308);  all_gather_into_tensor_308 = None
        split_103 = torch.ops.aten.split.Tensor(wait_tensor_379, 8);  wait_tensor_379 = None
        getitem_1909 = split_103[0]
        getitem_1910 = split_103[1]
        getitem_1911 = split_103[2]
        getitem_1912 = split_103[3]
        getitem_1913 = split_103[4]
        getitem_1914 = split_103[5]
        getitem_1915 = split_103[6]
        getitem_1916 = split_103[7]
        getitem_1917 = split_103[8]
        getitem_1918 = split_103[9]
        getitem_1919 = split_103[10]
        getitem_1920 = split_103[11]
        getitem_1921 = split_103[12]
        getitem_1922 = split_103[13]
        getitem_1923 = split_103[14]
        getitem_1924 = split_103[15];  split_103 = None
        cat_159 = torch.ops.aten.cat.default([getitem_1909, getitem_1910, getitem_1911, getitem_1912, getitem_1913, getitem_1914, getitem_1915, getitem_1916, getitem_1917, getitem_1918, getitem_1919, getitem_1920, getitem_1921, getitem_1922, getitem_1923, getitem_1924], 1);  getitem_1909 = getitem_1910 = getitem_1911 = getitem_1912 = getitem_1913 = getitem_1914 = getitem_1915 = getitem_1916 = getitem_1917 = getitem_1918 = getitem_1919 = getitem_1920 = getitem_1921 = getitem_1922 = getitem_1923 = getitem_1924 = None
        convert_element_type_990 = torch.ops.prims.convert_element_type.default(primals_306, torch.bfloat16)
        all_gather_into_tensor_310 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_990, 16, '1025');  convert_element_type_990 = None
        wait_tensor_381 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_310);  all_gather_into_tensor_310 = None
        split_104 = torch.ops.aten.split.Tensor(wait_tensor_381, 8);  wait_tensor_381 = None
        getitem_1925 = split_104[0]
        getitem_1926 = split_104[1]
        getitem_1927 = split_104[2]
        getitem_1928 = split_104[3]
        getitem_1929 = split_104[4]
        getitem_1930 = split_104[5]
        getitem_1931 = split_104[6]
        getitem_1932 = split_104[7]
        getitem_1933 = split_104[8]
        getitem_1934 = split_104[9]
        getitem_1935 = split_104[10]
        getitem_1936 = split_104[11]
        getitem_1937 = split_104[12]
        getitem_1938 = split_104[13]
        getitem_1939 = split_104[14]
        getitem_1940 = split_104[15];  split_104 = None
        cat_160 = torch.ops.aten.cat.default([getitem_1925, getitem_1926, getitem_1927, getitem_1928, getitem_1929, getitem_1930, getitem_1931, getitem_1932, getitem_1933, getitem_1934, getitem_1935, getitem_1936, getitem_1937, getitem_1938, getitem_1939, getitem_1940], 1);  getitem_1925 = getitem_1926 = getitem_1927 = getitem_1928 = getitem_1929 = getitem_1930 = getitem_1931 = getitem_1932 = getitem_1933 = getitem_1934 = getitem_1935 = getitem_1936 = getitem_1937 = getitem_1938 = getitem_1939 = getitem_1940 = None
        convert_element_type_991 = torch.ops.prims.convert_element_type.default(primals_307, torch.bfloat16)
        all_gather_into_tensor_311 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_991, 16, '1025');  convert_element_type_991 = None
        wait_tensor_382 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_311);  all_gather_into_tensor_311 = None
        split_105 = torch.ops.aten.split.Tensor(wait_tensor_382, 8);  wait_tensor_382 = None
        getitem_1941 = split_105[0]
        getitem_1942 = split_105[1]
        getitem_1943 = split_105[2]
        getitem_1944 = split_105[3]
        getitem_1945 = split_105[4]
        getitem_1946 = split_105[5]
        getitem_1947 = split_105[6]
        getitem_1948 = split_105[7]
        getitem_1949 = split_105[8]
        getitem_1950 = split_105[9]
        getitem_1951 = split_105[10]
        getitem_1952 = split_105[11]
        getitem_1953 = split_105[12]
        getitem_1954 = split_105[13]
        getitem_1955 = split_105[14]
        getitem_1956 = split_105[15];  split_105 = None
        cat_161 = torch.ops.aten.cat.default([getitem_1941, getitem_1942, getitem_1943, getitem_1944, getitem_1945, getitem_1946, getitem_1947, getitem_1948, getitem_1949, getitem_1950, getitem_1951, getitem_1952, getitem_1953, getitem_1954, getitem_1955, getitem_1956], 1);  getitem_1941 = getitem_1942 = getitem_1943 = getitem_1944 = getitem_1945 = getitem_1946 = getitem_1947 = getitem_1948 = getitem_1949 = getitem_1950 = getitem_1951 = getitem_1952 = getitem_1953 = getitem_1954 = getitem_1955 = getitem_1956 = None
        cumsum_53 = torch.ops.aten.cumsum.default(convert_element_type_986, 0, dtype = torch.int32);  convert_element_type_986 = None
        permute_275 = torch.ops.aten.permute.default(cat_159, [0, 2, 1]);  cat_159 = None
        _grouped_mm_51 = torch.ops.aten._grouped_mm.default(index_35, permute_275, cumsum_53)
        convert_element_type_994 = torch.ops.prims.convert_element_type.default(_grouped_mm_51, torch.float32)
        neg_35 = torch.ops.aten.neg.default(convert_element_type_994)
        exp_53 = torch.ops.aten.exp.default(neg_35);  neg_35 = None
        add_1188 = torch.ops.aten.add.Tensor(exp_53, 1);  exp_53 = None
        div_89 = torch.ops.aten.div.Tensor(convert_element_type_994, add_1188);  convert_element_type_994 = add_1188 = None
        convert_element_type_995 = torch.ops.prims.convert_element_type.default(div_89, torch.bfloat16);  div_89 = None
        permute_276 = torch.ops.aten.permute.default(cat_161, [0, 2, 1]);  cat_161 = None
        _grouped_mm_52 = torch.ops.aten._grouped_mm.default(index_35, permute_276, cumsum_53)
        mul_868 = torch.ops.aten.mul.Tensor(convert_element_type_995, _grouped_mm_52);  convert_element_type_995 = None
        permute_277 = torch.ops.aten.permute.default(cat_160, [0, 2, 1]);  cat_160 = None
        _grouped_mm_53 = torch.ops.aten._grouped_mm.default(mul_868, permute_277, cumsum_53)
        empty_17 = torch.ops.aten.empty.memory_format([sym_size_int_69, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_34 = torch.ops.aten.index_put.default(empty_17, [getitem_1892], _grouped_mm_53);  empty_17 = _grouped_mm_53 = None
        slice_113 = torch.ops.aten.slice.Tensor(index_put_34, 0, 0, -1);  index_put_34 = None
        all_to_all_single_53 = torch.ops._c10d_functional.all_to_all_single.default(slice_113, [_local_scalar_dense_272, _local_scalar_dense_273, _local_scalar_dense_274, _local_scalar_dense_275, _local_scalar_dense_276, _local_scalar_dense_277, _local_scalar_dense_278, _local_scalar_dense_279], [_local_scalar_dense_280, _local_scalar_dense_281, _local_scalar_dense_282, _local_scalar_dense_283, _local_scalar_dense_284, _local_scalar_dense_285, _local_scalar_dense_286, _local_scalar_dense_287], '1033');  slice_113 = None
        wait_tensor_385 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_53);  all_to_all_single_53 = None
        convert_element_type_996 = torch.ops.prims.convert_element_type.default(primals_308, torch.bfloat16)
        all_gather_into_tensor_314 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_996, 128, '0');  convert_element_type_996 = None
        wait_tensor_386 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_314);  all_gather_into_tensor_314 = None
        permute_278 = torch.ops.aten.permute.default(wait_tensor_386, [1, 0]);  wait_tensor_386 = None
        mm_148 = torch.ops.aten.mm.default(view_1197, permute_278);  permute_278 = None
        convert_element_type_999 = torch.ops.prims.convert_element_type.default(mm_148, torch.float32)
        neg_36 = torch.ops.aten.neg.default(convert_element_type_999)
        exp_54 = torch.ops.aten.exp.default(neg_36);  neg_36 = None
        add_1224 = torch.ops.aten.add.Tensor(exp_54, 1);  exp_54 = None
        div_90 = torch.ops.aten.div.Tensor(convert_element_type_999, add_1224);  convert_element_type_999 = add_1224 = None
        convert_element_type_1000 = torch.ops.prims.convert_element_type.default(div_90, torch.bfloat16);  div_90 = None
        convert_element_type_1001 = torch.ops.prims.convert_element_type.default(primals_309, torch.bfloat16)
        all_gather_into_tensor_315 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1001, 128, '0');  convert_element_type_1001 = None
        wait_tensor_387 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_315);  all_gather_into_tensor_315 = None
        permute_279 = torch.ops.aten.permute.default(wait_tensor_387, [1, 0]);  wait_tensor_387 = None
        mm_149 = torch.ops.aten.mm.default(view_1197, permute_279);  permute_279 = None
        mul_888 = torch.ops.aten.mul.Tensor(convert_element_type_1000, mm_149);  convert_element_type_1000 = None
        convert_element_type_1004 = torch.ops.prims.convert_element_type.default(primals_310, torch.bfloat16)
        all_gather_into_tensor_316 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1004, 128, '0');  convert_element_type_1004 = None
        wait_tensor_388 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_316);  all_gather_into_tensor_316 = None
        permute_280 = torch.ops.aten.permute.default(wait_tensor_388, [1, 0]);  wait_tensor_388 = None
        mm_150 = torch.ops.aten.mm.default(mul_888, permute_280);  permute_280 = None
        index_put_35 = torch.ops.aten.index_put.default(full_default_1, [getitem_1891], wait_tensor_385);  wait_tensor_385 = None
        view_1237 = torch.ops.aten.view.default(mul_850, [-1, 1, 6]);  mul_850 = None
        view_1238 = torch.ops.aten.view.default(index_put_35, [-1, 6, 2048]);  index_put_35 = None
        convert_element_type_1007 = torch.ops.prims.convert_element_type.default(view_1238, torch.float32);  view_1238 = None
        bmm_17 = torch.ops.aten.bmm.default(view_1237, convert_element_type_1007)
        convert_element_type_1008 = torch.ops.prims.convert_element_type.default(bmm_17, torch.bfloat16);  bmm_17 = None
        squeeze_17 = torch.ops.aten.squeeze.dim(convert_element_type_1008, 1);  convert_element_type_1008 = None
        add_1228 = torch.ops.aten.add.Tensor(mm_150, squeeze_17);  mm_150 = squeeze_17 = None
        view_1239 = torch.ops.aten.view.default(add_1228, [2, 4096, 2048]);  add_1228 = None
        add_1229 = torch.ops.aten.add.Tensor(add_1164, view_1239);  view_1239 = None
        convert_element_type_1009 = torch.ops.prims.convert_element_type.default(primals_311, torch.bfloat16)
        all_gather_into_tensor_317 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1009, 128, '0');  convert_element_type_1009 = None
        wait_tensor_389 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_317);  all_gather_into_tensor_317 = None
        convert_element_type_1010 = torch.ops.prims.convert_element_type.default(add_1229, torch.float32)
        pow_58 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1010, 2)
        mean_57 = torch.ops.aten.mean.dim(pow_58, [2], True);  pow_58 = None
        add_1230 = torch.ops.aten.add.Scalar(mean_57, 1e-05);  mean_57 = None
        rsqrt_57 = torch.ops.aten.rsqrt.default(add_1230);  add_1230 = None
        mul_891 = torch.ops.aten.mul.Tensor(convert_element_type_1010, rsqrt_57);  convert_element_type_1010 = None
        mul_892 = torch.ops.aten.mul.Tensor(mul_891, wait_tensor_389);  mul_891 = wait_tensor_389 = None
        convert_element_type_1011 = torch.ops.prims.convert_element_type.default(mul_892, torch.bfloat16);  mul_892 = None
        convert_element_type_1012 = torch.ops.prims.convert_element_type.default(primals_312, torch.bfloat16)
        all_gather_into_tensor_318 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1012, 128, '0');  convert_element_type_1012 = None
        wait_tensor_390 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_318);  all_gather_into_tensor_318 = None
        permute_281 = torch.ops.aten.permute.default(wait_tensor_390, [1, 0]);  wait_tensor_390 = None
        view_1242 = torch.ops.aten.view.default(convert_element_type_1011, [8192, 2048]);  convert_element_type_1011 = None
        mm_151 = torch.ops.aten.mm.default(view_1242, permute_281);  permute_281 = None
        view_1243 = torch.ops.aten.view.default(mm_151, [2, 4096, 3072]);  mm_151 = None
        view_1244 = torch.ops.aten.view.default(view_1243, [2, 4096, -1, 192]);  view_1243 = None
        split_with_sizes_57 = torch.ops.aten.split_with_sizes.default(view_1244, [128, 64], -1);  view_1244 = None
        getitem_1989 = split_with_sizes_57[0]
        getitem_1990 = split_with_sizes_57[1];  split_with_sizes_57 = None
        convert_element_type_1015 = torch.ops.prims.convert_element_type.default(getitem_1990, torch.float32);  getitem_1990 = None
        view_1245 = torch.ops.aten.view.default(convert_element_type_1015, [2, 4096, 16, -1, 2]);  convert_element_type_1015 = None
        view_as_complex_38 = torch.ops.aten.view_as_complex.default(view_1245);  view_1245 = None
        mul_893 = torch.ops.aten.mul.Tensor(view_as_complex_38, view_7);  view_as_complex_38 = None
        view_as_real_38 = torch.ops.aten.view_as_real.default(mul_893);  mul_893 = None
        view_1247 = torch.ops.aten.view.default(view_as_real_38, [2, 4096, 16, 64]);  view_as_real_38 = None
        convert_element_type_1016 = torch.ops.prims.convert_element_type.default(view_1247, torch.bfloat16);  view_1247 = None
        cat_164 = torch.ops.aten.cat.default([getitem_1989, convert_element_type_1016], -1);  getitem_1989 = convert_element_type_1016 = None
        convert_element_type_1017 = torch.ops.prims.convert_element_type.default(primals_313, torch.bfloat16)
        all_gather_into_tensor_319 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1017, 128, '0');  convert_element_type_1017 = None
        wait_tensor_391 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_319);  all_gather_into_tensor_319 = None
        slice_115 = torch.ops.aten.slice.Tensor(wait_tensor_391, 0, 0, 576);  wait_tensor_391 = None
        permute_282 = torch.ops.aten.permute.default(slice_115, [1, 0]);  slice_115 = None
        mm_152 = torch.ops.aten.mm.default(view_1242, permute_282);  permute_282 = None
        view_1250 = torch.ops.aten.view.default(mm_152, [2, 4096, 576]);  mm_152 = None
        split_with_sizes_58 = torch.ops.aten.split_with_sizes.default(view_1250, [512, 64], -1);  view_1250 = None
        getitem_1991 = split_with_sizes_58[0]
        getitem_1992 = split_with_sizes_58[1];  split_with_sizes_58 = None
        unsqueeze_37 = torch.ops.aten.unsqueeze.default(getitem_1992, 2);  getitem_1992 = None
        convert_element_type_1020 = torch.ops.prims.convert_element_type.default(unsqueeze_37, torch.float32);  unsqueeze_37 = None
        view_1251 = torch.ops.aten.view.default(convert_element_type_1020, [2, 4096, 1, -1, 2]);  convert_element_type_1020 = None
        view_as_complex_39 = torch.ops.aten.view_as_complex.default(view_1251);  view_1251 = None
        mul_894 = torch.ops.aten.mul.Tensor(view_as_complex_39, view_7);  view_as_complex_39 = None
        view_as_real_39 = torch.ops.aten.view_as_real.default(mul_894);  mul_894 = None
        view_1253 = torch.ops.aten.view.default(view_as_real_39, [2, 4096, 1, 64]);  view_as_real_39 = None
        convert_element_type_1021 = torch.ops.prims.convert_element_type.default(view_1253, torch.bfloat16);  view_1253 = None
        convert_element_type_1022 = torch.ops.prims.convert_element_type.default(primals_314, torch.bfloat16)
        all_gather_into_tensor_320 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1022, 128, '0');  convert_element_type_1022 = None
        wait_tensor_392 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_320);  all_gather_into_tensor_320 = None
        convert_element_type_1023 = torch.ops.prims.convert_element_type.default(getitem_1991, torch.float32)
        pow_59 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1023, 2)
        mean_58 = torch.ops.aten.mean.dim(pow_59, [2], True);  pow_59 = None
        add_1231 = torch.ops.aten.add.Scalar(mean_58, 1e-05);  mean_58 = None
        rsqrt_58 = torch.ops.aten.rsqrt.default(add_1231);  add_1231 = None
        mul_895 = torch.ops.aten.mul.Tensor(convert_element_type_1023, rsqrt_58);  convert_element_type_1023 = None
        mul_896 = torch.ops.aten.mul.Tensor(mul_895, wait_tensor_392);  mul_895 = wait_tensor_392 = None
        convert_element_type_1024 = torch.ops.prims.convert_element_type.default(mul_896, torch.bfloat16);  mul_896 = None
        convert_element_type_1025 = torch.ops.prims.convert_element_type.default(primals_315, torch.bfloat16)
        all_gather_into_tensor_321 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1025, 128, '0');  convert_element_type_1025 = None
        wait_tensor_393 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_321);  all_gather_into_tensor_321 = None
        permute_283 = torch.ops.aten.permute.default(wait_tensor_393, [1, 0]);  wait_tensor_393 = None
        view_1256 = torch.ops.aten.view.default(convert_element_type_1024, [8192, 512]);  convert_element_type_1024 = None
        mm_153 = torch.ops.aten.mm.default(view_1256, permute_283);  permute_283 = None
        view_1257 = torch.ops.aten.view.default(mm_153, [2, 4096, 4096]);  mm_153 = None
        view_1258 = torch.ops.aten.view.default(view_1257, [2, 4096, -1, 256]);  view_1257 = None
        split_with_sizes_59 = torch.ops.aten.split_with_sizes.default(view_1258, [128, 128], -1);  view_1258 = None
        getitem_1993 = split_with_sizes_59[0]
        getitem_1994 = split_with_sizes_59[1];  split_with_sizes_59 = None
        expand_19 = torch.ops.aten.expand.default(convert_element_type_1021, [-1, -1, 16, -1]);  convert_element_type_1021 = None
        cat_165 = torch.ops.aten.cat.default([getitem_1993, expand_19], -1);  getitem_1993 = expand_19 = None
        permute_284 = torch.ops.aten.permute.default(cat_164, [0, 2, 1, 3]);  cat_164 = None
        permute_285 = torch.ops.aten.permute.default(cat_165, [0, 2, 1, 3]);  cat_165 = None
        permute_286 = torch.ops.aten.permute.default(getitem_1994, [0, 2, 1, 3]);  getitem_1994 = None
        sdpa_score19 = self.sdpa_score19
        sdpa_mask19 = self.sdpa_mask19
        flex_attention_19 = torch.ops.higher_order.flex_attention(permute_284, permute_285, permute_286, sdpa_score19, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask19), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score19 = sdpa_mask19 = None
        getitem_1995 = flex_attention_19[0]
        getitem_1996 = flex_attention_19[1];  flex_attention_19 = None
        permute_287 = torch.ops.aten.permute.default(getitem_1995, [0, 2, 1, 3])
        view_1259 = torch.ops.aten.view.default(permute_287, [2, 4096, -1]);  permute_287 = None
        convert_element_type_1028 = torch.ops.prims.convert_element_type.default(primals_316, torch.bfloat16)
        all_gather_into_tensor_322 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1028, 128, '0');  convert_element_type_1028 = None
        wait_tensor_394 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_322);  all_gather_into_tensor_322 = None
        permute_288 = torch.ops.aten.permute.default(wait_tensor_394, [1, 0]);  wait_tensor_394 = None
        view_1261 = torch.ops.aten.view.default(view_1259, [8192, 2048]);  view_1259 = None
        mm_154 = torch.ops.aten.mm.default(view_1261, permute_288);  view_1261 = permute_288 = None
        view_1262 = torch.ops.aten.view.default(mm_154, [2, 4096, 2048]);  mm_154 = None
        add_1232 = torch.ops.aten.add.Tensor(add_1229, view_1262);  view_1262 = None
        convert_element_type_1031 = torch.ops.prims.convert_element_type.default(primals_317, torch.bfloat16)
        all_gather_into_tensor_323 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1031, 128, '0');  convert_element_type_1031 = None
        wait_tensor_395 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_323);  all_gather_into_tensor_323 = None
        convert_element_type_1032 = torch.ops.prims.convert_element_type.default(add_1232, torch.float32)
        pow_60 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1032, 2)
        mean_59 = torch.ops.aten.mean.dim(pow_60, [2], True);  pow_60 = None
        add_1233 = torch.ops.aten.add.Scalar(mean_59, 1e-05);  mean_59 = None
        rsqrt_59 = torch.ops.aten.rsqrt.default(add_1233);  add_1233 = None
        mul_897 = torch.ops.aten.mul.Tensor(convert_element_type_1032, rsqrt_59);  convert_element_type_1032 = None
        mul_898 = torch.ops.aten.mul.Tensor(mul_897, wait_tensor_395);  mul_897 = wait_tensor_395 = None
        convert_element_type_1033 = torch.ops.prims.convert_element_type.default(mul_898, torch.bfloat16);  mul_898 = None
        view_1264 = torch.ops.aten.view.default(convert_element_type_1033, [-1, 2048]);  convert_element_type_1033 = None
        convert_element_type_1034 = torch.ops.prims.convert_element_type.default(primals_319, torch.bfloat16)
        all_gather_into_tensor_324 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1034, 128, '0');  convert_element_type_1034 = None
        wait_tensor_396 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_324);  all_gather_into_tensor_324 = None
        slice_117 = torch.ops.aten.slice.Tensor(wait_tensor_396, 0, 0, 64);  wait_tensor_396 = None
        permute_289 = torch.ops.aten.permute.default(slice_117, [1, 0]);  slice_117 = None
        mm_155 = torch.ops.aten.mm.default(view_1264, permute_289);  permute_289 = None
        convert_element_type_1037 = torch.ops.prims.convert_element_type.default(mm_155, torch.float32)
        amax_18 = torch.ops.aten.amax.default(convert_element_type_1037, [1], True)
        sub_432 = torch.ops.aten.sub.Tensor(convert_element_type_1037, amax_18);  convert_element_type_1037 = None
        exp_55 = torch.ops.aten.exp.default(sub_432);  sub_432 = None
        sum_73 = torch.ops.aten.sum.dim_IntList(exp_55, [1], True)
        div_91 = torch.ops.aten.div.Tensor(exp_55, sum_73);  exp_55 = None
        add_1234 = torch.ops.aten.add.Tensor(div_91, primals_318);  primals_318 = None
        topk_18 = torch.ops.aten.topk.default(add_1234, 6, -1, True, False);  add_1234 = None
        getitem_1999 = topk_18[1];  topk_18 = None
        gather_18 = torch.ops.aten.gather.default(div_91, 1, getitem_1999);  div_91 = None
        mul_899 = torch.ops.aten.mul.Tensor(gather_18, 1.0);  gather_18 = None
        view_1266 = torch.ops.aten.view.default(getitem_1999, [-1])
        histc_36 = torch.ops.aten.histc.default(view_1266, 64, 0, 64)
        add_1235 = torch.ops.aten.add.Tensor(primals_320, histc_36)
        sort_18 = torch.ops.aten.sort.stable(view_1266, stable = True);  view_1266 = None
        getitem_2001 = sort_18[1];  sort_18 = None
        div_92 = torch.ops.aten.div.Tensor_mode(getitem_2001, 6, rounding_mode = 'floor')
        index_36 = torch.ops.aten.index.Tensor(view_1264, [div_92])
        all_to_all_single_54 = torch.ops._c10d_functional.all_to_all_single.default(histc_36, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_397 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_54);  all_to_all_single_54 = None
        wait_tensor_398 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_397);  wait_tensor_397 = None
        view_1270 = torch.ops.aten.view.default(histc_36, [8, -1]);  histc_36 = None
        sum_74 = torch.ops.aten.sum.dim_IntList(view_1270, [1]);  view_1270 = None
        device_put_36 = torch.ops.prims.device_put.default(sum_74, device(type='cpu'), True);  sum_74 = None
        view_1271 = torch.ops.aten.view.default(wait_tensor_398, [8, -1])
        sum_75 = torch.ops.aten.sum.dim_IntList(view_1271, [1])
        device_put_37 = torch.ops.prims.device_put.default(sum_75, device(type='cpu'));  sum_75 = None
        select_288 = torch.ops.aten.select.int(device_put_36, 0, 0)
        _local_scalar_dense_288 = torch.ops.aten._local_scalar_dense.default(select_288);  select_288 = None
        ge_360 = _local_scalar_dense_288 >= 0
        _assert_scalar_288 = torch.ops.aten._assert_scalar.default(ge_360, "Runtime assertion failed for expression u288 >= 0 on node 'ge_288'");  ge_360 = _assert_scalar_288 = None
        select_289 = torch.ops.aten.select.int(device_put_36, 0, 1)
        _local_scalar_dense_289 = torch.ops.aten._local_scalar_dense.default(select_289);  select_289 = None
        ge_361 = _local_scalar_dense_289 >= 0
        _assert_scalar_289 = torch.ops.aten._assert_scalar.default(ge_361, "Runtime assertion failed for expression u289 >= 0 on node 'ge_289'");  ge_361 = _assert_scalar_289 = None
        select_290 = torch.ops.aten.select.int(device_put_36, 0, 2)
        _local_scalar_dense_290 = torch.ops.aten._local_scalar_dense.default(select_290);  select_290 = None
        ge_362 = _local_scalar_dense_290 >= 0
        _assert_scalar_290 = torch.ops.aten._assert_scalar.default(ge_362, "Runtime assertion failed for expression u290 >= 0 on node 'ge_290'");  ge_362 = _assert_scalar_290 = None
        select_291 = torch.ops.aten.select.int(device_put_36, 0, 3)
        _local_scalar_dense_291 = torch.ops.aten._local_scalar_dense.default(select_291);  select_291 = None
        ge_363 = _local_scalar_dense_291 >= 0
        _assert_scalar_291 = torch.ops.aten._assert_scalar.default(ge_363, "Runtime assertion failed for expression u291 >= 0 on node 'ge_291'");  ge_363 = _assert_scalar_291 = None
        select_292 = torch.ops.aten.select.int(device_put_36, 0, 4)
        _local_scalar_dense_292 = torch.ops.aten._local_scalar_dense.default(select_292);  select_292 = None
        ge_364 = _local_scalar_dense_292 >= 0
        _assert_scalar_292 = torch.ops.aten._assert_scalar.default(ge_364, "Runtime assertion failed for expression u292 >= 0 on node 'ge_292'");  ge_364 = _assert_scalar_292 = None
        select_293 = torch.ops.aten.select.int(device_put_36, 0, 5)
        _local_scalar_dense_293 = torch.ops.aten._local_scalar_dense.default(select_293);  select_293 = None
        ge_365 = _local_scalar_dense_293 >= 0
        _assert_scalar_293 = torch.ops.aten._assert_scalar.default(ge_365, "Runtime assertion failed for expression u293 >= 0 on node 'ge_293'");  ge_365 = _assert_scalar_293 = None
        select_294 = torch.ops.aten.select.int(device_put_36, 0, 6)
        _local_scalar_dense_294 = torch.ops.aten._local_scalar_dense.default(select_294);  select_294 = None
        ge_366 = _local_scalar_dense_294 >= 0
        _assert_scalar_294 = torch.ops.aten._assert_scalar.default(ge_366, "Runtime assertion failed for expression u294 >= 0 on node 'ge_294'");  ge_366 = _assert_scalar_294 = None
        select_295 = torch.ops.aten.select.int(device_put_36, 0, 7);  device_put_36 = None
        _local_scalar_dense_295 = torch.ops.aten._local_scalar_dense.default(select_295);  select_295 = None
        ge_367 = _local_scalar_dense_295 >= 0
        _assert_scalar_295 = torch.ops.aten._assert_scalar.default(ge_367, "Runtime assertion failed for expression u295 >= 0 on node 'ge_295'");  ge_367 = _assert_scalar_295 = None
        select_296 = torch.ops.aten.select.int(device_put_37, 0, 0)
        _local_scalar_dense_296 = torch.ops.aten._local_scalar_dense.default(select_296);  select_296 = None
        ge_368 = _local_scalar_dense_296 >= 0
        _assert_scalar_296 = torch.ops.aten._assert_scalar.default(ge_368, "Runtime assertion failed for expression u296 >= 0 on node 'ge_296'");  ge_368 = _assert_scalar_296 = None
        select_297 = torch.ops.aten.select.int(device_put_37, 0, 1)
        _local_scalar_dense_297 = torch.ops.aten._local_scalar_dense.default(select_297);  select_297 = None
        ge_369 = _local_scalar_dense_297 >= 0
        _assert_scalar_297 = torch.ops.aten._assert_scalar.default(ge_369, "Runtime assertion failed for expression u297 >= 0 on node 'ge_297'");  ge_369 = _assert_scalar_297 = None
        select_298 = torch.ops.aten.select.int(device_put_37, 0, 2)
        _local_scalar_dense_298 = torch.ops.aten._local_scalar_dense.default(select_298);  select_298 = None
        ge_370 = _local_scalar_dense_298 >= 0
        _assert_scalar_298 = torch.ops.aten._assert_scalar.default(ge_370, "Runtime assertion failed for expression u298 >= 0 on node 'ge_298'");  ge_370 = _assert_scalar_298 = None
        select_299 = torch.ops.aten.select.int(device_put_37, 0, 3)
        _local_scalar_dense_299 = torch.ops.aten._local_scalar_dense.default(select_299);  select_299 = None
        ge_371 = _local_scalar_dense_299 >= 0
        _assert_scalar_299 = torch.ops.aten._assert_scalar.default(ge_371, "Runtime assertion failed for expression u299 >= 0 on node 'ge_299'");  ge_371 = _assert_scalar_299 = None
        select_300 = torch.ops.aten.select.int(device_put_37, 0, 4)
        _local_scalar_dense_300 = torch.ops.aten._local_scalar_dense.default(select_300);  select_300 = None
        ge_372 = _local_scalar_dense_300 >= 0
        _assert_scalar_300 = torch.ops.aten._assert_scalar.default(ge_372, "Runtime assertion failed for expression u300 >= 0 on node 'ge_300'");  ge_372 = _assert_scalar_300 = None
        select_301 = torch.ops.aten.select.int(device_put_37, 0, 5)
        _local_scalar_dense_301 = torch.ops.aten._local_scalar_dense.default(select_301);  select_301 = None
        ge_373 = _local_scalar_dense_301 >= 0
        _assert_scalar_301 = torch.ops.aten._assert_scalar.default(ge_373, "Runtime assertion failed for expression u301 >= 0 on node 'ge_301'");  ge_373 = _assert_scalar_301 = None
        select_302 = torch.ops.aten.select.int(device_put_37, 0, 6)
        _local_scalar_dense_302 = torch.ops.aten._local_scalar_dense.default(select_302);  select_302 = None
        ge_374 = _local_scalar_dense_302 >= 0
        _assert_scalar_302 = torch.ops.aten._assert_scalar.default(ge_374, "Runtime assertion failed for expression u302 >= 0 on node 'ge_302'");  ge_374 = _assert_scalar_302 = None
        select_303 = torch.ops.aten.select.int(device_put_37, 0, 7);  device_put_37 = None
        _local_scalar_dense_303 = torch.ops.aten._local_scalar_dense.default(select_303);  select_303 = None
        ge_375 = _local_scalar_dense_303 >= 0
        _assert_scalar_303 = torch.ops.aten._assert_scalar.default(ge_375, "Runtime assertion failed for expression u303 >= 0 on node 'ge_303'");  ge_375 = _assert_scalar_303 = None
        all_to_all_single_55 = torch.ops._c10d_functional.all_to_all_single.default(index_36, [_local_scalar_dense_296, _local_scalar_dense_297, _local_scalar_dense_298, _local_scalar_dense_299, _local_scalar_dense_300, _local_scalar_dense_301, _local_scalar_dense_302, _local_scalar_dense_303], [_local_scalar_dense_288, _local_scalar_dense_289, _local_scalar_dense_290, _local_scalar_dense_291, _local_scalar_dense_292, _local_scalar_dense_293, _local_scalar_dense_294, _local_scalar_dense_295], '1033');  index_36 = None
        sym_size_int_72 = torch.ops.aten.sym_size.int(all_to_all_single_55, 0)
        wait_tensor_399 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_55);  all_to_all_single_55 = None
        sym_sum_36 = torch.sym_sum((_local_scalar_dense_296, _local_scalar_dense_297, _local_scalar_dense_298, _local_scalar_dense_299, _local_scalar_dense_300, _local_scalar_dense_301, _local_scalar_dense_302, _local_scalar_dense_303))
        add_1242 = sym_sum_36 + 64;  sym_sum_36 = None
        add_1243 = add_1242 + 8;  add_1242 = None
        sub_435 = add_1243 - 1;  add_1243 = None
        floordiv_18 = sub_435 // 8;  sub_435 = None
        mul_904 = floordiv_18 * 8;  floordiv_18 = None
        cumsum_54 = torch.ops.aten.cumsum.default(wait_tensor_398, 0)
        sub_436 = torch.ops.aten.sub.Tensor(cumsum_54, wait_tensor_398);  cumsum_54 = None
        sum_76 = torch.ops.aten.sum.dim_IntList(view_1271, [0]);  view_1271 = None
        clamp_min_18 = torch.ops.aten.clamp_min.default(sum_76, 8);  sum_76 = None
        add_1244 = torch.ops.aten.add.Tensor(clamp_min_18, 8);  clamp_min_18 = None
        sub_437 = torch.ops.aten.sub.Tensor(add_1244, 1);  add_1244 = None
        div_93 = torch.ops.aten.div.Tensor_mode(sub_437, 8, rounding_mode = 'floor');  sub_437 = None
        mul_905 = torch.ops.aten.mul.Tensor(div_93, 8);  div_93 = None
        convert_element_type_1040 = torch.ops.prims.convert_element_type.default(mul_905, torch.int32);  mul_905 = None
        cumsum_55 = torch.ops.aten.cumsum.default(convert_element_type_1040, 0)
        sub_438 = torch.ops.aten.sub.Tensor(cumsum_55, convert_element_type_1040);  cumsum_55 = None
        full_254 = torch.ops.aten.full.default([mul_904], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_904 = None
        triton_kernel_wrapper_functional_proxy_18 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 18, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_398, 'start_index_values_ptr': sub_436, 'write_offsets_ptr': sub_438, 'output_ptr': full_254}, tensors_to_clone = ['output_ptr']);  wait_tensor_398 = sub_436 = sub_438 = full_254 = None
        getitem_2002 = triton_kernel_wrapper_functional_proxy_18['output_ptr'];  triton_kernel_wrapper_functional_proxy_18 = None
        cat_166 = torch.ops.aten.cat.default([wait_tensor_399, full_default]);  wait_tensor_399 = None
        sym_size_int_73 = torch.ops.aten.sym_size.int(cat_166, 0)
        sym_sum_37 = torch.sym_sum((1, _local_scalar_dense_296, _local_scalar_dense_297, _local_scalar_dense_298, _local_scalar_dense_299, _local_scalar_dense_300, _local_scalar_dense_301, _local_scalar_dense_302, _local_scalar_dense_303))
        index_37 = torch.ops.aten.index.Tensor(cat_166, [getitem_2002]);  cat_166 = None
        convert_element_type_1042 = torch.ops.prims.convert_element_type.default(primals_321, torch.bfloat16)
        all_gather_into_tensor_325 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1042, 16, '1025');  convert_element_type_1042 = None
        wait_tensor_400 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_325);  all_gather_into_tensor_325 = None
        split_109 = torch.ops.aten.split.Tensor(wait_tensor_400, 8);  wait_tensor_400 = None
        getitem_2019 = split_109[0]
        getitem_2020 = split_109[1]
        getitem_2021 = split_109[2]
        getitem_2022 = split_109[3]
        getitem_2023 = split_109[4]
        getitem_2024 = split_109[5]
        getitem_2025 = split_109[6]
        getitem_2026 = split_109[7]
        getitem_2027 = split_109[8]
        getitem_2028 = split_109[9]
        getitem_2029 = split_109[10]
        getitem_2030 = split_109[11]
        getitem_2031 = split_109[12]
        getitem_2032 = split_109[13]
        getitem_2033 = split_109[14]
        getitem_2034 = split_109[15];  split_109 = None
        cat_168 = torch.ops.aten.cat.default([getitem_2019, getitem_2020, getitem_2021, getitem_2022, getitem_2023, getitem_2024, getitem_2025, getitem_2026, getitem_2027, getitem_2028, getitem_2029, getitem_2030, getitem_2031, getitem_2032, getitem_2033, getitem_2034], 1);  getitem_2019 = getitem_2020 = getitem_2021 = getitem_2022 = getitem_2023 = getitem_2024 = getitem_2025 = getitem_2026 = getitem_2027 = getitem_2028 = getitem_2029 = getitem_2030 = getitem_2031 = getitem_2032 = getitem_2033 = getitem_2034 = None
        convert_element_type_1044 = torch.ops.prims.convert_element_type.default(primals_322, torch.bfloat16)
        all_gather_into_tensor_327 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1044, 16, '1025');  convert_element_type_1044 = None
        wait_tensor_402 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_327);  all_gather_into_tensor_327 = None
        split_110 = torch.ops.aten.split.Tensor(wait_tensor_402, 8);  wait_tensor_402 = None
        getitem_2035 = split_110[0]
        getitem_2036 = split_110[1]
        getitem_2037 = split_110[2]
        getitem_2038 = split_110[3]
        getitem_2039 = split_110[4]
        getitem_2040 = split_110[5]
        getitem_2041 = split_110[6]
        getitem_2042 = split_110[7]
        getitem_2043 = split_110[8]
        getitem_2044 = split_110[9]
        getitem_2045 = split_110[10]
        getitem_2046 = split_110[11]
        getitem_2047 = split_110[12]
        getitem_2048 = split_110[13]
        getitem_2049 = split_110[14]
        getitem_2050 = split_110[15];  split_110 = None
        cat_169 = torch.ops.aten.cat.default([getitem_2035, getitem_2036, getitem_2037, getitem_2038, getitem_2039, getitem_2040, getitem_2041, getitem_2042, getitem_2043, getitem_2044, getitem_2045, getitem_2046, getitem_2047, getitem_2048, getitem_2049, getitem_2050], 1);  getitem_2035 = getitem_2036 = getitem_2037 = getitem_2038 = getitem_2039 = getitem_2040 = getitem_2041 = getitem_2042 = getitem_2043 = getitem_2044 = getitem_2045 = getitem_2046 = getitem_2047 = getitem_2048 = getitem_2049 = getitem_2050 = None
        convert_element_type_1045 = torch.ops.prims.convert_element_type.default(primals_323, torch.bfloat16)
        all_gather_into_tensor_328 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1045, 16, '1025');  convert_element_type_1045 = None
        wait_tensor_403 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_328);  all_gather_into_tensor_328 = None
        split_111 = torch.ops.aten.split.Tensor(wait_tensor_403, 8);  wait_tensor_403 = None
        getitem_2051 = split_111[0]
        getitem_2052 = split_111[1]
        getitem_2053 = split_111[2]
        getitem_2054 = split_111[3]
        getitem_2055 = split_111[4]
        getitem_2056 = split_111[5]
        getitem_2057 = split_111[6]
        getitem_2058 = split_111[7]
        getitem_2059 = split_111[8]
        getitem_2060 = split_111[9]
        getitem_2061 = split_111[10]
        getitem_2062 = split_111[11]
        getitem_2063 = split_111[12]
        getitem_2064 = split_111[13]
        getitem_2065 = split_111[14]
        getitem_2066 = split_111[15];  split_111 = None
        cat_170 = torch.ops.aten.cat.default([getitem_2051, getitem_2052, getitem_2053, getitem_2054, getitem_2055, getitem_2056, getitem_2057, getitem_2058, getitem_2059, getitem_2060, getitem_2061, getitem_2062, getitem_2063, getitem_2064, getitem_2065, getitem_2066], 1);  getitem_2051 = getitem_2052 = getitem_2053 = getitem_2054 = getitem_2055 = getitem_2056 = getitem_2057 = getitem_2058 = getitem_2059 = getitem_2060 = getitem_2061 = getitem_2062 = getitem_2063 = getitem_2064 = getitem_2065 = getitem_2066 = None
        cumsum_56 = torch.ops.aten.cumsum.default(convert_element_type_1040, 0, dtype = torch.int32);  convert_element_type_1040 = None
        permute_290 = torch.ops.aten.permute.default(cat_168, [0, 2, 1]);  cat_168 = None
        _grouped_mm_54 = torch.ops.aten._grouped_mm.default(index_37, permute_290, cumsum_56)
        convert_element_type_1048 = torch.ops.prims.convert_element_type.default(_grouped_mm_54, torch.float32)
        neg_37 = torch.ops.aten.neg.default(convert_element_type_1048)
        exp_56 = torch.ops.aten.exp.default(neg_37);  neg_37 = None
        add_1256 = torch.ops.aten.add.Tensor(exp_56, 1);  exp_56 = None
        div_94 = torch.ops.aten.div.Tensor(convert_element_type_1048, add_1256);  convert_element_type_1048 = add_1256 = None
        convert_element_type_1049 = torch.ops.prims.convert_element_type.default(div_94, torch.bfloat16);  div_94 = None
        permute_291 = torch.ops.aten.permute.default(cat_170, [0, 2, 1]);  cat_170 = None
        _grouped_mm_55 = torch.ops.aten._grouped_mm.default(index_37, permute_291, cumsum_56)
        mul_917 = torch.ops.aten.mul.Tensor(convert_element_type_1049, _grouped_mm_55);  convert_element_type_1049 = None
        permute_292 = torch.ops.aten.permute.default(cat_169, [0, 2, 1]);  cat_169 = None
        _grouped_mm_56 = torch.ops.aten._grouped_mm.default(mul_917, permute_292, cumsum_56)
        empty_18 = torch.ops.aten.empty.memory_format([sym_size_int_73, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_36 = torch.ops.aten.index_put.default(empty_18, [getitem_2002], _grouped_mm_56);  empty_18 = _grouped_mm_56 = None
        slice_119 = torch.ops.aten.slice.Tensor(index_put_36, 0, 0, -1);  index_put_36 = None
        all_to_all_single_56 = torch.ops._c10d_functional.all_to_all_single.default(slice_119, [_local_scalar_dense_288, _local_scalar_dense_289, _local_scalar_dense_290, _local_scalar_dense_291, _local_scalar_dense_292, _local_scalar_dense_293, _local_scalar_dense_294, _local_scalar_dense_295], [_local_scalar_dense_296, _local_scalar_dense_297, _local_scalar_dense_298, _local_scalar_dense_299, _local_scalar_dense_300, _local_scalar_dense_301, _local_scalar_dense_302, _local_scalar_dense_303], '1033');  slice_119 = None
        wait_tensor_406 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_56);  all_to_all_single_56 = None
        convert_element_type_1050 = torch.ops.prims.convert_element_type.default(primals_324, torch.bfloat16)
        all_gather_into_tensor_331 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1050, 128, '0');  convert_element_type_1050 = None
        wait_tensor_407 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_331);  all_gather_into_tensor_331 = None
        permute_293 = torch.ops.aten.permute.default(wait_tensor_407, [1, 0]);  wait_tensor_407 = None
        mm_156 = torch.ops.aten.mm.default(view_1264, permute_293);  permute_293 = None
        convert_element_type_1053 = torch.ops.prims.convert_element_type.default(mm_156, torch.float32)
        neg_38 = torch.ops.aten.neg.default(convert_element_type_1053)
        exp_57 = torch.ops.aten.exp.default(neg_38);  neg_38 = None
        add_1292 = torch.ops.aten.add.Tensor(exp_57, 1);  exp_57 = None
        div_95 = torch.ops.aten.div.Tensor(convert_element_type_1053, add_1292);  convert_element_type_1053 = add_1292 = None
        convert_element_type_1054 = torch.ops.prims.convert_element_type.default(div_95, torch.bfloat16);  div_95 = None
        convert_element_type_1055 = torch.ops.prims.convert_element_type.default(primals_325, torch.bfloat16)
        all_gather_into_tensor_332 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1055, 128, '0');  convert_element_type_1055 = None
        wait_tensor_408 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_332);  all_gather_into_tensor_332 = None
        permute_294 = torch.ops.aten.permute.default(wait_tensor_408, [1, 0]);  wait_tensor_408 = None
        mm_157 = torch.ops.aten.mm.default(view_1264, permute_294);  permute_294 = None
        mul_937 = torch.ops.aten.mul.Tensor(convert_element_type_1054, mm_157);  convert_element_type_1054 = None
        convert_element_type_1058 = torch.ops.prims.convert_element_type.default(primals_326, torch.bfloat16)
        all_gather_into_tensor_333 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1058, 128, '0');  convert_element_type_1058 = None
        wait_tensor_409 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_333);  all_gather_into_tensor_333 = None
        permute_295 = torch.ops.aten.permute.default(wait_tensor_409, [1, 0]);  wait_tensor_409 = None
        mm_158 = torch.ops.aten.mm.default(mul_937, permute_295);  permute_295 = None
        index_put_37 = torch.ops.aten.index_put.default(full_default_1, [getitem_2001], wait_tensor_406);  wait_tensor_406 = None
        view_1304 = torch.ops.aten.view.default(mul_899, [-1, 1, 6]);  mul_899 = None
        view_1305 = torch.ops.aten.view.default(index_put_37, [-1, 6, 2048]);  index_put_37 = None
        convert_element_type_1061 = torch.ops.prims.convert_element_type.default(view_1305, torch.float32);  view_1305 = None
        bmm_18 = torch.ops.aten.bmm.default(view_1304, convert_element_type_1061)
        convert_element_type_1062 = torch.ops.prims.convert_element_type.default(bmm_18, torch.bfloat16);  bmm_18 = None
        squeeze_18 = torch.ops.aten.squeeze.dim(convert_element_type_1062, 1);  convert_element_type_1062 = None
        add_1296 = torch.ops.aten.add.Tensor(mm_158, squeeze_18);  mm_158 = squeeze_18 = None
        view_1306 = torch.ops.aten.view.default(add_1296, [2, 4096, 2048]);  add_1296 = None
        add_1297 = torch.ops.aten.add.Tensor(add_1232, view_1306);  view_1306 = None
        convert_element_type_1063 = torch.ops.prims.convert_element_type.default(primals_327, torch.bfloat16)
        all_gather_into_tensor_334 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1063, 128, '0');  convert_element_type_1063 = None
        wait_tensor_410 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_334);  all_gather_into_tensor_334 = None
        convert_element_type_1064 = torch.ops.prims.convert_element_type.default(add_1297, torch.float32)
        pow_61 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1064, 2)
        mean_60 = torch.ops.aten.mean.dim(pow_61, [2], True);  pow_61 = None
        add_1298 = torch.ops.aten.add.Scalar(mean_60, 1e-05);  mean_60 = None
        rsqrt_60 = torch.ops.aten.rsqrt.default(add_1298);  add_1298 = None
        mul_940 = torch.ops.aten.mul.Tensor(convert_element_type_1064, rsqrt_60);  convert_element_type_1064 = None
        mul_941 = torch.ops.aten.mul.Tensor(mul_940, wait_tensor_410);  mul_940 = wait_tensor_410 = None
        convert_element_type_1065 = torch.ops.prims.convert_element_type.default(mul_941, torch.bfloat16);  mul_941 = None
        convert_element_type_1066 = torch.ops.prims.convert_element_type.default(primals_328, torch.bfloat16)
        all_gather_into_tensor_335 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1066, 128, '0');  convert_element_type_1066 = None
        wait_tensor_411 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_335);  all_gather_into_tensor_335 = None
        permute_296 = torch.ops.aten.permute.default(wait_tensor_411, [1, 0]);  wait_tensor_411 = None
        view_1309 = torch.ops.aten.view.default(convert_element_type_1065, [8192, 2048]);  convert_element_type_1065 = None
        mm_159 = torch.ops.aten.mm.default(view_1309, permute_296);  permute_296 = None
        view_1310 = torch.ops.aten.view.default(mm_159, [2, 4096, 3072]);  mm_159 = None
        view_1311 = torch.ops.aten.view.default(view_1310, [2, 4096, -1, 192]);  view_1310 = None
        split_with_sizes_60 = torch.ops.aten.split_with_sizes.default(view_1311, [128, 64], -1);  view_1311 = None
        getitem_2099 = split_with_sizes_60[0]
        getitem_2100 = split_with_sizes_60[1];  split_with_sizes_60 = None
        convert_element_type_1069 = torch.ops.prims.convert_element_type.default(getitem_2100, torch.float32);  getitem_2100 = None
        view_1312 = torch.ops.aten.view.default(convert_element_type_1069, [2, 4096, 16, -1, 2]);  convert_element_type_1069 = None
        view_as_complex_40 = torch.ops.aten.view_as_complex.default(view_1312);  view_1312 = None
        mul_942 = torch.ops.aten.mul.Tensor(view_as_complex_40, view_7);  view_as_complex_40 = None
        view_as_real_40 = torch.ops.aten.view_as_real.default(mul_942);  mul_942 = None
        view_1314 = torch.ops.aten.view.default(view_as_real_40, [2, 4096, 16, 64]);  view_as_real_40 = None
        convert_element_type_1070 = torch.ops.prims.convert_element_type.default(view_1314, torch.bfloat16);  view_1314 = None
        cat_173 = torch.ops.aten.cat.default([getitem_2099, convert_element_type_1070], -1);  getitem_2099 = convert_element_type_1070 = None
        convert_element_type_1071 = torch.ops.prims.convert_element_type.default(primals_329, torch.bfloat16)
        all_gather_into_tensor_336 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1071, 128, '0');  convert_element_type_1071 = None
        wait_tensor_412 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_336);  all_gather_into_tensor_336 = None
        slice_121 = torch.ops.aten.slice.Tensor(wait_tensor_412, 0, 0, 576);  wait_tensor_412 = None
        permute_297 = torch.ops.aten.permute.default(slice_121, [1, 0]);  slice_121 = None
        mm_160 = torch.ops.aten.mm.default(view_1309, permute_297);  permute_297 = None
        view_1317 = torch.ops.aten.view.default(mm_160, [2, 4096, 576]);  mm_160 = None
        split_with_sizes_61 = torch.ops.aten.split_with_sizes.default(view_1317, [512, 64], -1);  view_1317 = None
        getitem_2101 = split_with_sizes_61[0]
        getitem_2102 = split_with_sizes_61[1];  split_with_sizes_61 = None
        unsqueeze_39 = torch.ops.aten.unsqueeze.default(getitem_2102, 2);  getitem_2102 = None
        convert_element_type_1074 = torch.ops.prims.convert_element_type.default(unsqueeze_39, torch.float32);  unsqueeze_39 = None
        view_1318 = torch.ops.aten.view.default(convert_element_type_1074, [2, 4096, 1, -1, 2]);  convert_element_type_1074 = None
        view_as_complex_41 = torch.ops.aten.view_as_complex.default(view_1318);  view_1318 = None
        mul_943 = torch.ops.aten.mul.Tensor(view_as_complex_41, view_7);  view_as_complex_41 = None
        view_as_real_41 = torch.ops.aten.view_as_real.default(mul_943);  mul_943 = None
        view_1320 = torch.ops.aten.view.default(view_as_real_41, [2, 4096, 1, 64]);  view_as_real_41 = None
        convert_element_type_1075 = torch.ops.prims.convert_element_type.default(view_1320, torch.bfloat16);  view_1320 = None
        convert_element_type_1076 = torch.ops.prims.convert_element_type.default(primals_330, torch.bfloat16)
        all_gather_into_tensor_337 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1076, 128, '0');  convert_element_type_1076 = None
        wait_tensor_413 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_337);  all_gather_into_tensor_337 = None
        convert_element_type_1077 = torch.ops.prims.convert_element_type.default(getitem_2101, torch.float32)
        pow_62 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1077, 2)
        mean_61 = torch.ops.aten.mean.dim(pow_62, [2], True);  pow_62 = None
        add_1299 = torch.ops.aten.add.Scalar(mean_61, 1e-05);  mean_61 = None
        rsqrt_61 = torch.ops.aten.rsqrt.default(add_1299);  add_1299 = None
        mul_944 = torch.ops.aten.mul.Tensor(convert_element_type_1077, rsqrt_61);  convert_element_type_1077 = None
        mul_945 = torch.ops.aten.mul.Tensor(mul_944, wait_tensor_413);  mul_944 = wait_tensor_413 = None
        convert_element_type_1078 = torch.ops.prims.convert_element_type.default(mul_945, torch.bfloat16);  mul_945 = None
        convert_element_type_1079 = torch.ops.prims.convert_element_type.default(primals_331, torch.bfloat16)
        all_gather_into_tensor_338 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1079, 128, '0');  convert_element_type_1079 = None
        wait_tensor_414 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_338);  all_gather_into_tensor_338 = None
        permute_298 = torch.ops.aten.permute.default(wait_tensor_414, [1, 0]);  wait_tensor_414 = None
        view_1323 = torch.ops.aten.view.default(convert_element_type_1078, [8192, 512]);  convert_element_type_1078 = None
        mm_161 = torch.ops.aten.mm.default(view_1323, permute_298);  permute_298 = None
        view_1324 = torch.ops.aten.view.default(mm_161, [2, 4096, 4096]);  mm_161 = None
        view_1325 = torch.ops.aten.view.default(view_1324, [2, 4096, -1, 256]);  view_1324 = None
        split_with_sizes_62 = torch.ops.aten.split_with_sizes.default(view_1325, [128, 128], -1);  view_1325 = None
        getitem_2103 = split_with_sizes_62[0]
        getitem_2104 = split_with_sizes_62[1];  split_with_sizes_62 = None
        expand_20 = torch.ops.aten.expand.default(convert_element_type_1075, [-1, -1, 16, -1]);  convert_element_type_1075 = None
        cat_174 = torch.ops.aten.cat.default([getitem_2103, expand_20], -1);  getitem_2103 = expand_20 = None
        permute_299 = torch.ops.aten.permute.default(cat_173, [0, 2, 1, 3]);  cat_173 = None
        permute_300 = torch.ops.aten.permute.default(cat_174, [0, 2, 1, 3]);  cat_174 = None
        permute_301 = torch.ops.aten.permute.default(getitem_2104, [0, 2, 1, 3]);  getitem_2104 = None
        sdpa_score20 = self.sdpa_score20
        sdpa_mask20 = self.sdpa_mask20
        flex_attention_20 = torch.ops.higher_order.flex_attention(permute_299, permute_300, permute_301, sdpa_score20, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask20), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score20 = sdpa_mask20 = None
        getitem_2105 = flex_attention_20[0]
        getitem_2106 = flex_attention_20[1];  flex_attention_20 = None
        permute_302 = torch.ops.aten.permute.default(getitem_2105, [0, 2, 1, 3])
        view_1326 = torch.ops.aten.view.default(permute_302, [2, 4096, -1]);  permute_302 = None
        convert_element_type_1082 = torch.ops.prims.convert_element_type.default(primals_332, torch.bfloat16)
        all_gather_into_tensor_339 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1082, 128, '0');  convert_element_type_1082 = None
        wait_tensor_415 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_339);  all_gather_into_tensor_339 = None
        permute_303 = torch.ops.aten.permute.default(wait_tensor_415, [1, 0]);  wait_tensor_415 = None
        view_1328 = torch.ops.aten.view.default(view_1326, [8192, 2048]);  view_1326 = None
        mm_162 = torch.ops.aten.mm.default(view_1328, permute_303);  view_1328 = permute_303 = None
        view_1329 = torch.ops.aten.view.default(mm_162, [2, 4096, 2048]);  mm_162 = None
        add_1300 = torch.ops.aten.add.Tensor(add_1297, view_1329);  view_1329 = None
        convert_element_type_1085 = torch.ops.prims.convert_element_type.default(primals_333, torch.bfloat16)
        all_gather_into_tensor_340 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1085, 128, '0');  convert_element_type_1085 = None
        wait_tensor_416 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_340);  all_gather_into_tensor_340 = None
        convert_element_type_1086 = torch.ops.prims.convert_element_type.default(add_1300, torch.float32)
        pow_63 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1086, 2)
        mean_62 = torch.ops.aten.mean.dim(pow_63, [2], True);  pow_63 = None
        add_1301 = torch.ops.aten.add.Scalar(mean_62, 1e-05);  mean_62 = None
        rsqrt_62 = torch.ops.aten.rsqrt.default(add_1301);  add_1301 = None
        mul_946 = torch.ops.aten.mul.Tensor(convert_element_type_1086, rsqrt_62);  convert_element_type_1086 = None
        mul_947 = torch.ops.aten.mul.Tensor(mul_946, wait_tensor_416);  mul_946 = wait_tensor_416 = None
        convert_element_type_1087 = torch.ops.prims.convert_element_type.default(mul_947, torch.bfloat16);  mul_947 = None
        view_1331 = torch.ops.aten.view.default(convert_element_type_1087, [-1, 2048]);  convert_element_type_1087 = None
        convert_element_type_1088 = torch.ops.prims.convert_element_type.default(primals_335, torch.bfloat16)
        all_gather_into_tensor_341 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1088, 128, '0');  convert_element_type_1088 = None
        wait_tensor_417 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_341);  all_gather_into_tensor_341 = None
        slice_123 = torch.ops.aten.slice.Tensor(wait_tensor_417, 0, 0, 64);  wait_tensor_417 = None
        permute_304 = torch.ops.aten.permute.default(slice_123, [1, 0]);  slice_123 = None
        mm_163 = torch.ops.aten.mm.default(view_1331, permute_304);  permute_304 = None
        convert_element_type_1091 = torch.ops.prims.convert_element_type.default(mm_163, torch.float32)
        amax_19 = torch.ops.aten.amax.default(convert_element_type_1091, [1], True)
        sub_456 = torch.ops.aten.sub.Tensor(convert_element_type_1091, amax_19);  convert_element_type_1091 = None
        exp_58 = torch.ops.aten.exp.default(sub_456);  sub_456 = None
        sum_77 = torch.ops.aten.sum.dim_IntList(exp_58, [1], True)
        div_96 = torch.ops.aten.div.Tensor(exp_58, sum_77);  exp_58 = None
        add_1302 = torch.ops.aten.add.Tensor(div_96, primals_334);  primals_334 = None
        topk_19 = torch.ops.aten.topk.default(add_1302, 6, -1, True, False);  add_1302 = None
        getitem_2109 = topk_19[1];  topk_19 = None
        gather_19 = torch.ops.aten.gather.default(div_96, 1, getitem_2109);  div_96 = None
        mul_948 = torch.ops.aten.mul.Tensor(gather_19, 1.0);  gather_19 = None
        view_1333 = torch.ops.aten.view.default(getitem_2109, [-1])
        histc_38 = torch.ops.aten.histc.default(view_1333, 64, 0, 64)
        add_1303 = torch.ops.aten.add.Tensor(primals_336, histc_38)
        sort_19 = torch.ops.aten.sort.stable(view_1333, stable = True);  view_1333 = None
        getitem_2111 = sort_19[1];  sort_19 = None
        div_97 = torch.ops.aten.div.Tensor_mode(getitem_2111, 6, rounding_mode = 'floor')
        index_38 = torch.ops.aten.index.Tensor(view_1331, [div_97])
        all_to_all_single_57 = torch.ops._c10d_functional.all_to_all_single.default(histc_38, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_418 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_57);  all_to_all_single_57 = None
        wait_tensor_419 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_418);  wait_tensor_418 = None
        view_1337 = torch.ops.aten.view.default(histc_38, [8, -1]);  histc_38 = None
        sum_78 = torch.ops.aten.sum.dim_IntList(view_1337, [1]);  view_1337 = None
        device_put_38 = torch.ops.prims.device_put.default(sum_78, device(type='cpu'), True);  sum_78 = None
        view_1338 = torch.ops.aten.view.default(wait_tensor_419, [8, -1])
        sum_79 = torch.ops.aten.sum.dim_IntList(view_1338, [1])
        device_put_39 = torch.ops.prims.device_put.default(sum_79, device(type='cpu'));  sum_79 = None
        select_304 = torch.ops.aten.select.int(device_put_38, 0, 0)
        _local_scalar_dense_304 = torch.ops.aten._local_scalar_dense.default(select_304);  select_304 = None
        ge_380 = _local_scalar_dense_304 >= 0
        _assert_scalar_304 = torch.ops.aten._assert_scalar.default(ge_380, "Runtime assertion failed for expression u304 >= 0 on node 'ge_304'");  ge_380 = _assert_scalar_304 = None
        select_305 = torch.ops.aten.select.int(device_put_38, 0, 1)
        _local_scalar_dense_305 = torch.ops.aten._local_scalar_dense.default(select_305);  select_305 = None
        ge_381 = _local_scalar_dense_305 >= 0
        _assert_scalar_305 = torch.ops.aten._assert_scalar.default(ge_381, "Runtime assertion failed for expression u305 >= 0 on node 'ge_305'");  ge_381 = _assert_scalar_305 = None
        select_306 = torch.ops.aten.select.int(device_put_38, 0, 2)
        _local_scalar_dense_306 = torch.ops.aten._local_scalar_dense.default(select_306);  select_306 = None
        ge_382 = _local_scalar_dense_306 >= 0
        _assert_scalar_306 = torch.ops.aten._assert_scalar.default(ge_382, "Runtime assertion failed for expression u306 >= 0 on node 'ge_306'");  ge_382 = _assert_scalar_306 = None
        select_307 = torch.ops.aten.select.int(device_put_38, 0, 3)
        _local_scalar_dense_307 = torch.ops.aten._local_scalar_dense.default(select_307);  select_307 = None
        ge_383 = _local_scalar_dense_307 >= 0
        _assert_scalar_307 = torch.ops.aten._assert_scalar.default(ge_383, "Runtime assertion failed for expression u307 >= 0 on node 'ge_307'");  ge_383 = _assert_scalar_307 = None
        select_308 = torch.ops.aten.select.int(device_put_38, 0, 4)
        _local_scalar_dense_308 = torch.ops.aten._local_scalar_dense.default(select_308);  select_308 = None
        ge_384 = _local_scalar_dense_308 >= 0
        _assert_scalar_308 = torch.ops.aten._assert_scalar.default(ge_384, "Runtime assertion failed for expression u308 >= 0 on node 'ge_308'");  ge_384 = _assert_scalar_308 = None
        select_309 = torch.ops.aten.select.int(device_put_38, 0, 5)
        _local_scalar_dense_309 = torch.ops.aten._local_scalar_dense.default(select_309);  select_309 = None
        ge_385 = _local_scalar_dense_309 >= 0
        _assert_scalar_309 = torch.ops.aten._assert_scalar.default(ge_385, "Runtime assertion failed for expression u309 >= 0 on node 'ge_309'");  ge_385 = _assert_scalar_309 = None
        select_310 = torch.ops.aten.select.int(device_put_38, 0, 6)
        _local_scalar_dense_310 = torch.ops.aten._local_scalar_dense.default(select_310);  select_310 = None
        ge_386 = _local_scalar_dense_310 >= 0
        _assert_scalar_310 = torch.ops.aten._assert_scalar.default(ge_386, "Runtime assertion failed for expression u310 >= 0 on node 'ge_310'");  ge_386 = _assert_scalar_310 = None
        select_311 = torch.ops.aten.select.int(device_put_38, 0, 7);  device_put_38 = None
        _local_scalar_dense_311 = torch.ops.aten._local_scalar_dense.default(select_311);  select_311 = None
        ge_387 = _local_scalar_dense_311 >= 0
        _assert_scalar_311 = torch.ops.aten._assert_scalar.default(ge_387, "Runtime assertion failed for expression u311 >= 0 on node 'ge_311'");  ge_387 = _assert_scalar_311 = None
        select_312 = torch.ops.aten.select.int(device_put_39, 0, 0)
        _local_scalar_dense_312 = torch.ops.aten._local_scalar_dense.default(select_312);  select_312 = None
        ge_388 = _local_scalar_dense_312 >= 0
        _assert_scalar_312 = torch.ops.aten._assert_scalar.default(ge_388, "Runtime assertion failed for expression u312 >= 0 on node 'ge_312'");  ge_388 = _assert_scalar_312 = None
        select_313 = torch.ops.aten.select.int(device_put_39, 0, 1)
        _local_scalar_dense_313 = torch.ops.aten._local_scalar_dense.default(select_313);  select_313 = None
        ge_389 = _local_scalar_dense_313 >= 0
        _assert_scalar_313 = torch.ops.aten._assert_scalar.default(ge_389, "Runtime assertion failed for expression u313 >= 0 on node 'ge_313'");  ge_389 = _assert_scalar_313 = None
        select_314 = torch.ops.aten.select.int(device_put_39, 0, 2)
        _local_scalar_dense_314 = torch.ops.aten._local_scalar_dense.default(select_314);  select_314 = None
        ge_390 = _local_scalar_dense_314 >= 0
        _assert_scalar_314 = torch.ops.aten._assert_scalar.default(ge_390, "Runtime assertion failed for expression u314 >= 0 on node 'ge_314'");  ge_390 = _assert_scalar_314 = None
        select_315 = torch.ops.aten.select.int(device_put_39, 0, 3)
        _local_scalar_dense_315 = torch.ops.aten._local_scalar_dense.default(select_315);  select_315 = None
        ge_391 = _local_scalar_dense_315 >= 0
        _assert_scalar_315 = torch.ops.aten._assert_scalar.default(ge_391, "Runtime assertion failed for expression u315 >= 0 on node 'ge_315'");  ge_391 = _assert_scalar_315 = None
        select_316 = torch.ops.aten.select.int(device_put_39, 0, 4)
        _local_scalar_dense_316 = torch.ops.aten._local_scalar_dense.default(select_316);  select_316 = None
        ge_392 = _local_scalar_dense_316 >= 0
        _assert_scalar_316 = torch.ops.aten._assert_scalar.default(ge_392, "Runtime assertion failed for expression u316 >= 0 on node 'ge_316'");  ge_392 = _assert_scalar_316 = None
        select_317 = torch.ops.aten.select.int(device_put_39, 0, 5)
        _local_scalar_dense_317 = torch.ops.aten._local_scalar_dense.default(select_317);  select_317 = None
        ge_393 = _local_scalar_dense_317 >= 0
        _assert_scalar_317 = torch.ops.aten._assert_scalar.default(ge_393, "Runtime assertion failed for expression u317 >= 0 on node 'ge_317'");  ge_393 = _assert_scalar_317 = None
        select_318 = torch.ops.aten.select.int(device_put_39, 0, 6)
        _local_scalar_dense_318 = torch.ops.aten._local_scalar_dense.default(select_318);  select_318 = None
        ge_394 = _local_scalar_dense_318 >= 0
        _assert_scalar_318 = torch.ops.aten._assert_scalar.default(ge_394, "Runtime assertion failed for expression u318 >= 0 on node 'ge_318'");  ge_394 = _assert_scalar_318 = None
        select_319 = torch.ops.aten.select.int(device_put_39, 0, 7);  device_put_39 = None
        _local_scalar_dense_319 = torch.ops.aten._local_scalar_dense.default(select_319);  select_319 = None
        ge_395 = _local_scalar_dense_319 >= 0
        _assert_scalar_319 = torch.ops.aten._assert_scalar.default(ge_395, "Runtime assertion failed for expression u319 >= 0 on node 'ge_319'");  ge_395 = _assert_scalar_319 = None
        all_to_all_single_58 = torch.ops._c10d_functional.all_to_all_single.default(index_38, [_local_scalar_dense_312, _local_scalar_dense_313, _local_scalar_dense_314, _local_scalar_dense_315, _local_scalar_dense_316, _local_scalar_dense_317, _local_scalar_dense_318, _local_scalar_dense_319], [_local_scalar_dense_304, _local_scalar_dense_305, _local_scalar_dense_306, _local_scalar_dense_307, _local_scalar_dense_308, _local_scalar_dense_309, _local_scalar_dense_310, _local_scalar_dense_311], '1033');  index_38 = None
        sym_size_int_76 = torch.ops.aten.sym_size.int(all_to_all_single_58, 0)
        wait_tensor_420 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_58);  all_to_all_single_58 = None
        sym_sum_38 = torch.sym_sum((_local_scalar_dense_312, _local_scalar_dense_313, _local_scalar_dense_314, _local_scalar_dense_315, _local_scalar_dense_316, _local_scalar_dense_317, _local_scalar_dense_318, _local_scalar_dense_319))
        add_1310 = sym_sum_38 + 64;  sym_sum_38 = None
        add_1311 = add_1310 + 8;  add_1310 = None
        sub_459 = add_1311 - 1;  add_1311 = None
        floordiv_19 = sub_459 // 8;  sub_459 = None
        mul_953 = floordiv_19 * 8;  floordiv_19 = None
        cumsum_57 = torch.ops.aten.cumsum.default(wait_tensor_419, 0)
        sub_460 = torch.ops.aten.sub.Tensor(cumsum_57, wait_tensor_419);  cumsum_57 = None
        sum_80 = torch.ops.aten.sum.dim_IntList(view_1338, [0]);  view_1338 = None
        clamp_min_19 = torch.ops.aten.clamp_min.default(sum_80, 8);  sum_80 = None
        add_1312 = torch.ops.aten.add.Tensor(clamp_min_19, 8);  clamp_min_19 = None
        sub_461 = torch.ops.aten.sub.Tensor(add_1312, 1);  add_1312 = None
        div_98 = torch.ops.aten.div.Tensor_mode(sub_461, 8, rounding_mode = 'floor');  sub_461 = None
        mul_954 = torch.ops.aten.mul.Tensor(div_98, 8);  div_98 = None
        convert_element_type_1094 = torch.ops.prims.convert_element_type.default(mul_954, torch.int32);  mul_954 = None
        cumsum_58 = torch.ops.aten.cumsum.default(convert_element_type_1094, 0)
        sub_462 = torch.ops.aten.sub.Tensor(cumsum_58, convert_element_type_1094);  cumsum_58 = None
        full_267 = torch.ops.aten.full.default([mul_953], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_953 = None
        triton_kernel_wrapper_functional_proxy_19 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 19, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_419, 'start_index_values_ptr': sub_460, 'write_offsets_ptr': sub_462, 'output_ptr': full_267}, tensors_to_clone = ['output_ptr']);  wait_tensor_419 = sub_460 = sub_462 = full_267 = None
        getitem_2112 = triton_kernel_wrapper_functional_proxy_19['output_ptr'];  triton_kernel_wrapper_functional_proxy_19 = None
        cat_175 = torch.ops.aten.cat.default([wait_tensor_420, full_default]);  wait_tensor_420 = None
        sym_size_int_77 = torch.ops.aten.sym_size.int(cat_175, 0)
        sym_sum_39 = torch.sym_sum((1, _local_scalar_dense_312, _local_scalar_dense_313, _local_scalar_dense_314, _local_scalar_dense_315, _local_scalar_dense_316, _local_scalar_dense_317, _local_scalar_dense_318, _local_scalar_dense_319))
        index_39 = torch.ops.aten.index.Tensor(cat_175, [getitem_2112]);  cat_175 = None
        convert_element_type_1096 = torch.ops.prims.convert_element_type.default(primals_337, torch.bfloat16)
        all_gather_into_tensor_342 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1096, 16, '1025');  convert_element_type_1096 = None
        wait_tensor_421 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_342);  all_gather_into_tensor_342 = None
        split_115 = torch.ops.aten.split.Tensor(wait_tensor_421, 8);  wait_tensor_421 = None
        getitem_2129 = split_115[0]
        getitem_2130 = split_115[1]
        getitem_2131 = split_115[2]
        getitem_2132 = split_115[3]
        getitem_2133 = split_115[4]
        getitem_2134 = split_115[5]
        getitem_2135 = split_115[6]
        getitem_2136 = split_115[7]
        getitem_2137 = split_115[8]
        getitem_2138 = split_115[9]
        getitem_2139 = split_115[10]
        getitem_2140 = split_115[11]
        getitem_2141 = split_115[12]
        getitem_2142 = split_115[13]
        getitem_2143 = split_115[14]
        getitem_2144 = split_115[15];  split_115 = None
        cat_177 = torch.ops.aten.cat.default([getitem_2129, getitem_2130, getitem_2131, getitem_2132, getitem_2133, getitem_2134, getitem_2135, getitem_2136, getitem_2137, getitem_2138, getitem_2139, getitem_2140, getitem_2141, getitem_2142, getitem_2143, getitem_2144], 1);  getitem_2129 = getitem_2130 = getitem_2131 = getitem_2132 = getitem_2133 = getitem_2134 = getitem_2135 = getitem_2136 = getitem_2137 = getitem_2138 = getitem_2139 = getitem_2140 = getitem_2141 = getitem_2142 = getitem_2143 = getitem_2144 = None
        convert_element_type_1098 = torch.ops.prims.convert_element_type.default(primals_338, torch.bfloat16)
        all_gather_into_tensor_344 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1098, 16, '1025');  convert_element_type_1098 = None
        wait_tensor_423 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_344);  all_gather_into_tensor_344 = None
        split_116 = torch.ops.aten.split.Tensor(wait_tensor_423, 8);  wait_tensor_423 = None
        getitem_2145 = split_116[0]
        getitem_2146 = split_116[1]
        getitem_2147 = split_116[2]
        getitem_2148 = split_116[3]
        getitem_2149 = split_116[4]
        getitem_2150 = split_116[5]
        getitem_2151 = split_116[6]
        getitem_2152 = split_116[7]
        getitem_2153 = split_116[8]
        getitem_2154 = split_116[9]
        getitem_2155 = split_116[10]
        getitem_2156 = split_116[11]
        getitem_2157 = split_116[12]
        getitem_2158 = split_116[13]
        getitem_2159 = split_116[14]
        getitem_2160 = split_116[15];  split_116 = None
        cat_178 = torch.ops.aten.cat.default([getitem_2145, getitem_2146, getitem_2147, getitem_2148, getitem_2149, getitem_2150, getitem_2151, getitem_2152, getitem_2153, getitem_2154, getitem_2155, getitem_2156, getitem_2157, getitem_2158, getitem_2159, getitem_2160], 1);  getitem_2145 = getitem_2146 = getitem_2147 = getitem_2148 = getitem_2149 = getitem_2150 = getitem_2151 = getitem_2152 = getitem_2153 = getitem_2154 = getitem_2155 = getitem_2156 = getitem_2157 = getitem_2158 = getitem_2159 = getitem_2160 = None
        convert_element_type_1099 = torch.ops.prims.convert_element_type.default(primals_339, torch.bfloat16)
        all_gather_into_tensor_345 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1099, 16, '1025');  convert_element_type_1099 = None
        wait_tensor_424 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_345);  all_gather_into_tensor_345 = None
        split_117 = torch.ops.aten.split.Tensor(wait_tensor_424, 8);  wait_tensor_424 = None
        getitem_2161 = split_117[0]
        getitem_2162 = split_117[1]
        getitem_2163 = split_117[2]
        getitem_2164 = split_117[3]
        getitem_2165 = split_117[4]
        getitem_2166 = split_117[5]
        getitem_2167 = split_117[6]
        getitem_2168 = split_117[7]
        getitem_2169 = split_117[8]
        getitem_2170 = split_117[9]
        getitem_2171 = split_117[10]
        getitem_2172 = split_117[11]
        getitem_2173 = split_117[12]
        getitem_2174 = split_117[13]
        getitem_2175 = split_117[14]
        getitem_2176 = split_117[15];  split_117 = None
        cat_179 = torch.ops.aten.cat.default([getitem_2161, getitem_2162, getitem_2163, getitem_2164, getitem_2165, getitem_2166, getitem_2167, getitem_2168, getitem_2169, getitem_2170, getitem_2171, getitem_2172, getitem_2173, getitem_2174, getitem_2175, getitem_2176], 1);  getitem_2161 = getitem_2162 = getitem_2163 = getitem_2164 = getitem_2165 = getitem_2166 = getitem_2167 = getitem_2168 = getitem_2169 = getitem_2170 = getitem_2171 = getitem_2172 = getitem_2173 = getitem_2174 = getitem_2175 = getitem_2176 = None
        cumsum_59 = torch.ops.aten.cumsum.default(convert_element_type_1094, 0, dtype = torch.int32);  convert_element_type_1094 = None
        permute_305 = torch.ops.aten.permute.default(cat_177, [0, 2, 1]);  cat_177 = None
        _grouped_mm_57 = torch.ops.aten._grouped_mm.default(index_39, permute_305, cumsum_59)
        convert_element_type_1102 = torch.ops.prims.convert_element_type.default(_grouped_mm_57, torch.float32)
        neg_39 = torch.ops.aten.neg.default(convert_element_type_1102)
        exp_59 = torch.ops.aten.exp.default(neg_39);  neg_39 = None
        add_1324 = torch.ops.aten.add.Tensor(exp_59, 1);  exp_59 = None
        div_99 = torch.ops.aten.div.Tensor(convert_element_type_1102, add_1324);  convert_element_type_1102 = add_1324 = None
        convert_element_type_1103 = torch.ops.prims.convert_element_type.default(div_99, torch.bfloat16);  div_99 = None
        permute_306 = torch.ops.aten.permute.default(cat_179, [0, 2, 1]);  cat_179 = None
        _grouped_mm_58 = torch.ops.aten._grouped_mm.default(index_39, permute_306, cumsum_59)
        mul_966 = torch.ops.aten.mul.Tensor(convert_element_type_1103, _grouped_mm_58);  convert_element_type_1103 = None
        permute_307 = torch.ops.aten.permute.default(cat_178, [0, 2, 1]);  cat_178 = None
        _grouped_mm_59 = torch.ops.aten._grouped_mm.default(mul_966, permute_307, cumsum_59)
        empty_19 = torch.ops.aten.empty.memory_format([sym_size_int_77, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_38 = torch.ops.aten.index_put.default(empty_19, [getitem_2112], _grouped_mm_59);  empty_19 = _grouped_mm_59 = None
        slice_125 = torch.ops.aten.slice.Tensor(index_put_38, 0, 0, -1);  index_put_38 = None
        all_to_all_single_59 = torch.ops._c10d_functional.all_to_all_single.default(slice_125, [_local_scalar_dense_304, _local_scalar_dense_305, _local_scalar_dense_306, _local_scalar_dense_307, _local_scalar_dense_308, _local_scalar_dense_309, _local_scalar_dense_310, _local_scalar_dense_311], [_local_scalar_dense_312, _local_scalar_dense_313, _local_scalar_dense_314, _local_scalar_dense_315, _local_scalar_dense_316, _local_scalar_dense_317, _local_scalar_dense_318, _local_scalar_dense_319], '1033');  slice_125 = None
        wait_tensor_427 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_59);  all_to_all_single_59 = None
        convert_element_type_1104 = torch.ops.prims.convert_element_type.default(primals_340, torch.bfloat16)
        all_gather_into_tensor_348 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1104, 128, '0');  convert_element_type_1104 = None
        wait_tensor_428 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_348);  all_gather_into_tensor_348 = None
        permute_308 = torch.ops.aten.permute.default(wait_tensor_428, [1, 0]);  wait_tensor_428 = None
        mm_164 = torch.ops.aten.mm.default(view_1331, permute_308);  permute_308 = None
        convert_element_type_1107 = torch.ops.prims.convert_element_type.default(mm_164, torch.float32)
        neg_40 = torch.ops.aten.neg.default(convert_element_type_1107)
        exp_60 = torch.ops.aten.exp.default(neg_40);  neg_40 = None
        add_1360 = torch.ops.aten.add.Tensor(exp_60, 1);  exp_60 = None
        div_100 = torch.ops.aten.div.Tensor(convert_element_type_1107, add_1360);  convert_element_type_1107 = add_1360 = None
        convert_element_type_1108 = torch.ops.prims.convert_element_type.default(div_100, torch.bfloat16);  div_100 = None
        convert_element_type_1109 = torch.ops.prims.convert_element_type.default(primals_341, torch.bfloat16)
        all_gather_into_tensor_349 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1109, 128, '0');  convert_element_type_1109 = None
        wait_tensor_429 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_349);  all_gather_into_tensor_349 = None
        permute_309 = torch.ops.aten.permute.default(wait_tensor_429, [1, 0]);  wait_tensor_429 = None
        mm_165 = torch.ops.aten.mm.default(view_1331, permute_309);  permute_309 = None
        mul_986 = torch.ops.aten.mul.Tensor(convert_element_type_1108, mm_165);  convert_element_type_1108 = None
        convert_element_type_1112 = torch.ops.prims.convert_element_type.default(primals_342, torch.bfloat16)
        all_gather_into_tensor_350 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1112, 128, '0');  convert_element_type_1112 = None
        wait_tensor_430 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_350);  all_gather_into_tensor_350 = None
        permute_310 = torch.ops.aten.permute.default(wait_tensor_430, [1, 0]);  wait_tensor_430 = None
        mm_166 = torch.ops.aten.mm.default(mul_986, permute_310);  permute_310 = None
        index_put_39 = torch.ops.aten.index_put.default(full_default_1, [getitem_2111], wait_tensor_427);  wait_tensor_427 = None
        view_1371 = torch.ops.aten.view.default(mul_948, [-1, 1, 6]);  mul_948 = None
        view_1372 = torch.ops.aten.view.default(index_put_39, [-1, 6, 2048]);  index_put_39 = None
        convert_element_type_1115 = torch.ops.prims.convert_element_type.default(view_1372, torch.float32);  view_1372 = None
        bmm_19 = torch.ops.aten.bmm.default(view_1371, convert_element_type_1115)
        convert_element_type_1116 = torch.ops.prims.convert_element_type.default(bmm_19, torch.bfloat16);  bmm_19 = None
        squeeze_19 = torch.ops.aten.squeeze.dim(convert_element_type_1116, 1);  convert_element_type_1116 = None
        add_1364 = torch.ops.aten.add.Tensor(mm_166, squeeze_19);  mm_166 = squeeze_19 = None
        view_1373 = torch.ops.aten.view.default(add_1364, [2, 4096, 2048]);  add_1364 = None
        add_1365 = torch.ops.aten.add.Tensor(add_1300, view_1373);  view_1373 = None
        convert_element_type_1117 = torch.ops.prims.convert_element_type.default(primals_343, torch.bfloat16)
        all_gather_into_tensor_351 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1117, 128, '0');  convert_element_type_1117 = None
        wait_tensor_431 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_351);  all_gather_into_tensor_351 = None
        convert_element_type_1118 = torch.ops.prims.convert_element_type.default(add_1365, torch.float32)
        pow_64 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1118, 2)
        mean_63 = torch.ops.aten.mean.dim(pow_64, [2], True);  pow_64 = None
        add_1366 = torch.ops.aten.add.Scalar(mean_63, 1e-05);  mean_63 = None
        rsqrt_63 = torch.ops.aten.rsqrt.default(add_1366);  add_1366 = None
        mul_989 = torch.ops.aten.mul.Tensor(convert_element_type_1118, rsqrt_63);  convert_element_type_1118 = None
        mul_990 = torch.ops.aten.mul.Tensor(mul_989, wait_tensor_431);  mul_989 = wait_tensor_431 = None
        convert_element_type_1119 = torch.ops.prims.convert_element_type.default(mul_990, torch.bfloat16);  mul_990 = None
        convert_element_type_1120 = torch.ops.prims.convert_element_type.default(primals_344, torch.bfloat16)
        all_gather_into_tensor_352 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1120, 128, '0');  convert_element_type_1120 = None
        wait_tensor_432 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_352);  all_gather_into_tensor_352 = None
        permute_311 = torch.ops.aten.permute.default(wait_tensor_432, [1, 0]);  wait_tensor_432 = None
        view_1376 = torch.ops.aten.view.default(convert_element_type_1119, [8192, 2048]);  convert_element_type_1119 = None
        mm_167 = torch.ops.aten.mm.default(view_1376, permute_311);  permute_311 = None
        view_1377 = torch.ops.aten.view.default(mm_167, [2, 4096, 3072]);  mm_167 = None
        view_1378 = torch.ops.aten.view.default(view_1377, [2, 4096, -1, 192]);  view_1377 = None
        split_with_sizes_63 = torch.ops.aten.split_with_sizes.default(view_1378, [128, 64], -1);  view_1378 = None
        getitem_2209 = split_with_sizes_63[0]
        getitem_2210 = split_with_sizes_63[1];  split_with_sizes_63 = None
        convert_element_type_1123 = torch.ops.prims.convert_element_type.default(getitem_2210, torch.float32);  getitem_2210 = None
        view_1379 = torch.ops.aten.view.default(convert_element_type_1123, [2, 4096, 16, -1, 2]);  convert_element_type_1123 = None
        view_as_complex_42 = torch.ops.aten.view_as_complex.default(view_1379);  view_1379 = None
        mul_991 = torch.ops.aten.mul.Tensor(view_as_complex_42, view_7);  view_as_complex_42 = None
        view_as_real_42 = torch.ops.aten.view_as_real.default(mul_991);  mul_991 = None
        view_1381 = torch.ops.aten.view.default(view_as_real_42, [2, 4096, 16, 64]);  view_as_real_42 = None
        convert_element_type_1124 = torch.ops.prims.convert_element_type.default(view_1381, torch.bfloat16);  view_1381 = None
        cat_182 = torch.ops.aten.cat.default([getitem_2209, convert_element_type_1124], -1);  getitem_2209 = convert_element_type_1124 = None
        convert_element_type_1125 = torch.ops.prims.convert_element_type.default(primals_345, torch.bfloat16)
        all_gather_into_tensor_353 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1125, 128, '0');  convert_element_type_1125 = None
        wait_tensor_433 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_353);  all_gather_into_tensor_353 = None
        slice_127 = torch.ops.aten.slice.Tensor(wait_tensor_433, 0, 0, 576);  wait_tensor_433 = None
        permute_312 = torch.ops.aten.permute.default(slice_127, [1, 0]);  slice_127 = None
        mm_168 = torch.ops.aten.mm.default(view_1376, permute_312);  permute_312 = None
        view_1384 = torch.ops.aten.view.default(mm_168, [2, 4096, 576]);  mm_168 = None
        split_with_sizes_64 = torch.ops.aten.split_with_sizes.default(view_1384, [512, 64], -1);  view_1384 = None
        getitem_2211 = split_with_sizes_64[0]
        getitem_2212 = split_with_sizes_64[1];  split_with_sizes_64 = None
        unsqueeze_41 = torch.ops.aten.unsqueeze.default(getitem_2212, 2);  getitem_2212 = None
        convert_element_type_1128 = torch.ops.prims.convert_element_type.default(unsqueeze_41, torch.float32);  unsqueeze_41 = None
        view_1385 = torch.ops.aten.view.default(convert_element_type_1128, [2, 4096, 1, -1, 2]);  convert_element_type_1128 = None
        view_as_complex_43 = torch.ops.aten.view_as_complex.default(view_1385);  view_1385 = None
        mul_992 = torch.ops.aten.mul.Tensor(view_as_complex_43, view_7);  view_as_complex_43 = None
        view_as_real_43 = torch.ops.aten.view_as_real.default(mul_992);  mul_992 = None
        view_1387 = torch.ops.aten.view.default(view_as_real_43, [2, 4096, 1, 64]);  view_as_real_43 = None
        convert_element_type_1129 = torch.ops.prims.convert_element_type.default(view_1387, torch.bfloat16);  view_1387 = None
        convert_element_type_1130 = torch.ops.prims.convert_element_type.default(primals_346, torch.bfloat16)
        all_gather_into_tensor_354 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1130, 128, '0');  convert_element_type_1130 = None
        wait_tensor_434 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_354);  all_gather_into_tensor_354 = None
        convert_element_type_1131 = torch.ops.prims.convert_element_type.default(getitem_2211, torch.float32)
        pow_65 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1131, 2)
        mean_64 = torch.ops.aten.mean.dim(pow_65, [2], True);  pow_65 = None
        add_1367 = torch.ops.aten.add.Scalar(mean_64, 1e-05);  mean_64 = None
        rsqrt_64 = torch.ops.aten.rsqrt.default(add_1367);  add_1367 = None
        mul_993 = torch.ops.aten.mul.Tensor(convert_element_type_1131, rsqrt_64);  convert_element_type_1131 = None
        mul_994 = torch.ops.aten.mul.Tensor(mul_993, wait_tensor_434);  mul_993 = wait_tensor_434 = None
        convert_element_type_1132 = torch.ops.prims.convert_element_type.default(mul_994, torch.bfloat16);  mul_994 = None
        convert_element_type_1133 = torch.ops.prims.convert_element_type.default(primals_347, torch.bfloat16)
        all_gather_into_tensor_355 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1133, 128, '0');  convert_element_type_1133 = None
        wait_tensor_435 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_355);  all_gather_into_tensor_355 = None
        permute_313 = torch.ops.aten.permute.default(wait_tensor_435, [1, 0]);  wait_tensor_435 = None
        view_1390 = torch.ops.aten.view.default(convert_element_type_1132, [8192, 512]);  convert_element_type_1132 = None
        mm_169 = torch.ops.aten.mm.default(view_1390, permute_313);  permute_313 = None
        view_1391 = torch.ops.aten.view.default(mm_169, [2, 4096, 4096]);  mm_169 = None
        view_1392 = torch.ops.aten.view.default(view_1391, [2, 4096, -1, 256]);  view_1391 = None
        split_with_sizes_65 = torch.ops.aten.split_with_sizes.default(view_1392, [128, 128], -1);  view_1392 = None
        getitem_2213 = split_with_sizes_65[0]
        getitem_2214 = split_with_sizes_65[1];  split_with_sizes_65 = None
        expand_21 = torch.ops.aten.expand.default(convert_element_type_1129, [-1, -1, 16, -1]);  convert_element_type_1129 = None
        cat_183 = torch.ops.aten.cat.default([getitem_2213, expand_21], -1);  getitem_2213 = expand_21 = None
        permute_314 = torch.ops.aten.permute.default(cat_182, [0, 2, 1, 3]);  cat_182 = None
        permute_315 = torch.ops.aten.permute.default(cat_183, [0, 2, 1, 3]);  cat_183 = None
        permute_316 = torch.ops.aten.permute.default(getitem_2214, [0, 2, 1, 3]);  getitem_2214 = None
        sdpa_score21 = self.sdpa_score21
        sdpa_mask21 = self.sdpa_mask21
        flex_attention_21 = torch.ops.higher_order.flex_attention(permute_314, permute_315, permute_316, sdpa_score21, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask21), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score21 = sdpa_mask21 = None
        getitem_2215 = flex_attention_21[0]
        getitem_2216 = flex_attention_21[1];  flex_attention_21 = None
        permute_317 = torch.ops.aten.permute.default(getitem_2215, [0, 2, 1, 3])
        view_1393 = torch.ops.aten.view.default(permute_317, [2, 4096, -1]);  permute_317 = None
        convert_element_type_1136 = torch.ops.prims.convert_element_type.default(primals_348, torch.bfloat16)
        all_gather_into_tensor_356 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1136, 128, '0');  convert_element_type_1136 = None
        wait_tensor_436 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_356);  all_gather_into_tensor_356 = None
        permute_318 = torch.ops.aten.permute.default(wait_tensor_436, [1, 0]);  wait_tensor_436 = None
        view_1395 = torch.ops.aten.view.default(view_1393, [8192, 2048]);  view_1393 = None
        mm_170 = torch.ops.aten.mm.default(view_1395, permute_318);  view_1395 = permute_318 = None
        view_1396 = torch.ops.aten.view.default(mm_170, [2, 4096, 2048]);  mm_170 = None
        add_1368 = torch.ops.aten.add.Tensor(add_1365, view_1396);  view_1396 = None
        convert_element_type_1139 = torch.ops.prims.convert_element_type.default(primals_349, torch.bfloat16)
        all_gather_into_tensor_357 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1139, 128, '0');  convert_element_type_1139 = None
        wait_tensor_437 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_357);  all_gather_into_tensor_357 = None
        convert_element_type_1140 = torch.ops.prims.convert_element_type.default(add_1368, torch.float32)
        pow_66 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1140, 2)
        mean_65 = torch.ops.aten.mean.dim(pow_66, [2], True);  pow_66 = None
        add_1369 = torch.ops.aten.add.Scalar(mean_65, 1e-05);  mean_65 = None
        rsqrt_65 = torch.ops.aten.rsqrt.default(add_1369);  add_1369 = None
        mul_995 = torch.ops.aten.mul.Tensor(convert_element_type_1140, rsqrt_65);  convert_element_type_1140 = None
        mul_996 = torch.ops.aten.mul.Tensor(mul_995, wait_tensor_437);  mul_995 = wait_tensor_437 = None
        convert_element_type_1141 = torch.ops.prims.convert_element_type.default(mul_996, torch.bfloat16);  mul_996 = None
        view_1398 = torch.ops.aten.view.default(convert_element_type_1141, [-1, 2048]);  convert_element_type_1141 = None
        convert_element_type_1142 = torch.ops.prims.convert_element_type.default(primals_351, torch.bfloat16)
        all_gather_into_tensor_358 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1142, 128, '0');  convert_element_type_1142 = None
        wait_tensor_438 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_358);  all_gather_into_tensor_358 = None
        slice_129 = torch.ops.aten.slice.Tensor(wait_tensor_438, 0, 0, 64);  wait_tensor_438 = None
        permute_319 = torch.ops.aten.permute.default(slice_129, [1, 0]);  slice_129 = None
        mm_171 = torch.ops.aten.mm.default(view_1398, permute_319);  permute_319 = None
        convert_element_type_1145 = torch.ops.prims.convert_element_type.default(mm_171, torch.float32)
        amax_20 = torch.ops.aten.amax.default(convert_element_type_1145, [1], True)
        sub_480 = torch.ops.aten.sub.Tensor(convert_element_type_1145, amax_20);  convert_element_type_1145 = None
        exp_61 = torch.ops.aten.exp.default(sub_480);  sub_480 = None
        sum_81 = torch.ops.aten.sum.dim_IntList(exp_61, [1], True)
        div_101 = torch.ops.aten.div.Tensor(exp_61, sum_81);  exp_61 = None
        add_1370 = torch.ops.aten.add.Tensor(div_101, primals_350);  primals_350 = None
        topk_20 = torch.ops.aten.topk.default(add_1370, 6, -1, True, False);  add_1370 = None
        getitem_2219 = topk_20[1];  topk_20 = None
        gather_20 = torch.ops.aten.gather.default(div_101, 1, getitem_2219);  div_101 = None
        mul_997 = torch.ops.aten.mul.Tensor(gather_20, 1.0);  gather_20 = None
        view_1400 = torch.ops.aten.view.default(getitem_2219, [-1])
        histc_40 = torch.ops.aten.histc.default(view_1400, 64, 0, 64)
        add_1371 = torch.ops.aten.add.Tensor(primals_352, histc_40)
        sort_20 = torch.ops.aten.sort.stable(view_1400, stable = True);  view_1400 = None
        getitem_2221 = sort_20[1];  sort_20 = None
        div_102 = torch.ops.aten.div.Tensor_mode(getitem_2221, 6, rounding_mode = 'floor')
        index_40 = torch.ops.aten.index.Tensor(view_1398, [div_102])
        all_to_all_single_60 = torch.ops._c10d_functional.all_to_all_single.default(histc_40, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_439 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_60);  all_to_all_single_60 = None
        wait_tensor_440 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_439);  wait_tensor_439 = None
        view_1404 = torch.ops.aten.view.default(histc_40, [8, -1]);  histc_40 = None
        sum_82 = torch.ops.aten.sum.dim_IntList(view_1404, [1]);  view_1404 = None
        device_put_40 = torch.ops.prims.device_put.default(sum_82, device(type='cpu'), True);  sum_82 = None
        view_1405 = torch.ops.aten.view.default(wait_tensor_440, [8, -1])
        sum_83 = torch.ops.aten.sum.dim_IntList(view_1405, [1])
        device_put_41 = torch.ops.prims.device_put.default(sum_83, device(type='cpu'));  sum_83 = None
        select_320 = torch.ops.aten.select.int(device_put_40, 0, 0)
        _local_scalar_dense_320 = torch.ops.aten._local_scalar_dense.default(select_320);  select_320 = None
        ge_400 = _local_scalar_dense_320 >= 0
        _assert_scalar_320 = torch.ops.aten._assert_scalar.default(ge_400, "Runtime assertion failed for expression u320 >= 0 on node 'ge_320'");  ge_400 = _assert_scalar_320 = None
        select_321 = torch.ops.aten.select.int(device_put_40, 0, 1)
        _local_scalar_dense_321 = torch.ops.aten._local_scalar_dense.default(select_321);  select_321 = None
        ge_401 = _local_scalar_dense_321 >= 0
        _assert_scalar_321 = torch.ops.aten._assert_scalar.default(ge_401, "Runtime assertion failed for expression u321 >= 0 on node 'ge_321'");  ge_401 = _assert_scalar_321 = None
        select_322 = torch.ops.aten.select.int(device_put_40, 0, 2)
        _local_scalar_dense_322 = torch.ops.aten._local_scalar_dense.default(select_322);  select_322 = None
        ge_402 = _local_scalar_dense_322 >= 0
        _assert_scalar_322 = torch.ops.aten._assert_scalar.default(ge_402, "Runtime assertion failed for expression u322 >= 0 on node 'ge_322'");  ge_402 = _assert_scalar_322 = None
        select_323 = torch.ops.aten.select.int(device_put_40, 0, 3)
        _local_scalar_dense_323 = torch.ops.aten._local_scalar_dense.default(select_323);  select_323 = None
        ge_403 = _local_scalar_dense_323 >= 0
        _assert_scalar_323 = torch.ops.aten._assert_scalar.default(ge_403, "Runtime assertion failed for expression u323 >= 0 on node 'ge_323'");  ge_403 = _assert_scalar_323 = None
        select_324 = torch.ops.aten.select.int(device_put_40, 0, 4)
        _local_scalar_dense_324 = torch.ops.aten._local_scalar_dense.default(select_324);  select_324 = None
        ge_404 = _local_scalar_dense_324 >= 0
        _assert_scalar_324 = torch.ops.aten._assert_scalar.default(ge_404, "Runtime assertion failed for expression u324 >= 0 on node 'ge_324'");  ge_404 = _assert_scalar_324 = None
        select_325 = torch.ops.aten.select.int(device_put_40, 0, 5)
        _local_scalar_dense_325 = torch.ops.aten._local_scalar_dense.default(select_325);  select_325 = None
        ge_405 = _local_scalar_dense_325 >= 0
        _assert_scalar_325 = torch.ops.aten._assert_scalar.default(ge_405, "Runtime assertion failed for expression u325 >= 0 on node 'ge_325'");  ge_405 = _assert_scalar_325 = None
        select_326 = torch.ops.aten.select.int(device_put_40, 0, 6)
        _local_scalar_dense_326 = torch.ops.aten._local_scalar_dense.default(select_326);  select_326 = None
        ge_406 = _local_scalar_dense_326 >= 0
        _assert_scalar_326 = torch.ops.aten._assert_scalar.default(ge_406, "Runtime assertion failed for expression u326 >= 0 on node 'ge_326'");  ge_406 = _assert_scalar_326 = None
        select_327 = torch.ops.aten.select.int(device_put_40, 0, 7);  device_put_40 = None
        _local_scalar_dense_327 = torch.ops.aten._local_scalar_dense.default(select_327);  select_327 = None
        ge_407 = _local_scalar_dense_327 >= 0
        _assert_scalar_327 = torch.ops.aten._assert_scalar.default(ge_407, "Runtime assertion failed for expression u327 >= 0 on node 'ge_327'");  ge_407 = _assert_scalar_327 = None
        select_328 = torch.ops.aten.select.int(device_put_41, 0, 0)
        _local_scalar_dense_328 = torch.ops.aten._local_scalar_dense.default(select_328);  select_328 = None
        ge_408 = _local_scalar_dense_328 >= 0
        _assert_scalar_328 = torch.ops.aten._assert_scalar.default(ge_408, "Runtime assertion failed for expression u328 >= 0 on node 'ge_328'");  ge_408 = _assert_scalar_328 = None
        select_329 = torch.ops.aten.select.int(device_put_41, 0, 1)
        _local_scalar_dense_329 = torch.ops.aten._local_scalar_dense.default(select_329);  select_329 = None
        ge_409 = _local_scalar_dense_329 >= 0
        _assert_scalar_329 = torch.ops.aten._assert_scalar.default(ge_409, "Runtime assertion failed for expression u329 >= 0 on node 'ge_329'");  ge_409 = _assert_scalar_329 = None
        select_330 = torch.ops.aten.select.int(device_put_41, 0, 2)
        _local_scalar_dense_330 = torch.ops.aten._local_scalar_dense.default(select_330);  select_330 = None
        ge_410 = _local_scalar_dense_330 >= 0
        _assert_scalar_330 = torch.ops.aten._assert_scalar.default(ge_410, "Runtime assertion failed for expression u330 >= 0 on node 'ge_330'");  ge_410 = _assert_scalar_330 = None
        select_331 = torch.ops.aten.select.int(device_put_41, 0, 3)
        _local_scalar_dense_331 = torch.ops.aten._local_scalar_dense.default(select_331);  select_331 = None
        ge_411 = _local_scalar_dense_331 >= 0
        _assert_scalar_331 = torch.ops.aten._assert_scalar.default(ge_411, "Runtime assertion failed for expression u331 >= 0 on node 'ge_331'");  ge_411 = _assert_scalar_331 = None
        select_332 = torch.ops.aten.select.int(device_put_41, 0, 4)
        _local_scalar_dense_332 = torch.ops.aten._local_scalar_dense.default(select_332);  select_332 = None
        ge_412 = _local_scalar_dense_332 >= 0
        _assert_scalar_332 = torch.ops.aten._assert_scalar.default(ge_412, "Runtime assertion failed for expression u332 >= 0 on node 'ge_332'");  ge_412 = _assert_scalar_332 = None
        select_333 = torch.ops.aten.select.int(device_put_41, 0, 5)
        _local_scalar_dense_333 = torch.ops.aten._local_scalar_dense.default(select_333);  select_333 = None
        ge_413 = _local_scalar_dense_333 >= 0
        _assert_scalar_333 = torch.ops.aten._assert_scalar.default(ge_413, "Runtime assertion failed for expression u333 >= 0 on node 'ge_333'");  ge_413 = _assert_scalar_333 = None
        select_334 = torch.ops.aten.select.int(device_put_41, 0, 6)
        _local_scalar_dense_334 = torch.ops.aten._local_scalar_dense.default(select_334);  select_334 = None
        ge_414 = _local_scalar_dense_334 >= 0
        _assert_scalar_334 = torch.ops.aten._assert_scalar.default(ge_414, "Runtime assertion failed for expression u334 >= 0 on node 'ge_334'");  ge_414 = _assert_scalar_334 = None
        select_335 = torch.ops.aten.select.int(device_put_41, 0, 7);  device_put_41 = None
        _local_scalar_dense_335 = torch.ops.aten._local_scalar_dense.default(select_335);  select_335 = None
        ge_415 = _local_scalar_dense_335 >= 0
        _assert_scalar_335 = torch.ops.aten._assert_scalar.default(ge_415, "Runtime assertion failed for expression u335 >= 0 on node 'ge_335'");  ge_415 = _assert_scalar_335 = None
        all_to_all_single_61 = torch.ops._c10d_functional.all_to_all_single.default(index_40, [_local_scalar_dense_328, _local_scalar_dense_329, _local_scalar_dense_330, _local_scalar_dense_331, _local_scalar_dense_332, _local_scalar_dense_333, _local_scalar_dense_334, _local_scalar_dense_335], [_local_scalar_dense_320, _local_scalar_dense_321, _local_scalar_dense_322, _local_scalar_dense_323, _local_scalar_dense_324, _local_scalar_dense_325, _local_scalar_dense_326, _local_scalar_dense_327], '1033');  index_40 = None
        sym_size_int_80 = torch.ops.aten.sym_size.int(all_to_all_single_61, 0)
        wait_tensor_441 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_61);  all_to_all_single_61 = None
        sym_sum_40 = torch.sym_sum((_local_scalar_dense_328, _local_scalar_dense_329, _local_scalar_dense_330, _local_scalar_dense_331, _local_scalar_dense_332, _local_scalar_dense_333, _local_scalar_dense_334, _local_scalar_dense_335))
        add_1378 = sym_sum_40 + 64;  sym_sum_40 = None
        add_1379 = add_1378 + 8;  add_1378 = None
        sub_483 = add_1379 - 1;  add_1379 = None
        floordiv_20 = sub_483 // 8;  sub_483 = None
        mul_1002 = floordiv_20 * 8;  floordiv_20 = None
        cumsum_60 = torch.ops.aten.cumsum.default(wait_tensor_440, 0)
        sub_484 = torch.ops.aten.sub.Tensor(cumsum_60, wait_tensor_440);  cumsum_60 = None
        sum_84 = torch.ops.aten.sum.dim_IntList(view_1405, [0]);  view_1405 = None
        clamp_min_20 = torch.ops.aten.clamp_min.default(sum_84, 8);  sum_84 = None
        add_1380 = torch.ops.aten.add.Tensor(clamp_min_20, 8);  clamp_min_20 = None
        sub_485 = torch.ops.aten.sub.Tensor(add_1380, 1);  add_1380 = None
        div_103 = torch.ops.aten.div.Tensor_mode(sub_485, 8, rounding_mode = 'floor');  sub_485 = None
        mul_1003 = torch.ops.aten.mul.Tensor(div_103, 8);  div_103 = None
        convert_element_type_1148 = torch.ops.prims.convert_element_type.default(mul_1003, torch.int32);  mul_1003 = None
        cumsum_61 = torch.ops.aten.cumsum.default(convert_element_type_1148, 0)
        sub_486 = torch.ops.aten.sub.Tensor(cumsum_61, convert_element_type_1148);  cumsum_61 = None
        full_280 = torch.ops.aten.full.default([mul_1002], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_1002 = None
        triton_kernel_wrapper_functional_proxy_20 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 20, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_440, 'start_index_values_ptr': sub_484, 'write_offsets_ptr': sub_486, 'output_ptr': full_280}, tensors_to_clone = ['output_ptr']);  wait_tensor_440 = sub_484 = sub_486 = full_280 = None
        getitem_2222 = triton_kernel_wrapper_functional_proxy_20['output_ptr'];  triton_kernel_wrapper_functional_proxy_20 = None
        cat_184 = torch.ops.aten.cat.default([wait_tensor_441, full_default]);  wait_tensor_441 = None
        sym_size_int_81 = torch.ops.aten.sym_size.int(cat_184, 0)
        sym_sum_41 = torch.sym_sum((1, _local_scalar_dense_328, _local_scalar_dense_329, _local_scalar_dense_330, _local_scalar_dense_331, _local_scalar_dense_332, _local_scalar_dense_333, _local_scalar_dense_334, _local_scalar_dense_335))
        index_41 = torch.ops.aten.index.Tensor(cat_184, [getitem_2222]);  cat_184 = None
        convert_element_type_1150 = torch.ops.prims.convert_element_type.default(primals_353, torch.bfloat16)
        all_gather_into_tensor_359 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1150, 16, '1025');  convert_element_type_1150 = None
        wait_tensor_442 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_359);  all_gather_into_tensor_359 = None
        split_121 = torch.ops.aten.split.Tensor(wait_tensor_442, 8);  wait_tensor_442 = None
        getitem_2239 = split_121[0]
        getitem_2240 = split_121[1]
        getitem_2241 = split_121[2]
        getitem_2242 = split_121[3]
        getitem_2243 = split_121[4]
        getitem_2244 = split_121[5]
        getitem_2245 = split_121[6]
        getitem_2246 = split_121[7]
        getitem_2247 = split_121[8]
        getitem_2248 = split_121[9]
        getitem_2249 = split_121[10]
        getitem_2250 = split_121[11]
        getitem_2251 = split_121[12]
        getitem_2252 = split_121[13]
        getitem_2253 = split_121[14]
        getitem_2254 = split_121[15];  split_121 = None
        cat_186 = torch.ops.aten.cat.default([getitem_2239, getitem_2240, getitem_2241, getitem_2242, getitem_2243, getitem_2244, getitem_2245, getitem_2246, getitem_2247, getitem_2248, getitem_2249, getitem_2250, getitem_2251, getitem_2252, getitem_2253, getitem_2254], 1);  getitem_2239 = getitem_2240 = getitem_2241 = getitem_2242 = getitem_2243 = getitem_2244 = getitem_2245 = getitem_2246 = getitem_2247 = getitem_2248 = getitem_2249 = getitem_2250 = getitem_2251 = getitem_2252 = getitem_2253 = getitem_2254 = None
        convert_element_type_1152 = torch.ops.prims.convert_element_type.default(primals_354, torch.bfloat16)
        all_gather_into_tensor_361 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1152, 16, '1025');  convert_element_type_1152 = None
        wait_tensor_444 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_361);  all_gather_into_tensor_361 = None
        split_122 = torch.ops.aten.split.Tensor(wait_tensor_444, 8);  wait_tensor_444 = None
        getitem_2255 = split_122[0]
        getitem_2256 = split_122[1]
        getitem_2257 = split_122[2]
        getitem_2258 = split_122[3]
        getitem_2259 = split_122[4]
        getitem_2260 = split_122[5]
        getitem_2261 = split_122[6]
        getitem_2262 = split_122[7]
        getitem_2263 = split_122[8]
        getitem_2264 = split_122[9]
        getitem_2265 = split_122[10]
        getitem_2266 = split_122[11]
        getitem_2267 = split_122[12]
        getitem_2268 = split_122[13]
        getitem_2269 = split_122[14]
        getitem_2270 = split_122[15];  split_122 = None
        cat_187 = torch.ops.aten.cat.default([getitem_2255, getitem_2256, getitem_2257, getitem_2258, getitem_2259, getitem_2260, getitem_2261, getitem_2262, getitem_2263, getitem_2264, getitem_2265, getitem_2266, getitem_2267, getitem_2268, getitem_2269, getitem_2270], 1);  getitem_2255 = getitem_2256 = getitem_2257 = getitem_2258 = getitem_2259 = getitem_2260 = getitem_2261 = getitem_2262 = getitem_2263 = getitem_2264 = getitem_2265 = getitem_2266 = getitem_2267 = getitem_2268 = getitem_2269 = getitem_2270 = None
        convert_element_type_1153 = torch.ops.prims.convert_element_type.default(primals_355, torch.bfloat16)
        all_gather_into_tensor_362 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1153, 16, '1025');  convert_element_type_1153 = None
        wait_tensor_445 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_362);  all_gather_into_tensor_362 = None
        split_123 = torch.ops.aten.split.Tensor(wait_tensor_445, 8);  wait_tensor_445 = None
        getitem_2271 = split_123[0]
        getitem_2272 = split_123[1]
        getitem_2273 = split_123[2]
        getitem_2274 = split_123[3]
        getitem_2275 = split_123[4]
        getitem_2276 = split_123[5]
        getitem_2277 = split_123[6]
        getitem_2278 = split_123[7]
        getitem_2279 = split_123[8]
        getitem_2280 = split_123[9]
        getitem_2281 = split_123[10]
        getitem_2282 = split_123[11]
        getitem_2283 = split_123[12]
        getitem_2284 = split_123[13]
        getitem_2285 = split_123[14]
        getitem_2286 = split_123[15];  split_123 = None
        cat_188 = torch.ops.aten.cat.default([getitem_2271, getitem_2272, getitem_2273, getitem_2274, getitem_2275, getitem_2276, getitem_2277, getitem_2278, getitem_2279, getitem_2280, getitem_2281, getitem_2282, getitem_2283, getitem_2284, getitem_2285, getitem_2286], 1);  getitem_2271 = getitem_2272 = getitem_2273 = getitem_2274 = getitem_2275 = getitem_2276 = getitem_2277 = getitem_2278 = getitem_2279 = getitem_2280 = getitem_2281 = getitem_2282 = getitem_2283 = getitem_2284 = getitem_2285 = getitem_2286 = None
        cumsum_62 = torch.ops.aten.cumsum.default(convert_element_type_1148, 0, dtype = torch.int32);  convert_element_type_1148 = None
        permute_320 = torch.ops.aten.permute.default(cat_186, [0, 2, 1]);  cat_186 = None
        _grouped_mm_60 = torch.ops.aten._grouped_mm.default(index_41, permute_320, cumsum_62)
        convert_element_type_1156 = torch.ops.prims.convert_element_type.default(_grouped_mm_60, torch.float32)
        neg_41 = torch.ops.aten.neg.default(convert_element_type_1156)
        exp_62 = torch.ops.aten.exp.default(neg_41);  neg_41 = None
        add_1392 = torch.ops.aten.add.Tensor(exp_62, 1);  exp_62 = None
        div_104 = torch.ops.aten.div.Tensor(convert_element_type_1156, add_1392);  convert_element_type_1156 = add_1392 = None
        convert_element_type_1157 = torch.ops.prims.convert_element_type.default(div_104, torch.bfloat16);  div_104 = None
        permute_321 = torch.ops.aten.permute.default(cat_188, [0, 2, 1]);  cat_188 = None
        _grouped_mm_61 = torch.ops.aten._grouped_mm.default(index_41, permute_321, cumsum_62)
        mul_1015 = torch.ops.aten.mul.Tensor(convert_element_type_1157, _grouped_mm_61);  convert_element_type_1157 = None
        permute_322 = torch.ops.aten.permute.default(cat_187, [0, 2, 1]);  cat_187 = None
        _grouped_mm_62 = torch.ops.aten._grouped_mm.default(mul_1015, permute_322, cumsum_62)
        empty_20 = torch.ops.aten.empty.memory_format([sym_size_int_81, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_40 = torch.ops.aten.index_put.default(empty_20, [getitem_2222], _grouped_mm_62);  empty_20 = _grouped_mm_62 = None
        slice_131 = torch.ops.aten.slice.Tensor(index_put_40, 0, 0, -1);  index_put_40 = None
        all_to_all_single_62 = torch.ops._c10d_functional.all_to_all_single.default(slice_131, [_local_scalar_dense_320, _local_scalar_dense_321, _local_scalar_dense_322, _local_scalar_dense_323, _local_scalar_dense_324, _local_scalar_dense_325, _local_scalar_dense_326, _local_scalar_dense_327], [_local_scalar_dense_328, _local_scalar_dense_329, _local_scalar_dense_330, _local_scalar_dense_331, _local_scalar_dense_332, _local_scalar_dense_333, _local_scalar_dense_334, _local_scalar_dense_335], '1033');  slice_131 = None
        wait_tensor_448 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_62);  all_to_all_single_62 = None
        convert_element_type_1158 = torch.ops.prims.convert_element_type.default(primals_356, torch.bfloat16)
        all_gather_into_tensor_365 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1158, 128, '0');  convert_element_type_1158 = None
        wait_tensor_449 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_365);  all_gather_into_tensor_365 = None
        permute_323 = torch.ops.aten.permute.default(wait_tensor_449, [1, 0]);  wait_tensor_449 = None
        mm_172 = torch.ops.aten.mm.default(view_1398, permute_323);  permute_323 = None
        convert_element_type_1161 = torch.ops.prims.convert_element_type.default(mm_172, torch.float32)
        neg_42 = torch.ops.aten.neg.default(convert_element_type_1161)
        exp_63 = torch.ops.aten.exp.default(neg_42);  neg_42 = None
        add_1428 = torch.ops.aten.add.Tensor(exp_63, 1);  exp_63 = None
        div_105 = torch.ops.aten.div.Tensor(convert_element_type_1161, add_1428);  convert_element_type_1161 = add_1428 = None
        convert_element_type_1162 = torch.ops.prims.convert_element_type.default(div_105, torch.bfloat16);  div_105 = None
        convert_element_type_1163 = torch.ops.prims.convert_element_type.default(primals_357, torch.bfloat16)
        all_gather_into_tensor_366 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1163, 128, '0');  convert_element_type_1163 = None
        wait_tensor_450 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_366);  all_gather_into_tensor_366 = None
        permute_324 = torch.ops.aten.permute.default(wait_tensor_450, [1, 0]);  wait_tensor_450 = None
        mm_173 = torch.ops.aten.mm.default(view_1398, permute_324);  permute_324 = None
        mul_1035 = torch.ops.aten.mul.Tensor(convert_element_type_1162, mm_173);  convert_element_type_1162 = None
        convert_element_type_1166 = torch.ops.prims.convert_element_type.default(primals_358, torch.bfloat16)
        all_gather_into_tensor_367 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1166, 128, '0');  convert_element_type_1166 = None
        wait_tensor_451 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_367);  all_gather_into_tensor_367 = None
        permute_325 = torch.ops.aten.permute.default(wait_tensor_451, [1, 0]);  wait_tensor_451 = None
        mm_174 = torch.ops.aten.mm.default(mul_1035, permute_325);  permute_325 = None
        index_put_41 = torch.ops.aten.index_put.default(full_default_1, [getitem_2221], wait_tensor_448);  wait_tensor_448 = None
        view_1438 = torch.ops.aten.view.default(mul_997, [-1, 1, 6]);  mul_997 = None
        view_1439 = torch.ops.aten.view.default(index_put_41, [-1, 6, 2048]);  index_put_41 = None
        convert_element_type_1169 = torch.ops.prims.convert_element_type.default(view_1439, torch.float32);  view_1439 = None
        bmm_20 = torch.ops.aten.bmm.default(view_1438, convert_element_type_1169)
        convert_element_type_1170 = torch.ops.prims.convert_element_type.default(bmm_20, torch.bfloat16);  bmm_20 = None
        squeeze_20 = torch.ops.aten.squeeze.dim(convert_element_type_1170, 1);  convert_element_type_1170 = None
        add_1432 = torch.ops.aten.add.Tensor(mm_174, squeeze_20);  mm_174 = squeeze_20 = None
        view_1440 = torch.ops.aten.view.default(add_1432, [2, 4096, 2048]);  add_1432 = None
        add_1433 = torch.ops.aten.add.Tensor(add_1368, view_1440);  view_1440 = None
        convert_element_type_1171 = torch.ops.prims.convert_element_type.default(primals_359, torch.bfloat16)
        all_gather_into_tensor_368 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1171, 128, '0');  convert_element_type_1171 = None
        wait_tensor_452 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_368);  all_gather_into_tensor_368 = None
        convert_element_type_1172 = torch.ops.prims.convert_element_type.default(add_1433, torch.float32)
        pow_67 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1172, 2)
        mean_66 = torch.ops.aten.mean.dim(pow_67, [2], True);  pow_67 = None
        add_1434 = torch.ops.aten.add.Scalar(mean_66, 1e-05);  mean_66 = None
        rsqrt_66 = torch.ops.aten.rsqrt.default(add_1434);  add_1434 = None
        mul_1038 = torch.ops.aten.mul.Tensor(convert_element_type_1172, rsqrt_66);  convert_element_type_1172 = None
        mul_1039 = torch.ops.aten.mul.Tensor(mul_1038, wait_tensor_452);  mul_1038 = wait_tensor_452 = None
        convert_element_type_1173 = torch.ops.prims.convert_element_type.default(mul_1039, torch.bfloat16);  mul_1039 = None
        convert_element_type_1174 = torch.ops.prims.convert_element_type.default(primals_360, torch.bfloat16)
        all_gather_into_tensor_369 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1174, 128, '0');  convert_element_type_1174 = None
        wait_tensor_453 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_369);  all_gather_into_tensor_369 = None
        permute_326 = torch.ops.aten.permute.default(wait_tensor_453, [1, 0]);  wait_tensor_453 = None
        view_1443 = torch.ops.aten.view.default(convert_element_type_1173, [8192, 2048]);  convert_element_type_1173 = None
        mm_175 = torch.ops.aten.mm.default(view_1443, permute_326);  permute_326 = None
        view_1444 = torch.ops.aten.view.default(mm_175, [2, 4096, 3072]);  mm_175 = None
        view_1445 = torch.ops.aten.view.default(view_1444, [2, 4096, -1, 192]);  view_1444 = None
        split_with_sizes_66 = torch.ops.aten.split_with_sizes.default(view_1445, [128, 64], -1);  view_1445 = None
        getitem_2319 = split_with_sizes_66[0]
        getitem_2320 = split_with_sizes_66[1];  split_with_sizes_66 = None
        convert_element_type_1177 = torch.ops.prims.convert_element_type.default(getitem_2320, torch.float32);  getitem_2320 = None
        view_1446 = torch.ops.aten.view.default(convert_element_type_1177, [2, 4096, 16, -1, 2]);  convert_element_type_1177 = None
        view_as_complex_44 = torch.ops.aten.view_as_complex.default(view_1446);  view_1446 = None
        mul_1040 = torch.ops.aten.mul.Tensor(view_as_complex_44, view_7);  view_as_complex_44 = None
        view_as_real_44 = torch.ops.aten.view_as_real.default(mul_1040);  mul_1040 = None
        view_1448 = torch.ops.aten.view.default(view_as_real_44, [2, 4096, 16, 64]);  view_as_real_44 = None
        convert_element_type_1178 = torch.ops.prims.convert_element_type.default(view_1448, torch.bfloat16);  view_1448 = None
        cat_191 = torch.ops.aten.cat.default([getitem_2319, convert_element_type_1178], -1);  getitem_2319 = convert_element_type_1178 = None
        convert_element_type_1179 = torch.ops.prims.convert_element_type.default(primals_361, torch.bfloat16)
        all_gather_into_tensor_370 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1179, 128, '0');  convert_element_type_1179 = None
        wait_tensor_454 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_370);  all_gather_into_tensor_370 = None
        slice_133 = torch.ops.aten.slice.Tensor(wait_tensor_454, 0, 0, 576);  wait_tensor_454 = None
        permute_327 = torch.ops.aten.permute.default(slice_133, [1, 0]);  slice_133 = None
        mm_176 = torch.ops.aten.mm.default(view_1443, permute_327);  permute_327 = None
        view_1451 = torch.ops.aten.view.default(mm_176, [2, 4096, 576]);  mm_176 = None
        split_with_sizes_67 = torch.ops.aten.split_with_sizes.default(view_1451, [512, 64], -1);  view_1451 = None
        getitem_2321 = split_with_sizes_67[0]
        getitem_2322 = split_with_sizes_67[1];  split_with_sizes_67 = None
        unsqueeze_43 = torch.ops.aten.unsqueeze.default(getitem_2322, 2);  getitem_2322 = None
        convert_element_type_1182 = torch.ops.prims.convert_element_type.default(unsqueeze_43, torch.float32);  unsqueeze_43 = None
        view_1452 = torch.ops.aten.view.default(convert_element_type_1182, [2, 4096, 1, -1, 2]);  convert_element_type_1182 = None
        view_as_complex_45 = torch.ops.aten.view_as_complex.default(view_1452);  view_1452 = None
        mul_1041 = torch.ops.aten.mul.Tensor(view_as_complex_45, view_7);  view_as_complex_45 = None
        view_as_real_45 = torch.ops.aten.view_as_real.default(mul_1041);  mul_1041 = None
        view_1454 = torch.ops.aten.view.default(view_as_real_45, [2, 4096, 1, 64]);  view_as_real_45 = None
        convert_element_type_1183 = torch.ops.prims.convert_element_type.default(view_1454, torch.bfloat16);  view_1454 = None
        convert_element_type_1184 = torch.ops.prims.convert_element_type.default(primals_362, torch.bfloat16)
        all_gather_into_tensor_371 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1184, 128, '0');  convert_element_type_1184 = None
        wait_tensor_455 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_371);  all_gather_into_tensor_371 = None
        convert_element_type_1185 = torch.ops.prims.convert_element_type.default(getitem_2321, torch.float32)
        pow_68 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1185, 2)
        mean_67 = torch.ops.aten.mean.dim(pow_68, [2], True);  pow_68 = None
        add_1435 = torch.ops.aten.add.Scalar(mean_67, 1e-05);  mean_67 = None
        rsqrt_67 = torch.ops.aten.rsqrt.default(add_1435);  add_1435 = None
        mul_1042 = torch.ops.aten.mul.Tensor(convert_element_type_1185, rsqrt_67);  convert_element_type_1185 = None
        mul_1043 = torch.ops.aten.mul.Tensor(mul_1042, wait_tensor_455);  mul_1042 = wait_tensor_455 = None
        convert_element_type_1186 = torch.ops.prims.convert_element_type.default(mul_1043, torch.bfloat16);  mul_1043 = None
        convert_element_type_1187 = torch.ops.prims.convert_element_type.default(primals_363, torch.bfloat16)
        all_gather_into_tensor_372 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1187, 128, '0');  convert_element_type_1187 = None
        wait_tensor_456 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_372);  all_gather_into_tensor_372 = None
        permute_328 = torch.ops.aten.permute.default(wait_tensor_456, [1, 0]);  wait_tensor_456 = None
        view_1457 = torch.ops.aten.view.default(convert_element_type_1186, [8192, 512]);  convert_element_type_1186 = None
        mm_177 = torch.ops.aten.mm.default(view_1457, permute_328);  permute_328 = None
        view_1458 = torch.ops.aten.view.default(mm_177, [2, 4096, 4096]);  mm_177 = None
        view_1459 = torch.ops.aten.view.default(view_1458, [2, 4096, -1, 256]);  view_1458 = None
        split_with_sizes_68 = torch.ops.aten.split_with_sizes.default(view_1459, [128, 128], -1);  view_1459 = None
        getitem_2323 = split_with_sizes_68[0]
        getitem_2324 = split_with_sizes_68[1];  split_with_sizes_68 = None
        expand_22 = torch.ops.aten.expand.default(convert_element_type_1183, [-1, -1, 16, -1]);  convert_element_type_1183 = None
        cat_192 = torch.ops.aten.cat.default([getitem_2323, expand_22], -1);  getitem_2323 = expand_22 = None
        permute_329 = torch.ops.aten.permute.default(cat_191, [0, 2, 1, 3]);  cat_191 = None
        permute_330 = torch.ops.aten.permute.default(cat_192, [0, 2, 1, 3]);  cat_192 = None
        permute_331 = torch.ops.aten.permute.default(getitem_2324, [0, 2, 1, 3]);  getitem_2324 = None
        sdpa_score22 = self.sdpa_score22
        sdpa_mask22 = self.sdpa_mask22
        flex_attention_22 = torch.ops.higher_order.flex_attention(permute_329, permute_330, permute_331, sdpa_score22, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask22), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score22 = sdpa_mask22 = None
        getitem_2325 = flex_attention_22[0]
        getitem_2326 = flex_attention_22[1];  flex_attention_22 = None
        permute_332 = torch.ops.aten.permute.default(getitem_2325, [0, 2, 1, 3])
        view_1460 = torch.ops.aten.view.default(permute_332, [2, 4096, -1]);  permute_332 = None
        convert_element_type_1190 = torch.ops.prims.convert_element_type.default(primals_364, torch.bfloat16)
        all_gather_into_tensor_373 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1190, 128, '0');  convert_element_type_1190 = None
        wait_tensor_457 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_373);  all_gather_into_tensor_373 = None
        permute_333 = torch.ops.aten.permute.default(wait_tensor_457, [1, 0]);  wait_tensor_457 = None
        view_1462 = torch.ops.aten.view.default(view_1460, [8192, 2048]);  view_1460 = None
        mm_178 = torch.ops.aten.mm.default(view_1462, permute_333);  view_1462 = permute_333 = None
        view_1463 = torch.ops.aten.view.default(mm_178, [2, 4096, 2048]);  mm_178 = None
        add_1436 = torch.ops.aten.add.Tensor(add_1433, view_1463);  view_1463 = None
        convert_element_type_1193 = torch.ops.prims.convert_element_type.default(primals_365, torch.bfloat16)
        all_gather_into_tensor_374 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1193, 128, '0');  convert_element_type_1193 = None
        wait_tensor_458 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_374);  all_gather_into_tensor_374 = None
        convert_element_type_1194 = torch.ops.prims.convert_element_type.default(add_1436, torch.float32)
        pow_69 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1194, 2)
        mean_68 = torch.ops.aten.mean.dim(pow_69, [2], True);  pow_69 = None
        add_1437 = torch.ops.aten.add.Scalar(mean_68, 1e-05);  mean_68 = None
        rsqrt_68 = torch.ops.aten.rsqrt.default(add_1437);  add_1437 = None
        mul_1044 = torch.ops.aten.mul.Tensor(convert_element_type_1194, rsqrt_68);  convert_element_type_1194 = None
        mul_1045 = torch.ops.aten.mul.Tensor(mul_1044, wait_tensor_458);  mul_1044 = wait_tensor_458 = None
        convert_element_type_1195 = torch.ops.prims.convert_element_type.default(mul_1045, torch.bfloat16);  mul_1045 = None
        view_1465 = torch.ops.aten.view.default(convert_element_type_1195, [-1, 2048]);  convert_element_type_1195 = None
        convert_element_type_1196 = torch.ops.prims.convert_element_type.default(primals_367, torch.bfloat16)
        all_gather_into_tensor_375 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1196, 128, '0');  convert_element_type_1196 = None
        wait_tensor_459 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_375);  all_gather_into_tensor_375 = None
        slice_135 = torch.ops.aten.slice.Tensor(wait_tensor_459, 0, 0, 64);  wait_tensor_459 = None
        permute_334 = torch.ops.aten.permute.default(slice_135, [1, 0]);  slice_135 = None
        mm_179 = torch.ops.aten.mm.default(view_1465, permute_334);  permute_334 = None
        convert_element_type_1199 = torch.ops.prims.convert_element_type.default(mm_179, torch.float32)
        amax_21 = torch.ops.aten.amax.default(convert_element_type_1199, [1], True)
        sub_504 = torch.ops.aten.sub.Tensor(convert_element_type_1199, amax_21);  convert_element_type_1199 = None
        exp_64 = torch.ops.aten.exp.default(sub_504);  sub_504 = None
        sum_85 = torch.ops.aten.sum.dim_IntList(exp_64, [1], True)
        div_106 = torch.ops.aten.div.Tensor(exp_64, sum_85);  exp_64 = None
        add_1438 = torch.ops.aten.add.Tensor(div_106, primals_366);  primals_366 = None
        topk_21 = torch.ops.aten.topk.default(add_1438, 6, -1, True, False);  add_1438 = None
        getitem_2329 = topk_21[1];  topk_21 = None
        gather_21 = torch.ops.aten.gather.default(div_106, 1, getitem_2329);  div_106 = None
        mul_1046 = torch.ops.aten.mul.Tensor(gather_21, 1.0);  gather_21 = None
        view_1467 = torch.ops.aten.view.default(getitem_2329, [-1])
        histc_42 = torch.ops.aten.histc.default(view_1467, 64, 0, 64)
        add_1439 = torch.ops.aten.add.Tensor(primals_368, histc_42)
        sort_21 = torch.ops.aten.sort.stable(view_1467, stable = True);  view_1467 = None
        getitem_2331 = sort_21[1];  sort_21 = None
        div_107 = torch.ops.aten.div.Tensor_mode(getitem_2331, 6, rounding_mode = 'floor')
        index_42 = torch.ops.aten.index.Tensor(view_1465, [div_107])
        all_to_all_single_63 = torch.ops._c10d_functional.all_to_all_single.default(histc_42, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_460 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_63);  all_to_all_single_63 = None
        wait_tensor_461 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_460);  wait_tensor_460 = None
        view_1471 = torch.ops.aten.view.default(histc_42, [8, -1]);  histc_42 = None
        sum_86 = torch.ops.aten.sum.dim_IntList(view_1471, [1]);  view_1471 = None
        device_put_42 = torch.ops.prims.device_put.default(sum_86, device(type='cpu'), True);  sum_86 = None
        view_1472 = torch.ops.aten.view.default(wait_tensor_461, [8, -1])
        sum_87 = torch.ops.aten.sum.dim_IntList(view_1472, [1])
        device_put_43 = torch.ops.prims.device_put.default(sum_87, device(type='cpu'));  sum_87 = None
        select_336 = torch.ops.aten.select.int(device_put_42, 0, 0)
        _local_scalar_dense_336 = torch.ops.aten._local_scalar_dense.default(select_336);  select_336 = None
        ge_420 = _local_scalar_dense_336 >= 0
        _assert_scalar_336 = torch.ops.aten._assert_scalar.default(ge_420, "Runtime assertion failed for expression u336 >= 0 on node 'ge_336'");  ge_420 = _assert_scalar_336 = None
        select_337 = torch.ops.aten.select.int(device_put_42, 0, 1)
        _local_scalar_dense_337 = torch.ops.aten._local_scalar_dense.default(select_337);  select_337 = None
        ge_421 = _local_scalar_dense_337 >= 0
        _assert_scalar_337 = torch.ops.aten._assert_scalar.default(ge_421, "Runtime assertion failed for expression u337 >= 0 on node 'ge_337'");  ge_421 = _assert_scalar_337 = None
        select_338 = torch.ops.aten.select.int(device_put_42, 0, 2)
        _local_scalar_dense_338 = torch.ops.aten._local_scalar_dense.default(select_338);  select_338 = None
        ge_422 = _local_scalar_dense_338 >= 0
        _assert_scalar_338 = torch.ops.aten._assert_scalar.default(ge_422, "Runtime assertion failed for expression u338 >= 0 on node 'ge_338'");  ge_422 = _assert_scalar_338 = None
        select_339 = torch.ops.aten.select.int(device_put_42, 0, 3)
        _local_scalar_dense_339 = torch.ops.aten._local_scalar_dense.default(select_339);  select_339 = None
        ge_423 = _local_scalar_dense_339 >= 0
        _assert_scalar_339 = torch.ops.aten._assert_scalar.default(ge_423, "Runtime assertion failed for expression u339 >= 0 on node 'ge_339'");  ge_423 = _assert_scalar_339 = None
        select_340 = torch.ops.aten.select.int(device_put_42, 0, 4)
        _local_scalar_dense_340 = torch.ops.aten._local_scalar_dense.default(select_340);  select_340 = None
        ge_424 = _local_scalar_dense_340 >= 0
        _assert_scalar_340 = torch.ops.aten._assert_scalar.default(ge_424, "Runtime assertion failed for expression u340 >= 0 on node 'ge_340'");  ge_424 = _assert_scalar_340 = None
        select_341 = torch.ops.aten.select.int(device_put_42, 0, 5)
        _local_scalar_dense_341 = torch.ops.aten._local_scalar_dense.default(select_341);  select_341 = None
        ge_425 = _local_scalar_dense_341 >= 0
        _assert_scalar_341 = torch.ops.aten._assert_scalar.default(ge_425, "Runtime assertion failed for expression u341 >= 0 on node 'ge_341'");  ge_425 = _assert_scalar_341 = None
        select_342 = torch.ops.aten.select.int(device_put_42, 0, 6)
        _local_scalar_dense_342 = torch.ops.aten._local_scalar_dense.default(select_342);  select_342 = None
        ge_426 = _local_scalar_dense_342 >= 0
        _assert_scalar_342 = torch.ops.aten._assert_scalar.default(ge_426, "Runtime assertion failed for expression u342 >= 0 on node 'ge_342'");  ge_426 = _assert_scalar_342 = None
        select_343 = torch.ops.aten.select.int(device_put_42, 0, 7);  device_put_42 = None
        _local_scalar_dense_343 = torch.ops.aten._local_scalar_dense.default(select_343);  select_343 = None
        ge_427 = _local_scalar_dense_343 >= 0
        _assert_scalar_343 = torch.ops.aten._assert_scalar.default(ge_427, "Runtime assertion failed for expression u343 >= 0 on node 'ge_343'");  ge_427 = _assert_scalar_343 = None
        select_344 = torch.ops.aten.select.int(device_put_43, 0, 0)
        _local_scalar_dense_344 = torch.ops.aten._local_scalar_dense.default(select_344);  select_344 = None
        ge_428 = _local_scalar_dense_344 >= 0
        _assert_scalar_344 = torch.ops.aten._assert_scalar.default(ge_428, "Runtime assertion failed for expression u344 >= 0 on node 'ge_344'");  ge_428 = _assert_scalar_344 = None
        select_345 = torch.ops.aten.select.int(device_put_43, 0, 1)
        _local_scalar_dense_345 = torch.ops.aten._local_scalar_dense.default(select_345);  select_345 = None
        ge_429 = _local_scalar_dense_345 >= 0
        _assert_scalar_345 = torch.ops.aten._assert_scalar.default(ge_429, "Runtime assertion failed for expression u345 >= 0 on node 'ge_345'");  ge_429 = _assert_scalar_345 = None
        select_346 = torch.ops.aten.select.int(device_put_43, 0, 2)
        _local_scalar_dense_346 = torch.ops.aten._local_scalar_dense.default(select_346);  select_346 = None
        ge_430 = _local_scalar_dense_346 >= 0
        _assert_scalar_346 = torch.ops.aten._assert_scalar.default(ge_430, "Runtime assertion failed for expression u346 >= 0 on node 'ge_346'");  ge_430 = _assert_scalar_346 = None
        select_347 = torch.ops.aten.select.int(device_put_43, 0, 3)
        _local_scalar_dense_347 = torch.ops.aten._local_scalar_dense.default(select_347);  select_347 = None
        ge_431 = _local_scalar_dense_347 >= 0
        _assert_scalar_347 = torch.ops.aten._assert_scalar.default(ge_431, "Runtime assertion failed for expression u347 >= 0 on node 'ge_347'");  ge_431 = _assert_scalar_347 = None
        select_348 = torch.ops.aten.select.int(device_put_43, 0, 4)
        _local_scalar_dense_348 = torch.ops.aten._local_scalar_dense.default(select_348);  select_348 = None
        ge_432 = _local_scalar_dense_348 >= 0
        _assert_scalar_348 = torch.ops.aten._assert_scalar.default(ge_432, "Runtime assertion failed for expression u348 >= 0 on node 'ge_348'");  ge_432 = _assert_scalar_348 = None
        select_349 = torch.ops.aten.select.int(device_put_43, 0, 5)
        _local_scalar_dense_349 = torch.ops.aten._local_scalar_dense.default(select_349);  select_349 = None
        ge_433 = _local_scalar_dense_349 >= 0
        _assert_scalar_349 = torch.ops.aten._assert_scalar.default(ge_433, "Runtime assertion failed for expression u349 >= 0 on node 'ge_349'");  ge_433 = _assert_scalar_349 = None
        select_350 = torch.ops.aten.select.int(device_put_43, 0, 6)
        _local_scalar_dense_350 = torch.ops.aten._local_scalar_dense.default(select_350);  select_350 = None
        ge_434 = _local_scalar_dense_350 >= 0
        _assert_scalar_350 = torch.ops.aten._assert_scalar.default(ge_434, "Runtime assertion failed for expression u350 >= 0 on node 'ge_350'");  ge_434 = _assert_scalar_350 = None
        select_351 = torch.ops.aten.select.int(device_put_43, 0, 7);  device_put_43 = None
        _local_scalar_dense_351 = torch.ops.aten._local_scalar_dense.default(select_351);  select_351 = None
        ge_435 = _local_scalar_dense_351 >= 0
        _assert_scalar_351 = torch.ops.aten._assert_scalar.default(ge_435, "Runtime assertion failed for expression u351 >= 0 on node 'ge_351'");  ge_435 = _assert_scalar_351 = None
        all_to_all_single_64 = torch.ops._c10d_functional.all_to_all_single.default(index_42, [_local_scalar_dense_344, _local_scalar_dense_345, _local_scalar_dense_346, _local_scalar_dense_347, _local_scalar_dense_348, _local_scalar_dense_349, _local_scalar_dense_350, _local_scalar_dense_351], [_local_scalar_dense_336, _local_scalar_dense_337, _local_scalar_dense_338, _local_scalar_dense_339, _local_scalar_dense_340, _local_scalar_dense_341, _local_scalar_dense_342, _local_scalar_dense_343], '1033');  index_42 = None
        sym_size_int_84 = torch.ops.aten.sym_size.int(all_to_all_single_64, 0)
        wait_tensor_462 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_64);  all_to_all_single_64 = None
        sym_sum_42 = torch.sym_sum((_local_scalar_dense_344, _local_scalar_dense_345, _local_scalar_dense_346, _local_scalar_dense_347, _local_scalar_dense_348, _local_scalar_dense_349, _local_scalar_dense_350, _local_scalar_dense_351))
        add_1446 = sym_sum_42 + 64;  sym_sum_42 = None
        add_1447 = add_1446 + 8;  add_1446 = None
        sub_507 = add_1447 - 1;  add_1447 = None
        floordiv_21 = sub_507 // 8;  sub_507 = None
        mul_1051 = floordiv_21 * 8;  floordiv_21 = None
        cumsum_63 = torch.ops.aten.cumsum.default(wait_tensor_461, 0)
        sub_508 = torch.ops.aten.sub.Tensor(cumsum_63, wait_tensor_461);  cumsum_63 = None
        sum_88 = torch.ops.aten.sum.dim_IntList(view_1472, [0]);  view_1472 = None
        clamp_min_21 = torch.ops.aten.clamp_min.default(sum_88, 8);  sum_88 = None
        add_1448 = torch.ops.aten.add.Tensor(clamp_min_21, 8);  clamp_min_21 = None
        sub_509 = torch.ops.aten.sub.Tensor(add_1448, 1);  add_1448 = None
        div_108 = torch.ops.aten.div.Tensor_mode(sub_509, 8, rounding_mode = 'floor');  sub_509 = None
        mul_1052 = torch.ops.aten.mul.Tensor(div_108, 8);  div_108 = None
        convert_element_type_1202 = torch.ops.prims.convert_element_type.default(mul_1052, torch.int32);  mul_1052 = None
        cumsum_64 = torch.ops.aten.cumsum.default(convert_element_type_1202, 0)
        sub_510 = torch.ops.aten.sub.Tensor(cumsum_64, convert_element_type_1202);  cumsum_64 = None
        full_293 = torch.ops.aten.full.default([mul_1051], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_1051 = None
        triton_kernel_wrapper_functional_proxy_21 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 21, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_461, 'start_index_values_ptr': sub_508, 'write_offsets_ptr': sub_510, 'output_ptr': full_293}, tensors_to_clone = ['output_ptr']);  wait_tensor_461 = sub_508 = sub_510 = full_293 = None
        getitem_2332 = triton_kernel_wrapper_functional_proxy_21['output_ptr'];  triton_kernel_wrapper_functional_proxy_21 = None
        cat_193 = torch.ops.aten.cat.default([wait_tensor_462, full_default]);  wait_tensor_462 = None
        sym_size_int_85 = torch.ops.aten.sym_size.int(cat_193, 0)
        sym_sum_43 = torch.sym_sum((1, _local_scalar_dense_344, _local_scalar_dense_345, _local_scalar_dense_346, _local_scalar_dense_347, _local_scalar_dense_348, _local_scalar_dense_349, _local_scalar_dense_350, _local_scalar_dense_351))
        index_43 = torch.ops.aten.index.Tensor(cat_193, [getitem_2332]);  cat_193 = None
        convert_element_type_1204 = torch.ops.prims.convert_element_type.default(primals_369, torch.bfloat16)
        all_gather_into_tensor_376 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1204, 16, '1025');  convert_element_type_1204 = None
        wait_tensor_463 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_376);  all_gather_into_tensor_376 = None
        split_127 = torch.ops.aten.split.Tensor(wait_tensor_463, 8);  wait_tensor_463 = None
        getitem_2349 = split_127[0]
        getitem_2350 = split_127[1]
        getitem_2351 = split_127[2]
        getitem_2352 = split_127[3]
        getitem_2353 = split_127[4]
        getitem_2354 = split_127[5]
        getitem_2355 = split_127[6]
        getitem_2356 = split_127[7]
        getitem_2357 = split_127[8]
        getitem_2358 = split_127[9]
        getitem_2359 = split_127[10]
        getitem_2360 = split_127[11]
        getitem_2361 = split_127[12]
        getitem_2362 = split_127[13]
        getitem_2363 = split_127[14]
        getitem_2364 = split_127[15];  split_127 = None
        cat_195 = torch.ops.aten.cat.default([getitem_2349, getitem_2350, getitem_2351, getitem_2352, getitem_2353, getitem_2354, getitem_2355, getitem_2356, getitem_2357, getitem_2358, getitem_2359, getitem_2360, getitem_2361, getitem_2362, getitem_2363, getitem_2364], 1);  getitem_2349 = getitem_2350 = getitem_2351 = getitem_2352 = getitem_2353 = getitem_2354 = getitem_2355 = getitem_2356 = getitem_2357 = getitem_2358 = getitem_2359 = getitem_2360 = getitem_2361 = getitem_2362 = getitem_2363 = getitem_2364 = None
        convert_element_type_1206 = torch.ops.prims.convert_element_type.default(primals_370, torch.bfloat16)
        all_gather_into_tensor_378 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1206, 16, '1025');  convert_element_type_1206 = None
        wait_tensor_465 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_378);  all_gather_into_tensor_378 = None
        split_128 = torch.ops.aten.split.Tensor(wait_tensor_465, 8);  wait_tensor_465 = None
        getitem_2365 = split_128[0]
        getitem_2366 = split_128[1]
        getitem_2367 = split_128[2]
        getitem_2368 = split_128[3]
        getitem_2369 = split_128[4]
        getitem_2370 = split_128[5]
        getitem_2371 = split_128[6]
        getitem_2372 = split_128[7]
        getitem_2373 = split_128[8]
        getitem_2374 = split_128[9]
        getitem_2375 = split_128[10]
        getitem_2376 = split_128[11]
        getitem_2377 = split_128[12]
        getitem_2378 = split_128[13]
        getitem_2379 = split_128[14]
        getitem_2380 = split_128[15];  split_128 = None
        cat_196 = torch.ops.aten.cat.default([getitem_2365, getitem_2366, getitem_2367, getitem_2368, getitem_2369, getitem_2370, getitem_2371, getitem_2372, getitem_2373, getitem_2374, getitem_2375, getitem_2376, getitem_2377, getitem_2378, getitem_2379, getitem_2380], 1);  getitem_2365 = getitem_2366 = getitem_2367 = getitem_2368 = getitem_2369 = getitem_2370 = getitem_2371 = getitem_2372 = getitem_2373 = getitem_2374 = getitem_2375 = getitem_2376 = getitem_2377 = getitem_2378 = getitem_2379 = getitem_2380 = None
        convert_element_type_1207 = torch.ops.prims.convert_element_type.default(primals_371, torch.bfloat16)
        all_gather_into_tensor_379 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1207, 16, '1025');  convert_element_type_1207 = None
        wait_tensor_466 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_379);  all_gather_into_tensor_379 = None
        split_129 = torch.ops.aten.split.Tensor(wait_tensor_466, 8);  wait_tensor_466 = None
        getitem_2381 = split_129[0]
        getitem_2382 = split_129[1]
        getitem_2383 = split_129[2]
        getitem_2384 = split_129[3]
        getitem_2385 = split_129[4]
        getitem_2386 = split_129[5]
        getitem_2387 = split_129[6]
        getitem_2388 = split_129[7]
        getitem_2389 = split_129[8]
        getitem_2390 = split_129[9]
        getitem_2391 = split_129[10]
        getitem_2392 = split_129[11]
        getitem_2393 = split_129[12]
        getitem_2394 = split_129[13]
        getitem_2395 = split_129[14]
        getitem_2396 = split_129[15];  split_129 = None
        cat_197 = torch.ops.aten.cat.default([getitem_2381, getitem_2382, getitem_2383, getitem_2384, getitem_2385, getitem_2386, getitem_2387, getitem_2388, getitem_2389, getitem_2390, getitem_2391, getitem_2392, getitem_2393, getitem_2394, getitem_2395, getitem_2396], 1);  getitem_2381 = getitem_2382 = getitem_2383 = getitem_2384 = getitem_2385 = getitem_2386 = getitem_2387 = getitem_2388 = getitem_2389 = getitem_2390 = getitem_2391 = getitem_2392 = getitem_2393 = getitem_2394 = getitem_2395 = getitem_2396 = None
        cumsum_65 = torch.ops.aten.cumsum.default(convert_element_type_1202, 0, dtype = torch.int32);  convert_element_type_1202 = None
        permute_335 = torch.ops.aten.permute.default(cat_195, [0, 2, 1]);  cat_195 = None
        _grouped_mm_63 = torch.ops.aten._grouped_mm.default(index_43, permute_335, cumsum_65)
        convert_element_type_1210 = torch.ops.prims.convert_element_type.default(_grouped_mm_63, torch.float32)
        neg_43 = torch.ops.aten.neg.default(convert_element_type_1210)
        exp_65 = torch.ops.aten.exp.default(neg_43);  neg_43 = None
        add_1460 = torch.ops.aten.add.Tensor(exp_65, 1);  exp_65 = None
        div_109 = torch.ops.aten.div.Tensor(convert_element_type_1210, add_1460);  convert_element_type_1210 = add_1460 = None
        convert_element_type_1211 = torch.ops.prims.convert_element_type.default(div_109, torch.bfloat16);  div_109 = None
        permute_336 = torch.ops.aten.permute.default(cat_197, [0, 2, 1]);  cat_197 = None
        _grouped_mm_64 = torch.ops.aten._grouped_mm.default(index_43, permute_336, cumsum_65)
        mul_1064 = torch.ops.aten.mul.Tensor(convert_element_type_1211, _grouped_mm_64);  convert_element_type_1211 = None
        permute_337 = torch.ops.aten.permute.default(cat_196, [0, 2, 1]);  cat_196 = None
        _grouped_mm_65 = torch.ops.aten._grouped_mm.default(mul_1064, permute_337, cumsum_65)
        empty_21 = torch.ops.aten.empty.memory_format([sym_size_int_85, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_42 = torch.ops.aten.index_put.default(empty_21, [getitem_2332], _grouped_mm_65);  empty_21 = _grouped_mm_65 = None
        slice_137 = torch.ops.aten.slice.Tensor(index_put_42, 0, 0, -1);  index_put_42 = None
        all_to_all_single_65 = torch.ops._c10d_functional.all_to_all_single.default(slice_137, [_local_scalar_dense_336, _local_scalar_dense_337, _local_scalar_dense_338, _local_scalar_dense_339, _local_scalar_dense_340, _local_scalar_dense_341, _local_scalar_dense_342, _local_scalar_dense_343], [_local_scalar_dense_344, _local_scalar_dense_345, _local_scalar_dense_346, _local_scalar_dense_347, _local_scalar_dense_348, _local_scalar_dense_349, _local_scalar_dense_350, _local_scalar_dense_351], '1033');  slice_137 = None
        wait_tensor_469 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_65);  all_to_all_single_65 = None
        convert_element_type_1212 = torch.ops.prims.convert_element_type.default(primals_372, torch.bfloat16)
        all_gather_into_tensor_382 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1212, 128, '0');  convert_element_type_1212 = None
        wait_tensor_470 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_382);  all_gather_into_tensor_382 = None
        permute_338 = torch.ops.aten.permute.default(wait_tensor_470, [1, 0]);  wait_tensor_470 = None
        mm_180 = torch.ops.aten.mm.default(view_1465, permute_338);  permute_338 = None
        convert_element_type_1215 = torch.ops.prims.convert_element_type.default(mm_180, torch.float32)
        neg_44 = torch.ops.aten.neg.default(convert_element_type_1215)
        exp_66 = torch.ops.aten.exp.default(neg_44);  neg_44 = None
        add_1496 = torch.ops.aten.add.Tensor(exp_66, 1);  exp_66 = None
        div_110 = torch.ops.aten.div.Tensor(convert_element_type_1215, add_1496);  convert_element_type_1215 = add_1496 = None
        convert_element_type_1216 = torch.ops.prims.convert_element_type.default(div_110, torch.bfloat16);  div_110 = None
        convert_element_type_1217 = torch.ops.prims.convert_element_type.default(primals_373, torch.bfloat16)
        all_gather_into_tensor_383 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1217, 128, '0');  convert_element_type_1217 = None
        wait_tensor_471 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_383);  all_gather_into_tensor_383 = None
        permute_339 = torch.ops.aten.permute.default(wait_tensor_471, [1, 0]);  wait_tensor_471 = None
        mm_181 = torch.ops.aten.mm.default(view_1465, permute_339);  permute_339 = None
        mul_1084 = torch.ops.aten.mul.Tensor(convert_element_type_1216, mm_181);  convert_element_type_1216 = None
        convert_element_type_1220 = torch.ops.prims.convert_element_type.default(primals_374, torch.bfloat16)
        all_gather_into_tensor_384 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1220, 128, '0');  convert_element_type_1220 = None
        wait_tensor_472 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_384);  all_gather_into_tensor_384 = None
        permute_340 = torch.ops.aten.permute.default(wait_tensor_472, [1, 0]);  wait_tensor_472 = None
        mm_182 = torch.ops.aten.mm.default(mul_1084, permute_340);  permute_340 = None
        index_put_43 = torch.ops.aten.index_put.default(full_default_1, [getitem_2331], wait_tensor_469);  wait_tensor_469 = None
        view_1505 = torch.ops.aten.view.default(mul_1046, [-1, 1, 6]);  mul_1046 = None
        view_1506 = torch.ops.aten.view.default(index_put_43, [-1, 6, 2048]);  index_put_43 = None
        convert_element_type_1223 = torch.ops.prims.convert_element_type.default(view_1506, torch.float32);  view_1506 = None
        bmm_21 = torch.ops.aten.bmm.default(view_1505, convert_element_type_1223)
        convert_element_type_1224 = torch.ops.prims.convert_element_type.default(bmm_21, torch.bfloat16);  bmm_21 = None
        squeeze_21 = torch.ops.aten.squeeze.dim(convert_element_type_1224, 1);  convert_element_type_1224 = None
        add_1500 = torch.ops.aten.add.Tensor(mm_182, squeeze_21);  mm_182 = squeeze_21 = None
        view_1507 = torch.ops.aten.view.default(add_1500, [2, 4096, 2048]);  add_1500 = None
        add_1501 = torch.ops.aten.add.Tensor(add_1436, view_1507);  view_1507 = None
        convert_element_type_1225 = torch.ops.prims.convert_element_type.default(primals_375, torch.bfloat16)
        all_gather_into_tensor_385 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1225, 128, '0');  convert_element_type_1225 = None
        wait_tensor_473 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_385);  all_gather_into_tensor_385 = None
        convert_element_type_1226 = torch.ops.prims.convert_element_type.default(add_1501, torch.float32)
        pow_70 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1226, 2)
        mean_69 = torch.ops.aten.mean.dim(pow_70, [2], True);  pow_70 = None
        add_1502 = torch.ops.aten.add.Scalar(mean_69, 1e-05);  mean_69 = None
        rsqrt_69 = torch.ops.aten.rsqrt.default(add_1502);  add_1502 = None
        mul_1087 = torch.ops.aten.mul.Tensor(convert_element_type_1226, rsqrt_69);  convert_element_type_1226 = None
        mul_1088 = torch.ops.aten.mul.Tensor(mul_1087, wait_tensor_473);  mul_1087 = wait_tensor_473 = None
        convert_element_type_1227 = torch.ops.prims.convert_element_type.default(mul_1088, torch.bfloat16);  mul_1088 = None
        convert_element_type_1228 = torch.ops.prims.convert_element_type.default(primals_376, torch.bfloat16)
        all_gather_into_tensor_386 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1228, 128, '0');  convert_element_type_1228 = None
        wait_tensor_474 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_386);  all_gather_into_tensor_386 = None
        permute_341 = torch.ops.aten.permute.default(wait_tensor_474, [1, 0]);  wait_tensor_474 = None
        view_1510 = torch.ops.aten.view.default(convert_element_type_1227, [8192, 2048]);  convert_element_type_1227 = None
        mm_183 = torch.ops.aten.mm.default(view_1510, permute_341);  permute_341 = None
        view_1511 = torch.ops.aten.view.default(mm_183, [2, 4096, 3072]);  mm_183 = None
        view_1512 = torch.ops.aten.view.default(view_1511, [2, 4096, -1, 192]);  view_1511 = None
        split_with_sizes_69 = torch.ops.aten.split_with_sizes.default(view_1512, [128, 64], -1);  view_1512 = None
        getitem_2429 = split_with_sizes_69[0]
        getitem_2430 = split_with_sizes_69[1];  split_with_sizes_69 = None
        convert_element_type_1231 = torch.ops.prims.convert_element_type.default(getitem_2430, torch.float32);  getitem_2430 = None
        view_1513 = torch.ops.aten.view.default(convert_element_type_1231, [2, 4096, 16, -1, 2]);  convert_element_type_1231 = None
        view_as_complex_46 = torch.ops.aten.view_as_complex.default(view_1513);  view_1513 = None
        mul_1089 = torch.ops.aten.mul.Tensor(view_as_complex_46, view_7);  view_as_complex_46 = None
        view_as_real_46 = torch.ops.aten.view_as_real.default(mul_1089);  mul_1089 = None
        view_1515 = torch.ops.aten.view.default(view_as_real_46, [2, 4096, 16, 64]);  view_as_real_46 = None
        convert_element_type_1232 = torch.ops.prims.convert_element_type.default(view_1515, torch.bfloat16);  view_1515 = None
        cat_200 = torch.ops.aten.cat.default([getitem_2429, convert_element_type_1232], -1);  getitem_2429 = convert_element_type_1232 = None
        convert_element_type_1233 = torch.ops.prims.convert_element_type.default(primals_377, torch.bfloat16)
        all_gather_into_tensor_387 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1233, 128, '0');  convert_element_type_1233 = None
        wait_tensor_475 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_387);  all_gather_into_tensor_387 = None
        slice_139 = torch.ops.aten.slice.Tensor(wait_tensor_475, 0, 0, 576);  wait_tensor_475 = None
        permute_342 = torch.ops.aten.permute.default(slice_139, [1, 0]);  slice_139 = None
        mm_184 = torch.ops.aten.mm.default(view_1510, permute_342);  permute_342 = None
        view_1518 = torch.ops.aten.view.default(mm_184, [2, 4096, 576]);  mm_184 = None
        split_with_sizes_70 = torch.ops.aten.split_with_sizes.default(view_1518, [512, 64], -1);  view_1518 = None
        getitem_2431 = split_with_sizes_70[0]
        getitem_2432 = split_with_sizes_70[1];  split_with_sizes_70 = None
        unsqueeze_45 = torch.ops.aten.unsqueeze.default(getitem_2432, 2);  getitem_2432 = None
        convert_element_type_1236 = torch.ops.prims.convert_element_type.default(unsqueeze_45, torch.float32);  unsqueeze_45 = None
        view_1519 = torch.ops.aten.view.default(convert_element_type_1236, [2, 4096, 1, -1, 2]);  convert_element_type_1236 = None
        view_as_complex_47 = torch.ops.aten.view_as_complex.default(view_1519);  view_1519 = None
        mul_1090 = torch.ops.aten.mul.Tensor(view_as_complex_47, view_7);  view_as_complex_47 = None
        view_as_real_47 = torch.ops.aten.view_as_real.default(mul_1090);  mul_1090 = None
        view_1521 = torch.ops.aten.view.default(view_as_real_47, [2, 4096, 1, 64]);  view_as_real_47 = None
        convert_element_type_1237 = torch.ops.prims.convert_element_type.default(view_1521, torch.bfloat16);  view_1521 = None
        convert_element_type_1238 = torch.ops.prims.convert_element_type.default(primals_378, torch.bfloat16)
        all_gather_into_tensor_388 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1238, 128, '0');  convert_element_type_1238 = None
        wait_tensor_476 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_388);  all_gather_into_tensor_388 = None
        convert_element_type_1239 = torch.ops.prims.convert_element_type.default(getitem_2431, torch.float32)
        pow_71 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1239, 2)
        mean_70 = torch.ops.aten.mean.dim(pow_71, [2], True);  pow_71 = None
        add_1503 = torch.ops.aten.add.Scalar(mean_70, 1e-05);  mean_70 = None
        rsqrt_70 = torch.ops.aten.rsqrt.default(add_1503);  add_1503 = None
        mul_1091 = torch.ops.aten.mul.Tensor(convert_element_type_1239, rsqrt_70);  convert_element_type_1239 = None
        mul_1092 = torch.ops.aten.mul.Tensor(mul_1091, wait_tensor_476);  mul_1091 = wait_tensor_476 = None
        convert_element_type_1240 = torch.ops.prims.convert_element_type.default(mul_1092, torch.bfloat16);  mul_1092 = None
        convert_element_type_1241 = torch.ops.prims.convert_element_type.default(primals_379, torch.bfloat16)
        all_gather_into_tensor_389 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1241, 128, '0');  convert_element_type_1241 = None
        wait_tensor_477 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_389);  all_gather_into_tensor_389 = None
        permute_343 = torch.ops.aten.permute.default(wait_tensor_477, [1, 0]);  wait_tensor_477 = None
        view_1524 = torch.ops.aten.view.default(convert_element_type_1240, [8192, 512]);  convert_element_type_1240 = None
        mm_185 = torch.ops.aten.mm.default(view_1524, permute_343);  permute_343 = None
        view_1525 = torch.ops.aten.view.default(mm_185, [2, 4096, 4096]);  mm_185 = None
        view_1526 = torch.ops.aten.view.default(view_1525, [2, 4096, -1, 256]);  view_1525 = None
        split_with_sizes_71 = torch.ops.aten.split_with_sizes.default(view_1526, [128, 128], -1);  view_1526 = None
        getitem_2433 = split_with_sizes_71[0]
        getitem_2434 = split_with_sizes_71[1];  split_with_sizes_71 = None
        expand_23 = torch.ops.aten.expand.default(convert_element_type_1237, [-1, -1, 16, -1]);  convert_element_type_1237 = None
        cat_201 = torch.ops.aten.cat.default([getitem_2433, expand_23], -1);  getitem_2433 = expand_23 = None
        permute_344 = torch.ops.aten.permute.default(cat_200, [0, 2, 1, 3]);  cat_200 = None
        permute_345 = torch.ops.aten.permute.default(cat_201, [0, 2, 1, 3]);  cat_201 = None
        permute_346 = torch.ops.aten.permute.default(getitem_2434, [0, 2, 1, 3]);  getitem_2434 = None
        sdpa_score23 = self.sdpa_score23
        sdpa_mask23 = self.sdpa_mask23
        flex_attention_23 = torch.ops.higher_order.flex_attention(permute_344, permute_345, permute_346, sdpa_score23, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask23), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score23 = sdpa_mask23 = None
        getitem_2435 = flex_attention_23[0]
        getitem_2436 = flex_attention_23[1];  flex_attention_23 = None
        permute_347 = torch.ops.aten.permute.default(getitem_2435, [0, 2, 1, 3])
        view_1527 = torch.ops.aten.view.default(permute_347, [2, 4096, -1]);  permute_347 = None
        convert_element_type_1244 = torch.ops.prims.convert_element_type.default(primals_380, torch.bfloat16)
        all_gather_into_tensor_390 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1244, 128, '0');  convert_element_type_1244 = None
        wait_tensor_478 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_390);  all_gather_into_tensor_390 = None
        permute_348 = torch.ops.aten.permute.default(wait_tensor_478, [1, 0]);  wait_tensor_478 = None
        view_1529 = torch.ops.aten.view.default(view_1527, [8192, 2048]);  view_1527 = None
        mm_186 = torch.ops.aten.mm.default(view_1529, permute_348);  view_1529 = permute_348 = None
        view_1530 = torch.ops.aten.view.default(mm_186, [2, 4096, 2048]);  mm_186 = None
        add_1504 = torch.ops.aten.add.Tensor(add_1501, view_1530);  view_1530 = None
        convert_element_type_1247 = torch.ops.prims.convert_element_type.default(primals_381, torch.bfloat16)
        all_gather_into_tensor_391 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1247, 128, '0');  convert_element_type_1247 = None
        wait_tensor_479 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_391);  all_gather_into_tensor_391 = None
        convert_element_type_1248 = torch.ops.prims.convert_element_type.default(add_1504, torch.float32)
        pow_72 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1248, 2)
        mean_71 = torch.ops.aten.mean.dim(pow_72, [2], True);  pow_72 = None
        add_1505 = torch.ops.aten.add.Scalar(mean_71, 1e-05);  mean_71 = None
        rsqrt_71 = torch.ops.aten.rsqrt.default(add_1505);  add_1505 = None
        mul_1093 = torch.ops.aten.mul.Tensor(convert_element_type_1248, rsqrt_71);  convert_element_type_1248 = None
        mul_1094 = torch.ops.aten.mul.Tensor(mul_1093, wait_tensor_479);  mul_1093 = wait_tensor_479 = None
        convert_element_type_1249 = torch.ops.prims.convert_element_type.default(mul_1094, torch.bfloat16);  mul_1094 = None
        view_1532 = torch.ops.aten.view.default(convert_element_type_1249, [-1, 2048]);  convert_element_type_1249 = None
        convert_element_type_1250 = torch.ops.prims.convert_element_type.default(primals_383, torch.bfloat16)
        all_gather_into_tensor_392 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1250, 128, '0');  convert_element_type_1250 = None
        wait_tensor_480 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_392);  all_gather_into_tensor_392 = None
        slice_141 = torch.ops.aten.slice.Tensor(wait_tensor_480, 0, 0, 64);  wait_tensor_480 = None
        permute_349 = torch.ops.aten.permute.default(slice_141, [1, 0]);  slice_141 = None
        mm_187 = torch.ops.aten.mm.default(view_1532, permute_349);  permute_349 = None
        convert_element_type_1253 = torch.ops.prims.convert_element_type.default(mm_187, torch.float32)
        amax_22 = torch.ops.aten.amax.default(convert_element_type_1253, [1], True)
        sub_528 = torch.ops.aten.sub.Tensor(convert_element_type_1253, amax_22);  convert_element_type_1253 = None
        exp_67 = torch.ops.aten.exp.default(sub_528);  sub_528 = None
        sum_89 = torch.ops.aten.sum.dim_IntList(exp_67, [1], True)
        div_111 = torch.ops.aten.div.Tensor(exp_67, sum_89);  exp_67 = None
        add_1506 = torch.ops.aten.add.Tensor(div_111, primals_382);  primals_382 = None
        topk_22 = torch.ops.aten.topk.default(add_1506, 6, -1, True, False);  add_1506 = None
        getitem_2439 = topk_22[1];  topk_22 = None
        gather_22 = torch.ops.aten.gather.default(div_111, 1, getitem_2439);  div_111 = None
        mul_1095 = torch.ops.aten.mul.Tensor(gather_22, 1.0);  gather_22 = None
        view_1534 = torch.ops.aten.view.default(getitem_2439, [-1])
        histc_44 = torch.ops.aten.histc.default(view_1534, 64, 0, 64)
        add_1507 = torch.ops.aten.add.Tensor(primals_384, histc_44)
        sort_22 = torch.ops.aten.sort.stable(view_1534, stable = True);  view_1534 = None
        getitem_2441 = sort_22[1];  sort_22 = None
        div_112 = torch.ops.aten.div.Tensor_mode(getitem_2441, 6, rounding_mode = 'floor')
        index_44 = torch.ops.aten.index.Tensor(view_1532, [div_112])
        all_to_all_single_66 = torch.ops._c10d_functional.all_to_all_single.default(histc_44, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_481 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_66);  all_to_all_single_66 = None
        wait_tensor_482 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_481);  wait_tensor_481 = None
        view_1538 = torch.ops.aten.view.default(histc_44, [8, -1]);  histc_44 = None
        sum_90 = torch.ops.aten.sum.dim_IntList(view_1538, [1]);  view_1538 = None
        device_put_44 = torch.ops.prims.device_put.default(sum_90, device(type='cpu'), True);  sum_90 = None
        view_1539 = torch.ops.aten.view.default(wait_tensor_482, [8, -1])
        sum_91 = torch.ops.aten.sum.dim_IntList(view_1539, [1])
        device_put_45 = torch.ops.prims.device_put.default(sum_91, device(type='cpu'));  sum_91 = None
        select_352 = torch.ops.aten.select.int(device_put_44, 0, 0)
        _local_scalar_dense_352 = torch.ops.aten._local_scalar_dense.default(select_352);  select_352 = None
        ge_440 = _local_scalar_dense_352 >= 0
        _assert_scalar_352 = torch.ops.aten._assert_scalar.default(ge_440, "Runtime assertion failed for expression u352 >= 0 on node 'ge_352'");  ge_440 = _assert_scalar_352 = None
        select_353 = torch.ops.aten.select.int(device_put_44, 0, 1)
        _local_scalar_dense_353 = torch.ops.aten._local_scalar_dense.default(select_353);  select_353 = None
        ge_441 = _local_scalar_dense_353 >= 0
        _assert_scalar_353 = torch.ops.aten._assert_scalar.default(ge_441, "Runtime assertion failed for expression u353 >= 0 on node 'ge_353'");  ge_441 = _assert_scalar_353 = None
        select_354 = torch.ops.aten.select.int(device_put_44, 0, 2)
        _local_scalar_dense_354 = torch.ops.aten._local_scalar_dense.default(select_354);  select_354 = None
        ge_442 = _local_scalar_dense_354 >= 0
        _assert_scalar_354 = torch.ops.aten._assert_scalar.default(ge_442, "Runtime assertion failed for expression u354 >= 0 on node 'ge_354'");  ge_442 = _assert_scalar_354 = None
        select_355 = torch.ops.aten.select.int(device_put_44, 0, 3)
        _local_scalar_dense_355 = torch.ops.aten._local_scalar_dense.default(select_355);  select_355 = None
        ge_443 = _local_scalar_dense_355 >= 0
        _assert_scalar_355 = torch.ops.aten._assert_scalar.default(ge_443, "Runtime assertion failed for expression u355 >= 0 on node 'ge_355'");  ge_443 = _assert_scalar_355 = None
        select_356 = torch.ops.aten.select.int(device_put_44, 0, 4)
        _local_scalar_dense_356 = torch.ops.aten._local_scalar_dense.default(select_356);  select_356 = None
        ge_444 = _local_scalar_dense_356 >= 0
        _assert_scalar_356 = torch.ops.aten._assert_scalar.default(ge_444, "Runtime assertion failed for expression u356 >= 0 on node 'ge_356'");  ge_444 = _assert_scalar_356 = None
        select_357 = torch.ops.aten.select.int(device_put_44, 0, 5)
        _local_scalar_dense_357 = torch.ops.aten._local_scalar_dense.default(select_357);  select_357 = None
        ge_445 = _local_scalar_dense_357 >= 0
        _assert_scalar_357 = torch.ops.aten._assert_scalar.default(ge_445, "Runtime assertion failed for expression u357 >= 0 on node 'ge_357'");  ge_445 = _assert_scalar_357 = None
        select_358 = torch.ops.aten.select.int(device_put_44, 0, 6)
        _local_scalar_dense_358 = torch.ops.aten._local_scalar_dense.default(select_358);  select_358 = None
        ge_446 = _local_scalar_dense_358 >= 0
        _assert_scalar_358 = torch.ops.aten._assert_scalar.default(ge_446, "Runtime assertion failed for expression u358 >= 0 on node 'ge_358'");  ge_446 = _assert_scalar_358 = None
        select_359 = torch.ops.aten.select.int(device_put_44, 0, 7);  device_put_44 = None
        _local_scalar_dense_359 = torch.ops.aten._local_scalar_dense.default(select_359);  select_359 = None
        ge_447 = _local_scalar_dense_359 >= 0
        _assert_scalar_359 = torch.ops.aten._assert_scalar.default(ge_447, "Runtime assertion failed for expression u359 >= 0 on node 'ge_359'");  ge_447 = _assert_scalar_359 = None
        select_360 = torch.ops.aten.select.int(device_put_45, 0, 0)
        _local_scalar_dense_360 = torch.ops.aten._local_scalar_dense.default(select_360);  select_360 = None
        ge_448 = _local_scalar_dense_360 >= 0
        _assert_scalar_360 = torch.ops.aten._assert_scalar.default(ge_448, "Runtime assertion failed for expression u360 >= 0 on node 'ge_360'");  ge_448 = _assert_scalar_360 = None
        select_361 = torch.ops.aten.select.int(device_put_45, 0, 1)
        _local_scalar_dense_361 = torch.ops.aten._local_scalar_dense.default(select_361);  select_361 = None
        ge_449 = _local_scalar_dense_361 >= 0
        _assert_scalar_361 = torch.ops.aten._assert_scalar.default(ge_449, "Runtime assertion failed for expression u361 >= 0 on node 'ge_361'");  ge_449 = _assert_scalar_361 = None
        select_362 = torch.ops.aten.select.int(device_put_45, 0, 2)
        _local_scalar_dense_362 = torch.ops.aten._local_scalar_dense.default(select_362);  select_362 = None
        ge_450 = _local_scalar_dense_362 >= 0
        _assert_scalar_362 = torch.ops.aten._assert_scalar.default(ge_450, "Runtime assertion failed for expression u362 >= 0 on node 'ge_362'");  ge_450 = _assert_scalar_362 = None
        select_363 = torch.ops.aten.select.int(device_put_45, 0, 3)
        _local_scalar_dense_363 = torch.ops.aten._local_scalar_dense.default(select_363);  select_363 = None
        ge_451 = _local_scalar_dense_363 >= 0
        _assert_scalar_363 = torch.ops.aten._assert_scalar.default(ge_451, "Runtime assertion failed for expression u363 >= 0 on node 'ge_363'");  ge_451 = _assert_scalar_363 = None
        select_364 = torch.ops.aten.select.int(device_put_45, 0, 4)
        _local_scalar_dense_364 = torch.ops.aten._local_scalar_dense.default(select_364);  select_364 = None
        ge_452 = _local_scalar_dense_364 >= 0
        _assert_scalar_364 = torch.ops.aten._assert_scalar.default(ge_452, "Runtime assertion failed for expression u364 >= 0 on node 'ge_364'");  ge_452 = _assert_scalar_364 = None
        select_365 = torch.ops.aten.select.int(device_put_45, 0, 5)
        _local_scalar_dense_365 = torch.ops.aten._local_scalar_dense.default(select_365);  select_365 = None
        ge_453 = _local_scalar_dense_365 >= 0
        _assert_scalar_365 = torch.ops.aten._assert_scalar.default(ge_453, "Runtime assertion failed for expression u365 >= 0 on node 'ge_365'");  ge_453 = _assert_scalar_365 = None
        select_366 = torch.ops.aten.select.int(device_put_45, 0, 6)
        _local_scalar_dense_366 = torch.ops.aten._local_scalar_dense.default(select_366);  select_366 = None
        ge_454 = _local_scalar_dense_366 >= 0
        _assert_scalar_366 = torch.ops.aten._assert_scalar.default(ge_454, "Runtime assertion failed for expression u366 >= 0 on node 'ge_366'");  ge_454 = _assert_scalar_366 = None
        select_367 = torch.ops.aten.select.int(device_put_45, 0, 7);  device_put_45 = None
        _local_scalar_dense_367 = torch.ops.aten._local_scalar_dense.default(select_367);  select_367 = None
        ge_455 = _local_scalar_dense_367 >= 0
        _assert_scalar_367 = torch.ops.aten._assert_scalar.default(ge_455, "Runtime assertion failed for expression u367 >= 0 on node 'ge_367'");  ge_455 = _assert_scalar_367 = None
        all_to_all_single_67 = torch.ops._c10d_functional.all_to_all_single.default(index_44, [_local_scalar_dense_360, _local_scalar_dense_361, _local_scalar_dense_362, _local_scalar_dense_363, _local_scalar_dense_364, _local_scalar_dense_365, _local_scalar_dense_366, _local_scalar_dense_367], [_local_scalar_dense_352, _local_scalar_dense_353, _local_scalar_dense_354, _local_scalar_dense_355, _local_scalar_dense_356, _local_scalar_dense_357, _local_scalar_dense_358, _local_scalar_dense_359], '1033');  index_44 = None
        sym_size_int_88 = torch.ops.aten.sym_size.int(all_to_all_single_67, 0)
        wait_tensor_483 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_67);  all_to_all_single_67 = None
        sym_sum_44 = torch.sym_sum((_local_scalar_dense_360, _local_scalar_dense_361, _local_scalar_dense_362, _local_scalar_dense_363, _local_scalar_dense_364, _local_scalar_dense_365, _local_scalar_dense_366, _local_scalar_dense_367))
        add_1514 = sym_sum_44 + 64;  sym_sum_44 = None
        add_1515 = add_1514 + 8;  add_1514 = None
        sub_531 = add_1515 - 1;  add_1515 = None
        floordiv_22 = sub_531 // 8;  sub_531 = None
        mul_1100 = floordiv_22 * 8;  floordiv_22 = None
        cumsum_66 = torch.ops.aten.cumsum.default(wait_tensor_482, 0)
        sub_532 = torch.ops.aten.sub.Tensor(cumsum_66, wait_tensor_482);  cumsum_66 = None
        sum_92 = torch.ops.aten.sum.dim_IntList(view_1539, [0]);  view_1539 = None
        clamp_min_22 = torch.ops.aten.clamp_min.default(sum_92, 8);  sum_92 = None
        add_1516 = torch.ops.aten.add.Tensor(clamp_min_22, 8);  clamp_min_22 = None
        sub_533 = torch.ops.aten.sub.Tensor(add_1516, 1);  add_1516 = None
        div_113 = torch.ops.aten.div.Tensor_mode(sub_533, 8, rounding_mode = 'floor');  sub_533 = None
        mul_1101 = torch.ops.aten.mul.Tensor(div_113, 8);  div_113 = None
        convert_element_type_1256 = torch.ops.prims.convert_element_type.default(mul_1101, torch.int32);  mul_1101 = None
        cumsum_67 = torch.ops.aten.cumsum.default(convert_element_type_1256, 0)
        sub_534 = torch.ops.aten.sub.Tensor(cumsum_67, convert_element_type_1256);  cumsum_67 = None
        full_306 = torch.ops.aten.full.default([mul_1100], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_1100 = None
        triton_kernel_wrapper_functional_proxy_22 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 22, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_482, 'start_index_values_ptr': sub_532, 'write_offsets_ptr': sub_534, 'output_ptr': full_306}, tensors_to_clone = ['output_ptr']);  wait_tensor_482 = sub_532 = sub_534 = full_306 = None
        getitem_2442 = triton_kernel_wrapper_functional_proxy_22['output_ptr'];  triton_kernel_wrapper_functional_proxy_22 = None
        cat_202 = torch.ops.aten.cat.default([wait_tensor_483, full_default]);  wait_tensor_483 = None
        sym_size_int_89 = torch.ops.aten.sym_size.int(cat_202, 0)
        sym_sum_45 = torch.sym_sum((1, _local_scalar_dense_360, _local_scalar_dense_361, _local_scalar_dense_362, _local_scalar_dense_363, _local_scalar_dense_364, _local_scalar_dense_365, _local_scalar_dense_366, _local_scalar_dense_367))
        index_45 = torch.ops.aten.index.Tensor(cat_202, [getitem_2442]);  cat_202 = None
        convert_element_type_1258 = torch.ops.prims.convert_element_type.default(primals_385, torch.bfloat16)
        all_gather_into_tensor_393 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1258, 16, '1025');  convert_element_type_1258 = None
        wait_tensor_484 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_393);  all_gather_into_tensor_393 = None
        split_133 = torch.ops.aten.split.Tensor(wait_tensor_484, 8);  wait_tensor_484 = None
        getitem_2459 = split_133[0]
        getitem_2460 = split_133[1]
        getitem_2461 = split_133[2]
        getitem_2462 = split_133[3]
        getitem_2463 = split_133[4]
        getitem_2464 = split_133[5]
        getitem_2465 = split_133[6]
        getitem_2466 = split_133[7]
        getitem_2467 = split_133[8]
        getitem_2468 = split_133[9]
        getitem_2469 = split_133[10]
        getitem_2470 = split_133[11]
        getitem_2471 = split_133[12]
        getitem_2472 = split_133[13]
        getitem_2473 = split_133[14]
        getitem_2474 = split_133[15];  split_133 = None
        cat_204 = torch.ops.aten.cat.default([getitem_2459, getitem_2460, getitem_2461, getitem_2462, getitem_2463, getitem_2464, getitem_2465, getitem_2466, getitem_2467, getitem_2468, getitem_2469, getitem_2470, getitem_2471, getitem_2472, getitem_2473, getitem_2474], 1);  getitem_2459 = getitem_2460 = getitem_2461 = getitem_2462 = getitem_2463 = getitem_2464 = getitem_2465 = getitem_2466 = getitem_2467 = getitem_2468 = getitem_2469 = getitem_2470 = getitem_2471 = getitem_2472 = getitem_2473 = getitem_2474 = None
        convert_element_type_1260 = torch.ops.prims.convert_element_type.default(primals_386, torch.bfloat16)
        all_gather_into_tensor_395 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1260, 16, '1025');  convert_element_type_1260 = None
        wait_tensor_486 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_395);  all_gather_into_tensor_395 = None
        split_134 = torch.ops.aten.split.Tensor(wait_tensor_486, 8);  wait_tensor_486 = None
        getitem_2475 = split_134[0]
        getitem_2476 = split_134[1]
        getitem_2477 = split_134[2]
        getitem_2478 = split_134[3]
        getitem_2479 = split_134[4]
        getitem_2480 = split_134[5]
        getitem_2481 = split_134[6]
        getitem_2482 = split_134[7]
        getitem_2483 = split_134[8]
        getitem_2484 = split_134[9]
        getitem_2485 = split_134[10]
        getitem_2486 = split_134[11]
        getitem_2487 = split_134[12]
        getitem_2488 = split_134[13]
        getitem_2489 = split_134[14]
        getitem_2490 = split_134[15];  split_134 = None
        cat_205 = torch.ops.aten.cat.default([getitem_2475, getitem_2476, getitem_2477, getitem_2478, getitem_2479, getitem_2480, getitem_2481, getitem_2482, getitem_2483, getitem_2484, getitem_2485, getitem_2486, getitem_2487, getitem_2488, getitem_2489, getitem_2490], 1);  getitem_2475 = getitem_2476 = getitem_2477 = getitem_2478 = getitem_2479 = getitem_2480 = getitem_2481 = getitem_2482 = getitem_2483 = getitem_2484 = getitem_2485 = getitem_2486 = getitem_2487 = getitem_2488 = getitem_2489 = getitem_2490 = None
        convert_element_type_1261 = torch.ops.prims.convert_element_type.default(primals_387, torch.bfloat16)
        all_gather_into_tensor_396 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1261, 16, '1025');  convert_element_type_1261 = None
        wait_tensor_487 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_396);  all_gather_into_tensor_396 = None
        split_135 = torch.ops.aten.split.Tensor(wait_tensor_487, 8);  wait_tensor_487 = None
        getitem_2491 = split_135[0]
        getitem_2492 = split_135[1]
        getitem_2493 = split_135[2]
        getitem_2494 = split_135[3]
        getitem_2495 = split_135[4]
        getitem_2496 = split_135[5]
        getitem_2497 = split_135[6]
        getitem_2498 = split_135[7]
        getitem_2499 = split_135[8]
        getitem_2500 = split_135[9]
        getitem_2501 = split_135[10]
        getitem_2502 = split_135[11]
        getitem_2503 = split_135[12]
        getitem_2504 = split_135[13]
        getitem_2505 = split_135[14]
        getitem_2506 = split_135[15];  split_135 = None
        cat_206 = torch.ops.aten.cat.default([getitem_2491, getitem_2492, getitem_2493, getitem_2494, getitem_2495, getitem_2496, getitem_2497, getitem_2498, getitem_2499, getitem_2500, getitem_2501, getitem_2502, getitem_2503, getitem_2504, getitem_2505, getitem_2506], 1);  getitem_2491 = getitem_2492 = getitem_2493 = getitem_2494 = getitem_2495 = getitem_2496 = getitem_2497 = getitem_2498 = getitem_2499 = getitem_2500 = getitem_2501 = getitem_2502 = getitem_2503 = getitem_2504 = getitem_2505 = getitem_2506 = None
        cumsum_68 = torch.ops.aten.cumsum.default(convert_element_type_1256, 0, dtype = torch.int32);  convert_element_type_1256 = None
        permute_350 = torch.ops.aten.permute.default(cat_204, [0, 2, 1]);  cat_204 = None
        _grouped_mm_66 = torch.ops.aten._grouped_mm.default(index_45, permute_350, cumsum_68)
        convert_element_type_1264 = torch.ops.prims.convert_element_type.default(_grouped_mm_66, torch.float32)
        neg_45 = torch.ops.aten.neg.default(convert_element_type_1264)
        exp_68 = torch.ops.aten.exp.default(neg_45);  neg_45 = None
        add_1528 = torch.ops.aten.add.Tensor(exp_68, 1);  exp_68 = None
        div_114 = torch.ops.aten.div.Tensor(convert_element_type_1264, add_1528);  convert_element_type_1264 = add_1528 = None
        convert_element_type_1265 = torch.ops.prims.convert_element_type.default(div_114, torch.bfloat16);  div_114 = None
        permute_351 = torch.ops.aten.permute.default(cat_206, [0, 2, 1]);  cat_206 = None
        _grouped_mm_67 = torch.ops.aten._grouped_mm.default(index_45, permute_351, cumsum_68)
        mul_1113 = torch.ops.aten.mul.Tensor(convert_element_type_1265, _grouped_mm_67);  convert_element_type_1265 = None
        permute_352 = torch.ops.aten.permute.default(cat_205, [0, 2, 1]);  cat_205 = None
        _grouped_mm_68 = torch.ops.aten._grouped_mm.default(mul_1113, permute_352, cumsum_68)
        empty_22 = torch.ops.aten.empty.memory_format([sym_size_int_89, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_44 = torch.ops.aten.index_put.default(empty_22, [getitem_2442], _grouped_mm_68);  empty_22 = _grouped_mm_68 = None
        slice_143 = torch.ops.aten.slice.Tensor(index_put_44, 0, 0, -1);  index_put_44 = None
        all_to_all_single_68 = torch.ops._c10d_functional.all_to_all_single.default(slice_143, [_local_scalar_dense_352, _local_scalar_dense_353, _local_scalar_dense_354, _local_scalar_dense_355, _local_scalar_dense_356, _local_scalar_dense_357, _local_scalar_dense_358, _local_scalar_dense_359], [_local_scalar_dense_360, _local_scalar_dense_361, _local_scalar_dense_362, _local_scalar_dense_363, _local_scalar_dense_364, _local_scalar_dense_365, _local_scalar_dense_366, _local_scalar_dense_367], '1033');  slice_143 = None
        wait_tensor_490 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_68);  all_to_all_single_68 = None
        convert_element_type_1266 = torch.ops.prims.convert_element_type.default(primals_388, torch.bfloat16)
        all_gather_into_tensor_399 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1266, 128, '0');  convert_element_type_1266 = None
        wait_tensor_491 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_399);  all_gather_into_tensor_399 = None
        permute_353 = torch.ops.aten.permute.default(wait_tensor_491, [1, 0]);  wait_tensor_491 = None
        mm_188 = torch.ops.aten.mm.default(view_1532, permute_353);  permute_353 = None
        convert_element_type_1269 = torch.ops.prims.convert_element_type.default(mm_188, torch.float32)
        neg_46 = torch.ops.aten.neg.default(convert_element_type_1269)
        exp_69 = torch.ops.aten.exp.default(neg_46);  neg_46 = None
        add_1564 = torch.ops.aten.add.Tensor(exp_69, 1);  exp_69 = None
        div_115 = torch.ops.aten.div.Tensor(convert_element_type_1269, add_1564);  convert_element_type_1269 = add_1564 = None
        convert_element_type_1270 = torch.ops.prims.convert_element_type.default(div_115, torch.bfloat16);  div_115 = None
        convert_element_type_1271 = torch.ops.prims.convert_element_type.default(primals_389, torch.bfloat16)
        all_gather_into_tensor_400 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1271, 128, '0');  convert_element_type_1271 = None
        wait_tensor_492 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_400);  all_gather_into_tensor_400 = None
        permute_354 = torch.ops.aten.permute.default(wait_tensor_492, [1, 0]);  wait_tensor_492 = None
        mm_189 = torch.ops.aten.mm.default(view_1532, permute_354);  permute_354 = None
        mul_1133 = torch.ops.aten.mul.Tensor(convert_element_type_1270, mm_189);  convert_element_type_1270 = None
        convert_element_type_1274 = torch.ops.prims.convert_element_type.default(primals_390, torch.bfloat16)
        all_gather_into_tensor_401 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1274, 128, '0');  convert_element_type_1274 = None
        wait_tensor_493 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_401);  all_gather_into_tensor_401 = None
        permute_355 = torch.ops.aten.permute.default(wait_tensor_493, [1, 0]);  wait_tensor_493 = None
        mm_190 = torch.ops.aten.mm.default(mul_1133, permute_355);  permute_355 = None
        index_put_45 = torch.ops.aten.index_put.default(full_default_1, [getitem_2441], wait_tensor_490);  wait_tensor_490 = None
        view_1572 = torch.ops.aten.view.default(mul_1095, [-1, 1, 6]);  mul_1095 = None
        view_1573 = torch.ops.aten.view.default(index_put_45, [-1, 6, 2048]);  index_put_45 = None
        convert_element_type_1277 = torch.ops.prims.convert_element_type.default(view_1573, torch.float32);  view_1573 = None
        bmm_22 = torch.ops.aten.bmm.default(view_1572, convert_element_type_1277)
        convert_element_type_1278 = torch.ops.prims.convert_element_type.default(bmm_22, torch.bfloat16);  bmm_22 = None
        squeeze_22 = torch.ops.aten.squeeze.dim(convert_element_type_1278, 1);  convert_element_type_1278 = None
        add_1568 = torch.ops.aten.add.Tensor(mm_190, squeeze_22);  mm_190 = squeeze_22 = None
        view_1574 = torch.ops.aten.view.default(add_1568, [2, 4096, 2048]);  add_1568 = None
        add_1569 = torch.ops.aten.add.Tensor(add_1504, view_1574);  view_1574 = None
        convert_element_type_1279 = torch.ops.prims.convert_element_type.default(primals_391, torch.bfloat16)
        all_gather_into_tensor_402 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1279, 128, '0');  convert_element_type_1279 = None
        wait_tensor_494 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_402);  all_gather_into_tensor_402 = None
        convert_element_type_1280 = torch.ops.prims.convert_element_type.default(add_1569, torch.float32)
        pow_73 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1280, 2)
        mean_72 = torch.ops.aten.mean.dim(pow_73, [2], True);  pow_73 = None
        add_1570 = torch.ops.aten.add.Scalar(mean_72, 1e-05);  mean_72 = None
        rsqrt_72 = torch.ops.aten.rsqrt.default(add_1570);  add_1570 = None
        mul_1136 = torch.ops.aten.mul.Tensor(convert_element_type_1280, rsqrt_72);  convert_element_type_1280 = None
        mul_1137 = torch.ops.aten.mul.Tensor(mul_1136, wait_tensor_494);  mul_1136 = wait_tensor_494 = None
        convert_element_type_1281 = torch.ops.prims.convert_element_type.default(mul_1137, torch.bfloat16);  mul_1137 = None
        convert_element_type_1282 = torch.ops.prims.convert_element_type.default(primals_392, torch.bfloat16)
        all_gather_into_tensor_403 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1282, 128, '0');  convert_element_type_1282 = None
        wait_tensor_495 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_403);  all_gather_into_tensor_403 = None
        permute_356 = torch.ops.aten.permute.default(wait_tensor_495, [1, 0]);  wait_tensor_495 = None
        view_1577 = torch.ops.aten.view.default(convert_element_type_1281, [8192, 2048]);  convert_element_type_1281 = None
        mm_191 = torch.ops.aten.mm.default(view_1577, permute_356);  permute_356 = None
        view_1578 = torch.ops.aten.view.default(mm_191, [2, 4096, 3072]);  mm_191 = None
        view_1579 = torch.ops.aten.view.default(view_1578, [2, 4096, -1, 192]);  view_1578 = None
        split_with_sizes_72 = torch.ops.aten.split_with_sizes.default(view_1579, [128, 64], -1);  view_1579 = None
        getitem_2539 = split_with_sizes_72[0]
        getitem_2540 = split_with_sizes_72[1];  split_with_sizes_72 = None
        convert_element_type_1285 = torch.ops.prims.convert_element_type.default(getitem_2540, torch.float32);  getitem_2540 = None
        view_1580 = torch.ops.aten.view.default(convert_element_type_1285, [2, 4096, 16, -1, 2]);  convert_element_type_1285 = None
        view_as_complex_48 = torch.ops.aten.view_as_complex.default(view_1580);  view_1580 = None
        mul_1138 = torch.ops.aten.mul.Tensor(view_as_complex_48, view_7);  view_as_complex_48 = None
        view_as_real_48 = torch.ops.aten.view_as_real.default(mul_1138);  mul_1138 = None
        view_1582 = torch.ops.aten.view.default(view_as_real_48, [2, 4096, 16, 64]);  view_as_real_48 = None
        convert_element_type_1286 = torch.ops.prims.convert_element_type.default(view_1582, torch.bfloat16);  view_1582 = None
        cat_209 = torch.ops.aten.cat.default([getitem_2539, convert_element_type_1286], -1);  getitem_2539 = convert_element_type_1286 = None
        convert_element_type_1287 = torch.ops.prims.convert_element_type.default(primals_393, torch.bfloat16)
        all_gather_into_tensor_404 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1287, 128, '0');  convert_element_type_1287 = None
        wait_tensor_496 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_404);  all_gather_into_tensor_404 = None
        slice_145 = torch.ops.aten.slice.Tensor(wait_tensor_496, 0, 0, 576);  wait_tensor_496 = None
        permute_357 = torch.ops.aten.permute.default(slice_145, [1, 0]);  slice_145 = None
        mm_192 = torch.ops.aten.mm.default(view_1577, permute_357);  permute_357 = None
        view_1585 = torch.ops.aten.view.default(mm_192, [2, 4096, 576]);  mm_192 = None
        split_with_sizes_73 = torch.ops.aten.split_with_sizes.default(view_1585, [512, 64], -1);  view_1585 = None
        getitem_2541 = split_with_sizes_73[0]
        getitem_2542 = split_with_sizes_73[1];  split_with_sizes_73 = None
        unsqueeze_47 = torch.ops.aten.unsqueeze.default(getitem_2542, 2);  getitem_2542 = None
        convert_element_type_1290 = torch.ops.prims.convert_element_type.default(unsqueeze_47, torch.float32);  unsqueeze_47 = None
        view_1586 = torch.ops.aten.view.default(convert_element_type_1290, [2, 4096, 1, -1, 2]);  convert_element_type_1290 = None
        view_as_complex_49 = torch.ops.aten.view_as_complex.default(view_1586);  view_1586 = None
        mul_1139 = torch.ops.aten.mul.Tensor(view_as_complex_49, view_7);  view_as_complex_49 = None
        view_as_real_49 = torch.ops.aten.view_as_real.default(mul_1139);  mul_1139 = None
        view_1588 = torch.ops.aten.view.default(view_as_real_49, [2, 4096, 1, 64]);  view_as_real_49 = None
        convert_element_type_1291 = torch.ops.prims.convert_element_type.default(view_1588, torch.bfloat16);  view_1588 = None
        convert_element_type_1292 = torch.ops.prims.convert_element_type.default(primals_394, torch.bfloat16)
        all_gather_into_tensor_405 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1292, 128, '0');  convert_element_type_1292 = None
        wait_tensor_497 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_405);  all_gather_into_tensor_405 = None
        convert_element_type_1293 = torch.ops.prims.convert_element_type.default(getitem_2541, torch.float32)
        pow_74 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1293, 2)
        mean_73 = torch.ops.aten.mean.dim(pow_74, [2], True);  pow_74 = None
        add_1571 = torch.ops.aten.add.Scalar(mean_73, 1e-05);  mean_73 = None
        rsqrt_73 = torch.ops.aten.rsqrt.default(add_1571);  add_1571 = None
        mul_1140 = torch.ops.aten.mul.Tensor(convert_element_type_1293, rsqrt_73);  convert_element_type_1293 = None
        mul_1141 = torch.ops.aten.mul.Tensor(mul_1140, wait_tensor_497);  mul_1140 = wait_tensor_497 = None
        convert_element_type_1294 = torch.ops.prims.convert_element_type.default(mul_1141, torch.bfloat16);  mul_1141 = None
        convert_element_type_1295 = torch.ops.prims.convert_element_type.default(primals_395, torch.bfloat16)
        all_gather_into_tensor_406 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1295, 128, '0');  convert_element_type_1295 = None
        wait_tensor_498 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_406);  all_gather_into_tensor_406 = None
        permute_358 = torch.ops.aten.permute.default(wait_tensor_498, [1, 0]);  wait_tensor_498 = None
        view_1591 = torch.ops.aten.view.default(convert_element_type_1294, [8192, 512]);  convert_element_type_1294 = None
        mm_193 = torch.ops.aten.mm.default(view_1591, permute_358);  permute_358 = None
        view_1592 = torch.ops.aten.view.default(mm_193, [2, 4096, 4096]);  mm_193 = None
        view_1593 = torch.ops.aten.view.default(view_1592, [2, 4096, -1, 256]);  view_1592 = None
        split_with_sizes_74 = torch.ops.aten.split_with_sizes.default(view_1593, [128, 128], -1);  view_1593 = None
        getitem_2543 = split_with_sizes_74[0]
        getitem_2544 = split_with_sizes_74[1];  split_with_sizes_74 = None
        expand_24 = torch.ops.aten.expand.default(convert_element_type_1291, [-1, -1, 16, -1]);  convert_element_type_1291 = None
        cat_210 = torch.ops.aten.cat.default([getitem_2543, expand_24], -1);  getitem_2543 = expand_24 = None
        permute_359 = torch.ops.aten.permute.default(cat_209, [0, 2, 1, 3]);  cat_209 = None
        permute_360 = torch.ops.aten.permute.default(cat_210, [0, 2, 1, 3]);  cat_210 = None
        permute_361 = torch.ops.aten.permute.default(getitem_2544, [0, 2, 1, 3]);  getitem_2544 = None
        sdpa_score24 = self.sdpa_score24
        sdpa_mask24 = self.sdpa_mask24
        flex_attention_24 = torch.ops.higher_order.flex_attention(permute_359, permute_360, permute_361, sdpa_score24, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask24), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score24 = sdpa_mask24 = None
        getitem_2545 = flex_attention_24[0]
        getitem_2546 = flex_attention_24[1];  flex_attention_24 = None
        permute_362 = torch.ops.aten.permute.default(getitem_2545, [0, 2, 1, 3])
        view_1594 = torch.ops.aten.view.default(permute_362, [2, 4096, -1]);  permute_362 = None
        convert_element_type_1298 = torch.ops.prims.convert_element_type.default(primals_396, torch.bfloat16)
        all_gather_into_tensor_407 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1298, 128, '0');  convert_element_type_1298 = None
        wait_tensor_499 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_407);  all_gather_into_tensor_407 = None
        permute_363 = torch.ops.aten.permute.default(wait_tensor_499, [1, 0]);  wait_tensor_499 = None
        view_1596 = torch.ops.aten.view.default(view_1594, [8192, 2048]);  view_1594 = None
        mm_194 = torch.ops.aten.mm.default(view_1596, permute_363);  view_1596 = permute_363 = None
        view_1597 = torch.ops.aten.view.default(mm_194, [2, 4096, 2048]);  mm_194 = None
        add_1572 = torch.ops.aten.add.Tensor(add_1569, view_1597);  view_1597 = None
        convert_element_type_1301 = torch.ops.prims.convert_element_type.default(primals_397, torch.bfloat16)
        all_gather_into_tensor_408 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1301, 128, '0');  convert_element_type_1301 = None
        wait_tensor_500 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_408);  all_gather_into_tensor_408 = None
        convert_element_type_1302 = torch.ops.prims.convert_element_type.default(add_1572, torch.float32)
        pow_75 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1302, 2)
        mean_74 = torch.ops.aten.mean.dim(pow_75, [2], True);  pow_75 = None
        add_1573 = torch.ops.aten.add.Scalar(mean_74, 1e-05);  mean_74 = None
        rsqrt_74 = torch.ops.aten.rsqrt.default(add_1573);  add_1573 = None
        mul_1142 = torch.ops.aten.mul.Tensor(convert_element_type_1302, rsqrt_74);  convert_element_type_1302 = None
        mul_1143 = torch.ops.aten.mul.Tensor(mul_1142, wait_tensor_500);  mul_1142 = wait_tensor_500 = None
        convert_element_type_1303 = torch.ops.prims.convert_element_type.default(mul_1143, torch.bfloat16);  mul_1143 = None
        view_1599 = torch.ops.aten.view.default(convert_element_type_1303, [-1, 2048]);  convert_element_type_1303 = None
        convert_element_type_1304 = torch.ops.prims.convert_element_type.default(primals_399, torch.bfloat16)
        all_gather_into_tensor_409 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1304, 128, '0');  convert_element_type_1304 = None
        wait_tensor_501 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_409);  all_gather_into_tensor_409 = None
        slice_147 = torch.ops.aten.slice.Tensor(wait_tensor_501, 0, 0, 64);  wait_tensor_501 = None
        permute_364 = torch.ops.aten.permute.default(slice_147, [1, 0]);  slice_147 = None
        mm_195 = torch.ops.aten.mm.default(view_1599, permute_364);  permute_364 = None
        convert_element_type_1307 = torch.ops.prims.convert_element_type.default(mm_195, torch.float32)
        amax_23 = torch.ops.aten.amax.default(convert_element_type_1307, [1], True)
        sub_552 = torch.ops.aten.sub.Tensor(convert_element_type_1307, amax_23);  convert_element_type_1307 = None
        exp_70 = torch.ops.aten.exp.default(sub_552);  sub_552 = None
        sum_93 = torch.ops.aten.sum.dim_IntList(exp_70, [1], True)
        div_116 = torch.ops.aten.div.Tensor(exp_70, sum_93);  exp_70 = None
        add_1574 = torch.ops.aten.add.Tensor(div_116, primals_398);  primals_398 = None
        topk_23 = torch.ops.aten.topk.default(add_1574, 6, -1, True, False);  add_1574 = None
        getitem_2549 = topk_23[1];  topk_23 = None
        gather_23 = torch.ops.aten.gather.default(div_116, 1, getitem_2549);  div_116 = None
        mul_1144 = torch.ops.aten.mul.Tensor(gather_23, 1.0);  gather_23 = None
        view_1601 = torch.ops.aten.view.default(getitem_2549, [-1])
        histc_46 = torch.ops.aten.histc.default(view_1601, 64, 0, 64)
        add_1575 = torch.ops.aten.add.Tensor(primals_400, histc_46)
        sort_23 = torch.ops.aten.sort.stable(view_1601, stable = True);  view_1601 = None
        getitem_2551 = sort_23[1];  sort_23 = None
        div_117 = torch.ops.aten.div.Tensor_mode(getitem_2551, 6, rounding_mode = 'floor')
        index_46 = torch.ops.aten.index.Tensor(view_1599, [div_117])
        all_to_all_single_69 = torch.ops._c10d_functional.all_to_all_single.default(histc_46, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_502 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_69);  all_to_all_single_69 = None
        wait_tensor_503 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_502);  wait_tensor_502 = None
        view_1605 = torch.ops.aten.view.default(histc_46, [8, -1]);  histc_46 = None
        sum_94 = torch.ops.aten.sum.dim_IntList(view_1605, [1]);  view_1605 = None
        device_put_46 = torch.ops.prims.device_put.default(sum_94, device(type='cpu'), True);  sum_94 = None
        view_1606 = torch.ops.aten.view.default(wait_tensor_503, [8, -1])
        sum_95 = torch.ops.aten.sum.dim_IntList(view_1606, [1])
        device_put_47 = torch.ops.prims.device_put.default(sum_95, device(type='cpu'));  sum_95 = None
        select_368 = torch.ops.aten.select.int(device_put_46, 0, 0)
        _local_scalar_dense_368 = torch.ops.aten._local_scalar_dense.default(select_368);  select_368 = None
        ge_460 = _local_scalar_dense_368 >= 0
        _assert_scalar_368 = torch.ops.aten._assert_scalar.default(ge_460, "Runtime assertion failed for expression u368 >= 0 on node 'ge_368'");  ge_460 = _assert_scalar_368 = None
        select_369 = torch.ops.aten.select.int(device_put_46, 0, 1)
        _local_scalar_dense_369 = torch.ops.aten._local_scalar_dense.default(select_369);  select_369 = None
        ge_461 = _local_scalar_dense_369 >= 0
        _assert_scalar_369 = torch.ops.aten._assert_scalar.default(ge_461, "Runtime assertion failed for expression u369 >= 0 on node 'ge_369'");  ge_461 = _assert_scalar_369 = None
        select_370 = torch.ops.aten.select.int(device_put_46, 0, 2)
        _local_scalar_dense_370 = torch.ops.aten._local_scalar_dense.default(select_370);  select_370 = None
        ge_462 = _local_scalar_dense_370 >= 0
        _assert_scalar_370 = torch.ops.aten._assert_scalar.default(ge_462, "Runtime assertion failed for expression u370 >= 0 on node 'ge_370'");  ge_462 = _assert_scalar_370 = None
        select_371 = torch.ops.aten.select.int(device_put_46, 0, 3)
        _local_scalar_dense_371 = torch.ops.aten._local_scalar_dense.default(select_371);  select_371 = None
        ge_463 = _local_scalar_dense_371 >= 0
        _assert_scalar_371 = torch.ops.aten._assert_scalar.default(ge_463, "Runtime assertion failed for expression u371 >= 0 on node 'ge_371'");  ge_463 = _assert_scalar_371 = None
        select_372 = torch.ops.aten.select.int(device_put_46, 0, 4)
        _local_scalar_dense_372 = torch.ops.aten._local_scalar_dense.default(select_372);  select_372 = None
        ge_464 = _local_scalar_dense_372 >= 0
        _assert_scalar_372 = torch.ops.aten._assert_scalar.default(ge_464, "Runtime assertion failed for expression u372 >= 0 on node 'ge_372'");  ge_464 = _assert_scalar_372 = None
        select_373 = torch.ops.aten.select.int(device_put_46, 0, 5)
        _local_scalar_dense_373 = torch.ops.aten._local_scalar_dense.default(select_373);  select_373 = None
        ge_465 = _local_scalar_dense_373 >= 0
        _assert_scalar_373 = torch.ops.aten._assert_scalar.default(ge_465, "Runtime assertion failed for expression u373 >= 0 on node 'ge_373'");  ge_465 = _assert_scalar_373 = None
        select_374 = torch.ops.aten.select.int(device_put_46, 0, 6)
        _local_scalar_dense_374 = torch.ops.aten._local_scalar_dense.default(select_374);  select_374 = None
        ge_466 = _local_scalar_dense_374 >= 0
        _assert_scalar_374 = torch.ops.aten._assert_scalar.default(ge_466, "Runtime assertion failed for expression u374 >= 0 on node 'ge_374'");  ge_466 = _assert_scalar_374 = None
        select_375 = torch.ops.aten.select.int(device_put_46, 0, 7);  device_put_46 = None
        _local_scalar_dense_375 = torch.ops.aten._local_scalar_dense.default(select_375);  select_375 = None
        ge_467 = _local_scalar_dense_375 >= 0
        _assert_scalar_375 = torch.ops.aten._assert_scalar.default(ge_467, "Runtime assertion failed for expression u375 >= 0 on node 'ge_375'");  ge_467 = _assert_scalar_375 = None
        select_376 = torch.ops.aten.select.int(device_put_47, 0, 0)
        _local_scalar_dense_376 = torch.ops.aten._local_scalar_dense.default(select_376);  select_376 = None
        ge_468 = _local_scalar_dense_376 >= 0
        _assert_scalar_376 = torch.ops.aten._assert_scalar.default(ge_468, "Runtime assertion failed for expression u376 >= 0 on node 'ge_376'");  ge_468 = _assert_scalar_376 = None
        select_377 = torch.ops.aten.select.int(device_put_47, 0, 1)
        _local_scalar_dense_377 = torch.ops.aten._local_scalar_dense.default(select_377);  select_377 = None
        ge_469 = _local_scalar_dense_377 >= 0
        _assert_scalar_377 = torch.ops.aten._assert_scalar.default(ge_469, "Runtime assertion failed for expression u377 >= 0 on node 'ge_377'");  ge_469 = _assert_scalar_377 = None
        select_378 = torch.ops.aten.select.int(device_put_47, 0, 2)
        _local_scalar_dense_378 = torch.ops.aten._local_scalar_dense.default(select_378);  select_378 = None
        ge_470 = _local_scalar_dense_378 >= 0
        _assert_scalar_378 = torch.ops.aten._assert_scalar.default(ge_470, "Runtime assertion failed for expression u378 >= 0 on node 'ge_378'");  ge_470 = _assert_scalar_378 = None
        select_379 = torch.ops.aten.select.int(device_put_47, 0, 3)
        _local_scalar_dense_379 = torch.ops.aten._local_scalar_dense.default(select_379);  select_379 = None
        ge_471 = _local_scalar_dense_379 >= 0
        _assert_scalar_379 = torch.ops.aten._assert_scalar.default(ge_471, "Runtime assertion failed for expression u379 >= 0 on node 'ge_379'");  ge_471 = _assert_scalar_379 = None
        select_380 = torch.ops.aten.select.int(device_put_47, 0, 4)
        _local_scalar_dense_380 = torch.ops.aten._local_scalar_dense.default(select_380);  select_380 = None
        ge_472 = _local_scalar_dense_380 >= 0
        _assert_scalar_380 = torch.ops.aten._assert_scalar.default(ge_472, "Runtime assertion failed for expression u380 >= 0 on node 'ge_380'");  ge_472 = _assert_scalar_380 = None
        select_381 = torch.ops.aten.select.int(device_put_47, 0, 5)
        _local_scalar_dense_381 = torch.ops.aten._local_scalar_dense.default(select_381);  select_381 = None
        ge_473 = _local_scalar_dense_381 >= 0
        _assert_scalar_381 = torch.ops.aten._assert_scalar.default(ge_473, "Runtime assertion failed for expression u381 >= 0 on node 'ge_381'");  ge_473 = _assert_scalar_381 = None
        select_382 = torch.ops.aten.select.int(device_put_47, 0, 6)
        _local_scalar_dense_382 = torch.ops.aten._local_scalar_dense.default(select_382);  select_382 = None
        ge_474 = _local_scalar_dense_382 >= 0
        _assert_scalar_382 = torch.ops.aten._assert_scalar.default(ge_474, "Runtime assertion failed for expression u382 >= 0 on node 'ge_382'");  ge_474 = _assert_scalar_382 = None
        select_383 = torch.ops.aten.select.int(device_put_47, 0, 7);  device_put_47 = None
        _local_scalar_dense_383 = torch.ops.aten._local_scalar_dense.default(select_383);  select_383 = None
        ge_475 = _local_scalar_dense_383 >= 0
        _assert_scalar_383 = torch.ops.aten._assert_scalar.default(ge_475, "Runtime assertion failed for expression u383 >= 0 on node 'ge_383'");  ge_475 = _assert_scalar_383 = None
        all_to_all_single_70 = torch.ops._c10d_functional.all_to_all_single.default(index_46, [_local_scalar_dense_376, _local_scalar_dense_377, _local_scalar_dense_378, _local_scalar_dense_379, _local_scalar_dense_380, _local_scalar_dense_381, _local_scalar_dense_382, _local_scalar_dense_383], [_local_scalar_dense_368, _local_scalar_dense_369, _local_scalar_dense_370, _local_scalar_dense_371, _local_scalar_dense_372, _local_scalar_dense_373, _local_scalar_dense_374, _local_scalar_dense_375], '1033');  index_46 = None
        sym_size_int_92 = torch.ops.aten.sym_size.int(all_to_all_single_70, 0)
        wait_tensor_504 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_70);  all_to_all_single_70 = None
        sym_sum_46 = torch.sym_sum((_local_scalar_dense_376, _local_scalar_dense_377, _local_scalar_dense_378, _local_scalar_dense_379, _local_scalar_dense_380, _local_scalar_dense_381, _local_scalar_dense_382, _local_scalar_dense_383))
        add_1582 = sym_sum_46 + 64;  sym_sum_46 = None
        add_1583 = add_1582 + 8;  add_1582 = None
        sub_555 = add_1583 - 1;  add_1583 = None
        floordiv_23 = sub_555 // 8;  sub_555 = None
        mul_1149 = floordiv_23 * 8;  floordiv_23 = None
        cumsum_69 = torch.ops.aten.cumsum.default(wait_tensor_503, 0)
        sub_556 = torch.ops.aten.sub.Tensor(cumsum_69, wait_tensor_503);  cumsum_69 = None
        sum_96 = torch.ops.aten.sum.dim_IntList(view_1606, [0]);  view_1606 = None
        clamp_min_23 = torch.ops.aten.clamp_min.default(sum_96, 8);  sum_96 = None
        add_1584 = torch.ops.aten.add.Tensor(clamp_min_23, 8);  clamp_min_23 = None
        sub_557 = torch.ops.aten.sub.Tensor(add_1584, 1);  add_1584 = None
        div_118 = torch.ops.aten.div.Tensor_mode(sub_557, 8, rounding_mode = 'floor');  sub_557 = None
        mul_1150 = torch.ops.aten.mul.Tensor(div_118, 8);  div_118 = None
        convert_element_type_1310 = torch.ops.prims.convert_element_type.default(mul_1150, torch.int32);  mul_1150 = None
        cumsum_70 = torch.ops.aten.cumsum.default(convert_element_type_1310, 0)
        sub_558 = torch.ops.aten.sub.Tensor(cumsum_70, convert_element_type_1310);  cumsum_70 = None
        full_319 = torch.ops.aten.full.default([mul_1149], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_1149 = None
        triton_kernel_wrapper_functional_proxy_23 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 23, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_503, 'start_index_values_ptr': sub_556, 'write_offsets_ptr': sub_558, 'output_ptr': full_319}, tensors_to_clone = ['output_ptr']);  wait_tensor_503 = sub_556 = sub_558 = full_319 = None
        getitem_2552 = triton_kernel_wrapper_functional_proxy_23['output_ptr'];  triton_kernel_wrapper_functional_proxy_23 = None
        cat_211 = torch.ops.aten.cat.default([wait_tensor_504, full_default]);  wait_tensor_504 = None
        sym_size_int_93 = torch.ops.aten.sym_size.int(cat_211, 0)
        sym_sum_47 = torch.sym_sum((1, _local_scalar_dense_376, _local_scalar_dense_377, _local_scalar_dense_378, _local_scalar_dense_379, _local_scalar_dense_380, _local_scalar_dense_381, _local_scalar_dense_382, _local_scalar_dense_383))
        index_47 = torch.ops.aten.index.Tensor(cat_211, [getitem_2552]);  cat_211 = None
        convert_element_type_1312 = torch.ops.prims.convert_element_type.default(primals_401, torch.bfloat16)
        all_gather_into_tensor_410 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1312, 16, '1025');  convert_element_type_1312 = None
        wait_tensor_505 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_410);  all_gather_into_tensor_410 = None
        split_139 = torch.ops.aten.split.Tensor(wait_tensor_505, 8);  wait_tensor_505 = None
        getitem_2569 = split_139[0]
        getitem_2570 = split_139[1]
        getitem_2571 = split_139[2]
        getitem_2572 = split_139[3]
        getitem_2573 = split_139[4]
        getitem_2574 = split_139[5]
        getitem_2575 = split_139[6]
        getitem_2576 = split_139[7]
        getitem_2577 = split_139[8]
        getitem_2578 = split_139[9]
        getitem_2579 = split_139[10]
        getitem_2580 = split_139[11]
        getitem_2581 = split_139[12]
        getitem_2582 = split_139[13]
        getitem_2583 = split_139[14]
        getitem_2584 = split_139[15];  split_139 = None
        cat_213 = torch.ops.aten.cat.default([getitem_2569, getitem_2570, getitem_2571, getitem_2572, getitem_2573, getitem_2574, getitem_2575, getitem_2576, getitem_2577, getitem_2578, getitem_2579, getitem_2580, getitem_2581, getitem_2582, getitem_2583, getitem_2584], 1);  getitem_2569 = getitem_2570 = getitem_2571 = getitem_2572 = getitem_2573 = getitem_2574 = getitem_2575 = getitem_2576 = getitem_2577 = getitem_2578 = getitem_2579 = getitem_2580 = getitem_2581 = getitem_2582 = getitem_2583 = getitem_2584 = None
        convert_element_type_1314 = torch.ops.prims.convert_element_type.default(primals_402, torch.bfloat16)
        all_gather_into_tensor_412 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1314, 16, '1025');  convert_element_type_1314 = None
        wait_tensor_507 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_412);  all_gather_into_tensor_412 = None
        split_140 = torch.ops.aten.split.Tensor(wait_tensor_507, 8);  wait_tensor_507 = None
        getitem_2585 = split_140[0]
        getitem_2586 = split_140[1]
        getitem_2587 = split_140[2]
        getitem_2588 = split_140[3]
        getitem_2589 = split_140[4]
        getitem_2590 = split_140[5]
        getitem_2591 = split_140[6]
        getitem_2592 = split_140[7]
        getitem_2593 = split_140[8]
        getitem_2594 = split_140[9]
        getitem_2595 = split_140[10]
        getitem_2596 = split_140[11]
        getitem_2597 = split_140[12]
        getitem_2598 = split_140[13]
        getitem_2599 = split_140[14]
        getitem_2600 = split_140[15];  split_140 = None
        cat_214 = torch.ops.aten.cat.default([getitem_2585, getitem_2586, getitem_2587, getitem_2588, getitem_2589, getitem_2590, getitem_2591, getitem_2592, getitem_2593, getitem_2594, getitem_2595, getitem_2596, getitem_2597, getitem_2598, getitem_2599, getitem_2600], 1);  getitem_2585 = getitem_2586 = getitem_2587 = getitem_2588 = getitem_2589 = getitem_2590 = getitem_2591 = getitem_2592 = getitem_2593 = getitem_2594 = getitem_2595 = getitem_2596 = getitem_2597 = getitem_2598 = getitem_2599 = getitem_2600 = None
        convert_element_type_1315 = torch.ops.prims.convert_element_type.default(primals_403, torch.bfloat16)
        all_gather_into_tensor_413 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1315, 16, '1025');  convert_element_type_1315 = None
        wait_tensor_508 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_413);  all_gather_into_tensor_413 = None
        split_141 = torch.ops.aten.split.Tensor(wait_tensor_508, 8);  wait_tensor_508 = None
        getitem_2601 = split_141[0]
        getitem_2602 = split_141[1]
        getitem_2603 = split_141[2]
        getitem_2604 = split_141[3]
        getitem_2605 = split_141[4]
        getitem_2606 = split_141[5]
        getitem_2607 = split_141[6]
        getitem_2608 = split_141[7]
        getitem_2609 = split_141[8]
        getitem_2610 = split_141[9]
        getitem_2611 = split_141[10]
        getitem_2612 = split_141[11]
        getitem_2613 = split_141[12]
        getitem_2614 = split_141[13]
        getitem_2615 = split_141[14]
        getitem_2616 = split_141[15];  split_141 = None
        cat_215 = torch.ops.aten.cat.default([getitem_2601, getitem_2602, getitem_2603, getitem_2604, getitem_2605, getitem_2606, getitem_2607, getitem_2608, getitem_2609, getitem_2610, getitem_2611, getitem_2612, getitem_2613, getitem_2614, getitem_2615, getitem_2616], 1);  getitem_2601 = getitem_2602 = getitem_2603 = getitem_2604 = getitem_2605 = getitem_2606 = getitem_2607 = getitem_2608 = getitem_2609 = getitem_2610 = getitem_2611 = getitem_2612 = getitem_2613 = getitem_2614 = getitem_2615 = getitem_2616 = None
        cumsum_71 = torch.ops.aten.cumsum.default(convert_element_type_1310, 0, dtype = torch.int32);  convert_element_type_1310 = None
        permute_365 = torch.ops.aten.permute.default(cat_213, [0, 2, 1]);  cat_213 = None
        _grouped_mm_69 = torch.ops.aten._grouped_mm.default(index_47, permute_365, cumsum_71)
        convert_element_type_1318 = torch.ops.prims.convert_element_type.default(_grouped_mm_69, torch.float32)
        neg_47 = torch.ops.aten.neg.default(convert_element_type_1318)
        exp_71 = torch.ops.aten.exp.default(neg_47);  neg_47 = None
        add_1596 = torch.ops.aten.add.Tensor(exp_71, 1);  exp_71 = None
        div_119 = torch.ops.aten.div.Tensor(convert_element_type_1318, add_1596);  convert_element_type_1318 = add_1596 = None
        convert_element_type_1319 = torch.ops.prims.convert_element_type.default(div_119, torch.bfloat16);  div_119 = None
        permute_366 = torch.ops.aten.permute.default(cat_215, [0, 2, 1]);  cat_215 = None
        _grouped_mm_70 = torch.ops.aten._grouped_mm.default(index_47, permute_366, cumsum_71)
        mul_1162 = torch.ops.aten.mul.Tensor(convert_element_type_1319, _grouped_mm_70);  convert_element_type_1319 = None
        permute_367 = torch.ops.aten.permute.default(cat_214, [0, 2, 1]);  cat_214 = None
        _grouped_mm_71 = torch.ops.aten._grouped_mm.default(mul_1162, permute_367, cumsum_71)
        empty_23 = torch.ops.aten.empty.memory_format([sym_size_int_93, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_46 = torch.ops.aten.index_put.default(empty_23, [getitem_2552], _grouped_mm_71);  empty_23 = _grouped_mm_71 = None
        slice_149 = torch.ops.aten.slice.Tensor(index_put_46, 0, 0, -1);  index_put_46 = None
        all_to_all_single_71 = torch.ops._c10d_functional.all_to_all_single.default(slice_149, [_local_scalar_dense_368, _local_scalar_dense_369, _local_scalar_dense_370, _local_scalar_dense_371, _local_scalar_dense_372, _local_scalar_dense_373, _local_scalar_dense_374, _local_scalar_dense_375], [_local_scalar_dense_376, _local_scalar_dense_377, _local_scalar_dense_378, _local_scalar_dense_379, _local_scalar_dense_380, _local_scalar_dense_381, _local_scalar_dense_382, _local_scalar_dense_383], '1033');  slice_149 = None
        wait_tensor_511 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_71);  all_to_all_single_71 = None
        convert_element_type_1320 = torch.ops.prims.convert_element_type.default(primals_404, torch.bfloat16)
        all_gather_into_tensor_416 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1320, 128, '0');  convert_element_type_1320 = None
        wait_tensor_512 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_416);  all_gather_into_tensor_416 = None
        permute_368 = torch.ops.aten.permute.default(wait_tensor_512, [1, 0]);  wait_tensor_512 = None
        mm_196 = torch.ops.aten.mm.default(view_1599, permute_368);  permute_368 = None
        convert_element_type_1323 = torch.ops.prims.convert_element_type.default(mm_196, torch.float32)
        neg_48 = torch.ops.aten.neg.default(convert_element_type_1323)
        exp_72 = torch.ops.aten.exp.default(neg_48);  neg_48 = None
        add_1632 = torch.ops.aten.add.Tensor(exp_72, 1);  exp_72 = None
        div_120 = torch.ops.aten.div.Tensor(convert_element_type_1323, add_1632);  convert_element_type_1323 = add_1632 = None
        convert_element_type_1324 = torch.ops.prims.convert_element_type.default(div_120, torch.bfloat16);  div_120 = None
        convert_element_type_1325 = torch.ops.prims.convert_element_type.default(primals_405, torch.bfloat16)
        all_gather_into_tensor_417 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1325, 128, '0');  convert_element_type_1325 = None
        wait_tensor_513 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_417);  all_gather_into_tensor_417 = None
        permute_369 = torch.ops.aten.permute.default(wait_tensor_513, [1, 0]);  wait_tensor_513 = None
        mm_197 = torch.ops.aten.mm.default(view_1599, permute_369);  permute_369 = None
        mul_1182 = torch.ops.aten.mul.Tensor(convert_element_type_1324, mm_197);  convert_element_type_1324 = None
        convert_element_type_1328 = torch.ops.prims.convert_element_type.default(primals_406, torch.bfloat16)
        all_gather_into_tensor_418 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1328, 128, '0');  convert_element_type_1328 = None
        wait_tensor_514 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_418);  all_gather_into_tensor_418 = None
        permute_370 = torch.ops.aten.permute.default(wait_tensor_514, [1, 0]);  wait_tensor_514 = None
        mm_198 = torch.ops.aten.mm.default(mul_1182, permute_370);  permute_370 = None
        index_put_47 = torch.ops.aten.index_put.default(full_default_1, [getitem_2551], wait_tensor_511);  wait_tensor_511 = None
        view_1639 = torch.ops.aten.view.default(mul_1144, [-1, 1, 6]);  mul_1144 = None
        view_1640 = torch.ops.aten.view.default(index_put_47, [-1, 6, 2048]);  index_put_47 = None
        convert_element_type_1331 = torch.ops.prims.convert_element_type.default(view_1640, torch.float32);  view_1640 = None
        bmm_23 = torch.ops.aten.bmm.default(view_1639, convert_element_type_1331)
        convert_element_type_1332 = torch.ops.prims.convert_element_type.default(bmm_23, torch.bfloat16);  bmm_23 = None
        squeeze_23 = torch.ops.aten.squeeze.dim(convert_element_type_1332, 1);  convert_element_type_1332 = None
        add_1636 = torch.ops.aten.add.Tensor(mm_198, squeeze_23);  mm_198 = squeeze_23 = None
        view_1641 = torch.ops.aten.view.default(add_1636, [2, 4096, 2048]);  add_1636 = None
        add_1637 = torch.ops.aten.add.Tensor(add_1572, view_1641);  view_1641 = None
        convert_element_type_1333 = torch.ops.prims.convert_element_type.default(primals_407, torch.bfloat16)
        all_gather_into_tensor_419 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1333, 128, '0');  convert_element_type_1333 = None
        wait_tensor_515 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_419);  all_gather_into_tensor_419 = None
        convert_element_type_1334 = torch.ops.prims.convert_element_type.default(add_1637, torch.float32)
        pow_76 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1334, 2)
        mean_75 = torch.ops.aten.mean.dim(pow_76, [2], True);  pow_76 = None
        add_1638 = torch.ops.aten.add.Scalar(mean_75, 1e-05);  mean_75 = None
        rsqrt_75 = torch.ops.aten.rsqrt.default(add_1638);  add_1638 = None
        mul_1185 = torch.ops.aten.mul.Tensor(convert_element_type_1334, rsqrt_75);  convert_element_type_1334 = None
        mul_1186 = torch.ops.aten.mul.Tensor(mul_1185, wait_tensor_515);  mul_1185 = wait_tensor_515 = None
        convert_element_type_1335 = torch.ops.prims.convert_element_type.default(mul_1186, torch.bfloat16);  mul_1186 = None
        convert_element_type_1336 = torch.ops.prims.convert_element_type.default(primals_408, torch.bfloat16)
        all_gather_into_tensor_420 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1336, 128, '0');  convert_element_type_1336 = None
        wait_tensor_516 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_420);  all_gather_into_tensor_420 = None
        permute_371 = torch.ops.aten.permute.default(wait_tensor_516, [1, 0]);  wait_tensor_516 = None
        view_1644 = torch.ops.aten.view.default(convert_element_type_1335, [8192, 2048]);  convert_element_type_1335 = None
        mm_199 = torch.ops.aten.mm.default(view_1644, permute_371);  permute_371 = None
        view_1645 = torch.ops.aten.view.default(mm_199, [2, 4096, 3072]);  mm_199 = None
        view_1646 = torch.ops.aten.view.default(view_1645, [2, 4096, -1, 192]);  view_1645 = None
        split_with_sizes_75 = torch.ops.aten.split_with_sizes.default(view_1646, [128, 64], -1);  view_1646 = None
        getitem_2649 = split_with_sizes_75[0]
        getitem_2650 = split_with_sizes_75[1];  split_with_sizes_75 = None
        convert_element_type_1339 = torch.ops.prims.convert_element_type.default(getitem_2650, torch.float32);  getitem_2650 = None
        view_1647 = torch.ops.aten.view.default(convert_element_type_1339, [2, 4096, 16, -1, 2]);  convert_element_type_1339 = None
        view_as_complex_50 = torch.ops.aten.view_as_complex.default(view_1647);  view_1647 = None
        mul_1187 = torch.ops.aten.mul.Tensor(view_as_complex_50, view_7);  view_as_complex_50 = None
        view_as_real_50 = torch.ops.aten.view_as_real.default(mul_1187);  mul_1187 = None
        view_1649 = torch.ops.aten.view.default(view_as_real_50, [2, 4096, 16, 64]);  view_as_real_50 = None
        convert_element_type_1340 = torch.ops.prims.convert_element_type.default(view_1649, torch.bfloat16);  view_1649 = None
        cat_218 = torch.ops.aten.cat.default([getitem_2649, convert_element_type_1340], -1);  getitem_2649 = convert_element_type_1340 = None
        convert_element_type_1341 = torch.ops.prims.convert_element_type.default(primals_409, torch.bfloat16)
        all_gather_into_tensor_421 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1341, 128, '0');  convert_element_type_1341 = None
        wait_tensor_517 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_421);  all_gather_into_tensor_421 = None
        slice_151 = torch.ops.aten.slice.Tensor(wait_tensor_517, 0, 0, 576);  wait_tensor_517 = None
        permute_372 = torch.ops.aten.permute.default(slice_151, [1, 0]);  slice_151 = None
        mm_200 = torch.ops.aten.mm.default(view_1644, permute_372);  permute_372 = None
        view_1652 = torch.ops.aten.view.default(mm_200, [2, 4096, 576]);  mm_200 = None
        split_with_sizes_76 = torch.ops.aten.split_with_sizes.default(view_1652, [512, 64], -1);  view_1652 = None
        getitem_2651 = split_with_sizes_76[0]
        getitem_2652 = split_with_sizes_76[1];  split_with_sizes_76 = None
        unsqueeze_49 = torch.ops.aten.unsqueeze.default(getitem_2652, 2);  getitem_2652 = None
        convert_element_type_1344 = torch.ops.prims.convert_element_type.default(unsqueeze_49, torch.float32);  unsqueeze_49 = None
        view_1653 = torch.ops.aten.view.default(convert_element_type_1344, [2, 4096, 1, -1, 2]);  convert_element_type_1344 = None
        view_as_complex_51 = torch.ops.aten.view_as_complex.default(view_1653);  view_1653 = None
        mul_1188 = torch.ops.aten.mul.Tensor(view_as_complex_51, view_7);  view_as_complex_51 = None
        view_as_real_51 = torch.ops.aten.view_as_real.default(mul_1188);  mul_1188 = None
        view_1655 = torch.ops.aten.view.default(view_as_real_51, [2, 4096, 1, 64]);  view_as_real_51 = None
        convert_element_type_1345 = torch.ops.prims.convert_element_type.default(view_1655, torch.bfloat16);  view_1655 = None
        convert_element_type_1346 = torch.ops.prims.convert_element_type.default(primals_410, torch.bfloat16)
        all_gather_into_tensor_422 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1346, 128, '0');  convert_element_type_1346 = None
        wait_tensor_518 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_422);  all_gather_into_tensor_422 = None
        convert_element_type_1347 = torch.ops.prims.convert_element_type.default(getitem_2651, torch.float32)
        pow_77 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1347, 2)
        mean_76 = torch.ops.aten.mean.dim(pow_77, [2], True);  pow_77 = None
        add_1639 = torch.ops.aten.add.Scalar(mean_76, 1e-05);  mean_76 = None
        rsqrt_76 = torch.ops.aten.rsqrt.default(add_1639);  add_1639 = None
        mul_1189 = torch.ops.aten.mul.Tensor(convert_element_type_1347, rsqrt_76);  convert_element_type_1347 = None
        mul_1190 = torch.ops.aten.mul.Tensor(mul_1189, wait_tensor_518);  mul_1189 = wait_tensor_518 = None
        convert_element_type_1348 = torch.ops.prims.convert_element_type.default(mul_1190, torch.bfloat16);  mul_1190 = None
        convert_element_type_1349 = torch.ops.prims.convert_element_type.default(primals_411, torch.bfloat16)
        all_gather_into_tensor_423 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1349, 128, '0');  convert_element_type_1349 = None
        wait_tensor_519 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_423);  all_gather_into_tensor_423 = None
        permute_373 = torch.ops.aten.permute.default(wait_tensor_519, [1, 0]);  wait_tensor_519 = None
        view_1658 = torch.ops.aten.view.default(convert_element_type_1348, [8192, 512]);  convert_element_type_1348 = None
        mm_201 = torch.ops.aten.mm.default(view_1658, permute_373);  permute_373 = None
        view_1659 = torch.ops.aten.view.default(mm_201, [2, 4096, 4096]);  mm_201 = None
        view_1660 = torch.ops.aten.view.default(view_1659, [2, 4096, -1, 256]);  view_1659 = None
        split_with_sizes_77 = torch.ops.aten.split_with_sizes.default(view_1660, [128, 128], -1);  view_1660 = None
        getitem_2653 = split_with_sizes_77[0]
        getitem_2654 = split_with_sizes_77[1];  split_with_sizes_77 = None
        expand_25 = torch.ops.aten.expand.default(convert_element_type_1345, [-1, -1, 16, -1]);  convert_element_type_1345 = None
        cat_219 = torch.ops.aten.cat.default([getitem_2653, expand_25], -1);  getitem_2653 = expand_25 = None
        permute_374 = torch.ops.aten.permute.default(cat_218, [0, 2, 1, 3]);  cat_218 = None
        permute_375 = torch.ops.aten.permute.default(cat_219, [0, 2, 1, 3]);  cat_219 = None
        permute_376 = torch.ops.aten.permute.default(getitem_2654, [0, 2, 1, 3]);  getitem_2654 = None
        sdpa_score25 = self.sdpa_score25
        sdpa_mask25 = self.sdpa_mask25
        flex_attention_25 = torch.ops.higher_order.flex_attention(permute_374, permute_375, permute_376, sdpa_score25, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask25), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score25 = sdpa_mask25 = None
        getitem_2655 = flex_attention_25[0]
        getitem_2656 = flex_attention_25[1];  flex_attention_25 = None
        permute_377 = torch.ops.aten.permute.default(getitem_2655, [0, 2, 1, 3])
        view_1661 = torch.ops.aten.view.default(permute_377, [2, 4096, -1]);  permute_377 = None
        convert_element_type_1352 = torch.ops.prims.convert_element_type.default(primals_412, torch.bfloat16)
        all_gather_into_tensor_424 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1352, 128, '0');  convert_element_type_1352 = None
        wait_tensor_520 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_424);  all_gather_into_tensor_424 = None
        permute_378 = torch.ops.aten.permute.default(wait_tensor_520, [1, 0]);  wait_tensor_520 = None
        view_1663 = torch.ops.aten.view.default(view_1661, [8192, 2048]);  view_1661 = None
        mm_202 = torch.ops.aten.mm.default(view_1663, permute_378);  view_1663 = permute_378 = None
        view_1664 = torch.ops.aten.view.default(mm_202, [2, 4096, 2048]);  mm_202 = None
        add_1640 = torch.ops.aten.add.Tensor(add_1637, view_1664);  view_1664 = None
        convert_element_type_1355 = torch.ops.prims.convert_element_type.default(primals_413, torch.bfloat16)
        all_gather_into_tensor_425 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1355, 128, '0');  convert_element_type_1355 = None
        wait_tensor_521 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_425);  all_gather_into_tensor_425 = None
        convert_element_type_1356 = torch.ops.prims.convert_element_type.default(add_1640, torch.float32)
        pow_78 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1356, 2)
        mean_77 = torch.ops.aten.mean.dim(pow_78, [2], True);  pow_78 = None
        add_1641 = torch.ops.aten.add.Scalar(mean_77, 1e-05);  mean_77 = None
        rsqrt_77 = torch.ops.aten.rsqrt.default(add_1641);  add_1641 = None
        mul_1191 = torch.ops.aten.mul.Tensor(convert_element_type_1356, rsqrt_77);  convert_element_type_1356 = None
        mul_1192 = torch.ops.aten.mul.Tensor(mul_1191, wait_tensor_521);  mul_1191 = wait_tensor_521 = None
        convert_element_type_1357 = torch.ops.prims.convert_element_type.default(mul_1192, torch.bfloat16);  mul_1192 = None
        view_1666 = torch.ops.aten.view.default(convert_element_type_1357, [-1, 2048]);  convert_element_type_1357 = None
        convert_element_type_1358 = torch.ops.prims.convert_element_type.default(primals_415, torch.bfloat16)
        all_gather_into_tensor_426 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1358, 128, '0');  convert_element_type_1358 = None
        wait_tensor_522 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_426);  all_gather_into_tensor_426 = None
        slice_153 = torch.ops.aten.slice.Tensor(wait_tensor_522, 0, 0, 64);  wait_tensor_522 = None
        permute_379 = torch.ops.aten.permute.default(slice_153, [1, 0]);  slice_153 = None
        mm_203 = torch.ops.aten.mm.default(view_1666, permute_379);  permute_379 = None
        convert_element_type_1361 = torch.ops.prims.convert_element_type.default(mm_203, torch.float32)
        amax_24 = torch.ops.aten.amax.default(convert_element_type_1361, [1], True)
        sub_576 = torch.ops.aten.sub.Tensor(convert_element_type_1361, amax_24);  convert_element_type_1361 = None
        exp_73 = torch.ops.aten.exp.default(sub_576);  sub_576 = None
        sum_97 = torch.ops.aten.sum.dim_IntList(exp_73, [1], True)
        div_121 = torch.ops.aten.div.Tensor(exp_73, sum_97);  exp_73 = None
        add_1642 = torch.ops.aten.add.Tensor(div_121, primals_414);  primals_414 = None
        topk_24 = torch.ops.aten.topk.default(add_1642, 6, -1, True, False);  add_1642 = None
        getitem_2659 = topk_24[1];  topk_24 = None
        gather_24 = torch.ops.aten.gather.default(div_121, 1, getitem_2659);  div_121 = None
        mul_1193 = torch.ops.aten.mul.Tensor(gather_24, 1.0);  gather_24 = None
        view_1668 = torch.ops.aten.view.default(getitem_2659, [-1])
        histc_48 = torch.ops.aten.histc.default(view_1668, 64, 0, 64)
        add_1643 = torch.ops.aten.add.Tensor(primals_416, histc_48)
        sort_24 = torch.ops.aten.sort.stable(view_1668, stable = True);  view_1668 = None
        getitem_2661 = sort_24[1];  sort_24 = None
        div_122 = torch.ops.aten.div.Tensor_mode(getitem_2661, 6, rounding_mode = 'floor')
        index_48 = torch.ops.aten.index.Tensor(view_1666, [div_122])
        all_to_all_single_72 = torch.ops._c10d_functional.all_to_all_single.default(histc_48, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_523 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_72);  all_to_all_single_72 = None
        wait_tensor_524 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_523);  wait_tensor_523 = None
        view_1672 = torch.ops.aten.view.default(histc_48, [8, -1]);  histc_48 = None
        sum_98 = torch.ops.aten.sum.dim_IntList(view_1672, [1]);  view_1672 = None
        device_put_48 = torch.ops.prims.device_put.default(sum_98, device(type='cpu'), True);  sum_98 = None
        view_1673 = torch.ops.aten.view.default(wait_tensor_524, [8, -1])
        sum_99 = torch.ops.aten.sum.dim_IntList(view_1673, [1])
        device_put_49 = torch.ops.prims.device_put.default(sum_99, device(type='cpu'));  sum_99 = None
        select_384 = torch.ops.aten.select.int(device_put_48, 0, 0)
        _local_scalar_dense_384 = torch.ops.aten._local_scalar_dense.default(select_384);  select_384 = None
        ge_480 = _local_scalar_dense_384 >= 0
        _assert_scalar_384 = torch.ops.aten._assert_scalar.default(ge_480, "Runtime assertion failed for expression u384 >= 0 on node 'ge_384'");  ge_480 = _assert_scalar_384 = None
        select_385 = torch.ops.aten.select.int(device_put_48, 0, 1)
        _local_scalar_dense_385 = torch.ops.aten._local_scalar_dense.default(select_385);  select_385 = None
        ge_481 = _local_scalar_dense_385 >= 0
        _assert_scalar_385 = torch.ops.aten._assert_scalar.default(ge_481, "Runtime assertion failed for expression u385 >= 0 on node 'ge_385'");  ge_481 = _assert_scalar_385 = None
        select_386 = torch.ops.aten.select.int(device_put_48, 0, 2)
        _local_scalar_dense_386 = torch.ops.aten._local_scalar_dense.default(select_386);  select_386 = None
        ge_482 = _local_scalar_dense_386 >= 0
        _assert_scalar_386 = torch.ops.aten._assert_scalar.default(ge_482, "Runtime assertion failed for expression u386 >= 0 on node 'ge_386'");  ge_482 = _assert_scalar_386 = None
        select_387 = torch.ops.aten.select.int(device_put_48, 0, 3)
        _local_scalar_dense_387 = torch.ops.aten._local_scalar_dense.default(select_387);  select_387 = None
        ge_483 = _local_scalar_dense_387 >= 0
        _assert_scalar_387 = torch.ops.aten._assert_scalar.default(ge_483, "Runtime assertion failed for expression u387 >= 0 on node 'ge_387'");  ge_483 = _assert_scalar_387 = None
        select_388 = torch.ops.aten.select.int(device_put_48, 0, 4)
        _local_scalar_dense_388 = torch.ops.aten._local_scalar_dense.default(select_388);  select_388 = None
        ge_484 = _local_scalar_dense_388 >= 0
        _assert_scalar_388 = torch.ops.aten._assert_scalar.default(ge_484, "Runtime assertion failed for expression u388 >= 0 on node 'ge_388'");  ge_484 = _assert_scalar_388 = None
        select_389 = torch.ops.aten.select.int(device_put_48, 0, 5)
        _local_scalar_dense_389 = torch.ops.aten._local_scalar_dense.default(select_389);  select_389 = None
        ge_485 = _local_scalar_dense_389 >= 0
        _assert_scalar_389 = torch.ops.aten._assert_scalar.default(ge_485, "Runtime assertion failed for expression u389 >= 0 on node 'ge_389'");  ge_485 = _assert_scalar_389 = None
        select_390 = torch.ops.aten.select.int(device_put_48, 0, 6)
        _local_scalar_dense_390 = torch.ops.aten._local_scalar_dense.default(select_390);  select_390 = None
        ge_486 = _local_scalar_dense_390 >= 0
        _assert_scalar_390 = torch.ops.aten._assert_scalar.default(ge_486, "Runtime assertion failed for expression u390 >= 0 on node 'ge_390'");  ge_486 = _assert_scalar_390 = None
        select_391 = torch.ops.aten.select.int(device_put_48, 0, 7);  device_put_48 = None
        _local_scalar_dense_391 = torch.ops.aten._local_scalar_dense.default(select_391);  select_391 = None
        ge_487 = _local_scalar_dense_391 >= 0
        _assert_scalar_391 = torch.ops.aten._assert_scalar.default(ge_487, "Runtime assertion failed for expression u391 >= 0 on node 'ge_391'");  ge_487 = _assert_scalar_391 = None
        select_392 = torch.ops.aten.select.int(device_put_49, 0, 0)
        _local_scalar_dense_392 = torch.ops.aten._local_scalar_dense.default(select_392);  select_392 = None
        ge_488 = _local_scalar_dense_392 >= 0
        _assert_scalar_392 = torch.ops.aten._assert_scalar.default(ge_488, "Runtime assertion failed for expression u392 >= 0 on node 'ge_392'");  ge_488 = _assert_scalar_392 = None
        select_393 = torch.ops.aten.select.int(device_put_49, 0, 1)
        _local_scalar_dense_393 = torch.ops.aten._local_scalar_dense.default(select_393);  select_393 = None
        ge_489 = _local_scalar_dense_393 >= 0
        _assert_scalar_393 = torch.ops.aten._assert_scalar.default(ge_489, "Runtime assertion failed for expression u393 >= 0 on node 'ge_393'");  ge_489 = _assert_scalar_393 = None
        select_394 = torch.ops.aten.select.int(device_put_49, 0, 2)
        _local_scalar_dense_394 = torch.ops.aten._local_scalar_dense.default(select_394);  select_394 = None
        ge_490 = _local_scalar_dense_394 >= 0
        _assert_scalar_394 = torch.ops.aten._assert_scalar.default(ge_490, "Runtime assertion failed for expression u394 >= 0 on node 'ge_394'");  ge_490 = _assert_scalar_394 = None
        select_395 = torch.ops.aten.select.int(device_put_49, 0, 3)
        _local_scalar_dense_395 = torch.ops.aten._local_scalar_dense.default(select_395);  select_395 = None
        ge_491 = _local_scalar_dense_395 >= 0
        _assert_scalar_395 = torch.ops.aten._assert_scalar.default(ge_491, "Runtime assertion failed for expression u395 >= 0 on node 'ge_395'");  ge_491 = _assert_scalar_395 = None
        select_396 = torch.ops.aten.select.int(device_put_49, 0, 4)
        _local_scalar_dense_396 = torch.ops.aten._local_scalar_dense.default(select_396);  select_396 = None
        ge_492 = _local_scalar_dense_396 >= 0
        _assert_scalar_396 = torch.ops.aten._assert_scalar.default(ge_492, "Runtime assertion failed for expression u396 >= 0 on node 'ge_396'");  ge_492 = _assert_scalar_396 = None
        select_397 = torch.ops.aten.select.int(device_put_49, 0, 5)
        _local_scalar_dense_397 = torch.ops.aten._local_scalar_dense.default(select_397);  select_397 = None
        ge_493 = _local_scalar_dense_397 >= 0
        _assert_scalar_397 = torch.ops.aten._assert_scalar.default(ge_493, "Runtime assertion failed for expression u397 >= 0 on node 'ge_397'");  ge_493 = _assert_scalar_397 = None
        select_398 = torch.ops.aten.select.int(device_put_49, 0, 6)
        _local_scalar_dense_398 = torch.ops.aten._local_scalar_dense.default(select_398);  select_398 = None
        ge_494 = _local_scalar_dense_398 >= 0
        _assert_scalar_398 = torch.ops.aten._assert_scalar.default(ge_494, "Runtime assertion failed for expression u398 >= 0 on node 'ge_398'");  ge_494 = _assert_scalar_398 = None
        select_399 = torch.ops.aten.select.int(device_put_49, 0, 7);  device_put_49 = None
        _local_scalar_dense_399 = torch.ops.aten._local_scalar_dense.default(select_399);  select_399 = None
        ge_495 = _local_scalar_dense_399 >= 0
        _assert_scalar_399 = torch.ops.aten._assert_scalar.default(ge_495, "Runtime assertion failed for expression u399 >= 0 on node 'ge_399'");  ge_495 = _assert_scalar_399 = None
        all_to_all_single_73 = torch.ops._c10d_functional.all_to_all_single.default(index_48, [_local_scalar_dense_392, _local_scalar_dense_393, _local_scalar_dense_394, _local_scalar_dense_395, _local_scalar_dense_396, _local_scalar_dense_397, _local_scalar_dense_398, _local_scalar_dense_399], [_local_scalar_dense_384, _local_scalar_dense_385, _local_scalar_dense_386, _local_scalar_dense_387, _local_scalar_dense_388, _local_scalar_dense_389, _local_scalar_dense_390, _local_scalar_dense_391], '1033');  index_48 = None
        sym_size_int_96 = torch.ops.aten.sym_size.int(all_to_all_single_73, 0)
        wait_tensor_525 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_73);  all_to_all_single_73 = None
        sym_sum_48 = torch.sym_sum((_local_scalar_dense_392, _local_scalar_dense_393, _local_scalar_dense_394, _local_scalar_dense_395, _local_scalar_dense_396, _local_scalar_dense_397, _local_scalar_dense_398, _local_scalar_dense_399))
        add_1650 = sym_sum_48 + 64;  sym_sum_48 = None
        add_1651 = add_1650 + 8;  add_1650 = None
        sub_579 = add_1651 - 1;  add_1651 = None
        floordiv_24 = sub_579 // 8;  sub_579 = None
        mul_1198 = floordiv_24 * 8;  floordiv_24 = None
        cumsum_72 = torch.ops.aten.cumsum.default(wait_tensor_524, 0)
        sub_580 = torch.ops.aten.sub.Tensor(cumsum_72, wait_tensor_524);  cumsum_72 = None
        sum_100 = torch.ops.aten.sum.dim_IntList(view_1673, [0]);  view_1673 = None
        clamp_min_24 = torch.ops.aten.clamp_min.default(sum_100, 8);  sum_100 = None
        add_1652 = torch.ops.aten.add.Tensor(clamp_min_24, 8);  clamp_min_24 = None
        sub_581 = torch.ops.aten.sub.Tensor(add_1652, 1);  add_1652 = None
        div_123 = torch.ops.aten.div.Tensor_mode(sub_581, 8, rounding_mode = 'floor');  sub_581 = None
        mul_1199 = torch.ops.aten.mul.Tensor(div_123, 8);  div_123 = None
        convert_element_type_1364 = torch.ops.prims.convert_element_type.default(mul_1199, torch.int32);  mul_1199 = None
        cumsum_73 = torch.ops.aten.cumsum.default(convert_element_type_1364, 0)
        sub_582 = torch.ops.aten.sub.Tensor(cumsum_73, convert_element_type_1364);  cumsum_73 = None
        full_332 = torch.ops.aten.full.default([mul_1198], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_1198 = None
        triton_kernel_wrapper_functional_proxy_24 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 24, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_524, 'start_index_values_ptr': sub_580, 'write_offsets_ptr': sub_582, 'output_ptr': full_332}, tensors_to_clone = ['output_ptr']);  wait_tensor_524 = sub_580 = sub_582 = full_332 = None
        getitem_2662 = triton_kernel_wrapper_functional_proxy_24['output_ptr'];  triton_kernel_wrapper_functional_proxy_24 = None
        cat_220 = torch.ops.aten.cat.default([wait_tensor_525, full_default]);  wait_tensor_525 = None
        sym_size_int_97 = torch.ops.aten.sym_size.int(cat_220, 0)
        sym_sum_49 = torch.sym_sum((1, _local_scalar_dense_392, _local_scalar_dense_393, _local_scalar_dense_394, _local_scalar_dense_395, _local_scalar_dense_396, _local_scalar_dense_397, _local_scalar_dense_398, _local_scalar_dense_399))
        index_49 = torch.ops.aten.index.Tensor(cat_220, [getitem_2662]);  cat_220 = None
        convert_element_type_1366 = torch.ops.prims.convert_element_type.default(primals_417, torch.bfloat16)
        all_gather_into_tensor_427 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1366, 16, '1025');  convert_element_type_1366 = None
        wait_tensor_526 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_427);  all_gather_into_tensor_427 = None
        split_145 = torch.ops.aten.split.Tensor(wait_tensor_526, 8);  wait_tensor_526 = None
        getitem_2679 = split_145[0]
        getitem_2680 = split_145[1]
        getitem_2681 = split_145[2]
        getitem_2682 = split_145[3]
        getitem_2683 = split_145[4]
        getitem_2684 = split_145[5]
        getitem_2685 = split_145[6]
        getitem_2686 = split_145[7]
        getitem_2687 = split_145[8]
        getitem_2688 = split_145[9]
        getitem_2689 = split_145[10]
        getitem_2690 = split_145[11]
        getitem_2691 = split_145[12]
        getitem_2692 = split_145[13]
        getitem_2693 = split_145[14]
        getitem_2694 = split_145[15];  split_145 = None
        cat_222 = torch.ops.aten.cat.default([getitem_2679, getitem_2680, getitem_2681, getitem_2682, getitem_2683, getitem_2684, getitem_2685, getitem_2686, getitem_2687, getitem_2688, getitem_2689, getitem_2690, getitem_2691, getitem_2692, getitem_2693, getitem_2694], 1);  getitem_2679 = getitem_2680 = getitem_2681 = getitem_2682 = getitem_2683 = getitem_2684 = getitem_2685 = getitem_2686 = getitem_2687 = getitem_2688 = getitem_2689 = getitem_2690 = getitem_2691 = getitem_2692 = getitem_2693 = getitem_2694 = None
        convert_element_type_1368 = torch.ops.prims.convert_element_type.default(primals_418, torch.bfloat16)
        all_gather_into_tensor_429 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1368, 16, '1025');  convert_element_type_1368 = None
        wait_tensor_528 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_429);  all_gather_into_tensor_429 = None
        split_146 = torch.ops.aten.split.Tensor(wait_tensor_528, 8);  wait_tensor_528 = None
        getitem_2695 = split_146[0]
        getitem_2696 = split_146[1]
        getitem_2697 = split_146[2]
        getitem_2698 = split_146[3]
        getitem_2699 = split_146[4]
        getitem_2700 = split_146[5]
        getitem_2701 = split_146[6]
        getitem_2702 = split_146[7]
        getitem_2703 = split_146[8]
        getitem_2704 = split_146[9]
        getitem_2705 = split_146[10]
        getitem_2706 = split_146[11]
        getitem_2707 = split_146[12]
        getitem_2708 = split_146[13]
        getitem_2709 = split_146[14]
        getitem_2710 = split_146[15];  split_146 = None
        cat_223 = torch.ops.aten.cat.default([getitem_2695, getitem_2696, getitem_2697, getitem_2698, getitem_2699, getitem_2700, getitem_2701, getitem_2702, getitem_2703, getitem_2704, getitem_2705, getitem_2706, getitem_2707, getitem_2708, getitem_2709, getitem_2710], 1);  getitem_2695 = getitem_2696 = getitem_2697 = getitem_2698 = getitem_2699 = getitem_2700 = getitem_2701 = getitem_2702 = getitem_2703 = getitem_2704 = getitem_2705 = getitem_2706 = getitem_2707 = getitem_2708 = getitem_2709 = getitem_2710 = None
        convert_element_type_1369 = torch.ops.prims.convert_element_type.default(primals_419, torch.bfloat16)
        all_gather_into_tensor_430 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1369, 16, '1025');  convert_element_type_1369 = None
        wait_tensor_529 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_430);  all_gather_into_tensor_430 = None
        split_147 = torch.ops.aten.split.Tensor(wait_tensor_529, 8);  wait_tensor_529 = None
        getitem_2711 = split_147[0]
        getitem_2712 = split_147[1]
        getitem_2713 = split_147[2]
        getitem_2714 = split_147[3]
        getitem_2715 = split_147[4]
        getitem_2716 = split_147[5]
        getitem_2717 = split_147[6]
        getitem_2718 = split_147[7]
        getitem_2719 = split_147[8]
        getitem_2720 = split_147[9]
        getitem_2721 = split_147[10]
        getitem_2722 = split_147[11]
        getitem_2723 = split_147[12]
        getitem_2724 = split_147[13]
        getitem_2725 = split_147[14]
        getitem_2726 = split_147[15];  split_147 = None
        cat_224 = torch.ops.aten.cat.default([getitem_2711, getitem_2712, getitem_2713, getitem_2714, getitem_2715, getitem_2716, getitem_2717, getitem_2718, getitem_2719, getitem_2720, getitem_2721, getitem_2722, getitem_2723, getitem_2724, getitem_2725, getitem_2726], 1);  getitem_2711 = getitem_2712 = getitem_2713 = getitem_2714 = getitem_2715 = getitem_2716 = getitem_2717 = getitem_2718 = getitem_2719 = getitem_2720 = getitem_2721 = getitem_2722 = getitem_2723 = getitem_2724 = getitem_2725 = getitem_2726 = None
        cumsum_74 = torch.ops.aten.cumsum.default(convert_element_type_1364, 0, dtype = torch.int32);  convert_element_type_1364 = None
        permute_380 = torch.ops.aten.permute.default(cat_222, [0, 2, 1]);  cat_222 = None
        _grouped_mm_72 = torch.ops.aten._grouped_mm.default(index_49, permute_380, cumsum_74)
        convert_element_type_1372 = torch.ops.prims.convert_element_type.default(_grouped_mm_72, torch.float32)
        neg_49 = torch.ops.aten.neg.default(convert_element_type_1372)
        exp_74 = torch.ops.aten.exp.default(neg_49);  neg_49 = None
        add_1664 = torch.ops.aten.add.Tensor(exp_74, 1);  exp_74 = None
        div_124 = torch.ops.aten.div.Tensor(convert_element_type_1372, add_1664);  convert_element_type_1372 = add_1664 = None
        convert_element_type_1373 = torch.ops.prims.convert_element_type.default(div_124, torch.bfloat16);  div_124 = None
        permute_381 = torch.ops.aten.permute.default(cat_224, [0, 2, 1]);  cat_224 = None
        _grouped_mm_73 = torch.ops.aten._grouped_mm.default(index_49, permute_381, cumsum_74)
        mul_1211 = torch.ops.aten.mul.Tensor(convert_element_type_1373, _grouped_mm_73);  convert_element_type_1373 = None
        permute_382 = torch.ops.aten.permute.default(cat_223, [0, 2, 1]);  cat_223 = None
        _grouped_mm_74 = torch.ops.aten._grouped_mm.default(mul_1211, permute_382, cumsum_74)
        empty_24 = torch.ops.aten.empty.memory_format([sym_size_int_97, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_48 = torch.ops.aten.index_put.default(empty_24, [getitem_2662], _grouped_mm_74);  empty_24 = _grouped_mm_74 = None
        slice_155 = torch.ops.aten.slice.Tensor(index_put_48, 0, 0, -1);  index_put_48 = None
        all_to_all_single_74 = torch.ops._c10d_functional.all_to_all_single.default(slice_155, [_local_scalar_dense_384, _local_scalar_dense_385, _local_scalar_dense_386, _local_scalar_dense_387, _local_scalar_dense_388, _local_scalar_dense_389, _local_scalar_dense_390, _local_scalar_dense_391], [_local_scalar_dense_392, _local_scalar_dense_393, _local_scalar_dense_394, _local_scalar_dense_395, _local_scalar_dense_396, _local_scalar_dense_397, _local_scalar_dense_398, _local_scalar_dense_399], '1033');  slice_155 = None
        wait_tensor_532 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_74);  all_to_all_single_74 = None
        convert_element_type_1374 = torch.ops.prims.convert_element_type.default(primals_420, torch.bfloat16)
        all_gather_into_tensor_433 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1374, 128, '0');  convert_element_type_1374 = None
        wait_tensor_533 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_433);  all_gather_into_tensor_433 = None
        permute_383 = torch.ops.aten.permute.default(wait_tensor_533, [1, 0]);  wait_tensor_533 = None
        mm_204 = torch.ops.aten.mm.default(view_1666, permute_383);  permute_383 = None
        convert_element_type_1377 = torch.ops.prims.convert_element_type.default(mm_204, torch.float32)
        neg_50 = torch.ops.aten.neg.default(convert_element_type_1377)
        exp_75 = torch.ops.aten.exp.default(neg_50);  neg_50 = None
        add_1700 = torch.ops.aten.add.Tensor(exp_75, 1);  exp_75 = None
        div_125 = torch.ops.aten.div.Tensor(convert_element_type_1377, add_1700);  convert_element_type_1377 = add_1700 = None
        convert_element_type_1378 = torch.ops.prims.convert_element_type.default(div_125, torch.bfloat16);  div_125 = None
        convert_element_type_1379 = torch.ops.prims.convert_element_type.default(primals_421, torch.bfloat16)
        all_gather_into_tensor_434 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1379, 128, '0');  convert_element_type_1379 = None
        wait_tensor_534 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_434);  all_gather_into_tensor_434 = None
        permute_384 = torch.ops.aten.permute.default(wait_tensor_534, [1, 0]);  wait_tensor_534 = None
        mm_205 = torch.ops.aten.mm.default(view_1666, permute_384);  permute_384 = None
        mul_1231 = torch.ops.aten.mul.Tensor(convert_element_type_1378, mm_205);  convert_element_type_1378 = None
        convert_element_type_1382 = torch.ops.prims.convert_element_type.default(primals_422, torch.bfloat16)
        all_gather_into_tensor_435 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1382, 128, '0');  convert_element_type_1382 = None
        wait_tensor_535 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_435);  all_gather_into_tensor_435 = None
        permute_385 = torch.ops.aten.permute.default(wait_tensor_535, [1, 0]);  wait_tensor_535 = None
        mm_206 = torch.ops.aten.mm.default(mul_1231, permute_385);  permute_385 = None
        index_put_49 = torch.ops.aten.index_put.default(full_default_1, [getitem_2661], wait_tensor_532);  wait_tensor_532 = None
        view_1706 = torch.ops.aten.view.default(mul_1193, [-1, 1, 6]);  mul_1193 = None
        view_1707 = torch.ops.aten.view.default(index_put_49, [-1, 6, 2048]);  index_put_49 = None
        convert_element_type_1385 = torch.ops.prims.convert_element_type.default(view_1707, torch.float32);  view_1707 = None
        bmm_24 = torch.ops.aten.bmm.default(view_1706, convert_element_type_1385)
        convert_element_type_1386 = torch.ops.prims.convert_element_type.default(bmm_24, torch.bfloat16);  bmm_24 = None
        squeeze_24 = torch.ops.aten.squeeze.dim(convert_element_type_1386, 1);  convert_element_type_1386 = None
        add_1704 = torch.ops.aten.add.Tensor(mm_206, squeeze_24);  mm_206 = squeeze_24 = None
        view_1708 = torch.ops.aten.view.default(add_1704, [2, 4096, 2048]);  add_1704 = None
        add_1705 = torch.ops.aten.add.Tensor(add_1640, view_1708);  view_1708 = None
        convert_element_type_1387 = torch.ops.prims.convert_element_type.default(primals_423, torch.bfloat16)
        all_gather_into_tensor_436 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1387, 128, '0');  convert_element_type_1387 = None
        wait_tensor_536 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_436);  all_gather_into_tensor_436 = None
        convert_element_type_1388 = torch.ops.prims.convert_element_type.default(add_1705, torch.float32)
        pow_79 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1388, 2)
        mean_78 = torch.ops.aten.mean.dim(pow_79, [2], True);  pow_79 = None
        add_1706 = torch.ops.aten.add.Scalar(mean_78, 1e-05);  mean_78 = None
        rsqrt_78 = torch.ops.aten.rsqrt.default(add_1706);  add_1706 = None
        mul_1234 = torch.ops.aten.mul.Tensor(convert_element_type_1388, rsqrt_78);  convert_element_type_1388 = None
        mul_1235 = torch.ops.aten.mul.Tensor(mul_1234, wait_tensor_536);  mul_1234 = wait_tensor_536 = None
        convert_element_type_1389 = torch.ops.prims.convert_element_type.default(mul_1235, torch.bfloat16);  mul_1235 = None
        convert_element_type_1390 = torch.ops.prims.convert_element_type.default(primals_424, torch.bfloat16)
        all_gather_into_tensor_437 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1390, 128, '0');  convert_element_type_1390 = None
        wait_tensor_537 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_437);  all_gather_into_tensor_437 = None
        permute_386 = torch.ops.aten.permute.default(wait_tensor_537, [1, 0]);  wait_tensor_537 = None
        view_1711 = torch.ops.aten.view.default(convert_element_type_1389, [8192, 2048]);  convert_element_type_1389 = None
        mm_207 = torch.ops.aten.mm.default(view_1711, permute_386);  permute_386 = None
        view_1712 = torch.ops.aten.view.default(mm_207, [2, 4096, 3072]);  mm_207 = None
        view_1713 = torch.ops.aten.view.default(view_1712, [2, 4096, -1, 192]);  view_1712 = None
        split_with_sizes_78 = torch.ops.aten.split_with_sizes.default(view_1713, [128, 64], -1);  view_1713 = None
        getitem_2759 = split_with_sizes_78[0]
        getitem_2760 = split_with_sizes_78[1];  split_with_sizes_78 = None
        convert_element_type_1393 = torch.ops.prims.convert_element_type.default(getitem_2760, torch.float32);  getitem_2760 = None
        view_1714 = torch.ops.aten.view.default(convert_element_type_1393, [2, 4096, 16, -1, 2]);  convert_element_type_1393 = None
        view_as_complex_52 = torch.ops.aten.view_as_complex.default(view_1714);  view_1714 = None
        mul_1236 = torch.ops.aten.mul.Tensor(view_as_complex_52, view_7);  view_as_complex_52 = None
        view_as_real_52 = torch.ops.aten.view_as_real.default(mul_1236);  mul_1236 = None
        view_1716 = torch.ops.aten.view.default(view_as_real_52, [2, 4096, 16, 64]);  view_as_real_52 = None
        convert_element_type_1394 = torch.ops.prims.convert_element_type.default(view_1716, torch.bfloat16);  view_1716 = None
        cat_227 = torch.ops.aten.cat.default([getitem_2759, convert_element_type_1394], -1);  getitem_2759 = convert_element_type_1394 = None
        convert_element_type_1395 = torch.ops.prims.convert_element_type.default(primals_425, torch.bfloat16)
        all_gather_into_tensor_438 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1395, 128, '0');  convert_element_type_1395 = None
        wait_tensor_538 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_438);  all_gather_into_tensor_438 = None
        slice_157 = torch.ops.aten.slice.Tensor(wait_tensor_538, 0, 0, 576);  wait_tensor_538 = None
        permute_387 = torch.ops.aten.permute.default(slice_157, [1, 0]);  slice_157 = None
        mm_208 = torch.ops.aten.mm.default(view_1711, permute_387);  permute_387 = None
        view_1719 = torch.ops.aten.view.default(mm_208, [2, 4096, 576]);  mm_208 = None
        split_with_sizes_79 = torch.ops.aten.split_with_sizes.default(view_1719, [512, 64], -1);  view_1719 = None
        getitem_2761 = split_with_sizes_79[0]
        getitem_2762 = split_with_sizes_79[1];  split_with_sizes_79 = None
        unsqueeze_51 = torch.ops.aten.unsqueeze.default(getitem_2762, 2);  getitem_2762 = None
        convert_element_type_1398 = torch.ops.prims.convert_element_type.default(unsqueeze_51, torch.float32);  unsqueeze_51 = None
        view_1720 = torch.ops.aten.view.default(convert_element_type_1398, [2, 4096, 1, -1, 2]);  convert_element_type_1398 = None
        view_as_complex_53 = torch.ops.aten.view_as_complex.default(view_1720);  view_1720 = None
        mul_1237 = torch.ops.aten.mul.Tensor(view_as_complex_53, view_7);  view_as_complex_53 = view_7 = None
        view_as_real_53 = torch.ops.aten.view_as_real.default(mul_1237);  mul_1237 = None
        view_1722 = torch.ops.aten.view.default(view_as_real_53, [2, 4096, 1, 64]);  view_as_real_53 = None
        convert_element_type_1399 = torch.ops.prims.convert_element_type.default(view_1722, torch.bfloat16);  view_1722 = None
        convert_element_type_1400 = torch.ops.prims.convert_element_type.default(primals_426, torch.bfloat16)
        all_gather_into_tensor_439 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1400, 128, '0');  convert_element_type_1400 = None
        wait_tensor_539 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_439);  all_gather_into_tensor_439 = None
        convert_element_type_1401 = torch.ops.prims.convert_element_type.default(getitem_2761, torch.float32)
        pow_80 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1401, 2)
        mean_79 = torch.ops.aten.mean.dim(pow_80, [2], True);  pow_80 = None
        add_1707 = torch.ops.aten.add.Scalar(mean_79, 1e-05);  mean_79 = None
        rsqrt_79 = torch.ops.aten.rsqrt.default(add_1707);  add_1707 = None
        mul_1238 = torch.ops.aten.mul.Tensor(convert_element_type_1401, rsqrt_79);  convert_element_type_1401 = None
        mul_1239 = torch.ops.aten.mul.Tensor(mul_1238, wait_tensor_539);  mul_1238 = wait_tensor_539 = None
        convert_element_type_1402 = torch.ops.prims.convert_element_type.default(mul_1239, torch.bfloat16);  mul_1239 = None
        convert_element_type_1403 = torch.ops.prims.convert_element_type.default(primals_427, torch.bfloat16)
        all_gather_into_tensor_440 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1403, 128, '0');  convert_element_type_1403 = None
        wait_tensor_540 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_440);  all_gather_into_tensor_440 = None
        permute_388 = torch.ops.aten.permute.default(wait_tensor_540, [1, 0]);  wait_tensor_540 = None
        view_1725 = torch.ops.aten.view.default(convert_element_type_1402, [8192, 512]);  convert_element_type_1402 = None
        mm_209 = torch.ops.aten.mm.default(view_1725, permute_388);  permute_388 = None
        view_1726 = torch.ops.aten.view.default(mm_209, [2, 4096, 4096]);  mm_209 = None
        view_1727 = torch.ops.aten.view.default(view_1726, [2, 4096, -1, 256]);  view_1726 = None
        split_with_sizes_80 = torch.ops.aten.split_with_sizes.default(view_1727, [128, 128], -1);  view_1727 = None
        getitem_2763 = split_with_sizes_80[0]
        getitem_2764 = split_with_sizes_80[1];  split_with_sizes_80 = None
        expand_26 = torch.ops.aten.expand.default(convert_element_type_1399, [-1, -1, 16, -1]);  convert_element_type_1399 = None
        cat_228 = torch.ops.aten.cat.default([getitem_2763, expand_26], -1);  getitem_2763 = expand_26 = None
        permute_389 = torch.ops.aten.permute.default(cat_227, [0, 2, 1, 3]);  cat_227 = None
        permute_390 = torch.ops.aten.permute.default(cat_228, [0, 2, 1, 3]);  cat_228 = None
        permute_391 = torch.ops.aten.permute.default(getitem_2764, [0, 2, 1, 3]);  getitem_2764 = None
        sdpa_score26 = self.sdpa_score26
        sdpa_mask26 = self.sdpa_mask26
        flex_attention_26 = torch.ops.higher_order.flex_attention(permute_389, permute_390, permute_391, sdpa_score26, (4096, 4096, primals_10, primals_9, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, 128, 128, sdpa_mask26), 0.07216878364870322, {'BACKEND': 'AUTO', 'PRESCALE_QK': False, 'ROWS_GUARANTEED_SAFE': False, 'BLOCKS_ARE_CONTIGUOUS': False, 'WRITE_DQ': True, 'OUTPUT_LOGSUMEXP': True, 'OUTPUT_MAX': False}, (), (primals_11,));  sdpa_score26 = sdpa_mask26 = None
        getitem_2765 = flex_attention_26[0]
        getitem_2766 = flex_attention_26[1];  flex_attention_26 = None
        permute_392 = torch.ops.aten.permute.default(getitem_2765, [0, 2, 1, 3])
        view_1728 = torch.ops.aten.view.default(permute_392, [2, 4096, -1]);  permute_392 = None
        convert_element_type_1406 = torch.ops.prims.convert_element_type.default(primals_428, torch.bfloat16)
        all_gather_into_tensor_441 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1406, 128, '0');  convert_element_type_1406 = None
        wait_tensor_541 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_441);  all_gather_into_tensor_441 = None
        permute_393 = torch.ops.aten.permute.default(wait_tensor_541, [1, 0]);  wait_tensor_541 = None
        view_1730 = torch.ops.aten.view.default(view_1728, [8192, 2048]);  view_1728 = None
        mm_210 = torch.ops.aten.mm.default(view_1730, permute_393);  view_1730 = permute_393 = None
        view_1731 = torch.ops.aten.view.default(mm_210, [2, 4096, 2048]);  mm_210 = None
        add_1708 = torch.ops.aten.add.Tensor(add_1705, view_1731);  view_1731 = None
        convert_element_type_1409 = torch.ops.prims.convert_element_type.default(primals_429, torch.bfloat16)
        all_gather_into_tensor_442 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1409, 128, '0');  convert_element_type_1409 = None
        wait_tensor_542 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_442);  all_gather_into_tensor_442 = None
        convert_element_type_1410 = torch.ops.prims.convert_element_type.default(add_1708, torch.float32)
        pow_81 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1410, 2)
        mean_80 = torch.ops.aten.mean.dim(pow_81, [2], True);  pow_81 = None
        add_1709 = torch.ops.aten.add.Scalar(mean_80, 1e-05);  mean_80 = None
        rsqrt_80 = torch.ops.aten.rsqrt.default(add_1709);  add_1709 = None
        mul_1240 = torch.ops.aten.mul.Tensor(convert_element_type_1410, rsqrt_80);  convert_element_type_1410 = None
        mul_1241 = torch.ops.aten.mul.Tensor(mul_1240, wait_tensor_542);  mul_1240 = wait_tensor_542 = None
        convert_element_type_1411 = torch.ops.prims.convert_element_type.default(mul_1241, torch.bfloat16);  mul_1241 = None
        view_1733 = torch.ops.aten.view.default(convert_element_type_1411, [-1, 2048]);  convert_element_type_1411 = None
        convert_element_type_1412 = torch.ops.prims.convert_element_type.default(primals_431, torch.bfloat16)
        all_gather_into_tensor_443 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1412, 128, '0');  convert_element_type_1412 = None
        wait_tensor_543 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_443);  all_gather_into_tensor_443 = None
        slice_159 = torch.ops.aten.slice.Tensor(wait_tensor_543, 0, 0, 64);  wait_tensor_543 = None
        permute_394 = torch.ops.aten.permute.default(slice_159, [1, 0]);  slice_159 = None
        mm_211 = torch.ops.aten.mm.default(view_1733, permute_394);  permute_394 = None
        convert_element_type_1415 = torch.ops.prims.convert_element_type.default(mm_211, torch.float32)
        amax_25 = torch.ops.aten.amax.default(convert_element_type_1415, [1], True)
        sub_600 = torch.ops.aten.sub.Tensor(convert_element_type_1415, amax_25);  convert_element_type_1415 = None
        exp_76 = torch.ops.aten.exp.default(sub_600);  sub_600 = None
        sum_101 = torch.ops.aten.sum.dim_IntList(exp_76, [1], True)
        div_126 = torch.ops.aten.div.Tensor(exp_76, sum_101);  exp_76 = None
        add_1710 = torch.ops.aten.add.Tensor(div_126, primals_430);  primals_430 = None
        topk_25 = torch.ops.aten.topk.default(add_1710, 6, -1, True, False);  add_1710 = None
        getitem_2769 = topk_25[1];  topk_25 = None
        gather_25 = torch.ops.aten.gather.default(div_126, 1, getitem_2769);  div_126 = None
        mul_1242 = torch.ops.aten.mul.Tensor(gather_25, 1.0);  gather_25 = None
        view_1735 = torch.ops.aten.view.default(getitem_2769, [-1])
        histc_50 = torch.ops.aten.histc.default(view_1735, 64, 0, 64)
        add_1711 = torch.ops.aten.add.Tensor(primals_432, histc_50)
        sort_25 = torch.ops.aten.sort.stable(view_1735, stable = True);  view_1735 = None
        getitem_2771 = sort_25[1];  sort_25 = None
        div_127 = torch.ops.aten.div.Tensor_mode(getitem_2771, 6, rounding_mode = 'floor')
        index_50 = torch.ops.aten.index.Tensor(view_1733, [div_127])
        all_to_all_single_75 = torch.ops._c10d_functional.all_to_all_single.default(histc_50, [8, 8, 8, 8, 8, 8, 8, 8], [8, 8, 8, 8, 8, 8, 8, 8], '1033')
        wait_tensor_544 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_75);  all_to_all_single_75 = None
        wait_tensor_545 = torch.ops._c10d_functional.wait_tensor.default(wait_tensor_544);  wait_tensor_544 = None
        view_1739 = torch.ops.aten.view.default(histc_50, [8, -1]);  histc_50 = None
        sum_102 = torch.ops.aten.sum.dim_IntList(view_1739, [1]);  view_1739 = None
        device_put_50 = torch.ops.prims.device_put.default(sum_102, device(type='cpu'), True);  sum_102 = None
        view_1740 = torch.ops.aten.view.default(wait_tensor_545, [8, -1])
        sum_103 = torch.ops.aten.sum.dim_IntList(view_1740, [1])
        device_put_51 = torch.ops.prims.device_put.default(sum_103, device(type='cpu'));  sum_103 = None
        select_400 = torch.ops.aten.select.int(device_put_50, 0, 0)
        _local_scalar_dense_400 = torch.ops.aten._local_scalar_dense.default(select_400);  select_400 = None
        ge_500 = _local_scalar_dense_400 >= 0
        _assert_scalar_400 = torch.ops.aten._assert_scalar.default(ge_500, "Runtime assertion failed for expression u400 >= 0 on node 'ge_400'");  ge_500 = _assert_scalar_400 = None
        select_401 = torch.ops.aten.select.int(device_put_50, 0, 1)
        _local_scalar_dense_401 = torch.ops.aten._local_scalar_dense.default(select_401);  select_401 = None
        ge_501 = _local_scalar_dense_401 >= 0
        _assert_scalar_401 = torch.ops.aten._assert_scalar.default(ge_501, "Runtime assertion failed for expression u401 >= 0 on node 'ge_401'");  ge_501 = _assert_scalar_401 = None
        select_402 = torch.ops.aten.select.int(device_put_50, 0, 2)
        _local_scalar_dense_402 = torch.ops.aten._local_scalar_dense.default(select_402);  select_402 = None
        ge_502 = _local_scalar_dense_402 >= 0
        _assert_scalar_402 = torch.ops.aten._assert_scalar.default(ge_502, "Runtime assertion failed for expression u402 >= 0 on node 'ge_402'");  ge_502 = _assert_scalar_402 = None
        select_403 = torch.ops.aten.select.int(device_put_50, 0, 3)
        _local_scalar_dense_403 = torch.ops.aten._local_scalar_dense.default(select_403);  select_403 = None
        ge_503 = _local_scalar_dense_403 >= 0
        _assert_scalar_403 = torch.ops.aten._assert_scalar.default(ge_503, "Runtime assertion failed for expression u403 >= 0 on node 'ge_403'");  ge_503 = _assert_scalar_403 = None
        select_404 = torch.ops.aten.select.int(device_put_50, 0, 4)
        _local_scalar_dense_404 = torch.ops.aten._local_scalar_dense.default(select_404);  select_404 = None
        ge_504 = _local_scalar_dense_404 >= 0
        _assert_scalar_404 = torch.ops.aten._assert_scalar.default(ge_504, "Runtime assertion failed for expression u404 >= 0 on node 'ge_404'");  ge_504 = _assert_scalar_404 = None
        select_405 = torch.ops.aten.select.int(device_put_50, 0, 5)
        _local_scalar_dense_405 = torch.ops.aten._local_scalar_dense.default(select_405);  select_405 = None
        ge_505 = _local_scalar_dense_405 >= 0
        _assert_scalar_405 = torch.ops.aten._assert_scalar.default(ge_505, "Runtime assertion failed for expression u405 >= 0 on node 'ge_405'");  ge_505 = _assert_scalar_405 = None
        select_406 = torch.ops.aten.select.int(device_put_50, 0, 6)
        _local_scalar_dense_406 = torch.ops.aten._local_scalar_dense.default(select_406);  select_406 = None
        ge_506 = _local_scalar_dense_406 >= 0
        _assert_scalar_406 = torch.ops.aten._assert_scalar.default(ge_506, "Runtime assertion failed for expression u406 >= 0 on node 'ge_406'");  ge_506 = _assert_scalar_406 = None
        select_407 = torch.ops.aten.select.int(device_put_50, 0, 7);  device_put_50 = None
        _local_scalar_dense_407 = torch.ops.aten._local_scalar_dense.default(select_407);  select_407 = None
        ge_507 = _local_scalar_dense_407 >= 0
        _assert_scalar_407 = torch.ops.aten._assert_scalar.default(ge_507, "Runtime assertion failed for expression u407 >= 0 on node 'ge_407'");  ge_507 = _assert_scalar_407 = None
        select_408 = torch.ops.aten.select.int(device_put_51, 0, 0)
        _local_scalar_dense_408 = torch.ops.aten._local_scalar_dense.default(select_408);  select_408 = None
        ge_508 = _local_scalar_dense_408 >= 0
        _assert_scalar_408 = torch.ops.aten._assert_scalar.default(ge_508, "Runtime assertion failed for expression u408 >= 0 on node 'ge_408'");  ge_508 = _assert_scalar_408 = None
        select_409 = torch.ops.aten.select.int(device_put_51, 0, 1)
        _local_scalar_dense_409 = torch.ops.aten._local_scalar_dense.default(select_409);  select_409 = None
        ge_509 = _local_scalar_dense_409 >= 0
        _assert_scalar_409 = torch.ops.aten._assert_scalar.default(ge_509, "Runtime assertion failed for expression u409 >= 0 on node 'ge_409'");  ge_509 = _assert_scalar_409 = None
        select_410 = torch.ops.aten.select.int(device_put_51, 0, 2)
        _local_scalar_dense_410 = torch.ops.aten._local_scalar_dense.default(select_410);  select_410 = None
        ge_510 = _local_scalar_dense_410 >= 0
        _assert_scalar_410 = torch.ops.aten._assert_scalar.default(ge_510, "Runtime assertion failed for expression u410 >= 0 on node 'ge_410'");  ge_510 = _assert_scalar_410 = None
        select_411 = torch.ops.aten.select.int(device_put_51, 0, 3)
        _local_scalar_dense_411 = torch.ops.aten._local_scalar_dense.default(select_411);  select_411 = None
        ge_511 = _local_scalar_dense_411 >= 0
        _assert_scalar_411 = torch.ops.aten._assert_scalar.default(ge_511, "Runtime assertion failed for expression u411 >= 0 on node 'ge_411'");  ge_511 = _assert_scalar_411 = None
        select_412 = torch.ops.aten.select.int(device_put_51, 0, 4)
        _local_scalar_dense_412 = torch.ops.aten._local_scalar_dense.default(select_412);  select_412 = None
        ge_512 = _local_scalar_dense_412 >= 0
        _assert_scalar_412 = torch.ops.aten._assert_scalar.default(ge_512, "Runtime assertion failed for expression u412 >= 0 on node 'ge_412'");  ge_512 = _assert_scalar_412 = None
        select_413 = torch.ops.aten.select.int(device_put_51, 0, 5)
        _local_scalar_dense_413 = torch.ops.aten._local_scalar_dense.default(select_413);  select_413 = None
        ge_513 = _local_scalar_dense_413 >= 0
        _assert_scalar_413 = torch.ops.aten._assert_scalar.default(ge_513, "Runtime assertion failed for expression u413 >= 0 on node 'ge_413'");  ge_513 = _assert_scalar_413 = None
        select_414 = torch.ops.aten.select.int(device_put_51, 0, 6)
        _local_scalar_dense_414 = torch.ops.aten._local_scalar_dense.default(select_414);  select_414 = None
        ge_514 = _local_scalar_dense_414 >= 0
        _assert_scalar_414 = torch.ops.aten._assert_scalar.default(ge_514, "Runtime assertion failed for expression u414 >= 0 on node 'ge_414'");  ge_514 = _assert_scalar_414 = None
        select_415 = torch.ops.aten.select.int(device_put_51, 0, 7);  device_put_51 = None
        _local_scalar_dense_415 = torch.ops.aten._local_scalar_dense.default(select_415);  select_415 = None
        ge_515 = _local_scalar_dense_415 >= 0
        _assert_scalar_415 = torch.ops.aten._assert_scalar.default(ge_515, "Runtime assertion failed for expression u415 >= 0 on node 'ge_415'");  ge_515 = _assert_scalar_415 = None
        all_to_all_single_76 = torch.ops._c10d_functional.all_to_all_single.default(index_50, [_local_scalar_dense_408, _local_scalar_dense_409, _local_scalar_dense_410, _local_scalar_dense_411, _local_scalar_dense_412, _local_scalar_dense_413, _local_scalar_dense_414, _local_scalar_dense_415], [_local_scalar_dense_400, _local_scalar_dense_401, _local_scalar_dense_402, _local_scalar_dense_403, _local_scalar_dense_404, _local_scalar_dense_405, _local_scalar_dense_406, _local_scalar_dense_407], '1033');  index_50 = None
        sym_size_int_100 = torch.ops.aten.sym_size.int(all_to_all_single_76, 0)
        wait_tensor_546 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_76);  all_to_all_single_76 = None
        sym_sum_50 = torch.sym_sum((_local_scalar_dense_408, _local_scalar_dense_409, _local_scalar_dense_410, _local_scalar_dense_411, _local_scalar_dense_412, _local_scalar_dense_413, _local_scalar_dense_414, _local_scalar_dense_415))
        add_1718 = sym_sum_50 + 64;  sym_sum_50 = None
        add_1719 = add_1718 + 8;  add_1718 = None
        sub_603 = add_1719 - 1;  add_1719 = None
        floordiv_25 = sub_603 // 8;  sub_603 = None
        mul_1247 = floordiv_25 * 8;  floordiv_25 = None
        cumsum_75 = torch.ops.aten.cumsum.default(wait_tensor_545, 0)
        sub_604 = torch.ops.aten.sub.Tensor(cumsum_75, wait_tensor_545);  cumsum_75 = None
        sum_104 = torch.ops.aten.sum.dim_IntList(view_1740, [0]);  view_1740 = None
        clamp_min_25 = torch.ops.aten.clamp_min.default(sum_104, 8);  sum_104 = None
        add_1720 = torch.ops.aten.add.Tensor(clamp_min_25, 8);  clamp_min_25 = None
        sub_605 = torch.ops.aten.sub.Tensor(add_1720, 1);  add_1720 = None
        div_128 = torch.ops.aten.div.Tensor_mode(sub_605, 8, rounding_mode = 'floor');  sub_605 = None
        mul_1248 = torch.ops.aten.mul.Tensor(div_128, 8);  div_128 = None
        convert_element_type_1418 = torch.ops.prims.convert_element_type.default(mul_1248, torch.int32);  mul_1248 = None
        cumsum_76 = torch.ops.aten.cumsum.default(convert_element_type_1418, 0)
        sub_606 = torch.ops.aten.sub.Tensor(cumsum_76, convert_element_type_1418);  cumsum_76 = None
        full_345 = torch.ops.aten.full.default([mul_1247], -1, dtype = torch.int32, device = device(type='cuda', index=0), pin_memory = False);  mul_1247 = None
        triton_kernel_wrapper_functional_proxy_25 = torch.ops.higher_order.triton_kernel_wrapper_functional(kernel_idx = 0, constant_args_idx = 25, grid = [(8, 1, 1)], tma_descriptor_metadata = {}, kwargs = {'tokens_per_expert_group_ptr': wait_tensor_545, 'start_index_values_ptr': sub_604, 'write_offsets_ptr': sub_606, 'output_ptr': full_345}, tensors_to_clone = ['output_ptr']);  wait_tensor_545 = sub_604 = sub_606 = full_345 = None
        getitem_2772 = triton_kernel_wrapper_functional_proxy_25['output_ptr'];  triton_kernel_wrapper_functional_proxy_25 = None
        cat_229 = torch.ops.aten.cat.default([wait_tensor_546, full_default]);  wait_tensor_546 = full_default = None
        sym_size_int_101 = torch.ops.aten.sym_size.int(cat_229, 0)
        sym_sum_51 = torch.sym_sum((1, _local_scalar_dense_408, _local_scalar_dense_409, _local_scalar_dense_410, _local_scalar_dense_411, _local_scalar_dense_412, _local_scalar_dense_413, _local_scalar_dense_414, _local_scalar_dense_415))
        index_51 = torch.ops.aten.index.Tensor(cat_229, [getitem_2772]);  cat_229 = None
        convert_element_type_1420 = torch.ops.prims.convert_element_type.default(primals_433, torch.bfloat16)
        all_gather_into_tensor_444 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1420, 16, '1025');  convert_element_type_1420 = None
        wait_tensor_547 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_444);  all_gather_into_tensor_444 = None
        split_151 = torch.ops.aten.split.Tensor(wait_tensor_547, 8);  wait_tensor_547 = None
        getitem_2789 = split_151[0]
        getitem_2790 = split_151[1]
        getitem_2791 = split_151[2]
        getitem_2792 = split_151[3]
        getitem_2793 = split_151[4]
        getitem_2794 = split_151[5]
        getitem_2795 = split_151[6]
        getitem_2796 = split_151[7]
        getitem_2797 = split_151[8]
        getitem_2798 = split_151[9]
        getitem_2799 = split_151[10]
        getitem_2800 = split_151[11]
        getitem_2801 = split_151[12]
        getitem_2802 = split_151[13]
        getitem_2803 = split_151[14]
        getitem_2804 = split_151[15];  split_151 = None
        cat_231 = torch.ops.aten.cat.default([getitem_2789, getitem_2790, getitem_2791, getitem_2792, getitem_2793, getitem_2794, getitem_2795, getitem_2796, getitem_2797, getitem_2798, getitem_2799, getitem_2800, getitem_2801, getitem_2802, getitem_2803, getitem_2804], 1);  getitem_2789 = getitem_2790 = getitem_2791 = getitem_2792 = getitem_2793 = getitem_2794 = getitem_2795 = getitem_2796 = getitem_2797 = getitem_2798 = getitem_2799 = getitem_2800 = getitem_2801 = getitem_2802 = getitem_2803 = getitem_2804 = None
        convert_element_type_1422 = torch.ops.prims.convert_element_type.default(primals_434, torch.bfloat16)
        all_gather_into_tensor_446 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1422, 16, '1025');  convert_element_type_1422 = None
        wait_tensor_549 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_446);  all_gather_into_tensor_446 = None
        split_152 = torch.ops.aten.split.Tensor(wait_tensor_549, 8);  wait_tensor_549 = None
        getitem_2805 = split_152[0]
        getitem_2806 = split_152[1]
        getitem_2807 = split_152[2]
        getitem_2808 = split_152[3]
        getitem_2809 = split_152[4]
        getitem_2810 = split_152[5]
        getitem_2811 = split_152[6]
        getitem_2812 = split_152[7]
        getitem_2813 = split_152[8]
        getitem_2814 = split_152[9]
        getitem_2815 = split_152[10]
        getitem_2816 = split_152[11]
        getitem_2817 = split_152[12]
        getitem_2818 = split_152[13]
        getitem_2819 = split_152[14]
        getitem_2820 = split_152[15];  split_152 = None
        cat_232 = torch.ops.aten.cat.default([getitem_2805, getitem_2806, getitem_2807, getitem_2808, getitem_2809, getitem_2810, getitem_2811, getitem_2812, getitem_2813, getitem_2814, getitem_2815, getitem_2816, getitem_2817, getitem_2818, getitem_2819, getitem_2820], 1);  getitem_2805 = getitem_2806 = getitem_2807 = getitem_2808 = getitem_2809 = getitem_2810 = getitem_2811 = getitem_2812 = getitem_2813 = getitem_2814 = getitem_2815 = getitem_2816 = getitem_2817 = getitem_2818 = getitem_2819 = getitem_2820 = None
        convert_element_type_1423 = torch.ops.prims.convert_element_type.default(primals_435, torch.bfloat16)
        all_gather_into_tensor_447 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1423, 16, '1025');  convert_element_type_1423 = None
        wait_tensor_550 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_447);  all_gather_into_tensor_447 = None
        split_153 = torch.ops.aten.split.Tensor(wait_tensor_550, 8);  wait_tensor_550 = None
        getitem_2821 = split_153[0]
        getitem_2822 = split_153[1]
        getitem_2823 = split_153[2]
        getitem_2824 = split_153[3]
        getitem_2825 = split_153[4]
        getitem_2826 = split_153[5]
        getitem_2827 = split_153[6]
        getitem_2828 = split_153[7]
        getitem_2829 = split_153[8]
        getitem_2830 = split_153[9]
        getitem_2831 = split_153[10]
        getitem_2832 = split_153[11]
        getitem_2833 = split_153[12]
        getitem_2834 = split_153[13]
        getitem_2835 = split_153[14]
        getitem_2836 = split_153[15];  split_153 = None
        cat_233 = torch.ops.aten.cat.default([getitem_2821, getitem_2822, getitem_2823, getitem_2824, getitem_2825, getitem_2826, getitem_2827, getitem_2828, getitem_2829, getitem_2830, getitem_2831, getitem_2832, getitem_2833, getitem_2834, getitem_2835, getitem_2836], 1);  getitem_2821 = getitem_2822 = getitem_2823 = getitem_2824 = getitem_2825 = getitem_2826 = getitem_2827 = getitem_2828 = getitem_2829 = getitem_2830 = getitem_2831 = getitem_2832 = getitem_2833 = getitem_2834 = getitem_2835 = getitem_2836 = None
        cumsum_77 = torch.ops.aten.cumsum.default(convert_element_type_1418, 0, dtype = torch.int32);  convert_element_type_1418 = None
        permute_395 = torch.ops.aten.permute.default(cat_231, [0, 2, 1]);  cat_231 = None
        _grouped_mm_75 = torch.ops.aten._grouped_mm.default(index_51, permute_395, cumsum_77)
        convert_element_type_1426 = torch.ops.prims.convert_element_type.default(_grouped_mm_75, torch.float32)
        neg_51 = torch.ops.aten.neg.default(convert_element_type_1426)
        exp_77 = torch.ops.aten.exp.default(neg_51);  neg_51 = None
        add_1732 = torch.ops.aten.add.Tensor(exp_77, 1);  exp_77 = None
        div_129 = torch.ops.aten.div.Tensor(convert_element_type_1426, add_1732);  convert_element_type_1426 = add_1732 = None
        convert_element_type_1427 = torch.ops.prims.convert_element_type.default(div_129, torch.bfloat16);  div_129 = None
        permute_396 = torch.ops.aten.permute.default(cat_233, [0, 2, 1]);  cat_233 = None
        _grouped_mm_76 = torch.ops.aten._grouped_mm.default(index_51, permute_396, cumsum_77)
        mul_1260 = torch.ops.aten.mul.Tensor(convert_element_type_1427, _grouped_mm_76);  convert_element_type_1427 = None
        permute_397 = torch.ops.aten.permute.default(cat_232, [0, 2, 1]);  cat_232 = None
        _grouped_mm_77 = torch.ops.aten._grouped_mm.default(mul_1260, permute_397, cumsum_77)
        empty_25 = torch.ops.aten.empty.memory_format([sym_size_int_101, 2048], dtype = torch.bfloat16, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        index_put_50 = torch.ops.aten.index_put.default(empty_25, [getitem_2772], _grouped_mm_77);  empty_25 = _grouped_mm_77 = None
        slice_161 = torch.ops.aten.slice.Tensor(index_put_50, 0, 0, -1);  index_put_50 = None
        all_to_all_single_77 = torch.ops._c10d_functional.all_to_all_single.default(slice_161, [_local_scalar_dense_400, _local_scalar_dense_401, _local_scalar_dense_402, _local_scalar_dense_403, _local_scalar_dense_404, _local_scalar_dense_405, _local_scalar_dense_406, _local_scalar_dense_407], [_local_scalar_dense_408, _local_scalar_dense_409, _local_scalar_dense_410, _local_scalar_dense_411, _local_scalar_dense_412, _local_scalar_dense_413, _local_scalar_dense_414, _local_scalar_dense_415], '1033');  slice_161 = None
        wait_tensor_553 = torch.ops._c10d_functional.wait_tensor.default(all_to_all_single_77);  all_to_all_single_77 = None
        convert_element_type_1428 = torch.ops.prims.convert_element_type.default(primals_436, torch.bfloat16)
        all_gather_into_tensor_450 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1428, 128, '0');  convert_element_type_1428 = None
        wait_tensor_554 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_450);  all_gather_into_tensor_450 = None
        permute_398 = torch.ops.aten.permute.default(wait_tensor_554, [1, 0]);  wait_tensor_554 = None
        mm_212 = torch.ops.aten.mm.default(view_1733, permute_398);  permute_398 = None
        convert_element_type_1431 = torch.ops.prims.convert_element_type.default(mm_212, torch.float32)
        neg_52 = torch.ops.aten.neg.default(convert_element_type_1431)
        exp_78 = torch.ops.aten.exp.default(neg_52);  neg_52 = None
        add_1768 = torch.ops.aten.add.Tensor(exp_78, 1);  exp_78 = None
        div_130 = torch.ops.aten.div.Tensor(convert_element_type_1431, add_1768);  convert_element_type_1431 = add_1768 = None
        convert_element_type_1432 = torch.ops.prims.convert_element_type.default(div_130, torch.bfloat16);  div_130 = None
        convert_element_type_1433 = torch.ops.prims.convert_element_type.default(primals_437, torch.bfloat16)
        all_gather_into_tensor_451 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1433, 128, '0');  convert_element_type_1433 = None
        wait_tensor_555 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_451);  all_gather_into_tensor_451 = None
        permute_399 = torch.ops.aten.permute.default(wait_tensor_555, [1, 0]);  wait_tensor_555 = None
        mm_213 = torch.ops.aten.mm.default(view_1733, permute_399);  permute_399 = None
        mul_1280 = torch.ops.aten.mul.Tensor(convert_element_type_1432, mm_213);  convert_element_type_1432 = None
        convert_element_type_1436 = torch.ops.prims.convert_element_type.default(primals_438, torch.bfloat16)
        all_gather_into_tensor_452 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1436, 128, '0');  convert_element_type_1436 = None
        wait_tensor_556 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_452);  all_gather_into_tensor_452 = None
        permute_400 = torch.ops.aten.permute.default(wait_tensor_556, [1, 0]);  wait_tensor_556 = None
        mm_214 = torch.ops.aten.mm.default(mul_1280, permute_400);  permute_400 = None
        index_put_51 = torch.ops.aten.index_put.default(full_default_1, [getitem_2771], wait_tensor_553);  full_default_1 = wait_tensor_553 = None
        view_1773 = torch.ops.aten.view.default(mul_1242, [-1, 1, 6]);  mul_1242 = None
        view_1774 = torch.ops.aten.view.default(index_put_51, [-1, 6, 2048]);  index_put_51 = None
        convert_element_type_1439 = torch.ops.prims.convert_element_type.default(view_1774, torch.float32);  view_1774 = None
        bmm_25 = torch.ops.aten.bmm.default(view_1773, convert_element_type_1439)
        convert_element_type_1440 = torch.ops.prims.convert_element_type.default(bmm_25, torch.bfloat16);  bmm_25 = None
        squeeze_25 = torch.ops.aten.squeeze.dim(convert_element_type_1440, 1);  convert_element_type_1440 = None
        add_1772 = torch.ops.aten.add.Tensor(mm_214, squeeze_25);  mm_214 = squeeze_25 = None
        view_1775 = torch.ops.aten.view.default(add_1772, [2, 4096, 2048]);  add_1772 = None
        add_1773 = torch.ops.aten.add.Tensor(add_1708, view_1775);  view_1775 = None
        convert_element_type_1441 = torch.ops.prims.convert_element_type.default(primals_439, torch.bfloat16)
        all_gather_into_tensor_453 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1441, 128, '0');  convert_element_type_1441 = None
        wait_tensor_557 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_453);  all_gather_into_tensor_453 = None
        convert_element_type_1442 = torch.ops.prims.convert_element_type.default(add_1773, torch.float32)
        pow_82 = torch.ops.aten.pow.Tensor_Scalar(convert_element_type_1442, 2)
        mean_81 = torch.ops.aten.mean.dim(pow_82, [2], True);  pow_82 = None
        add_1774 = torch.ops.aten.add.Scalar(mean_81, 1.1920928955078125e-07);  mean_81 = None
        rsqrt_81 = torch.ops.aten.rsqrt.default(add_1774);  add_1774 = None
        mul_1283 = torch.ops.aten.mul.Tensor(convert_element_type_1442, rsqrt_81);  convert_element_type_1442 = None
        mul_1284 = torch.ops.aten.mul.Tensor(mul_1283, wait_tensor_557);  mul_1283 = wait_tensor_557 = None
        convert_element_type_1443 = torch.ops.prims.convert_element_type.default(mul_1284, torch.bfloat16);  mul_1284 = None
        convert_element_type_1444 = torch.ops.prims.convert_element_type.default(primals_440, torch.bfloat16)
        all_gather_into_tensor_454 = torch.ops._c10d_functional.all_gather_into_tensor.default(convert_element_type_1444, 128, '0');  convert_element_type_1444 = None
        wait_tensor_558 = torch.ops._c10d_functional.wait_tensor.default(all_gather_into_tensor_454);  all_gather_into_tensor_454 = None
        permute_401 = torch.ops.aten.permute.default(wait_tensor_558, [1, 0]);  wait_tensor_558 = None
        view_1778 = torch.ops.aten.view.default(convert_element_type_1443, [8192, 2048]);  convert_element_type_1443 = None
        mm_215 = torch.ops.aten.mm.default(view_1778, permute_401);  permute_401 = None
        view_1779 = torch.ops.aten.view.default(mm_215, [2, 4096, 102400]);  mm_215 = None
        permute_406 = torch.ops.aten.permute.default(view_1773, [0, 2, 1]);  view_1773 = None
        permute_407 = torch.ops.aten.permute.default(convert_element_type_1439, [0, 2, 1]);  convert_element_type_1439 = None
        permute_422 = torch.ops.aten.permute.default(permute_397, [0, 2, 1]);  permute_397 = None
        permute_426 = torch.ops.aten.permute.default(permute_396, [0, 2, 1]);  permute_396 = None
        permute_430 = torch.ops.aten.permute.default(permute_395, [0, 2, 1]);  permute_395 = None
        add_1781 = 0 + sym_size_int_100;  sym_size_int_100 = None
        full_default_54 = torch.ops.aten.full.default([0, 2048], 0, dtype = torch.float32, layout = torch.strided, device = device(type='cuda', index=0), pin_memory = False)
        permute_456 = torch.ops.aten.permute.default(view_1706, [0, 2, 1]);  view_1706 = None
        permute_457 = torch.ops.aten.permute.default(convert_element_type_1385, [0, 2, 1]);  convert_element_type_1385 = None
        permute_472 = torch.ops.aten.permute.default(permute_382, [0, 2, 1]);  permute_382 = None
        permute_476 = torch.ops.aten.permute.default(permute_381, [0, 2, 1]);  permute_381 = None
        permute_480 = torch.ops.aten.permute.default(permute_380, [0, 2, 1]);  permute_380 = None
        add_1796 = 0 + sym_size_int_96;  sym_size_int_96 = None
        permute_506 = torch.ops.aten.permute.default(view_1639, [0, 2, 1]);  view_1639 = None
        permute_507 = torch.ops.aten.permute.default(convert_element_type_1331, [0, 2, 1]);  convert_element_type_1331 = None
        permute_522 = torch.ops.aten.permute.default(permute_367, [0, 2, 1]);  permute_367 = None
        permute_526 = torch.ops.aten.permute.default(permute_366, [0, 2, 1]);  permute_366 = None
        permute_530 = torch.ops.aten.permute.default(permute_365, [0, 2, 1]);  permute_365 = None
        add_1811 = 0 + sym_size_int_92;  sym_size_int_92 = None
        permute_556 = torch.ops.aten.permute.default(view_1572, [0, 2, 1]);  view_1572 = None
        permute_557 = torch.ops.aten.permute.default(convert_element_type_1277, [0, 2, 1]);  convert_element_type_1277 = None
        permute_572 = torch.ops.aten.permute.default(permute_352, [0, 2, 1]);  permute_352 = None
        permute_576 = torch.ops.aten.permute.default(permute_351, [0, 2, 1]);  permute_351 = None
        permute_580 = torch.ops.aten.permute.default(permute_350, [0, 2, 1]);  permute_350 = None
        add_1826 = 0 + sym_size_int_88;  sym_size_int_88 = None
        permute_606 = torch.ops.aten.permute.default(view_1505, [0, 2, 1]);  view_1505 = None
        permute_607 = torch.ops.aten.permute.default(convert_element_type_1223, [0, 2, 1]);  convert_element_type_1223 = None
        permute_622 = torch.ops.aten.permute.default(permute_337, [0, 2, 1]);  permute_337 = None
        permute_626 = torch.ops.aten.permute.default(permute_336, [0, 2, 1]);  permute_336 = None
        permute_630 = torch.ops.aten.permute.default(permute_335, [0, 2, 1]);  permute_335 = None
        add_1841 = 0 + sym_size_int_84;  sym_size_int_84 = None
        permute_656 = torch.ops.aten.permute.default(view_1438, [0, 2, 1]);  view_1438 = None
        permute_657 = torch.ops.aten.permute.default(convert_element_type_1169, [0, 2, 1]);  convert_element_type_1169 = None
        permute_672 = torch.ops.aten.permute.default(permute_322, [0, 2, 1]);  permute_322 = None
        permute_676 = torch.ops.aten.permute.default(permute_321, [0, 2, 1]);  permute_321 = None
        permute_680 = torch.ops.aten.permute.default(permute_320, [0, 2, 1]);  permute_320 = None
        add_1856 = 0 + sym_size_int_80;  sym_size_int_80 = None
        permute_706 = torch.ops.aten.permute.default(view_1371, [0, 2, 1]);  view_1371 = None
        permute_707 = torch.ops.aten.permute.default(convert_element_type_1115, [0, 2, 1]);  convert_element_type_1115 = None
        permute_722 = torch.ops.aten.permute.default(permute_307, [0, 2, 1]);  permute_307 = None
        permute_726 = torch.ops.aten.permute.default(permute_306, [0, 2, 1]);  permute_306 = None
        permute_730 = torch.ops.aten.permute.default(permute_305, [0, 2, 1]);  permute_305 = None
        add_1871 = 0 + sym_size_int_76;  sym_size_int_76 = None
        permute_756 = torch.ops.aten.permute.default(view_1304, [0, 2, 1]);  view_1304 = None
        permute_757 = torch.ops.aten.permute.default(convert_element_type_1061, [0, 2, 1]);  convert_element_type_1061 = None
        permute_772 = torch.ops.aten.permute.default(permute_292, [0, 2, 1]);  permute_292 = None
        permute_776 = torch.ops.aten.permute.default(permute_291, [0, 2, 1]);  permute_291 = None
        permute_780 = torch.ops.aten.permute.default(permute_290, [0, 2, 1]);  permute_290 = None
        add_1886 = 0 + sym_size_int_72;  sym_size_int_72 = None
        permute_806 = torch.ops.aten.permute.default(view_1237, [0, 2, 1]);  view_1237 = None
        permute_807 = torch.ops.aten.permute.default(convert_element_type_1007, [0, 2, 1]);  convert_element_type_1007 = None
        permute_822 = torch.ops.aten.permute.default(permute_277, [0, 2, 1]);  permute_277 = None
        permute_826 = torch.ops.aten.permute.default(permute_276, [0, 2, 1]);  permute_276 = None
        permute_830 = torch.ops.aten.permute.default(permute_275, [0, 2, 1]);  permute_275 = None
        add_1901 = 0 + sym_size_int_68;  sym_size_int_68 = None
        permute_856 = torch.ops.aten.permute.default(view_1170, [0, 2, 1]);  view_1170 = None
        permute_857 = torch.ops.aten.permute.default(convert_element_type_953, [0, 2, 1]);  convert_element_type_953 = None
        permute_872 = torch.ops.aten.permute.default(permute_262, [0, 2, 1]);  permute_262 = None
        permute_876 = torch.ops.aten.permute.default(permute_261, [0, 2, 1]);  permute_261 = None
        permute_880 = torch.ops.aten.permute.default(permute_260, [0, 2, 1]);  permute_260 = None
        add_1916 = 0 + sym_size_int_64;  sym_size_int_64 = None
        permute_906 = torch.ops.aten.permute.default(view_1103, [0, 2, 1]);  view_1103 = None
        permute_907 = torch.ops.aten.permute.default(convert_element_type_899, [0, 2, 1]);  convert_element_type_899 = None
        permute_922 = torch.ops.aten.permute.default(permute_247, [0, 2, 1]);  permute_247 = None
        permute_926 = torch.ops.aten.permute.default(permute_246, [0, 2, 1]);  permute_246 = None
        permute_930 = torch.ops.aten.permute.default(permute_245, [0, 2, 1]);  permute_245 = None
        add_1931 = 0 + sym_size_int_60;  sym_size_int_60 = None
        permute_956 = torch.ops.aten.permute.default(view_1036, [0, 2, 1]);  view_1036 = None
        permute_957 = torch.ops.aten.permute.default(convert_element_type_845, [0, 2, 1]);  convert_element_type_845 = None
        permute_972 = torch.ops.aten.permute.default(permute_232, [0, 2, 1]);  permute_232 = None
        permute_976 = torch.ops.aten.permute.default(permute_231, [0, 2, 1]);  permute_231 = None
        permute_980 = torch.ops.aten.permute.default(permute_230, [0, 2, 1]);  permute_230 = None
        add_1946 = 0 + sym_size_int_56;  sym_size_int_56 = None
        permute_1006 = torch.ops.aten.permute.default(view_969, [0, 2, 1]);  view_969 = None
        permute_1007 = torch.ops.aten.permute.default(convert_element_type_791, [0, 2, 1]);  convert_element_type_791 = None
        permute_1022 = torch.ops.aten.permute.default(permute_217, [0, 2, 1]);  permute_217 = None
        permute_1026 = torch.ops.aten.permute.default(permute_216, [0, 2, 1]);  permute_216 = None
        permute_1030 = torch.ops.aten.permute.default(permute_215, [0, 2, 1]);  permute_215 = None
        add_1961 = 0 + sym_size_int_52;  sym_size_int_52 = None
        permute_1056 = torch.ops.aten.permute.default(view_902, [0, 2, 1]);  view_902 = None
        permute_1057 = torch.ops.aten.permute.default(convert_element_type_737, [0, 2, 1]);  convert_element_type_737 = None
        permute_1072 = torch.ops.aten.permute.default(permute_202, [0, 2, 1]);  permute_202 = None
        permute_1076 = torch.ops.aten.permute.default(permute_201, [0, 2, 1]);  permute_201 = None
        permute_1080 = torch.ops.aten.permute.default(permute_200, [0, 2, 1]);  permute_200 = None
        add_1976 = 0 + sym_size_int_48;  sym_size_int_48 = None
        permute_1106 = torch.ops.aten.permute.default(view_835, [0, 2, 1]);  view_835 = None
        permute_1107 = torch.ops.aten.permute.default(convert_element_type_683, [0, 2, 1]);  convert_element_type_683 = None
        permute_1122 = torch.ops.aten.permute.default(permute_187, [0, 2, 1]);  permute_187 = None
        permute_1126 = torch.ops.aten.permute.default(permute_186, [0, 2, 1]);  permute_186 = None
        permute_1130 = torch.ops.aten.permute.default(permute_185, [0, 2, 1]);  permute_185 = None
        add_1991 = 0 + sym_size_int_44;  sym_size_int_44 = None
        permute_1156 = torch.ops.aten.permute.default(view_768, [0, 2, 1]);  view_768 = None
        permute_1157 = torch.ops.aten.permute.default(convert_element_type_629, [0, 2, 1]);  convert_element_type_629 = None
        permute_1172 = torch.ops.aten.permute.default(permute_172, [0, 2, 1]);  permute_172 = None
        permute_1176 = torch.ops.aten.permute.default(permute_171, [0, 2, 1]);  permute_171 = None
        permute_1180 = torch.ops.aten.permute.default(permute_170, [0, 2, 1]);  permute_170 = None
        add_2006 = 0 + sym_size_int_40;  sym_size_int_40 = None
        permute_1206 = torch.ops.aten.permute.default(view_701, [0, 2, 1]);  view_701 = None
        permute_1207 = torch.ops.aten.permute.default(convert_element_type_575, [0, 2, 1]);  convert_element_type_575 = None
        permute_1222 = torch.ops.aten.permute.default(permute_157, [0, 2, 1]);  permute_157 = None
        permute_1226 = torch.ops.aten.permute.default(permute_156, [0, 2, 1]);  permute_156 = None
        permute_1230 = torch.ops.aten.permute.default(permute_155, [0, 2, 1]);  permute_155 = None
        add_2021 = 0 + sym_size_int_36;  sym_size_int_36 = None
        permute_1256 = torch.ops.aten.permute.default(view_634, [0, 2, 1]);  view_634 = None
        permute_1257 = torch.ops.aten.permute.default(convert_element_type_521, [0, 2, 1]);  convert_element_type_521 = None
        permute_1272 = torch.ops.aten.permute.default(permute_142, [0, 2, 1]);  permute_142 = None
        permute_1276 = torch.ops.aten.permute.default(permute_141, [0, 2, 1]);  permute_141 = None
        permute_1280 = torch.ops.aten.permute.default(permute_140, [0, 2, 1]);  permute_140 = None
        add_2036 = 0 + sym_size_int_32;  sym_size_int_32 = None
        permute_1306 = torch.ops.aten.permute.default(view_567, [0, 2, 1]);  view_567 = None
        permute_1307 = torch.ops.aten.permute.default(convert_element_type_467, [0, 2, 1]);  convert_element_type_467 = None
        permute_1322 = torch.ops.aten.permute.default(permute_127, [0, 2, 1]);  permute_127 = None
        permute_1326 = torch.ops.aten.permute.default(permute_126, [0, 2, 1]);  permute_126 = None
        permute_1330 = torch.ops.aten.permute.default(permute_125, [0, 2, 1]);  permute_125 = None
        add_2051 = 0 + sym_size_int_28;  sym_size_int_28 = None
        permute_1356 = torch.ops.aten.permute.default(view_500, [0, 2, 1]);  view_500 = None
        permute_1357 = torch.ops.aten.permute.default(convert_element_type_413, [0, 2, 1]);  convert_element_type_413 = None
        permute_1372 = torch.ops.aten.permute.default(permute_112, [0, 2, 1]);  permute_112 = None
        permute_1376 = torch.ops.aten.permute.default(permute_111, [0, 2, 1]);  permute_111 = None
        permute_1380 = torch.ops.aten.permute.default(permute_110, [0, 2, 1]);  permute_110 = None
        add_2066 = 0 + sym_size_int_24;  sym_size_int_24 = None
        permute_1406 = torch.ops.aten.permute.default(view_433, [0, 2, 1]);  view_433 = None
        permute_1407 = torch.ops.aten.permute.default(convert_element_type_359, [0, 2, 1]);  convert_element_type_359 = None
        permute_1422 = torch.ops.aten.permute.default(permute_97, [0, 2, 1]);  permute_97 = None
        permute_1426 = torch.ops.aten.permute.default(permute_96, [0, 2, 1]);  permute_96 = None
        permute_1430 = torch.ops.aten.permute.default(permute_95, [0, 2, 1]);  permute_95 = None
        add_2081 = 0 + sym_size_int_20;  sym_size_int_20 = None
        permute_1456 = torch.ops.aten.permute.default(view_366, [0, 2, 1]);  view_366 = None
        permute_1457 = torch.ops.aten.permute.default(convert_element_type_305, [0, 2, 1]);  convert_element_type_305 = None
        permute_1472 = torch.ops.aten.permute.default(permute_82, [0, 2, 1]);  permute_82 = None
        permute_1476 = torch.ops.aten.permute.default(permute_81, [0, 2, 1]);  permute_81 = None
        permute_1480 = torch.ops.aten.permute.default(permute_80, [0, 2, 1]);  permute_80 = None
        add_2096 = 0 + sym_size_int_16;  sym_size_int_16 = None
        permute_1506 = torch.ops.aten.permute.default(view_299, [0, 2, 1]);  view_299 = None
        permute_1507 = torch.ops.aten.permute.default(convert_element_type_251, [0, 2, 1]);  convert_element_type_251 = None
        permute_1522 = torch.ops.aten.permute.default(permute_67, [0, 2, 1]);  permute_67 = None
        permute_1526 = torch.ops.aten.permute.default(permute_66, [0, 2, 1]);  permute_66 = None
        permute_1530 = torch.ops.aten.permute.default(permute_65, [0, 2, 1]);  permute_65 = None
        add_2111 = 0 + sym_size_int_12;  sym_size_int_12 = None
        permute_1556 = torch.ops.aten.permute.default(view_232, [0, 2, 1]);  view_232 = None
        permute_1557 = torch.ops.aten.permute.default(convert_element_type_197, [0, 2, 1]);  convert_element_type_197 = None
        permute_1572 = torch.ops.aten.permute.default(permute_52, [0, 2, 1]);  permute_52 = None
        permute_1576 = torch.ops.aten.permute.default(permute_51, [0, 2, 1]);  permute_51 = None
        permute_1580 = torch.ops.aten.permute.default(permute_50, [0, 2, 1]);  permute_50 = None
        add_2126 = 0 + sym_size_int_8;  sym_size_int_8 = None
        permute_1606 = torch.ops.aten.permute.default(view_165, [0, 2, 1]);  view_165 = None
        permute_1607 = torch.ops.aten.permute.default(convert_element_type_143, [0, 2, 1]);  convert_element_type_143 = None
        permute_1622 = torch.ops.aten.permute.default(permute_37, [0, 2, 1]);  permute_37 = None
        permute_1626 = torch.ops.aten.permute.default(permute_36, [0, 2, 1]);  permute_36 = None
        permute_1630 = torch.ops.aten.permute.default(permute_35, [0, 2, 1]);  permute_35 = None
        add_2141 = 0 + sym_size_int_4;  sym_size_int_4 = None
        permute_1656 = torch.ops.aten.permute.default(view_98, [0, 2, 1]);  view_98 = None
        permute_1657 = torch.ops.aten.permute.default(convert_element_type_89, [0, 2, 1]);  convert_element_type_89 = None
        permute_1672 = torch.ops.aten.permute.default(permute_22, [0, 2, 1]);  permute_22 = None
        permute_1676 = torch.ops.aten.permute.default(permute_21, [0, 2, 1]);  permute_21 = None
        permute_1680 = torch.ops.aten.permute.default(permute_20, [0, 2, 1]);  permute_20 = None
        add_2156 = 0 + sym_size_int;  sym_size_int = None
        copy_ = torch.ops.aten.copy_.default(primals_32, add_11);  primals_32 = add_11 = copy_ = None
        copy__1 = torch.ops.aten.copy_.default(primals_48, add_79);  primals_48 = add_79 = copy__1 = None
        copy__2 = torch.ops.aten.copy_.default(primals_64, add_147);  primals_64 = add_147 = copy__2 = None
        copy__3 = torch.ops.aten.copy_.default(primals_80, add_215);  primals_80 = add_215 = copy__3 = None
        copy__4 = torch.ops.aten.copy_.default(primals_96, add_283);  primals_96 = add_283 = copy__4 = None
        copy__5 = torch.ops.aten.copy_.default(primals_112, add_351);  primals_112 = add_351 = copy__5 = None
        copy__6 = torch.ops.aten.copy_.default(primals_128, add_419);  primals_128 = add_419 = copy__6 = None
        copy__7 = torch.ops.aten.copy_.default(primals_144, add_487);  primals_144 = add_487 = copy__7 = None
        copy__8 = torch.ops.aten.copy_.default(primals_160, add_555);  primals_160 = add_555 = copy__8 = None
        copy__9 = torch.ops.aten.copy_.default(primals_176, add_623);  primals_176 = add_623 = copy__9 = None
        copy__10 = torch.ops.aten.copy_.default(primals_192, add_691);  primals_192 = add_691 = copy__10 = None
        copy__11 = torch.ops.aten.copy_.default(primals_208, add_759);  primals_208 = add_759 = copy__11 = None
        copy__12 = torch.ops.aten.copy_.default(primals_224, add_827);  primals_224 = add_827 = copy__12 = None
        copy__13 = torch.ops.aten.copy_.default(primals_240, add_895);  primals_240 = add_895 = copy__13 = None
        copy__14 = torch.ops.aten.copy_.default(primals_256, add_963);  primals_256 = add_963 = copy__14 = None
        copy__15 = torch.ops.aten.copy_.default(primals_272, add_1031);  primals_272 = add_1031 = copy__15 = None
        copy__16 = torch.ops.aten.copy_.default(primals_288, add_1099);  primals_288 = add_1099 = copy__16 = None
        copy__17 = torch.ops.aten.copy_.default(primals_304, add_1167);  primals_304 = add_1167 = copy__17 = None
        copy__18 = torch.ops.aten.copy_.default(primals_320, add_1235);  primals_320 = add_1235 = copy__18 = None
        copy__19 = torch.ops.aten.copy_.default(primals_336, add_1303);  primals_336 = add_1303 = copy__19 = None
        copy__20 = torch.ops.aten.copy_.default(primals_352, add_1371);  primals_352 = add_1371 = copy__20 = None
        copy__21 = torch.ops.aten.copy_.default(primals_368, add_1439);  primals_368 = add_1439 = copy__21 = None
        copy__22 = torch.ops.aten.copy_.default(primals_384, add_1507);  primals_384 = add_1507 = copy__22 = None
        copy__23 = torch.ops.aten.copy_.default(primals_400, add_1575);  primals_400 = add_1575 = copy__23 = None
        copy__24 = torch.ops.aten.copy_.default(primals_416, add_1643);  primals_416 = add_1643 = copy__24 = None
        copy__25 = torch.ops.aten.copy_.default(primals_432, add_1711);  primals_432 = add_1711 = copy__25 = None
        return (view_1779, getitem_22, sym_sum_1, _local_scalar_dense_8, _local_scalar_dense_9, _local_scalar_dense_10, _local_scalar_dense_11, _local_scalar_dense_12, _local_scalar_dense_13, _local_scalar_dense_14, _local_scalar_dense_15, _local_scalar_dense, _local_scalar_dense_1, _local_scalar_dense_2, _local_scalar_dense_3, _local_scalar_dense_4, _local_scalar_dense_5, _local_scalar_dense_6, _local_scalar_dense_7, getitem_132, sym_sum_3, _local_scalar_dense_24, _local_scalar_dense_25, _local_scalar_dense_26, _local_scalar_dense_27, _local_scalar_dense_28, _local_scalar_dense_29, _local_scalar_dense_30, _local_scalar_dense_31, _local_scalar_dense_16, _local_scalar_dense_17, _local_scalar_dense_18, _local_scalar_dense_19, _local_scalar_dense_20, _local_scalar_dense_21, _local_scalar_dense_22, _local_scalar_dense_23, getitem_242, sym_sum_5, _local_scalar_dense_40, _local_scalar_dense_41, _local_scalar_dense_42, _local_scalar_dense_43, _local_scalar_dense_44, _local_scalar_dense_45, _local_scalar_dense_46, _local_scalar_dense_47, _local_scalar_dense_32, _local_scalar_dense_33, _local_scalar_dense_34, _local_scalar_dense_35, _local_scalar_dense_36, _local_scalar_dense_37, _local_scalar_dense_38, _local_scalar_dense_39, getitem_352, sym_sum_7, _local_scalar_dense_56, _local_scalar_dense_57, _local_scalar_dense_58, _local_scalar_dense_59, _local_scalar_dense_60, _local_scalar_dense_61, _local_scalar_dense_62, _local_scalar_dense_63, _local_scalar_dense_48, _local_scalar_dense_49, _local_scalar_dense_50, _local_scalar_dense_51, _local_scalar_dense_52, _local_scalar_dense_53, _local_scalar_dense_54, _local_scalar_dense_55, getitem_462, sym_sum_9, _local_scalar_dense_72, _local_scalar_dense_73, _local_scalar_dense_74, _local_scalar_dense_75, _local_scalar_dense_76, _local_scalar_dense_77, _local_scalar_dense_78, _local_scalar_dense_79, _local_scalar_dense_64, _local_scalar_dense_65, _local_scalar_dense_66, _local_scalar_dense_67, _local_scalar_dense_68, _local_scalar_dense_69, _local_scalar_dense_70, _local_scalar_dense_71, getitem_572, sym_sum_11, _local_scalar_dense_88, _local_scalar_dense_89, _local_scalar_dense_90, _local_scalar_dense_91, _local_scalar_dense_92, _local_scalar_dense_93, _local_scalar_dense_94, _local_scalar_dense_95, _local_scalar_dense_80, _local_scalar_dense_81, _local_scalar_dense_82, _local_scalar_dense_83, _local_scalar_dense_84, _local_scalar_dense_85, _local_scalar_dense_86, _local_scalar_dense_87, getitem_682, sym_sum_13, _local_scalar_dense_104, _local_scalar_dense_105, _local_scalar_dense_106, _local_scalar_dense_107, _local_scalar_dense_108, _local_scalar_dense_109, _local_scalar_dense_110, _local_scalar_dense_111, _local_scalar_dense_96, _local_scalar_dense_97, _local_scalar_dense_98, _local_scalar_dense_99, _local_scalar_dense_100, _local_scalar_dense_101, _local_scalar_dense_102, _local_scalar_dense_103, getitem_792, sym_sum_15, _local_scalar_dense_120, _local_scalar_dense_121, _local_scalar_dense_122, _local_scalar_dense_123, _local_scalar_dense_124, _local_scalar_dense_125, _local_scalar_dense_126, _local_scalar_dense_127, _local_scalar_dense_112, _local_scalar_dense_113, _local_scalar_dense_114, _local_scalar_dense_115, _local_scalar_dense_116, _local_scalar_dense_117, _local_scalar_dense_118, _local_scalar_dense_119, getitem_902, sym_sum_17, _local_scalar_dense_136, _local_scalar_dense_137, _local_scalar_dense_138, _local_scalar_dense_139, _local_scalar_dense_140, _local_scalar_dense_141, _local_scalar_dense_142, _local_scalar_dense_143, _local_scalar_dense_128, _local_scalar_dense_129, _local_scalar_dense_130, _local_scalar_dense_131, _local_scalar_dense_132, _local_scalar_dense_133, _local_scalar_dense_134, _local_scalar_dense_135, getitem_1012, sym_sum_19, _local_scalar_dense_152, _local_scalar_dense_153, _local_scalar_dense_154, _local_scalar_dense_155, _local_scalar_dense_156, _local_scalar_dense_157, _local_scalar_dense_158, _local_scalar_dense_159, _local_scalar_dense_144, _local_scalar_dense_145, _local_scalar_dense_146, _local_scalar_dense_147, _local_scalar_dense_148, _local_scalar_dense_149, _local_scalar_dense_150, _local_scalar_dense_151, getitem_1122, sym_sum_21, _local_scalar_dense_168, _local_scalar_dense_169, _local_scalar_dense_170, _local_scalar_dense_171, _local_scalar_dense_172, _local_scalar_dense_173, _local_scalar_dense_174, _local_scalar_dense_175, _local_scalar_dense_160, _local_scalar_dense_161, _local_scalar_dense_162, _local_scalar_dense_163, _local_scalar_dense_164, _local_scalar_dense_165, _local_scalar_dense_166, _local_scalar_dense_167, getitem_1232, sym_sum_23, _local_scalar_dense_184, _local_scalar_dense_185, _local_scalar_dense_186, _local_scalar_dense_187, _local_scalar_dense_188, _local_scalar_dense_189, _local_scalar_dense_190, _local_scalar_dense_191, _local_scalar_dense_176, _local_scalar_dense_177, _local_scalar_dense_178, _local_scalar_dense_179, _local_scalar_dense_180, _local_scalar_dense_181, _local_scalar_dense_182, _local_scalar_dense_183, getitem_1342, sym_sum_25, _local_scalar_dense_200, _local_scalar_dense_201, _local_scalar_dense_202, _local_scalar_dense_203, _local_scalar_dense_204, _local_scalar_dense_205, _local_scalar_dense_206, _local_scalar_dense_207, _local_scalar_dense_192, _local_scalar_dense_193, _local_scalar_dense_194, _local_scalar_dense_195, _local_scalar_dense_196, _local_scalar_dense_197, _local_scalar_dense_198, _local_scalar_dense_199, getitem_1452, sym_sum_27, _local_scalar_dense_216, _local_scalar_dense_217, _local_scalar_dense_218, _local_scalar_dense_219, _local_scalar_dense_220, _local_scalar_dense_221, _local_scalar_dense_222, _local_scalar_dense_223, _local_scalar_dense_208, _local_scalar_dense_209, _local_scalar_dense_210, _local_scalar_dense_211, _local_scalar_dense_212, _local_scalar_dense_213, _local_scalar_dense_214, _local_scalar_dense_215, getitem_1562, sym_sum_29, _local_scalar_dense_232, _local_scalar_dense_233, _local_scalar_dense_234, _local_scalar_dense_235, _local_scalar_dense_236, _local_scalar_dense_237, _local_scalar_dense_238, _local_scalar_dense_239, _local_scalar_dense_224, _local_scalar_dense_225, _local_scalar_dense_226, _local_scalar_dense_227, _local_scalar_dense_228, _local_scalar_dense_229, _local_scalar_dense_230, _local_scalar_dense_231, getitem_1672, sym_sum_31, _local_scalar_dense_248, _local_scalar_dense_249, _local_scalar_dense_250, _local_scalar_dense_251, _local_scalar_dense_252, _local_scalar_dense_253, _local_scalar_dense_254, _local_scalar_dense_255, _local_scalar_dense_240, _local_scalar_dense_241, _local_scalar_dense_242, _local_scalar_dense_243, _local_scalar_dense_244, _local_scalar_dense_245, _local_scalar_dense_246, _local_scalar_dense_247, getitem_1782, sym_sum_33, _local_scalar_dense_264, _local_scalar_dense_265, _local_scalar_dense_266, _local_scalar_dense_267, _local_scalar_dense_268, _local_scalar_dense_269, _local_scalar_dense_270, _local_scalar_dense_271, _local_scalar_dense_256, _local_scalar_dense_257, _local_scalar_dense_258, _local_scalar_dense_259, _local_scalar_dense_260, _local_scalar_dense_261, _local_scalar_dense_262, _local_scalar_dense_263, getitem_1892, sym_sum_35, _local_scalar_dense_280, _local_scalar_dense_281, _local_scalar_dense_282, _local_scalar_dense_283, _local_scalar_dense_284, _local_scalar_dense_285, _local_scalar_dense_286, _local_scalar_dense_287, _local_scalar_dense_272, _local_scalar_dense_273, _local_scalar_dense_274, _local_scalar_dense_275, _local_scalar_dense_276, _local_scalar_dense_277, _local_scalar_dense_278, _local_scalar_dense_279, getitem_2002, sym_sum_37, _local_scalar_dense_296, _local_scalar_dense_297, _local_scalar_dense_298, _local_scalar_dense_299, _local_scalar_dense_300, _local_scalar_dense_301, _local_scalar_dense_302, _local_scalar_dense_303, _local_scalar_dense_288, _local_scalar_dense_289, _local_scalar_dense_290, _local_scalar_dense_291, _local_scalar_dense_292, _local_scalar_dense_293, _local_scalar_dense_294, _local_scalar_dense_295, getitem_2112, sym_sum_39, _local_scalar_dense_312, _local_scalar_dense_313, _local_scalar_dense_314, _local_scalar_dense_315, _local_scalar_dense_316, _local_scalar_dense_317, _local_scalar_dense_318, _local_scalar_dense_319, _local_scalar_dense_304, _local_scalar_dense_305, _local_scalar_dense_306, _local_scalar_dense_307, _local_scalar_dense_308, _local_scalar_dense_309, _local_scalar_dense_310, _local_scalar_dense_311, getitem_2222, sym_sum_41, _local_scalar_dense_328, _local_scalar_dense_329, _local_scalar_dense_330, _local_scalar_dense_331, _local_scalar_dense_332, _local_scalar_dense_333, _local_scalar_dense_334, _local_scalar_dense_335, _local_scalar_dense_320, _local_scalar_dense_321, _local_scalar_dense_322, _local_scalar_dense_323, _local_scalar_dense_324, _local_scalar_dense_325, _local_scalar_dense_326, _local_scalar_dense_327, getitem_2332, sym_sum_43, _local_scalar_dense_344, _local_scalar_dense_345, _local_scalar_dense_346, _local_scalar_dense_347, _local_scalar_dense_348, _local_scalar_dense_349, _local_scalar_dense_350, _local_scalar_dense_351, _local_scalar_dense_336, _local_scalar_dense_337, _local_scalar_dense_338, _local_scalar_dense_339, _local_scalar_dense_340, _local_scalar_dense_341, _local_scalar_dense_342, _local_scalar_dense_343, getitem_2442, sym_sum_45, _local_scalar_dense_360, _local_scalar_dense_361, _local_scalar_dense_362, _local_scalar_dense_363, _local_scalar_dense_364, _local_scalar_dense_365, _local_scalar_dense_366, _local_scalar_dense_367, _local_scalar_dense_352, _local_scalar_dense_353, _local_scalar_dense_354, _local_scalar_dense_355, _local_scalar_dense_356, _local_scalar_dense_357, _local_scalar_dense_358, _local_scalar_dense_359, getitem_2552, sym_sum_47, _local_scalar_dense_376, _local_scalar_dense_377, _local_scalar_dense_378, _local_scalar_dense_379, _local_scalar_dense_380, _local_scalar_dense_381, _local_scalar_dense_382, _local_scalar_dense_383, _local_scalar_dense_368, _local_scalar_dense_369, _local_scalar_dense_370, _local_scalar_dense_371, _local_scalar_dense_372, _local_scalar_dense_373, _local_scalar_dense_374, _local_scalar_dense_375, getitem_2662, sym_sum_49, _local_scalar_dense_392, _local_scalar_dense_393, _local_scalar_dense_394, _local_scalar_dense_395, _local_scalar_dense_396, _local_scalar_dense_397, _local_scalar_dense_398, _local_scalar_dense_399, _local_scalar_dense_384, _local_scalar_dense_385, _local_scalar_dense_386, _local_scalar_dense_387, _local_scalar_dense_388, _local_scalar_dense_389, _local_scalar_dense_390, _local_scalar_dense_391, getitem_2772, sym_sum_51, _local_scalar_dense_408, _local_scalar_dense_409, _local_scalar_dense_410, _local_scalar_dense_411, _local_scalar_dense_412, _local_scalar_dense_413, _local_scalar_dense_414, _local_scalar_dense_415, _local_scalar_dense_400, _local_scalar_dense_401, _local_scalar_dense_402, _local_scalar_dense_403, _local_scalar_dense_404, _local_scalar_dense_405, _local_scalar_dense_406, _local_scalar_dense_407, primals_1, primals_2, primals_3, primals_4, primals_5, primals_6, primals_7, primals_8, primals_9, primals_10, primals_11, primals_12, primals_13, primals_14, primals_15, primals_16, primals_17, primals_18, primals_19, primals_20, primals_21, primals_22, primals_23, primals_24, primals_25, primals_26, primals_27, primals_28, primals_29, primals_31, primals_33, primals_34, primals_35, primals_36, primals_37, primals_38, primals_39, primals_40, primals_41, primals_42, primals_43, primals_44, primals_45, primals_47, primals_49, primals_50, primals_51, primals_52, primals_53, primals_54, primals_55, primals_56, primals_57, primals_58, primals_59, primals_60, primals_61, primals_63, primals_65, primals_66, primals_67, primals_68, primals_69, primals_70, primals_71, primals_72, primals_73, primals_74, primals_75, primals_76, primals_77, primals_79, primals_81, primals_82, primals_83, primals_84, primals_85, primals_86, primals_87, primals_88, primals_89, primals_90, primals_91, primals_92, primals_93, primals_95, primals_97, primals_98, primals_99, primals_100, primals_101, primals_102, primals_103, primals_104, primals_105, primals_106, primals_107, primals_108, primals_109, primals_111, primals_113, primals_114, primals_115, primals_116, primals_117, primals_118, primals_119, primals_120, primals_121, primals_122, primals_123, primals_124, primals_125, primals_127, primals_129, primals_130, primals_131, primals_132, primals_133, primals_134, primals_135, primals_136, primals_137, primals_138, primals_139, primals_140, primals_141, primals_143, primals_145, primals_146, primals_147, primals_148, primals_149, primals_150, primals_151, primals_152, primals_153, primals_154, primals_155, primals_156, primals_157, primals_159, primals_161, primals_162, primals_163, primals_164, primals_165, primals_166, primals_167, primals_168, primals_169, primals_170, primals_171, primals_172, primals_173, primals_175, primals_177, primals_178, primals_179, primals_180, primals_181, primals_182, primals_183, primals_184, primals_185, primals_186, primals_187, primals_188, primals_189, primals_191, primals_193, primals_194, primals_195, primals_196, primals_197, primals_198, primals_199, primals_200, primals_201, primals_202, primals_203, primals_204, primals_205, primals_207, primals_209, primals_210, primals_211, primals_212, primals_213, primals_214, primals_215, primals_216, primals_217, primals_218, primals_219, primals_220, primals_221, primals_223, primals_225, primals_226, primals_227, primals_228, primals_229, primals_230, primals_231, primals_232, primals_233, primals_234, primals_235, primals_236, primals_237, primals_239, primals_241, primals_242, primals_243, primals_244, primals_245, primals_246, primals_247, primals_248, primals_249, primals_250, primals_251, primals_252, primals_253, primals_255, primals_257, primals_258, primals_259, primals_260, primals_261, primals_262, primals_263, primals_264, primals_265, primals_266, primals_267, primals_268, primals_269, primals_271, primals_273, primals_274, primals_275, primals_276, primals_277, primals_278, primals_279, primals_280, primals_281, primals_282, primals_283, primals_284, primals_285, primals_287, primals_289, primals_290, primals_291, primals_292, primals_293, primals_294, primals_295, primals_296, primals_297, primals_298, primals_299, primals_300, primals_301, primals_303, primals_305, primals_306, primals_307, primals_308, primals_309, primals_310, primals_311, primals_312, primals_313, primals_314, primals_315, primals_316, primals_317, primals_319, primals_321, primals_322, primals_323, primals_324, primals_325, primals_326, primals_327, primals_328, primals_329, primals_330, primals_331, primals_332, primals_333, primals_335, primals_337, primals_338, primals_339, primals_340, primals_341, primals_342, primals_343, primals_344, primals_345, primals_346, primals_347, primals_348, primals_349, primals_351, primals_353, primals_354, primals_355, primals_356, primals_357, primals_358, primals_359, primals_360, primals_361, primals_362, primals_363, primals_364, primals_365, primals_367, primals_369, primals_370, primals_371, primals_372, primals_373, primals_374, primals_375, primals_376, primals_377, primals_378, primals_379, primals_380, primals_381, primals_383, primals_385, primals_386, primals_387, primals_388, primals_389, primals_390, primals_391, primals_392, primals_393, primals_394, primals_395, primals_396, primals_397, primals_399, primals_401, primals_402, primals_403, primals_404, primals_405, primals_406, primals_407, primals_408, primals_409, primals_410, primals_411, primals_412, primals_413, primals_415, primals_417, primals_418, primals_419, primals_420, primals_421, primals_422, primals_423, primals_424, primals_425, primals_426, primals_427, primals_428, primals_429, primals_431, primals_433, primals_434, primals_435, primals_436, primals_437, primals_438, primals_439, primals_440, embedding, rsqrt, view_3, getitem_2, rsqrt_1, view_17, permute_3, permute_4, permute_5, getitem_6, getitem_7, mm_3, rsqrt_2, view_26, mm_4, mm_5, view_32, add_5, rsqrt_3, view_36, getitem_11, rsqrt_4, view_50, permute_14, permute_15, permute_16, getitem_15, getitem_16, add_8, rsqrt_5, view_58, mm_11, amax, sum_1, getitem_19, getitem_21, div_2, getitem_22, index_1, cumsum_2, _grouped_mm, _grouped_mm_1, mul_35, mm_12, mm_13, mul_55, add_73, rsqrt_6, view_103, getitem_121, rsqrt_7, view_117, permute_29, permute_30, permute_31, getitem_125, getitem_126, add_76, rsqrt_8, view_125, mm_19, amax_1, sum_5, getitem_129, getitem_131, div_7, getitem_132, index_3, cumsum_5, _grouped_mm_3, _grouped_mm_4, mul_84, mm_20, mm_21, mul_104, add_141, rsqrt_9, view_170, getitem_231, rsqrt_10, view_184, permute_44, permute_45, permute_46, getitem_235, getitem_236, add_144, rsqrt_11, view_192, mm_27, amax_2, sum_9, getitem_239, getitem_241, div_12, getitem_242, index_5, cumsum_8, _grouped_mm_6, _grouped_mm_7, mul_133, mm_28, mm_29, mul_153, add_209, rsqrt_12, view_237, getitem_341, rsqrt_13, view_251, permute_59, permute_60, permute_61, getitem_345, getitem_346, add_212, rsqrt_14, view_259, mm_35, amax_3, sum_13, getitem_349, getitem_351, div_17, getitem_352, index_7, cumsum_11, _grouped_mm_9, _grouped_mm_10, mul_182, mm_36, mm_37, mul_202, add_277, rsqrt_15, view_304, getitem_451, rsqrt_16, view_318, permute_74, permute_75, permute_76, getitem_455, getitem_456, add_280, rsqrt_17, view_326, mm_43, amax_4, sum_17, getitem_459, getitem_461, div_22, getitem_462, index_9, cumsum_14, _grouped_mm_12, _grouped_mm_13, mul_231, mm_44, mm_45, mul_251, add_345, rsqrt_18, view_371, getitem_561, rsqrt_19, view_385, permute_89, permute_90, permute_91, getitem_565, getitem_566, add_348, rsqrt_20, view_393, mm_51, amax_5, sum_21, getitem_569, getitem_571, div_27, getitem_572, index_11, cumsum_17, _grouped_mm_15, _grouped_mm_16, mul_280, mm_52, mm_53, mul_300, add_413, rsqrt_21, view_438, getitem_671, rsqrt_22, view_452, permute_104, permute_105, permute_106, getitem_675, getitem_676, add_416, rsqrt_23, view_460, mm_59, amax_6, sum_25, getitem_679, getitem_681, div_32, getitem_682, index_13, cumsum_20, _grouped_mm_18, _grouped_mm_19, mul_329, mm_60, mm_61, mul_349, add_481, rsqrt_24, view_505, getitem_781, rsqrt_25, view_519, permute_119, permute_120, permute_121, getitem_785, getitem_786, add_484, rsqrt_26, view_527, mm_67, amax_7, sum_29, getitem_789, getitem_791, div_37, getitem_792, index_15, cumsum_23, _grouped_mm_21, _grouped_mm_22, mul_378, mm_68, mm_69, mul_398, add_549, rsqrt_27, view_572, getitem_891, rsqrt_28, view_586, permute_134, permute_135, permute_136, getitem_895, getitem_896, add_552, rsqrt_29, view_594, mm_75, amax_8, sum_33, getitem_899, getitem_901, div_42, getitem_902, index_17, cumsum_26, _grouped_mm_24, _grouped_mm_25, mul_427, mm_76, mm_77, mul_447, add_617, rsqrt_30, view_639, getitem_1001, rsqrt_31, view_653, permute_149, permute_150, permute_151, getitem_1005, getitem_1006, add_620, rsqrt_32, view_661, mm_83, amax_9, sum_37, getitem_1009, getitem_1011, div_47, getitem_1012, index_19, cumsum_29, _grouped_mm_27, _grouped_mm_28, mul_476, mm_84, mm_85, mul_496, add_685, rsqrt_33, view_706, getitem_1111, rsqrt_34, view_720, permute_164, permute_165, permute_166, getitem_1115, getitem_1116, add_688, rsqrt_35, view_728, mm_91, amax_10, sum_41, getitem_1119, getitem_1121, div_52, getitem_1122, index_21, cumsum_32, _grouped_mm_30, _grouped_mm_31, mul_525, mm_92, mm_93, mul_545, add_753, rsqrt_36, view_773, getitem_1221, rsqrt_37, view_787, permute_179, permute_180, permute_181, getitem_1225, getitem_1226, add_756, rsqrt_38, view_795, mm_99, amax_11, sum_45, getitem_1229, getitem_1231, div_57, getitem_1232, index_23, cumsum_35, _grouped_mm_33, _grouped_mm_34, mul_574, mm_100, mm_101, mul_594, add_821, rsqrt_39, view_840, getitem_1331, rsqrt_40, view_854, permute_194, permute_195, permute_196, getitem_1335, getitem_1336, add_824, rsqrt_41, view_862, mm_107, amax_12, sum_49, getitem_1339, getitem_1341, div_62, getitem_1342, index_25, cumsum_38, _grouped_mm_36, _grouped_mm_37, mul_623, mm_108, mm_109, mul_643, add_889, rsqrt_42, view_907, getitem_1441, rsqrt_43, view_921, permute_209, permute_210, permute_211, getitem_1445, getitem_1446, add_892, rsqrt_44, view_929, mm_115, amax_13, sum_53, getitem_1449, getitem_1451, div_67, getitem_1452, index_27, cumsum_41, _grouped_mm_39, _grouped_mm_40, mul_672, mm_116, mm_117, mul_692, add_957, rsqrt_45, view_974, getitem_1551, rsqrt_46, view_988, permute_224, permute_225, permute_226, getitem_1555, getitem_1556, add_960, rsqrt_47, view_996, mm_123, amax_14, sum_57, getitem_1559, getitem_1561, div_72, getitem_1562, index_29, cumsum_44, _grouped_mm_42, _grouped_mm_43, mul_721, mm_124, mm_125, mul_741, add_1025, rsqrt_48, view_1041, getitem_1661, rsqrt_49, view_1055, permute_239, permute_240, permute_241, getitem_1665, getitem_1666, add_1028, rsqrt_50, view_1063, mm_131, amax_15, sum_61, getitem_1669, getitem_1671, div_77, getitem_1672, index_31, cumsum_47, _grouped_mm_45, _grouped_mm_46, mul_770, mm_132, mm_133, mul_790, add_1093, rsqrt_51, view_1108, getitem_1771, rsqrt_52, view_1122, permute_254, permute_255, permute_256, getitem_1775, getitem_1776, add_1096, rsqrt_53, view_1130, mm_139, amax_16, sum_65, getitem_1779, getitem_1781, div_82, getitem_1782, index_33, cumsum_50, _grouped_mm_48, _grouped_mm_49, mul_819, mm_140, mm_141, mul_839, add_1161, rsqrt_54, view_1175, getitem_1881, rsqrt_55, view_1189, permute_269, permute_270, permute_271, getitem_1885, getitem_1886, add_1164, rsqrt_56, view_1197, mm_147, amax_17, sum_69, getitem_1889, getitem_1891, div_87, getitem_1892, index_35, cumsum_53, _grouped_mm_51, _grouped_mm_52, mul_868, mm_148, mm_149, mul_888, add_1229, rsqrt_57, view_1242, getitem_1991, rsqrt_58, view_1256, permute_284, permute_285, permute_286, getitem_1995, getitem_1996, add_1232, rsqrt_59, view_1264, mm_155, amax_18, sum_73, getitem_1999, getitem_2001, div_92, getitem_2002, index_37, cumsum_56, _grouped_mm_54, _grouped_mm_55, mul_917, mm_156, mm_157, mul_937, add_1297, rsqrt_60, view_1309, getitem_2101, rsqrt_61, view_1323, permute_299, permute_300, permute_301, getitem_2105, getitem_2106, add_1300, rsqrt_62, view_1331, mm_163, amax_19, sum_77, getitem_2109, getitem_2111, div_97, getitem_2112, index_39, cumsum_59, _grouped_mm_57, _grouped_mm_58, mul_966, mm_164, mm_165, mul_986, add_1365, rsqrt_63, view_1376, getitem_2211, rsqrt_64, view_1390, permute_314, permute_315, permute_316, getitem_2215, getitem_2216, add_1368, rsqrt_65, view_1398, mm_171, amax_20, sum_81, getitem_2219, getitem_2221, div_102, getitem_2222, index_41, cumsum_62, _grouped_mm_60, _grouped_mm_61, mul_1015, mm_172, mm_173, mul_1035, add_1433, rsqrt_66, view_1443, getitem_2321, rsqrt_67, view_1457, permute_329, permute_330, permute_331, getitem_2325, getitem_2326, add_1436, rsqrt_68, view_1465, mm_179, amax_21, sum_85, getitem_2329, getitem_2331, div_107, getitem_2332, index_43, cumsum_65, _grouped_mm_63, _grouped_mm_64, mul_1064, mm_180, mm_181, mul_1084, add_1501, rsqrt_69, view_1510, getitem_2431, rsqrt_70, view_1524, permute_344, permute_345, permute_346, getitem_2435, getitem_2436, add_1504, rsqrt_71, view_1532, mm_187, amax_22, sum_89, getitem_2439, getitem_2441, div_112, getitem_2442, index_45, cumsum_68, _grouped_mm_66, _grouped_mm_67, mul_1113, mm_188, mm_189, mul_1133, add_1569, rsqrt_72, view_1577, getitem_2541, rsqrt_73, view_1591, permute_359, permute_360, permute_361, getitem_2545, getitem_2546, add_1572, rsqrt_74, view_1599, mm_195, amax_23, sum_93, getitem_2549, getitem_2551, div_117, getitem_2552, index_47, cumsum_71, _grouped_mm_69, _grouped_mm_70, mul_1162, mm_196, mm_197, mul_1182, add_1637, rsqrt_75, view_1644, getitem_2651, rsqrt_76, view_1658, permute_374, permute_375, permute_376, getitem_2655, getitem_2656, add_1640, rsqrt_77, view_1666, mm_203, amax_24, sum_97, getitem_2659, getitem_2661, div_122, getitem_2662, index_49, cumsum_74, _grouped_mm_72, _grouped_mm_73, mul_1211, mm_204, mm_205, mul_1231, add_1705, rsqrt_78, view_1711, getitem_2761, rsqrt_79, view_1725, permute_389, permute_390, permute_391, getitem_2765, getitem_2766, add_1708, rsqrt_80, view_1733, mm_211, amax_25, sum_101, getitem_2769, getitem_2771, div_127, getitem_2772, index_51, cumsum_77, _grouped_mm_75, _grouped_mm_76, mul_1260, mm_212, mm_213, mul_1280, add_1773, rsqrt_81, view_1778, permute_406, permute_407, permute_422, permute_426, permute_430, full_default_54, permute_456, permute_457, permute_472, permute_476, permute_480, permute_506, permute_507, permute_522, permute_526, permute_530, permute_556, permute_557, permute_572, permute_576, permute_580, permute_606, permute_607, permute_622, permute_626, permute_630, permute_656, permute_657, permute_672, permute_676, permute_680, permute_706, permute_707, permute_722, permute_726, permute_730, permute_756, permute_757, permute_772, permute_776, permute_780, permute_806, permute_807, permute_822, permute_826, permute_830, permute_856, permute_857, permute_872, permute_876, permute_880, permute_906, permute_907, permute_922, permute_926, permute_930, permute_956, permute_957, permute_972, permute_976, permute_980, permute_1006, permute_1007, permute_1022, permute_1026, permute_1030, permute_1056, permute_1057, permute_1072, permute_1076, permute_1080, permute_1106, permute_1107, permute_1122, permute_1126, permute_1130, permute_1156, permute_1157, permute_1172, permute_1176, permute_1180, permute_1206, permute_1207, permute_1222, permute_1226, permute_1230, permute_1256, permute_1257, permute_1272, permute_1276, permute_1280, permute_1306, permute_1307, permute_1322, permute_1326, permute_1330, permute_1356, permute_1357, permute_1372, permute_1376, permute_1380, permute_1406, permute_1407, permute_1422, permute_1426, permute_1430, permute_1456, permute_1457, permute_1472, permute_1476, permute_1480, permute_1506, permute_1507, permute_1522, permute_1526, permute_1530, permute_1556, permute_1557, permute_1572, permute_1576, permute_1580, permute_1606, permute_1607, permute_1622, permute_1626, permute_1630, permute_1656, permute_1657, permute_1672, permute_1676, permute_1680, _local_scalar_dense, _local_scalar_dense_1, _local_scalar_dense_2, _local_scalar_dense_3, _local_scalar_dense_4, _local_scalar_dense_5, _local_scalar_dense_6, _local_scalar_dense_7, _local_scalar_dense_8, _local_scalar_dense_9, _local_scalar_dense_10, _local_scalar_dense_11, _local_scalar_dense_12, _local_scalar_dense_13, _local_scalar_dense_14, _local_scalar_dense_15, _local_scalar_dense_16, _local_scalar_dense_17, _local_scalar_dense_18, _local_scalar_dense_19, _local_scalar_dense_20, _local_scalar_dense_21, _local_scalar_dense_22, _local_scalar_dense_23, _local_scalar_dense_24, _local_scalar_dense_25, _local_scalar_dense_26, _local_scalar_dense_27, _local_scalar_dense_28, _local_scalar_dense_29, _local_scalar_dense_30, _local_scalar_dense_31, _local_scalar_dense_32, _local_scalar_dense_33, _local_scalar_dense_34, _local_scalar_dense_35, _local_scalar_dense_36, _local_scalar_dense_37, _local_scalar_dense_38, _local_scalar_dense_39, _local_scalar_dense_40, _local_scalar_dense_41, _local_scalar_dense_42, _local_scalar_dense_43, _local_scalar_dense_44, _local_scalar_dense_45, _local_scalar_dense_46, _local_scalar_dense_47, _local_scalar_dense_48, _local_scalar_dense_49, _local_scalar_dense_50, _local_scalar_dense_51, _local_scalar_dense_52, _local_scalar_dense_53, _local_scalar_dense_54, _local_scalar_dense_55, _local_scalar_dense_56, _local_scalar_dense_57, _local_scalar_dense_58, _local_scalar_dense_59, _local_scalar_dense_60, _local_scalar_dense_61, _local_scalar_dense_62, _local_scalar_dense_63, _local_scalar_dense_64, _local_scalar_dense_65, _local_scalar_dense_66, _local_scalar_dense_67, _local_scalar_dense_68, _local_scalar_dense_69, _local_scalar_dense_70, _local_scalar_dense_71, _local_scalar_dense_72, _local_scalar_dense_73, _local_scalar_dense_74, _local_scalar_dense_75, _local_scalar_dense_76, _local_scalar_dense_77, _local_scalar_dense_78, _local_scalar_dense_79, _local_scalar_dense_80, _local_scalar_dense_81, _local_scalar_dense_82, _local_scalar_dense_83, _local_scalar_dense_84, _local_scalar_dense_85, _local_scalar_dense_86, _local_scalar_dense_87, _local_scalar_dense_88, _local_scalar_dense_89, _local_scalar_dense_90, _local_scalar_dense_91, _local_scalar_dense_92, _local_scalar_dense_93, _local_scalar_dense_94, _local_scalar_dense_95, _local_scalar_dense_96, _local_scalar_dense_97, _local_scalar_dense_98, _local_scalar_dense_99, _local_scalar_dense_100, _local_scalar_dense_101, _local_scalar_dense_102, _local_scalar_dense_103, _local_scalar_dense_104, _local_scalar_dense_105, _local_scalar_dense_106, _local_scalar_dense_107, _local_scalar_dense_108, _local_scalar_dense_109, _local_scalar_dense_110, _local_scalar_dense_111, _local_scalar_dense_112, _local_scalar_dense_113, _local_scalar_dense_114, _local_scalar_dense_115, _local_scalar_dense_116, _local_scalar_dense_117, _local_scalar_dense_118, _local_scalar_dense_119, _local_scalar_dense_120, _local_scalar_dense_121, _local_scalar_dense_122, _local_scalar_dense_123, _local_scalar_dense_124, _local_scalar_dense_125, _local_scalar_dense_126, _local_scalar_dense_127, _local_scalar_dense_128, _local_scalar_dense_129, _local_scalar_dense_130, _local_scalar_dense_131, _local_scalar_dense_132, _local_scalar_dense_133, _local_scalar_dense_134, _local_scalar_dense_135, _local_scalar_dense_136, _local_scalar_dense_137, _local_scalar_dense_138, _local_scalar_dense_139, _local_scalar_dense_140, _local_scalar_dense_141, _local_scalar_dense_142, _local_scalar_dense_143, _local_scalar_dense_144, _local_scalar_dense_145, _local_scalar_dense_146, _local_scalar_dense_147, _local_scalar_dense_148, _local_scalar_dense_149, _local_scalar_dense_150, _local_scalar_dense_151, _local_scalar_dense_152, _local_scalar_dense_153, _local_scalar_dense_154, _local_scalar_dense_155, _local_scalar_dense_156, _local_scalar_dense_157, _local_scalar_dense_158, _local_scalar_dense_159, _local_scalar_dense_160, _local_scalar_dense_161, _local_scalar_dense_162, _local_scalar_dense_163, _local_scalar_dense_164, _local_scalar_dense_165, _local_scalar_dense_166, _local_scalar_dense_167, _local_scalar_dense_168, _local_scalar_dense_169, _local_scalar_dense_170, _local_scalar_dense_171, _local_scalar_dense_172, _local_scalar_dense_173, _local_scalar_dense_174, _local_scalar_dense_175, _local_scalar_dense_176, _local_scalar_dense_177, _local_scalar_dense_178, _local_scalar_dense_179, _local_scalar_dense_180, _local_scalar_dense_181, _local_scalar_dense_182, _local_scalar_dense_183, _local_scalar_dense_184, _local_scalar_dense_185, _local_scalar_dense_186, _local_scalar_dense_187, _local_scalar_dense_188, _local_scalar_dense_189, _local_scalar_dense_190, _local_scalar_dense_191, _local_scalar_dense_192, _local_scalar_dense_193, _local_scalar_dense_194, _local_scalar_dense_195, _local_scalar_dense_196, _local_scalar_dense_197, _local_scalar_dense_198, _local_scalar_dense_199, _local_scalar_dense_200, _local_scalar_dense_201, _local_scalar_dense_202, _local_scalar_dense_203, _local_scalar_dense_204, _local_scalar_dense_205, _local_scalar_dense_206, _local_scalar_dense_207, _local_scalar_dense_208, _local_scalar_dense_209, _local_scalar_dense_210, _local_scalar_dense_211, _local_scalar_dense_212, _local_scalar_dense_213, _local_scalar_dense_214, _local_scalar_dense_215, _local_scalar_dense_216, _local_scalar_dense_217, _local_scalar_dense_218, _local_scalar_dense_219, _local_scalar_dense_220, _local_scalar_dense_221, _local_scalar_dense_222, _local_scalar_dense_223, _local_scalar_dense_224, _local_scalar_dense_225, _local_scalar_dense_226, _local_scalar_dense_227, _local_scalar_dense_228, _local_scalar_dense_229, _local_scalar_dense_230, _local_scalar_dense_231, _local_scalar_dense_232, _local_scalar_dense_233, _local_scalar_dense_234, _local_scalar_dense_235, _local_scalar_dense_236, _local_scalar_dense_237, _local_scalar_dense_238, _local_scalar_dense_239, _local_scalar_dense_240, _local_scalar_dense_241, _local_scalar_dense_242, _local_scalar_dense_243, _local_scalar_dense_244, _local_scalar_dense_245, _local_scalar_dense_246, _local_scalar_dense_247, _local_scalar_dense_248, _local_scalar_dense_249, _local_scalar_dense_250, _local_scalar_dense_251, _local_scalar_dense_252, _local_scalar_dense_253, _local_scalar_dense_254, _local_scalar_dense_255, _local_scalar_dense_256, _local_scalar_dense_257, _local_scalar_dense_258, _local_scalar_dense_259, _local_scalar_dense_260, _local_scalar_dense_261, _local_scalar_dense_262, _local_scalar_dense_263, _local_scalar_dense_264, _local_scalar_dense_265, _local_scalar_dense_266, _local_scalar_dense_267, _local_scalar_dense_268, _local_scalar_dense_269, _local_scalar_dense_270, _local_scalar_dense_271, _local_scalar_dense_272, _local_scalar_dense_273, _local_scalar_dense_274, _local_scalar_dense_275, _local_scalar_dense_276, _local_scalar_dense_277, _local_scalar_dense_278, _local_scalar_dense_279, _local_scalar_dense_280, _local_scalar_dense_281, _local_scalar_dense_282, _local_scalar_dense_283, _local_scalar_dense_284, _local_scalar_dense_285, _local_scalar_dense_286, _local_scalar_dense_287, _local_scalar_dense_288, _local_scalar_dense_289, _local_scalar_dense_290, _local_scalar_dense_291, _local_scalar_dense_292, _local_scalar_dense_293, _local_scalar_dense_294, _local_scalar_dense_295, _local_scalar_dense_296, _local_scalar_dense_297, _local_scalar_dense_298, _local_scalar_dense_299, _local_scalar_dense_300, _local_scalar_dense_301, _local_scalar_dense_302, _local_scalar_dense_303, _local_scalar_dense_304, _local_scalar_dense_305, _local_scalar_dense_306, _local_scalar_dense_307, _local_scalar_dense_308, _local_scalar_dense_309, _local_scalar_dense_310, _local_scalar_dense_311, _local_scalar_dense_312, _local_scalar_dense_313, _local_scalar_dense_314, _local_scalar_dense_315, _local_scalar_dense_316, _local_scalar_dense_317, _local_scalar_dense_318, _local_scalar_dense_319, _local_scalar_dense_320, _local_scalar_dense_321, _local_scalar_dense_322, _local_scalar_dense_323, _local_scalar_dense_324, _local_scalar_dense_325, _local_scalar_dense_326, _local_scalar_dense_327, _local_scalar_dense_328, _local_scalar_dense_329, _local_scalar_dense_330, _local_scalar_dense_331, _local_scalar_dense_332, _local_scalar_dense_333, _local_scalar_dense_334, _local_scalar_dense_335, _local_scalar_dense_336, _local_scalar_dense_337, _local_scalar_dense_338, _local_scalar_dense_339, _local_scalar_dense_340, _local_scalar_dense_341, _local_scalar_dense_342, _local_scalar_dense_343, _local_scalar_dense_344, _local_scalar_dense_345, _local_scalar_dense_346, _local_scalar_dense_347, _local_scalar_dense_348, _local_scalar_dense_349, _local_scalar_dense_350, _local_scalar_dense_351, _local_scalar_dense_352, _local_scalar_dense_353, _local_scalar_dense_354, _local_scalar_dense_355, _local_scalar_dense_356, _local_scalar_dense_357, _local_scalar_dense_358, _local_scalar_dense_359, _local_scalar_dense_360, _local_scalar_dense_361, _local_scalar_dense_362, _local_scalar_dense_363, _local_scalar_dense_364, _local_scalar_dense_365, _local_scalar_dense_366, _local_scalar_dense_367, _local_scalar_dense_368, _local_scalar_dense_369, _local_scalar_dense_370, _local_scalar_dense_371, _local_scalar_dense_372, _local_scalar_dense_373, _local_scalar_dense_374, _local_scalar_dense_375, _local_scalar_dense_376, _local_scalar_dense_377, _local_scalar_dense_378, _local_scalar_dense_379, _local_scalar_dense_380, _local_scalar_dense_381, _local_scalar_dense_382, _local_scalar_dense_383, _local_scalar_dense_384, _local_scalar_dense_385, _local_scalar_dense_386, _local_scalar_dense_387, _local_scalar_dense_388, _local_scalar_dense_389, _local_scalar_dense_390, _local_scalar_dense_391, _local_scalar_dense_392, _local_scalar_dense_393, _local_scalar_dense_394, _local_scalar_dense_395, _local_scalar_dense_396, _local_scalar_dense_397, _local_scalar_dense_398, _local_scalar_dense_399, _local_scalar_dense_400, _local_scalar_dense_401, _local_scalar_dense_402, _local_scalar_dense_403, _local_scalar_dense_404, _local_scalar_dense_405, _local_scalar_dense_406, _local_scalar_dense_407, _local_scalar_dense_408, _local_scalar_dense_409, _local_scalar_dense_410, _local_scalar_dense_411, _local_scalar_dense_412, _local_scalar_dense_413, _local_scalar_dense_414, _local_scalar_dense_415, sym_size_int_1, sym_size_int_5, sym_size_int_9, sym_size_int_13, sym_size_int_17, sym_size_int_21, sym_size_int_25, sym_size_int_29, sym_size_int_33, sym_size_int_37, sym_size_int_41, sym_size_int_45, sym_size_int_49, sym_size_int_53, sym_size_int_57, sym_size_int_61, sym_size_int_65, sym_size_int_69, sym_size_int_73, sym_size_int_77, sym_size_int_81, sym_size_int_85, sym_size_int_89, sym_size_int_93, sym_size_int_97, sym_size_int_101, add_1781, add_1796, add_1811, add_1826, add_1841, add_1856, add_1871, add_1886, add_1901, add_1916, add_1931, add_1946, add_1961, add_1976, add_1991, add_2006, add_2021, add_2036, add_2051, add_2066, add_2081, add_2096, add_2111, add_2126, add_2141, add_2156)

def load_args(reader):
    buf0 = reader.storage(None, 6553600, device=device(type='cuda', index=0))
    reader.tensor(buf0, (800, 2048), is_leaf=True)  # primals_1
    buf1 = reader.storage(None, 65536, device=device(type='cuda', index=0), dtype_hint=torch.int64)
    reader.tensor(buf1, (2, 4096), dtype=torch.int64, is_leaf=True)  # primals_2
    buf2 = reader.storage(None, 1048576, device=device(type='cuda', index=0), dtype_hint=torch.complex64)
    reader.tensor(buf2, (4096, 32), dtype=torch.complex64, is_leaf=True)  # primals_3
    buf3 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf3, (16,), is_leaf=True)  # primals_4
    buf4 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf4, (24, 2048), is_leaf=True)  # primals_5
    buf5 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf5, (5, 2048), is_leaf=True)  # primals_6
    buf6 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf6, (4,), is_leaf=True)  # primals_7
    buf7 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf7, (32, 512), is_leaf=True)  # primals_8
    buf8 = reader.storage(None, 8192, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf8, (2, 1, 32, 32), dtype=torch.int32, is_leaf=True)  # primals_9
    buf9 = reader.storage(None, 256, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf9, (2, 1, 32), dtype=torch.int32, is_leaf=True)  # primals_10
    buf10 = reader.storage(None, 32768, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf10, (2, 4096), dtype=torch.int32, is_leaf=True)  # primals_11
    buf11 = reader.storage(None, 256, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf11, (2, 1, 32), dtype=torch.int32, is_leaf=True)  # primals_12
    buf12 = reader.storage(None, 8192, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf12, (2, 1, 32, 32), dtype=torch.int32, is_leaf=True)  # primals_13
    buf13 = reader.storage(None, 256, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf13, (2, 1, 32), dtype=torch.int32, is_leaf=True)  # primals_14
    buf14 = reader.storage(None, 8192, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf14, (2, 1, 32, 32), dtype=torch.int32, is_leaf=True)  # primals_15
    buf15 = reader.storage(None, 256, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf15, (2, 1, 32), dtype=torch.int32, is_leaf=True)  # primals_16
    buf16 = reader.storage(None, 8192, device=device(type='cuda', index=0), dtype_hint=torch.int32)
    reader.tensor(buf16, (2, 1, 32, 32), dtype=torch.int32, is_leaf=True)  # primals_17
    buf17 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf17, (16, 2048), is_leaf=True)  # primals_18
    buf18 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf18, (16,), is_leaf=True)  # primals_19
    buf19 = reader.storage(None, 704512, device=device(type='cuda', index=0))
    reader.tensor(buf19, (86, 2048), is_leaf=True)  # primals_20
    buf20 = reader.storage(None, 704512, device=device(type='cuda', index=0))
    reader.tensor(buf20, (86, 2048), is_leaf=True)  # primals_21
    buf21 = reader.storage(None, 700416, device=device(type='cuda', index=0))
    reader.tensor(buf21, (16, 10944), is_leaf=True)  # primals_22
    buf22 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf22, (16,), is_leaf=True)  # primals_23
    buf23 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf23, (24, 2048), is_leaf=True)  # primals_24
    buf24 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf24, (5, 2048), is_leaf=True)  # primals_25
    buf25 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf25, (4,), is_leaf=True)  # primals_26
    buf26 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf26, (32, 512), is_leaf=True)  # primals_27
    buf27 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf27, (16, 2048), is_leaf=True)  # primals_28
    buf28 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf28, (16,), is_leaf=True)  # primals_29
    buf29 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf29, (64,), is_leaf=True)  # primals_30
    buf30 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf30, (1, 2048), is_leaf=True)  # primals_31
    buf31 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf31, (64,), is_leaf=True)  # primals_32
    buf32 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf32, (8, 88, 2048), is_leaf=True)  # primals_33
    buf33 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf33, (8, 128, 1408), is_leaf=True)  # primals_34
    buf34 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf34, (8, 88, 2048), is_leaf=True)  # primals_35
    buf35 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf35, (22, 2048), is_leaf=True)  # primals_36
    buf36 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf36, (22, 2048), is_leaf=True)  # primals_37
    buf37 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf37, (16, 2816), is_leaf=True)  # primals_38
    buf38 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf38, (16,), is_leaf=True)  # primals_39
    buf39 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf39, (24, 2048), is_leaf=True)  # primals_40
    buf40 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf40, (5, 2048), is_leaf=True)  # primals_41
    buf41 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf41, (4,), is_leaf=True)  # primals_42
    buf42 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf42, (32, 512), is_leaf=True)  # primals_43
    buf43 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf43, (16, 2048), is_leaf=True)  # primals_44
    buf44 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf44, (16,), is_leaf=True)  # primals_45
    buf45 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf45, (64,), is_leaf=True)  # primals_46
    buf46 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf46, (1, 2048), is_leaf=True)  # primals_47
    buf47 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf47, (64,), is_leaf=True)  # primals_48
    buf48 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf48, (8, 88, 2048), is_leaf=True)  # primals_49
    buf49 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf49, (8, 128, 1408), is_leaf=True)  # primals_50
    buf50 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf50, (8, 88, 2048), is_leaf=True)  # primals_51
    buf51 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf51, (22, 2048), is_leaf=True)  # primals_52
    buf52 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf52, (22, 2048), is_leaf=True)  # primals_53
    buf53 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf53, (16, 2816), is_leaf=True)  # primals_54
    buf54 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf54, (16,), is_leaf=True)  # primals_55
    buf55 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf55, (24, 2048), is_leaf=True)  # primals_56
    buf56 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf56, (5, 2048), is_leaf=True)  # primals_57
    buf57 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf57, (4,), is_leaf=True)  # primals_58
    buf58 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf58, (32, 512), is_leaf=True)  # primals_59
    buf59 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf59, (16, 2048), is_leaf=True)  # primals_60
    buf60 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf60, (16,), is_leaf=True)  # primals_61
    buf61 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf61, (64,), is_leaf=True)  # primals_62
    buf62 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf62, (1, 2048), is_leaf=True)  # primals_63
    buf63 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf63, (64,), is_leaf=True)  # primals_64
    buf64 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf64, (8, 88, 2048), is_leaf=True)  # primals_65
    buf65 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf65, (8, 128, 1408), is_leaf=True)  # primals_66
    buf66 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf66, (8, 88, 2048), is_leaf=True)  # primals_67
    buf67 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf67, (22, 2048), is_leaf=True)  # primals_68
    buf68 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf68, (22, 2048), is_leaf=True)  # primals_69
    buf69 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf69, (16, 2816), is_leaf=True)  # primals_70
    buf70 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf70, (16,), is_leaf=True)  # primals_71
    buf71 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf71, (24, 2048), is_leaf=True)  # primals_72
    buf72 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf72, (5, 2048), is_leaf=True)  # primals_73
    buf73 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf73, (4,), is_leaf=True)  # primals_74
    buf74 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf74, (32, 512), is_leaf=True)  # primals_75
    buf75 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf75, (16, 2048), is_leaf=True)  # primals_76
    buf76 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf76, (16,), is_leaf=True)  # primals_77
    buf77 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf77, (64,), is_leaf=True)  # primals_78
    buf78 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf78, (1, 2048), is_leaf=True)  # primals_79
    buf79 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf79, (64,), is_leaf=True)  # primals_80
    buf80 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf80, (8, 88, 2048), is_leaf=True)  # primals_81
    buf81 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf81, (8, 128, 1408), is_leaf=True)  # primals_82
    buf82 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf82, (8, 88, 2048), is_leaf=True)  # primals_83
    buf83 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf83, (22, 2048), is_leaf=True)  # primals_84
    buf84 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf84, (22, 2048), is_leaf=True)  # primals_85
    buf85 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf85, (16, 2816), is_leaf=True)  # primals_86
    buf86 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf86, (16,), is_leaf=True)  # primals_87
    buf87 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf87, (24, 2048), is_leaf=True)  # primals_88
    buf88 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf88, (5, 2048), is_leaf=True)  # primals_89
    buf89 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf89, (4,), is_leaf=True)  # primals_90
    buf90 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf90, (32, 512), is_leaf=True)  # primals_91
    buf91 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf91, (16, 2048), is_leaf=True)  # primals_92
    buf92 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf92, (16,), is_leaf=True)  # primals_93
    buf93 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf93, (64,), is_leaf=True)  # primals_94
    buf94 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf94, (1, 2048), is_leaf=True)  # primals_95
    buf95 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf95, (64,), is_leaf=True)  # primals_96
    buf96 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf96, (8, 88, 2048), is_leaf=True)  # primals_97
    buf97 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf97, (8, 128, 1408), is_leaf=True)  # primals_98
    buf98 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf98, (8, 88, 2048), is_leaf=True)  # primals_99
    buf99 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf99, (22, 2048), is_leaf=True)  # primals_100
    buf100 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf100, (22, 2048), is_leaf=True)  # primals_101
    buf101 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf101, (16, 2816), is_leaf=True)  # primals_102
    buf102 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf102, (16,), is_leaf=True)  # primals_103
    buf103 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf103, (24, 2048), is_leaf=True)  # primals_104
    buf104 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf104, (5, 2048), is_leaf=True)  # primals_105
    buf105 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf105, (4,), is_leaf=True)  # primals_106
    buf106 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf106, (32, 512), is_leaf=True)  # primals_107
    buf107 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf107, (16, 2048), is_leaf=True)  # primals_108
    buf108 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf108, (16,), is_leaf=True)  # primals_109
    buf109 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf109, (64,), is_leaf=True)  # primals_110
    buf110 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf110, (1, 2048), is_leaf=True)  # primals_111
    buf111 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf111, (64,), is_leaf=True)  # primals_112
    buf112 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf112, (8, 88, 2048), is_leaf=True)  # primals_113
    buf113 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf113, (8, 128, 1408), is_leaf=True)  # primals_114
    buf114 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf114, (8, 88, 2048), is_leaf=True)  # primals_115
    buf115 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf115, (22, 2048), is_leaf=True)  # primals_116
    buf116 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf116, (22, 2048), is_leaf=True)  # primals_117
    buf117 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf117, (16, 2816), is_leaf=True)  # primals_118
    buf118 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf118, (16,), is_leaf=True)  # primals_119
    buf119 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf119, (24, 2048), is_leaf=True)  # primals_120
    buf120 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf120, (5, 2048), is_leaf=True)  # primals_121
    buf121 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf121, (4,), is_leaf=True)  # primals_122
    buf122 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf122, (32, 512), is_leaf=True)  # primals_123
    buf123 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf123, (16, 2048), is_leaf=True)  # primals_124
    buf124 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf124, (16,), is_leaf=True)  # primals_125
    buf125 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf125, (64,), is_leaf=True)  # primals_126
    buf126 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf126, (1, 2048), is_leaf=True)  # primals_127
    buf127 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf127, (64,), is_leaf=True)  # primals_128
    buf128 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf128, (8, 88, 2048), is_leaf=True)  # primals_129
    buf129 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf129, (8, 128, 1408), is_leaf=True)  # primals_130
    buf130 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf130, (8, 88, 2048), is_leaf=True)  # primals_131
    buf131 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf131, (22, 2048), is_leaf=True)  # primals_132
    buf132 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf132, (22, 2048), is_leaf=True)  # primals_133
    buf133 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf133, (16, 2816), is_leaf=True)  # primals_134
    buf134 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf134, (16,), is_leaf=True)  # primals_135
    buf135 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf135, (24, 2048), is_leaf=True)  # primals_136
    buf136 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf136, (5, 2048), is_leaf=True)  # primals_137
    buf137 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf137, (4,), is_leaf=True)  # primals_138
    buf138 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf138, (32, 512), is_leaf=True)  # primals_139
    buf139 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf139, (16, 2048), is_leaf=True)  # primals_140
    buf140 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf140, (16,), is_leaf=True)  # primals_141
    buf141 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf141, (64,), is_leaf=True)  # primals_142
    buf142 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf142, (1, 2048), is_leaf=True)  # primals_143
    buf143 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf143, (64,), is_leaf=True)  # primals_144
    buf144 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf144, (8, 88, 2048), is_leaf=True)  # primals_145
    buf145 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf145, (8, 128, 1408), is_leaf=True)  # primals_146
    buf146 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf146, (8, 88, 2048), is_leaf=True)  # primals_147
    buf147 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf147, (22, 2048), is_leaf=True)  # primals_148
    buf148 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf148, (22, 2048), is_leaf=True)  # primals_149
    buf149 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf149, (16, 2816), is_leaf=True)  # primals_150
    buf150 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf150, (16,), is_leaf=True)  # primals_151
    buf151 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf151, (24, 2048), is_leaf=True)  # primals_152
    buf152 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf152, (5, 2048), is_leaf=True)  # primals_153
    buf153 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf153, (4,), is_leaf=True)  # primals_154
    buf154 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf154, (32, 512), is_leaf=True)  # primals_155
    buf155 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf155, (16, 2048), is_leaf=True)  # primals_156
    buf156 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf156, (16,), is_leaf=True)  # primals_157
    buf157 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf157, (64,), is_leaf=True)  # primals_158
    buf158 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf158, (1, 2048), is_leaf=True)  # primals_159
    buf159 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf159, (64,), is_leaf=True)  # primals_160
    buf160 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf160, (8, 88, 2048), is_leaf=True)  # primals_161
    buf161 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf161, (8, 128, 1408), is_leaf=True)  # primals_162
    buf162 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf162, (8, 88, 2048), is_leaf=True)  # primals_163
    buf163 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf163, (22, 2048), is_leaf=True)  # primals_164
    buf164 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf164, (22, 2048), is_leaf=True)  # primals_165
    buf165 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf165, (16, 2816), is_leaf=True)  # primals_166
    buf166 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf166, (16,), is_leaf=True)  # primals_167
    buf167 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf167, (24, 2048), is_leaf=True)  # primals_168
    buf168 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf168, (5, 2048), is_leaf=True)  # primals_169
    buf169 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf169, (4,), is_leaf=True)  # primals_170
    buf170 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf170, (32, 512), is_leaf=True)  # primals_171
    buf171 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf171, (16, 2048), is_leaf=True)  # primals_172
    buf172 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf172, (16,), is_leaf=True)  # primals_173
    buf173 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf173, (64,), is_leaf=True)  # primals_174
    buf174 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf174, (1, 2048), is_leaf=True)  # primals_175
    buf175 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf175, (64,), is_leaf=True)  # primals_176
    buf176 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf176, (8, 88, 2048), is_leaf=True)  # primals_177
    buf177 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf177, (8, 128, 1408), is_leaf=True)  # primals_178
    buf178 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf178, (8, 88, 2048), is_leaf=True)  # primals_179
    buf179 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf179, (22, 2048), is_leaf=True)  # primals_180
    buf180 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf180, (22, 2048), is_leaf=True)  # primals_181
    buf181 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf181, (16, 2816), is_leaf=True)  # primals_182
    buf182 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf182, (16,), is_leaf=True)  # primals_183
    buf183 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf183, (24, 2048), is_leaf=True)  # primals_184
    buf184 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf184, (5, 2048), is_leaf=True)  # primals_185
    buf185 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf185, (4,), is_leaf=True)  # primals_186
    buf186 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf186, (32, 512), is_leaf=True)  # primals_187
    buf187 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf187, (16, 2048), is_leaf=True)  # primals_188
    buf188 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf188, (16,), is_leaf=True)  # primals_189
    buf189 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf189, (64,), is_leaf=True)  # primals_190
    buf190 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf190, (1, 2048), is_leaf=True)  # primals_191
    buf191 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf191, (64,), is_leaf=True)  # primals_192
    buf192 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf192, (8, 88, 2048), is_leaf=True)  # primals_193
    buf193 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf193, (8, 128, 1408), is_leaf=True)  # primals_194
    buf194 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf194, (8, 88, 2048), is_leaf=True)  # primals_195
    buf195 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf195, (22, 2048), is_leaf=True)  # primals_196
    buf196 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf196, (22, 2048), is_leaf=True)  # primals_197
    buf197 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf197, (16, 2816), is_leaf=True)  # primals_198
    buf198 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf198, (16,), is_leaf=True)  # primals_199
    buf199 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf199, (24, 2048), is_leaf=True)  # primals_200
    buf200 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf200, (5, 2048), is_leaf=True)  # primals_201
    buf201 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf201, (4,), is_leaf=True)  # primals_202
    buf202 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf202, (32, 512), is_leaf=True)  # primals_203
    buf203 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf203, (16, 2048), is_leaf=True)  # primals_204
    buf204 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf204, (16,), is_leaf=True)  # primals_205
    buf205 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf205, (64,), is_leaf=True)  # primals_206
    buf206 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf206, (1, 2048), is_leaf=True)  # primals_207
    buf207 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf207, (64,), is_leaf=True)  # primals_208
    buf208 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf208, (8, 88, 2048), is_leaf=True)  # primals_209
    buf209 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf209, (8, 128, 1408), is_leaf=True)  # primals_210
    buf210 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf210, (8, 88, 2048), is_leaf=True)  # primals_211
    buf211 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf211, (22, 2048), is_leaf=True)  # primals_212
    buf212 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf212, (22, 2048), is_leaf=True)  # primals_213
    buf213 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf213, (16, 2816), is_leaf=True)  # primals_214
    buf214 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf214, (16,), is_leaf=True)  # primals_215
    buf215 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf215, (24, 2048), is_leaf=True)  # primals_216
    buf216 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf216, (5, 2048), is_leaf=True)  # primals_217
    buf217 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf217, (4,), is_leaf=True)  # primals_218
    buf218 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf218, (32, 512), is_leaf=True)  # primals_219
    buf219 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf219, (16, 2048), is_leaf=True)  # primals_220
    buf220 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf220, (16,), is_leaf=True)  # primals_221
    buf221 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf221, (64,), is_leaf=True)  # primals_222
    buf222 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf222, (1, 2048), is_leaf=True)  # primals_223
    buf223 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf223, (64,), is_leaf=True)  # primals_224
    buf224 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf224, (8, 88, 2048), is_leaf=True)  # primals_225
    buf225 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf225, (8, 128, 1408), is_leaf=True)  # primals_226
    buf226 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf226, (8, 88, 2048), is_leaf=True)  # primals_227
    buf227 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf227, (22, 2048), is_leaf=True)  # primals_228
    buf228 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf228, (22, 2048), is_leaf=True)  # primals_229
    buf229 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf229, (16, 2816), is_leaf=True)  # primals_230
    buf230 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf230, (16,), is_leaf=True)  # primals_231
    buf231 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf231, (24, 2048), is_leaf=True)  # primals_232
    buf232 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf232, (5, 2048), is_leaf=True)  # primals_233
    buf233 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf233, (4,), is_leaf=True)  # primals_234
    buf234 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf234, (32, 512), is_leaf=True)  # primals_235
    buf235 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf235, (16, 2048), is_leaf=True)  # primals_236
    buf236 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf236, (16,), is_leaf=True)  # primals_237
    buf237 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf237, (64,), is_leaf=True)  # primals_238
    buf238 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf238, (1, 2048), is_leaf=True)  # primals_239
    buf239 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf239, (64,), is_leaf=True)  # primals_240
    buf240 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf240, (8, 88, 2048), is_leaf=True)  # primals_241
    buf241 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf241, (8, 128, 1408), is_leaf=True)  # primals_242
    buf242 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf242, (8, 88, 2048), is_leaf=True)  # primals_243
    buf243 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf243, (22, 2048), is_leaf=True)  # primals_244
    buf244 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf244, (22, 2048), is_leaf=True)  # primals_245
    buf245 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf245, (16, 2816), is_leaf=True)  # primals_246
    buf246 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf246, (16,), is_leaf=True)  # primals_247
    buf247 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf247, (24, 2048), is_leaf=True)  # primals_248
    buf248 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf248, (5, 2048), is_leaf=True)  # primals_249
    buf249 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf249, (4,), is_leaf=True)  # primals_250
    buf250 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf250, (32, 512), is_leaf=True)  # primals_251
    buf251 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf251, (16, 2048), is_leaf=True)  # primals_252
    buf252 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf252, (16,), is_leaf=True)  # primals_253
    buf253 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf253, (64,), is_leaf=True)  # primals_254
    buf254 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf254, (1, 2048), is_leaf=True)  # primals_255
    buf255 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf255, (64,), is_leaf=True)  # primals_256
    buf256 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf256, (8, 88, 2048), is_leaf=True)  # primals_257
    buf257 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf257, (8, 128, 1408), is_leaf=True)  # primals_258
    buf258 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf258, (8, 88, 2048), is_leaf=True)  # primals_259
    buf259 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf259, (22, 2048), is_leaf=True)  # primals_260
    buf260 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf260, (22, 2048), is_leaf=True)  # primals_261
    buf261 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf261, (16, 2816), is_leaf=True)  # primals_262
    buf262 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf262, (16,), is_leaf=True)  # primals_263
    buf263 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf263, (24, 2048), is_leaf=True)  # primals_264
    buf264 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf264, (5, 2048), is_leaf=True)  # primals_265
    buf265 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf265, (4,), is_leaf=True)  # primals_266
    buf266 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf266, (32, 512), is_leaf=True)  # primals_267
    buf267 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf267, (16, 2048), is_leaf=True)  # primals_268
    buf268 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf268, (16,), is_leaf=True)  # primals_269
    buf269 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf269, (64,), is_leaf=True)  # primals_270
    buf270 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf270, (1, 2048), is_leaf=True)  # primals_271
    buf271 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf271, (64,), is_leaf=True)  # primals_272
    buf272 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf272, (8, 88, 2048), is_leaf=True)  # primals_273
    buf273 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf273, (8, 128, 1408), is_leaf=True)  # primals_274
    buf274 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf274, (8, 88, 2048), is_leaf=True)  # primals_275
    buf275 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf275, (22, 2048), is_leaf=True)  # primals_276
    buf276 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf276, (22, 2048), is_leaf=True)  # primals_277
    buf277 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf277, (16, 2816), is_leaf=True)  # primals_278
    buf278 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf278, (16,), is_leaf=True)  # primals_279
    buf279 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf279, (24, 2048), is_leaf=True)  # primals_280
    buf280 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf280, (5, 2048), is_leaf=True)  # primals_281
    buf281 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf281, (4,), is_leaf=True)  # primals_282
    buf282 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf282, (32, 512), is_leaf=True)  # primals_283
    buf283 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf283, (16, 2048), is_leaf=True)  # primals_284
    buf284 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf284, (16,), is_leaf=True)  # primals_285
    buf285 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf285, (64,), is_leaf=True)  # primals_286
    buf286 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf286, (1, 2048), is_leaf=True)  # primals_287
    buf287 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf287, (64,), is_leaf=True)  # primals_288
    buf288 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf288, (8, 88, 2048), is_leaf=True)  # primals_289
    buf289 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf289, (8, 128, 1408), is_leaf=True)  # primals_290
    buf290 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf290, (8, 88, 2048), is_leaf=True)  # primals_291
    buf291 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf291, (22, 2048), is_leaf=True)  # primals_292
    buf292 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf292, (22, 2048), is_leaf=True)  # primals_293
    buf293 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf293, (16, 2816), is_leaf=True)  # primals_294
    buf294 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf294, (16,), is_leaf=True)  # primals_295
    buf295 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf295, (24, 2048), is_leaf=True)  # primals_296
    buf296 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf296, (5, 2048), is_leaf=True)  # primals_297
    buf297 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf297, (4,), is_leaf=True)  # primals_298
    buf298 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf298, (32, 512), is_leaf=True)  # primals_299
    buf299 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf299, (16, 2048), is_leaf=True)  # primals_300
    buf300 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf300, (16,), is_leaf=True)  # primals_301
    buf301 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf301, (64,), is_leaf=True)  # primals_302
    buf302 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf302, (1, 2048), is_leaf=True)  # primals_303
    buf303 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf303, (64,), is_leaf=True)  # primals_304
    buf304 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf304, (8, 88, 2048), is_leaf=True)  # primals_305
    buf305 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf305, (8, 128, 1408), is_leaf=True)  # primals_306
    buf306 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf306, (8, 88, 2048), is_leaf=True)  # primals_307
    buf307 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf307, (22, 2048), is_leaf=True)  # primals_308
    buf308 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf308, (22, 2048), is_leaf=True)  # primals_309
    buf309 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf309, (16, 2816), is_leaf=True)  # primals_310
    buf310 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf310, (16,), is_leaf=True)  # primals_311
    buf311 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf311, (24, 2048), is_leaf=True)  # primals_312
    buf312 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf312, (5, 2048), is_leaf=True)  # primals_313
    buf313 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf313, (4,), is_leaf=True)  # primals_314
    buf314 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf314, (32, 512), is_leaf=True)  # primals_315
    buf315 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf315, (16, 2048), is_leaf=True)  # primals_316
    buf316 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf316, (16,), is_leaf=True)  # primals_317
    buf317 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf317, (64,), is_leaf=True)  # primals_318
    buf318 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf318, (1, 2048), is_leaf=True)  # primals_319
    buf319 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf319, (64,), is_leaf=True)  # primals_320
    buf320 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf320, (8, 88, 2048), is_leaf=True)  # primals_321
    buf321 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf321, (8, 128, 1408), is_leaf=True)  # primals_322
    buf322 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf322, (8, 88, 2048), is_leaf=True)  # primals_323
    buf323 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf323, (22, 2048), is_leaf=True)  # primals_324
    buf324 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf324, (22, 2048), is_leaf=True)  # primals_325
    buf325 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf325, (16, 2816), is_leaf=True)  # primals_326
    buf326 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf326, (16,), is_leaf=True)  # primals_327
    buf327 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf327, (24, 2048), is_leaf=True)  # primals_328
    buf328 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf328, (5, 2048), is_leaf=True)  # primals_329
    buf329 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf329, (4,), is_leaf=True)  # primals_330
    buf330 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf330, (32, 512), is_leaf=True)  # primals_331
    buf331 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf331, (16, 2048), is_leaf=True)  # primals_332
    buf332 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf332, (16,), is_leaf=True)  # primals_333
    buf333 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf333, (64,), is_leaf=True)  # primals_334
    buf334 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf334, (1, 2048), is_leaf=True)  # primals_335
    buf335 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf335, (64,), is_leaf=True)  # primals_336
    buf336 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf336, (8, 88, 2048), is_leaf=True)  # primals_337
    buf337 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf337, (8, 128, 1408), is_leaf=True)  # primals_338
    buf338 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf338, (8, 88, 2048), is_leaf=True)  # primals_339
    buf339 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf339, (22, 2048), is_leaf=True)  # primals_340
    buf340 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf340, (22, 2048), is_leaf=True)  # primals_341
    buf341 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf341, (16, 2816), is_leaf=True)  # primals_342
    buf342 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf342, (16,), is_leaf=True)  # primals_343
    buf343 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf343, (24, 2048), is_leaf=True)  # primals_344
    buf344 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf344, (5, 2048), is_leaf=True)  # primals_345
    buf345 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf345, (4,), is_leaf=True)  # primals_346
    buf346 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf346, (32, 512), is_leaf=True)  # primals_347
    buf347 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf347, (16, 2048), is_leaf=True)  # primals_348
    buf348 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf348, (16,), is_leaf=True)  # primals_349
    buf349 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf349, (64,), is_leaf=True)  # primals_350
    buf350 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf350, (1, 2048), is_leaf=True)  # primals_351
    buf351 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf351, (64,), is_leaf=True)  # primals_352
    buf352 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf352, (8, 88, 2048), is_leaf=True)  # primals_353
    buf353 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf353, (8, 128, 1408), is_leaf=True)  # primals_354
    buf354 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf354, (8, 88, 2048), is_leaf=True)  # primals_355
    buf355 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf355, (22, 2048), is_leaf=True)  # primals_356
    buf356 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf356, (22, 2048), is_leaf=True)  # primals_357
    buf357 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf357, (16, 2816), is_leaf=True)  # primals_358
    buf358 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf358, (16,), is_leaf=True)  # primals_359
    buf359 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf359, (24, 2048), is_leaf=True)  # primals_360
    buf360 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf360, (5, 2048), is_leaf=True)  # primals_361
    buf361 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf361, (4,), is_leaf=True)  # primals_362
    buf362 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf362, (32, 512), is_leaf=True)  # primals_363
    buf363 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf363, (16, 2048), is_leaf=True)  # primals_364
    buf364 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf364, (16,), is_leaf=True)  # primals_365
    buf365 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf365, (64,), is_leaf=True)  # primals_366
    buf366 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf366, (1, 2048), is_leaf=True)  # primals_367
    buf367 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf367, (64,), is_leaf=True)  # primals_368
    buf368 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf368, (8, 88, 2048), is_leaf=True)  # primals_369
    buf369 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf369, (8, 128, 1408), is_leaf=True)  # primals_370
    buf370 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf370, (8, 88, 2048), is_leaf=True)  # primals_371
    buf371 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf371, (22, 2048), is_leaf=True)  # primals_372
    buf372 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf372, (22, 2048), is_leaf=True)  # primals_373
    buf373 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf373, (16, 2816), is_leaf=True)  # primals_374
    buf374 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf374, (16,), is_leaf=True)  # primals_375
    buf375 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf375, (24, 2048), is_leaf=True)  # primals_376
    buf376 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf376, (5, 2048), is_leaf=True)  # primals_377
    buf377 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf377, (4,), is_leaf=True)  # primals_378
    buf378 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf378, (32, 512), is_leaf=True)  # primals_379
    buf379 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf379, (16, 2048), is_leaf=True)  # primals_380
    buf380 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf380, (16,), is_leaf=True)  # primals_381
    buf381 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf381, (64,), is_leaf=True)  # primals_382
    buf382 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf382, (1, 2048), is_leaf=True)  # primals_383
    buf383 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf383, (64,), is_leaf=True)  # primals_384
    buf384 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf384, (8, 88, 2048), is_leaf=True)  # primals_385
    buf385 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf385, (8, 128, 1408), is_leaf=True)  # primals_386
    buf386 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf386, (8, 88, 2048), is_leaf=True)  # primals_387
    buf387 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf387, (22, 2048), is_leaf=True)  # primals_388
    buf388 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf388, (22, 2048), is_leaf=True)  # primals_389
    buf389 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf389, (16, 2816), is_leaf=True)  # primals_390
    buf390 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf390, (16,), is_leaf=True)  # primals_391
    buf391 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf391, (24, 2048), is_leaf=True)  # primals_392
    buf392 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf392, (5, 2048), is_leaf=True)  # primals_393
    buf393 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf393, (4,), is_leaf=True)  # primals_394
    buf394 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf394, (32, 512), is_leaf=True)  # primals_395
    buf395 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf395, (16, 2048), is_leaf=True)  # primals_396
    buf396 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf396, (16,), is_leaf=True)  # primals_397
    buf397 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf397, (64,), is_leaf=True)  # primals_398
    buf398 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf398, (1, 2048), is_leaf=True)  # primals_399
    buf399 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf399, (64,), is_leaf=True)  # primals_400
    buf400 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf400, (8, 88, 2048), is_leaf=True)  # primals_401
    buf401 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf401, (8, 128, 1408), is_leaf=True)  # primals_402
    buf402 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf402, (8, 88, 2048), is_leaf=True)  # primals_403
    buf403 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf403, (22, 2048), is_leaf=True)  # primals_404
    buf404 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf404, (22, 2048), is_leaf=True)  # primals_405
    buf405 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf405, (16, 2816), is_leaf=True)  # primals_406
    buf406 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf406, (16,), is_leaf=True)  # primals_407
    buf407 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf407, (24, 2048), is_leaf=True)  # primals_408
    buf408 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf408, (5, 2048), is_leaf=True)  # primals_409
    buf409 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf409, (4,), is_leaf=True)  # primals_410
    buf410 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf410, (32, 512), is_leaf=True)  # primals_411
    buf411 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf411, (16, 2048), is_leaf=True)  # primals_412
    buf412 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf412, (16,), is_leaf=True)  # primals_413
    buf413 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf413, (64,), is_leaf=True)  # primals_414
    buf414 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf414, (1, 2048), is_leaf=True)  # primals_415
    buf415 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf415, (64,), is_leaf=True)  # primals_416
    buf416 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf416, (8, 88, 2048), is_leaf=True)  # primals_417
    buf417 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf417, (8, 128, 1408), is_leaf=True)  # primals_418
    buf418 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf418, (8, 88, 2048), is_leaf=True)  # primals_419
    buf419 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf419, (22, 2048), is_leaf=True)  # primals_420
    buf420 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf420, (22, 2048), is_leaf=True)  # primals_421
    buf421 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf421, (16, 2816), is_leaf=True)  # primals_422
    buf422 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf422, (16,), is_leaf=True)  # primals_423
    buf423 = reader.storage(None, 196608, device=device(type='cuda', index=0))
    reader.tensor(buf423, (24, 2048), is_leaf=True)  # primals_424
    buf424 = reader.storage(None, 40960, device=device(type='cuda', index=0))
    reader.tensor(buf424, (5, 2048), is_leaf=True)  # primals_425
    buf425 = reader.storage(None, 16, device=device(type='cuda', index=0))
    reader.tensor(buf425, (4,), is_leaf=True)  # primals_426
    buf426 = reader.storage(None, 65536, device=device(type='cuda', index=0))
    reader.tensor(buf426, (32, 512), is_leaf=True)  # primals_427
    buf427 = reader.storage(None, 131072, device=device(type='cuda', index=0))
    reader.tensor(buf427, (16, 2048), is_leaf=True)  # primals_428
    buf428 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf428, (16,), is_leaf=True)  # primals_429
    buf429 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf429, (64,), is_leaf=True)  # primals_430
    buf430 = reader.storage(None, 8192, device=device(type='cuda', index=0))
    reader.tensor(buf430, (1, 2048), is_leaf=True)  # primals_431
    buf431 = reader.storage(None, 256, device=device(type='cuda', index=0))
    reader.tensor(buf431, (64,), is_leaf=True)  # primals_432
    buf432 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf432, (8, 88, 2048), is_leaf=True)  # primals_433
    buf433 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf433, (8, 128, 1408), is_leaf=True)  # primals_434
    buf434 = reader.storage(None, 5767168, device=device(type='cuda', index=0))
    reader.tensor(buf434, (8, 88, 2048), is_leaf=True)  # primals_435
    buf435 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf435, (22, 2048), is_leaf=True)  # primals_436
    buf436 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf436, (22, 2048), is_leaf=True)  # primals_437
    buf437 = reader.storage(None, 180224, device=device(type='cuda', index=0))
    reader.tensor(buf437, (16, 2816), is_leaf=True)  # primals_438
    buf438 = reader.storage(None, 64, device=device(type='cuda', index=0))
    reader.tensor(buf438, (16,), is_leaf=True)  # primals_439
    buf439 = reader.storage(None, 6553600, device=device(type='cuda', index=0))
    reader.tensor(buf439, (800, 2048), is_leaf=True)  # primals_440
load_args._version = 0
mod = Repro()
if __name__ == '__main__':
    from torch._dynamo.repro.after_aot import run_repro
    from torch._dynamo.repro.after_aot import setup_fake_process_groups
    setup_fake_process_groups({'0': {'size': 128, 'rank': 0}, '1033': {'size': 8, 'rank': 0}, '1025': {'size': 16, 'rank': 0}})
    with torch.no_grad():
        run_repro(mod, load_args, accuracy=False, command='run', save_dir=None, tracing_mode='real', check_str=None)
        # To run it separately, do 
        # mod, args = run_repro(mod, load_args, accuracy=False, command='get_args', save_dir=None, tracing_mode='real', check_str=None)
        # mod(*args)
    dist.destroy_process_group()

# Helper functions for overlap simulator
def get_pg_config():
    """DSv3 128 GPUs: FSDP=128, TP=1, EP=8."""
    return {'0': {'size': 128, 'rank': 0}, '1025': {'size': 16, 'rank': 0}, '1033': {'size': 8, 'rank': 0}}

def get_colls_estimations_file():
    return "colls16_8.table"

def get_colls_group_mapping():
    # FSDP "0"  internode (table group "0"), all other groups  intranode (table group "1")
    return {'0': '0', '1025': '1', '1033': '1'}
